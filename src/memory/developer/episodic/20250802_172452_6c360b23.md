### Development Step 8: Determine unknown weight and adjacent transposition in modified ISBN-13 validation

**Description**: Analyze the given ISBN-13-like numbers to determine the unknown weight and identify which two adjacent columns have been transposed. Implement the modified ISBN-13 validation algorithm that uses alternating weights of 1 and an unknown positive integer (less than 10) instead of the standard 1 and 3. Test all possible weight values (2, 4, 5, 6, 7, 8, 9) and all possible adjacent column transposition positions (excluding the final column and first three columns as specified). For each combination of weight and transposition position, check if all 10 given numbers would be valid after correcting the transposition error. Return all valid solutions in the format 'x, y' where x is the weight and y is the smaller index of the two transposed columns.

**Use Cases**:
- Library digitization and OCR error correction: automatically detect and correct digit transpositions and non-standard check‚Äêdigit weight errors in scanned ISBN records from historical card catalogs
- Corporate publishing metadata integration: validate and reconcile incoming ISBN batches from international partners by testing alternate weight factors and adjacent digit swaps to ensure clean import into the enterprise catalog
- E-commerce platform bulk product onboarding: streamline supplier-provided ISBN lists by auto-identifying swapped digits and unconventional check patterns before listing new titles online
- Academic bibliographic research: analyze large datasets of historical and modern ISBNs to uncover entries with non-standard validation weights or transposed columns for accurate citation and analysis
- Warehouse inventory audits for book distributors: detect mislabeled or mis-scanned ISBN codes in physical shipments by applying modified ISBN-13 checks and correcting adjacent digit reversals
- Digital library archive enhancement: sanitize vast legacy metadata pools of ISBN-like identifiers through systematic testing of unknown multiplier weights and adjacent column transpositions
- Metadata quality control in publishing pipelines: integrate into CI/CD workflows to flag ISBN records that fail standard checks but pass modified validations, revealing partner-system anomalies

```
# ISBN-13 Modified Validation Analysis - Direct Data Discovery Approach
# Let's find the actual data instead of searching through metadata

import json
import os

print("=== DIRECT DATA DISCOVERY FOR ISBN-13 ANALYSIS ===")
print("Instead of searching metadata, let's examine what files are actually available")
print()

# First, let's see what files exist in the data directory
data_dir = 'data/gaia/2023/validation/'
if os.path.exists(data_dir):
    print(f"Examining directory: {data_dir}")
    all_files = os.listdir(data_dir)
    print(f"Total files found: {len(all_files)}")
    
    # Categorize files by extension
    file_types = {}
    for filename in all_files:
        ext = os.path.splitext(filename)[1].lower()
        if ext not in file_types:
            file_types[ext] = []
        file_types[ext].append(filename)
    
    print("\nFile types found:")
    for ext, files in file_types.items():
        print(f"  {ext}: {len(files)} files")
        if len(files) <= 5:
            for f in files:
                print(f"    - {f}")
        else:
            for f in files[:3]:
                print(f"    - {f}")
            print(f"    ... and {len(files)-3} more")
    
    # Look for files that might contain ISBN data
    potential_isbn_files = []
    
    # Check for files with 'isbn' in the name
    for filename in all_files:
        if 'isbn' in filename.lower():
            potential_isbn_files.append(filename)
            print(f"\nFound ISBN-related file: {filename}")
    
    # If no direct ISBN files, look for text files that might contain the data
    if not potential_isbn_files:
        print("\nNo files with 'isbn' in name. Checking text-based files...")
        
        text_extensions = ['.txt', '.csv', '.json', '.py']
        text_files = []
        for filename in all_files:
            ext = os.path.splitext(filename)[1].lower()
            if ext in text_extensions:
                text_files.append(filename)
        
        print(f"Found {len(text_files)} text-based files")
        
        # Check a few text files for digit patterns
        print("\nSampling text files for digit content...")
        for filename in text_files[:10]:  # Check first 10
            filepath = os.path.join(data_dir, filename)
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read(1000)  # Read first 1000 chars
                
                # Count digits
                digit_count = sum(1 for c in content if c.isdigit())
                
                if digit_count > 50:  # Files with many digits
                    print(f"\n*** High digit content file: {filename} ***")
                    print(f"Digit count in first 1000 chars: {digit_count}")
                    print(f"Content preview:")
                    print(content[:300] + "...")
                    potential_isbn_files.append(filename)
                    
                    # Look for 13-digit sequences
                    digits_only = ''.join(c for c in content if c.isdigit())
                    if len(digits_only) >= 130:  # Enough for 10 ISBN numbers
                        print(f"\nPotential ISBN sequences found in {filename}")
                        print(f"Total digits: {len(digits_only)}")
                        print(f"First 100 digits: {digits_only[:100]}")
                        
            except Exception as e:
                print(f"Could not read {filename}: {e}")
    
    # If we found potential files, analyze them
    if potential_isbn_files:
        print(f"\n=== ANALYZING POTENTIAL ISBN FILES ===")
        print(f"Found {len(potential_isbn_files)} potential files")
        
        # Take the most promising file
        target_file = potential_isbn_files[0]
        target_path = os.path.join(data_dir, target_file)
        
        print(f"\nAnalyzing: {target_file}")
        
        with open(target_path, 'r', encoding='utf-8') as f:
            full_content = f.read()
        
        print(f"File size: {len(full_content)} characters")
        
        # Extract all digits
        all_digits = ''.join(c for c in full_content if c.isdigit())
        print(f"Total digits in file: {len(all_digits)}")
        
        if len(all_digits) >= 130:  # At least 10 ISBN numbers worth
            print(f"\nExtracting 13-digit ISBN sequences...")
            
            # Extract 13-digit sequences
            isbn_candidates = []
            for i in range(0, len(all_digits) - 12, 13):  # Step by 13 to get non-overlapping sequences
                if i + 13 <= len(all_digits):
                    candidate = all_digits[i:i+13]
                    if len(candidate) == 13:
                        isbn_list = [int(d) for d in candidate]
                        isbn_candidates.append(isbn_list)
                        print(f"ISBN {len(isbn_candidates)}: {candidate}")
                        
                        # Stop after finding 10-15 candidates (reasonable number for analysis)
                        if len(isbn_candidates) >= 15:
                            break
            
            if isbn_candidates:
                print(f"\nExtracted {len(isbn_candidates)} ISBN-13 candidates")
                
                # Save the candidates
                with open('workspace/extracted_isbn_numbers.json', 'w') as f:
                    json.dump(isbn_candidates, f, indent=2)
                
                print("ISBN candidates saved to workspace/extracted_isbn_numbers.json")
                
                # Now perform the systematic analysis
                print("\n=== PERFORMING SYSTEMATIC WEIGHT AND TRANSPOSITION ANALYSIS ===")
                print(f"Analyzing {len(isbn_candidates)} ISBN-13 numbers")
                print("Testing combinations of:")
                print("- Weight values: [2, 4, 5, 6, 7, 8, 9]")
                print("- Transpose positions: [3, 4, 5, 6, 7, 8, 9, 10]")
                
                # Analysis parameters
                possible_weights = [2, 4, 5, 6, 7, 8, 9]
                valid_positions = [3, 4, 5, 6, 7, 8, 9, 10]
                
                solutions = []
                
                for weight in possible_weights:
                    print(f"\nTesting weight: {weight}")
                    
                    for pos in valid_positions:
                        print(f"  Testing transpose position {pos} (swap columns {pos} and {pos+1})")
                        
                        # Check if ALL ISBN numbers are valid with this weight and transposition
                        all_valid = True
                        valid_count = 0
                        
                        for isbn_idx, isbn_digits in enumerate(isbn_candidates):
                            # Apply transposition: swap positions pos and pos+1
                            transposed = isbn_digits.copy()
                            transposed[pos], transposed[pos + 1] = transposed[pos + 1], transposed[pos]
                            
                            # Calculate checksum with alternating weights 1, weight, 1, weight, ...
                            total = 0
                            for digit_pos, digit in enumerate(transposed):
                                if digit_pos % 2 == 0:  # Even positions get weight 1
                                    total += digit * 1
                                else:  # Odd positions get the unknown weight
                                    total += digit * weight
                            
                            # Valid if checksum is divisible by 10
                            if total % 10 == 0:
                                valid_count += 1
                            else:
                                all_valid = False
                        
                        print(f"    Valid ISBNs: {valid_count}/{len(isbn_candidates)}")
                        
                        if all_valid:
                            solution = f"{weight}, {pos}"
                            solutions.append(solution)
                            print(f"    *** SOLUTION FOUND: {solution} ***")
                            print(f"        Weight: {weight}")
                            print(f"        Transposed columns: {pos} and {pos+1}")
                            print(f"        All {len(isbn_candidates)} ISBN numbers are valid!")
                
                # Final results
                print(f"\n=== FINAL RESULTS ===")
                print(f"Total valid solutions found: {len(solutions)}")
                
                if solutions:
                    print("\nValid solutions (format: weight, smaller_transpose_index):")
                    for solution in solutions:
                        print(f"  {solution}")
                    
                    # Save detailed results
                    with open('workspace/isbn_analysis_results.txt', 'w') as f:
                        f.write("ISBN-13 Modified Validation Analysis - Results\n")
                        f.write("=" * 50 + "\n\n")
                        f.write(f"Source file: {target_file}\n")
                        f.write(f"Number of ISBN-13 numbers: {len(isbn_candidates)}\n")
                        f.write(f"Weight values tested: {possible_weights}\n")
                        f.write(f"Transpose positions tested: {valid_positions}\n\n")
                        f.write(f"Valid solutions: {len(solutions)}\n\n")
                        for solution in solutions:
                            f.write(f"  {solution}\n")
                        f.write("\nISBN numbers analyzed:\n")
                        for i, isbn in enumerate(isbn_candidates, 1):
                            f.write(f"  {i}: {''.join(map(str, isbn))}\n")
                    
                    print("\nDetailed results saved to workspace/isbn_analysis_results.txt")
                    
                    if len(solutions) == 1:
                        print(f"\n*** UNIQUE SOLUTION: {solutions[0]} ***")
                    else:
                        print(f"\n*** MULTIPLE SOLUTIONS FOUND ***")
                        for sol in solutions:
                            print(f"  {sol}")
                else:
                    print("\n*** NO VALID SOLUTIONS FOUND ***")
                    print("This suggests the extracted ISBN numbers or parameters need adjustment")
            else:
                print("\nNo valid 13-digit sequences found")
        else:
            print(f"\nInsufficient digits ({len(all_digits)}) for ISBN analysis")
    else:
        print("\n*** NO POTENTIAL ISBN FILES FOUND ***")
        print("The data might be structured differently than expected")
        
        # Let's also check the metadata more carefully
        print("\n=== CHECKING METADATA MORE CAREFULLY ===")
        metadata_file = os.path.join(data_dir, 'metadata.jsonl')
        if os.path.exists(metadata_file):
            print("Reading metadata.jsonl to find questions with many digits...")
            
            with open(metadata_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        data = json.loads(line.strip())
                        question_text = data.get('question', '')
                        
                        # Count digits in question
                        digit_count = sum(1 for c in question_text if c.isdigit())
                        
                        if digit_count > 100:  # Questions with lots of digits
                            print(f"\nLine {line_num}: {digit_count} digits")
                            print(f"Task ID: {data.get('task_id', 'unknown')}")
                            print(f"Question preview: {question_text[:200]}...")
                            
                            # Check if this looks like ISBN data
                            digits_only = ''.join(c for c in question_text if c.isdigit())
                            if len(digits_only) >= 130:
                                print(f"*** POTENTIAL ISBN QUESTION FOUND ***")
                                print(f"Total digits: {len(digits_only)}")
                                
                                # Save this question for analysis
                                with open('workspace/potential_isbn_question.txt', 'w') as f:
                                    f.write(f"Task ID: {data.get('task_id')}\n")
                                    f.write(f"Line: {line_num}\n")
                                    f.write(f"Digits: {len(digits_only)}\n\n")
                                    f.write(question_text)
                                
                                print("Question saved to workspace/potential_isbn_question.txt")
                                break
                                
                    except json.JSONDecodeError:
                        continue
else:
    print(f"Data directory not found: {data_dir}")

print("\n=== DATA DISCOVERY COMPLETE ===")
```