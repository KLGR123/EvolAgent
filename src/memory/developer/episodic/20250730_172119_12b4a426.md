### Development Step 19: Undergraduate Institutions of U.S. Homeland Security Secretaries Before April 2019 (Excluding Acting)

**Description**: Search for the complete list of United States Secretaries of Homeland Security who served prior to April 2019 (excluding acting secretaries) and identify their educational backgrounds, specifically focusing on where each secretary obtained their bachelor's degree.

**Use Cases**:
- Academic research in political science analyzing trends in alma maters among US Secretaries of Homeland Security before April 2019
- Investigative journalism background checks on DHS leadership education for an in-depth news feature
- Government HR compliance auditing to verify that senior security officials meet bachelor’s degree requirements
- Data science project building a visualization of bachelor’s degree institutions across cabinet positions
- Civics education platform integration that displays cabinet members’ undergraduate backgrounds for students
- Alumni relations case study at universities showcasing notable graduates who served as Homeland Security Secretaries
- Automated fact-checking pipeline for a news aggregator verifying Secretary education details from Wikipedia
- Think tank policy analysis correlating educational pedigree of Homeland Security leaders with legislative priorities

```
import requests
import os
import re
import json
from bs4 import BeautifulSoup
import time

# Define workspace directory
workspace_dir = 'workspace'
os.makedirs(workspace_dir, exist_ok=True)

print("Starting search for US Secretaries of Homeland Security and their education...")

# Function to perform web requests with exponential backoff
def fetch_with_backoff(url, max_retries=5):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    for attempt in range(max_retries):
        try:
            print(f"Attempt {attempt + 1} to fetch URL: {url}")
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            return response
        except requests.exceptions.RequestException as e:
            wait_time = 2 ** attempt
            if attempt < max_retries - 1:
                print(f"Error: {e}. Retrying in {wait_time} seconds...")
                time.sleep(wait_time)
            else:
                print(f"Failed after {max_retries} attempts: {e}")
                return None

# Define the list of secretaries who served before April 2019
# Using a hardcoded list since the previous attempts to parse the Wikipedia table were unsuccessful
secretaries = [
    {
        "name": "Tom Ridge",
        "term": "January 24, 2003 - February 1, 2005",
        "wiki_link": "https://en.wikipedia.org/wiki/Tom_Ridge"
    },
    {
        "name": "Michael Chertoff",
        "term": "February 15, 2005 - January 21, 2009",
        "wiki_link": "https://en.wikipedia.org/wiki/Michael_Chertoff"
    },
    {
        "name": "Janet Napolitano",
        "term": "January 21, 2009 - September 6, 2013",
        "wiki_link": "https://en.wikipedia.org/wiki/Janet_Napolitano"
    },
    {
        "name": "Jeh Johnson",
        "term": "December 23, 2013 - January 20, 2017",
        "wiki_link": "https://en.wikipedia.org/wiki/Jeh_Johnson"
    },
    {
        "name": "John F. Kelly",
        "term": "January 20, 2017 - July 31, 2017",
        "wiki_link": "https://en.wikipedia.org/wiki/John_F._Kelly"
    },
    {
        "name": "Kirstjen Nielsen",
        "term": "December 6, 2017 - April 10, 2019",
        "wiki_link": "https://en.wikipedia.org/wiki/Kirstjen_Nielsen"
    }
]

print(f"Using predefined list of {len(secretaries)} Secretaries who served before April 2019 (excluding acting secretaries)")

# Function to extract educational background from a secretary's Wikipedia page
def get_education_background(wiki_link):
    if not wiki_link:
        return "Wikipedia link not available"
    
    print(f"\nFetching education details from: {wiki_link}")
    response = fetch_with_backoff(wiki_link)
    if not response:
        return "Education information not available"
    
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # Print page title to confirm we're on the right page
    page_title = soup.find('title').text if soup.find('title') else "Unknown page"
    print(f"Loaded page: {page_title}")
    
    # Look for education information in the infobox
    education = []
    infobox = soup.find('table', class_='infobox')
    if infobox:
        print("Found infobox, searching for education information...")
        for row in infobox.find_all('tr'):
            header = row.find('th')
            if header:
                header_text = header.get_text().lower()
                if 'education' in header_text or 'alma mater' in header_text:
                    value = row.find('td')
                    if value:
                        education_text = value.get_text().strip()
                        print(f"Found education in infobox: '{education_text[:100]}...'" if len(education_text) > 100 else f"Found education in infobox: '{education_text}'")
                        education.append(education_text)
    else:
        print("No infobox found on the page")
    
    # If not found in infobox, look in the content
    if not education:
        print("Education not found in infobox, searching in content...")
        content = soup.find('div', class_='mw-parser-output')
        if content:
            paragraphs = content.find_all('p')
            education_keywords = ['graduate', 'graduated', 'degree', 'university', 'college', 'b.a.', 'b.s.', 'bachelor', 'education']
            
            for paragraph in paragraphs:
                text = paragraph.get_text().lower()
                if any(keyword in text for keyword in education_keywords):
                    para_text = paragraph.get_text().strip()
                    print(f"Found paragraph with education keywords: '{para_text[:100]}...'" if len(para_text) > 100 else f"Found paragraph with education keywords: '{para_text}'")
                    education.append(para_text)
    
    if education:
        combined_education = "\n".join(education)
        return combined_education
    else:
        print("No education information found")
        return "Education information not found"

# Improved function to extract bachelor's degree from education text
def extract_bachelors_degree(education_text):
    if not education_text or education_text in ["Education information not available", "Education information not found", "Wikipedia link not available"]:
        return "Unknown"
    
    print(f"Extracting bachelor's degree from: '{education_text[:100]}...'" if len(education_text) > 100 else f"Extracting bachelor's degree from: '{education_text}'")
    
    # First, check for explicit bachelor's degree mentions with university name
    ba_patterns = [
        r"([\w\s&,]+)\s+University\s+\((?:BA|B\.A\.|B\.S\.|BS)\)",
        r"([\w\s&,]+)\s+College\s+\((?:BA|B\.A\.|B\.S\.|BS)\)",
        r"([\w\s&,]+?)\s+\((?:BA|B\.A\.|B\.S\.|BS)\)",
        r"bachelor(?:'s|s)?\s+(?:of|degree|in)\s+[\w\s]+\s+(?:from|at)\s+([\w\s&,.]+)(?=[\.,]|$)",
        r"(?:BA|B\.A\.|B\.S\.|BS)\s+(?:from|at)\s+([\w\s&,.]+)(?=[\.,]|$)",
    ]
    
    for pattern in ba_patterns:
        try:
            matches = re.findall(pattern, education_text, re.IGNORECASE)
            if matches:
                # Clean up any remaining references or annotations
                degree = re.sub(r'\[\d+\]', '', matches[0]).strip()
                print(f"Found bachelor's degree using specific pattern: '{degree}'")
                return degree
        except Exception as e:
            print(f"Error with pattern: {e}")
    
    # If no explicit mention, look for university names in education text
    # First, split education text into segments that might represent different degrees
    segments = re.split(r'\s*\n\s*|\s+(?=University|College)|\s*;\s*', education_text)
    
    for segment in segments:
        # Skip segments that look like they're about graduate degrees
        if re.search(r'\b(?:JD|PhD|MA|M\.A\.|M\.S\.|LL\.M|LL\.B)\b', segment, re.IGNORECASE) and not re.search(r'\b(?:BA|B\.A\.|B\.S\.|BS)\b', segment, re.IGNORECASE):
            continue
            
        # Look for bachelor's degree indicators in the segment
        if re.search(r'\b(?:BA|B\.A\.|B\.S\.|BS|Bachelor|undergraduate)\b', segment, re.IGNORECASE):
            # Try to extract the institution name
            uni_patterns = [
                r"([\w\s&,.]+?)\s+University",
                r"([\w\s&,.]+?)\s+College",
                r"University\s+of\s+([\w\s&,.]+)",
                r"([\w\s&,.]+?)\s+Institute",
            ]
            
            for pattern in uni_patterns:
                matches = re.findall(pattern, segment, re.IGNORECASE)
                if matches:
                    institution = matches[0].strip()
                    if institution:
                        full_name = f"{institution} University" if "University" not in institution else institution
                        print(f"Found bachelor's degree institution: '{full_name}'")
                        return full_name
    
    # Final attempt: just look for the first university or college mentioned
    uni_patterns = [
        r"([\w\s&,.]+?)\s+University",
        r"([\w\s&,.]+?)\s+College",
        r"University\s+of\s+([\w\s&,.]+)",
    ]
    
    for pattern in uni_patterns:
        matches = re.findall(pattern, education_text, re.IGNORECASE)
        if matches:
            institution = matches[0].strip()
            if institution:
                if pattern.startswith("University"):
                    full_name = f"University of {institution}"
                else:
                    full_name = f"{institution} University" if "University" not in institution else institution
                print(f"Found first mentioned institution: '{full_name}'")
                return full_name
    
    print("No bachelor's degree information found")
    return "Not specifically identified"

# Enhance secretaries data with education information
print("\nRetrieving educational background for each Secretary...")
for secretary in secretaries:
    print(f"\n{'='*50}\nProcessing Secretary: {secretary['name']}")
    
    if secretary['wiki_link']:
        education_text = get_education_background(secretary['wiki_link'])
        secretary['education'] = education_text
        
        # Extract bachelor's degree
        bachelors_degree = extract_bachelors_degree(education_text)
        secretary['bachelors_degree'] = bachelors_degree
        
        print(f"Secretary: {secretary['name']}")
        print(f"Bachelor's Degree: {bachelors_degree}")
    else:
        print(f"No Wikipedia link available for {secretary['name']}")
        secretary['education'] = "Wikipedia link not available"
        secretary['bachelors_degree'] = "Unknown"

# Save the results
results_file = os.path.join(workspace_dir, 'homeland_security_secretaries.json')
with open(results_file, 'w') as f:
    json.dump(secretaries, f, indent=4)

print(f"\nResults saved to {results_file}")

# Print a summary of the findings
print("\nSummary of US Secretaries of Homeland Security who served prior to April 2019:")
print("-" * 80)
for secretary in secretaries:
    print(f"Name: {secretary['name']}")
    print(f"Term: {secretary.get('term', 'Term information not available')}")
    print(f"Bachelor's Degree: {secretary.get('bachelors_degree', 'Unknown')}")
    print("-" * 80)
```