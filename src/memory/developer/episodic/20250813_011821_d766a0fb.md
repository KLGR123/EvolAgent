### Development Step 18: Verify publisher of Harriet Martineau’s 1877–78 four-volume History of England During Thirty Years’ Peace

**Description**: Conduct a targeted verification search specifically for the publisher of Harriet Martineau's 'The History of England During the Thirty Years' Peace: 1816-1846' four-volume edition published in 1877-1878. Search for bibliographic records, library catalogs, antiquarian book listings, and academic references that explicitly identify the publisher of this specific edition. Use search terms including 'Harriet Martineau History England Thirty Years Peace 1877 1878 four volume publisher', 'Martineau 1816-1846 four volumes 1877 publisher', and check sources like WorldCat, British Library catalog, and historical bibliography databases to obtain definitive publisher identification rather than inferential analysis.

**Use Cases**:
- Academic library metadata validation and enrichment for Harriet Martineau’s four-volume 1877-1878 edition to ensure accurate OPAC entries
- Antiquarian bookseller appraisal and pricing automation based on verified publisher information for rare 19th-century history volumes
- Digital humanities project populating and normalizing publisher fields across Victorian historical corpora for bibliometric and network analysis
- Scholarly article preparation requiring precise citation of the 1877-1878 publisher in a study on female historians and historiography
- Provenance and conservation research verifying original publisher details for insurance documentation and authenticity assessments of rare book collections
- Consortium catalog integration scripts reconciling publisher metadata from WorldCat, the British Library, and local OPACs to maintain a unified shared catalog
- Historical publishing network study extracting and mapping publisher data points to analyze 19th-century British historiographical trends
- Library management system automated audits detecting and correcting publisher misattributions in digital and print holdings of Martineau’s works

```
import os
import requests
from bs4 import BeautifulSoup
import json
import time
from urllib.parse import quote_plus

print('=== TARGETED SEARCH FOR MARTINEAU "HISTORY OF ENGLAND" 1877-1878 PUBLISHER ===')
print('Title: The History of England During the Thirty Years\' Peace: 1816-1846')
print('Author: Harriet Martineau')
print('Edition: Four-volume set')
print('Publication years: 1877-1878')
print('Objective: Identify the specific publisher of this edition')
print('\n' + '='*100 + '\n')

# Ensure workspace directory exists
os.makedirs('workspace', exist_ok=True)

# Headers for web requests
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1'
}

# Define highly specific search queries for bibliographic verification
bibliographic_queries = [
    '"Harriet Martineau" "History of England During the Thirty Years Peace" 1877 1878 four volume publisher',
    'Martineau "1816-1846" four volumes 1877 publisher bibliographic',
    '"The History of England During the Thirty Years Peace" Martineau 1877 1878 publisher',
    'Harriet Martineau "Thirty Years Peace" 1877 four volume edition publisher',
    'Martineau "History England" 1816-1846 1877-1878 publisher catalog',
    '"History of England During Thirty Years Peace" four volumes 1877 publisher',
    'Harriet Martineau 1877 1878 "History England" publisher bibliographic record',
    'Martineau "Thirty Years Peace" four volume set 1877 publisher',
    '"History England During Thirty Years Peace" Martineau 1877 publisher library',
    'Harriet Martineau 1816-1846 history four volumes 1877 1878 publisher'
]

print('=== STEP 1: CONDUCTING BIBLIOGRAPHIC SEARCHES ===')
print(f'Total targeted queries: {len(bibliographic_queries)}')
print('\nBibliographic search queries:')
for i, query in enumerate(bibliographic_queries, 1):
    print(f'  {i:2d}. {query}')

search_results = {}
search_base_url = 'https://html.duckduckgo.com/html/'

# Function to perform targeted bibliographic search
def perform_bibliographic_search(query, search_index):
    print(f'\n--- BIBLIOGRAPHIC SEARCH {search_index}: {query} ---')
    try:
        params = {'q': query}
        response = requests.get(search_base_url, params=params, headers=headers, timeout=30)
        print(f'Status: {response.status_code}')
        
        if response.status_code == 200:
            # Save raw HTML for detailed analysis - FIXED QUOTE ISSUE
            clean_query = query.replace(' ', '_').replace('"', '').replace("'", '')[:50]
            filename = f'martineau_history_search_{search_index:02d}_{clean_query}.html'
            filepath = os.path.join('workspace', filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            print(f'Saved: {filepath}')
            
            # Parse for bibliographic and publisher information
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Look for highly relevant bibliographic results
            bibliographic_findings = []
            for link in soup.find_all('a', href=True):
                href = link.get('href')
                text = link.get_text().strip()
                
                if href and text and len(text) > 20:
                    text_lower = text.lower()
                    relevance_score = 0
                    
                    # High-priority terms for this specific search
                    critical_terms = [
                        ('1877', 5), ('1878', 5),
                        ('martineau', 3), ('harriet martineau', 4),
                        ('history of england', 4), ('thirty years peace', 4),
                        ('1816-1846', 4), ('four volume', 3), ('four volumes', 3),
                        ('publisher', 4), ('published', 3), ('publication', 3),
                        ('bibliographic', 3), ('catalog', 2), ('catalogue', 2),
                        ('library', 2), ('worldcat', 3), ('british library', 4)
                    ]
                    
                    # Known publishers of 19th-century historical works
                    publisher_terms = [
                        ('george bell', 4), ('bell and sons', 4), ('george bell and sons', 5),
                        ('macmillan', 3), ('longman', 3), ('longmans', 3),
                        ('john murray', 4), ('chapman and hall', 4),
                        ('smith elder', 3), ('blackwood', 3),
                        ('cambridge university press', 4), ('oxford university press', 4),
                        ('kegan paul', 3), ('trench', 3), ('trubner', 3)
                    ]
                    
                    # Calculate relevance score
                    for term, score in critical_terms + publisher_terms:
                        if term in text_lower:
                            relevance_score += score
                    
                    # Bonus for bibliographic domains
                    if href:
                        href_lower = href.lower()
                        if any(domain in href_lower for domain in ['worldcat.org', 'bl.uk', 'loc.gov', 'catalog', 'opac']):
                            relevance_score += 5
                        elif any(domain in href_lower for domain in ['amazon.com', 'abebooks.com', 'biblio.com', 'vialibri.net']):
                            relevance_score += 3
                    
                    # Only include highly relevant bibliographic results
                    if relevance_score >= 8:  # Higher threshold for precision
                        bibliographic_findings.append({
                            'url': href,
                            'text': text[:400],  # Extended text for better analysis
                            'relevance_score': relevance_score,
                            'has_1877': '1877' in text_lower,
                            'has_1878': '1878' in text_lower,
                            'has_four_volume': any(term in text_lower for term in ['four volume', 'four volumes', '4 volume', '4 volumes']),
                            'has_publisher_info': any(term in text_lower for term in ['publisher', 'published', 'publication'])
                        })
            
            # Sort by relevance score
            bibliographic_findings.sort(key=lambda x: x['relevance_score'], reverse=True)
            
            search_results[query] = {
                'html_file': filepath,
                'status_code': response.status_code,
                'bibliographic_findings': bibliographic_findings[:20],  # Top 20 most relevant
                'total_findings': len(bibliographic_findings)
            }
            
            print(f'Found {len(bibliographic_findings)} highly relevant bibliographic results')
            if bibliographic_findings:
                print('Top bibliographic findings:')
                for i, finding in enumerate(bibliographic_findings[:5], 1):
                    indicators = []
                    if finding['has_1877']: indicators.append('1877')
                    if finding['has_1878']: indicators.append('1878')
                    if finding['has_four_volume']: indicators.append('4vol')
                    if finding['has_publisher_info']: indicators.append('pub')
                    
                    print(f'  {i}. Score {finding["relevance_score"]} [{"|" .join(indicators)}]: {finding["text"][:120]}...')
                    print(f'     URL: {finding["url"]}')
            
            time.sleep(2)  # Rate limiting
            return True
        else:
            print(f'Failed: HTTP {response.status_code}')
            return False
            
    except Exception as e:
        print(f'Error: {str(e)}')
        return False

# Execute all bibliographic searches
print('\n=== EXECUTING BIBLIOGRAPHIC SEARCHES ===')
successful_searches = 0

for i, query in enumerate(bibliographic_queries, 1):
    if perform_bibliographic_search(query, i):
        successful_searches += 1
    
    # Brief pause between searches
    if i < len(bibliographic_queries):
        time.sleep(1)

print(f'\n=== STEP 2: ANALYZING BIBLIOGRAPHIC FINDINGS ===')
print(f'Successful searches: {successful_searches}/{len(bibliographic_queries)}')

# Compile all high-priority findings
high_priority_findings = []
publisher_mentions = {}
date_verified_findings = []

print('\n--- ANALYZING ALL BIBLIOGRAPHIC RESULTS FOR PUBLISHER IDENTIFICATION ---')

for query, results in search_results.items():
    print(f'\nQuery: "{query}"')
    print(f'  Bibliographic findings: {results["total_findings"]}')
    
    for finding in results['bibliographic_findings']:
        text_lower = finding['text'].lower()
        
        # Check for date verification (1877 or 1878)
        has_target_dates = finding['has_1877'] or finding['has_1878']
        
        if has_target_dates and finding['has_publisher_info']:
            # This is a high-priority finding with both date and publisher info
            high_priority_findings.append({
                'query': query,
                'text': finding['text'],
                'url': finding['url'],
                'score': finding['relevance_score'],
                'has_1877': finding['has_1877'],
                'has_1878': finding['has_1878'],
                'has_four_volume': finding['has_four_volume'],
                'priority': 'CRITICAL - Date + Publisher Info'
            })
            
            print(f'  🎯 CRITICAL: Date-verified finding with publisher info (Score: {finding["relevance_score"]})')
            print(f'     Text: {finding["text"][:200]}...')
            
            # Extract potential publisher names
            known_publishers = [
                'George Bell', 'Bell and Sons', 'George Bell and Sons', 'Bell & Sons',
                'Macmillan', 'Longman', 'Longmans', 'John Murray', 'Chapman and Hall',
                'Smith Elder', 'Blackwood', 'Cambridge University Press',
                'Oxford University Press', 'Kegan Paul', 'Trench', 'Trubner'
            ]
            
            for publisher in known_publishers:
                if publisher.lower() in text_lower:
                    if publisher not in publisher_mentions:
                        publisher_mentions[publisher] = []
                    publisher_mentions[publisher].append({
                        'query': query,
                        'text': finding['text'][:300],
                        'url': finding['url'],
                        'score': finding['relevance_score'],
                        'date_verified': has_target_dates
                    })
                    print(f'     📚 PUBLISHER IDENTIFIED: {publisher}')
        
        elif has_target_dates:
            # Date-verified but may need manual publisher extraction
            date_verified_findings.append({
                'query': query,
                'text': finding['text'],
                'url': finding['url'],
                'score': finding['relevance_score'],
                'has_1877': finding['has_1877'],
                'has_1878': finding['has_1878'],
                'has_four_volume': finding['has_four_volume'],
                'priority': 'HIGH - Date Verified'
            })
            
            print(f'  📍 HIGH: Date-verified finding (Score: {finding["relevance_score"]})')

print(f'\n=== STEP 3: PUBLISHER IDENTIFICATION ANALYSIS ===')
print(f'Critical findings (date + publisher): {len(high_priority_findings)}')
print(f'Date-verified findings: {len(date_verified_findings)}')
print(f'Publishers explicitly mentioned: {len(publisher_mentions)}')

if publisher_mentions:
    print('\n🏆 PUBLISHERS IDENTIFIED IN BIBLIOGRAPHIC RECORDS:')
    
    # Sort publishers by frequency and evidence quality
    sorted_publishers = sorted(publisher_mentions.items(), 
                             key=lambda x: (len(x[1]), sum(m['score'] for m in x[1])), 
                             reverse=True)
    
    for publisher, mentions in sorted_publishers:
        print(f'\n📚 {publisher}: {len(mentions)} mention(s)')
        
        # Calculate total evidence score
        total_score = sum(m['score'] for m in mentions)
        date_verified_count = sum(1 for m in mentions if m['date_verified'])
        
        print(f'   Total evidence score: {total_score}')
        print(f'   Date-verified mentions: {date_verified_count}/{len(mentions)}')
        
        # Show evidence for top publishers
        if len(mentions) >= 2 or total_score >= 15:  # Strong evidence threshold
            print('   Key evidence:')
            for i, mention in enumerate(mentions[:3], 1):  # Top 3 pieces of evidence
                date_info = []
                if '1877' in mention['text'].lower(): date_info.append('1877')
                if '1878' in mention['text'].lower(): date_info.append('1878')
                date_str = f"[{'/'.join(date_info)}]" if date_info else ''
                
                print(f'     {i}. {date_str} Score {mention["score"]}: {mention["text"][:150]}...')
                print(f'        URL: {mention["url"]}')
        print()
    
    # Identify most likely publisher
    if sorted_publishers:
        top_publisher = sorted_publishers[0][0]
        top_mentions = sorted_publishers[0][1]
        top_total_score = sum(m['score'] for m in top_mentions)
        top_date_verified = sum(1 for m in top_mentions if m['date_verified'])
        
        print(f'🎯 MOST LIKELY PUBLISHER: {top_publisher}')
        print(f'Evidence strength: {len(top_mentions)} mentions, total score {top_total_score}')
        print(f'Date verification: {top_date_verified}/{len(top_mentions)} mentions verified')
        
        # Determine confidence level
        if top_total_score >= 25 and top_date_verified >= 2:
            confidence = 'very_high'
        elif top_total_score >= 15 and top_date_verified >= 1:
            confidence = 'high'
        elif top_total_score >= 10:
            confidence = 'medium'
        else:
            confidence = 'low'
        
        print(f'Confidence level: {confidence}')
else:
    print('\n⚠ No specific publishers clearly identified in bibliographic searches')
    print('Publishers may be mentioned but not explicitly extracted')

print(f'\n=== STEP 4: DETAILED ANALYSIS OF DATE-VERIFIED FINDINGS ===')

if date_verified_findings:
    print(f'\nAnalyzing {len(date_verified_findings)} date-verified findings for publisher clues:')
    
    # Sort by score
    date_verified_findings.sort(key=lambda x: x['score'], reverse=True)
    
    for i, finding in enumerate(date_verified_findings[:10], 1):  # Top 10 findings
        date_info = []
        if finding['has_1877']: date_info.append('1877')
        if finding['has_1878']: date_info.append('1878')
        vol_info = ' [4vol]' if finding['has_four_volume'] else ''
        
        print(f'\n📅 DATE-VERIFIED FINDING {i} [{"|" .join(date_info)}]{vol_info} (Score: {finding["score"]})')
        print(f'Query: {finding["query"]}') 
        print(f'URL: {finding["url"]}')
        print(f'Text: {finding["text"][:500]}...')
        print('-' * 120)
        
        # Manual publisher pattern detection in date-verified findings
        text_lower = finding['text'].lower()
        potential_publishers = []
        
        # Look for common publisher patterns
        import re
        publisher_patterns = [
            r'published by ([A-Z][^\n,]{10,50})',
            r'publisher[:\s]+([A-Z][^\n,]{10,50})',
            r'([A-Z][a-z]+ (?:and |& )?[A-Z][a-z]+(?:, |\s+)[A-Z][a-z]+)',  # Publisher name patterns
            r'(George Bell[^\n,]{0,20})',
            r'(Macmillan[^\n,]{0,20})',
            r'(Longman[^\n,]{0,20})',
            r'(John Murray[^\n,]{0,20})'
        ]
        
        for pattern in publisher_patterns:
            matches = re.findall(pattern, finding['text'], re.IGNORECASE)
            for match in matches:
                if isinstance(match, tuple):
                    match = match[0] if match[0] else ''
                match = match.strip()
                if len(match) > 5 and match not in potential_publishers:
                    potential_publishers.append(match)
        
        if potential_publishers:
            print(f'  🔍 POTENTIAL PUBLISHERS DETECTED: {potential_publishers}')
else:
    print('\nNo date-verified findings available for detailed analysis')

# Save comprehensive bibliographic analysis
bibliographic_analysis = {
    'search_objective': 'Identify publisher of Martineau\'s "History of England During the Thirty Years\' Peace" 1877-1878 edition',
    'book_details': {
        'title': 'The History of England During the Thirty Years\' Peace: 1816-1846',
        'author': 'Harriet Martineau',
        'edition': 'Four-volume set',
        'publication_years': '1877-1878',
        'time_period_covered': '1816-1846'
    },
    'search_summary': {
        'total_queries': len(bibliographic_queries),
        'successful_searches': successful_searches,
        'total_bibliographic_findings': sum(len(r['bibliographic_findings']) for r in search_results.values()),
        'critical_findings': len(high_priority_findings),
        'date_verified_findings': len(date_verified_findings)
    },
    'publisher_analysis': {
        'publishers_identified': list(publisher_mentions.keys()) if publisher_mentions else [],
        'publisher_evidence': publisher_mentions if publisher_mentions else {},
        'most_likely_publisher': sorted_publishers[0][0] if 'sorted_publishers' in locals() and sorted_publishers else None,
        'confidence_level': confidence if 'confidence' in locals() else 'unknown'
    },
    'high_priority_findings': high_priority_findings[:10],  # Top 10 critical findings
    'date_verified_findings': date_verified_findings[:10],  # Top 10 date-verified findings
    'search_queries_used': bibliographic_queries,
    'analysis_timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
}

analysis_file = 'workspace/martineau_history_england_1877_publisher_analysis.json'
with open(analysis_file, 'w', encoding='utf-8') as f:
    json.dump(bibliographic_analysis, f, indent=2, ensure_ascii=False)

print(f'\n*** BIBLIOGRAPHIC PUBLISHER SEARCH COMPLETE ***')
print(f'✓ Conducted {successful_searches} successful bibliographic searches')
print(f'✓ Analyzed {sum(len(r["bibliographic_findings"]) for r in search_results.values())} bibliographic findings')
print(f'✓ Found {len(high_priority_findings)} critical findings with date + publisher info')
print(f'✓ Found {len(date_verified_findings)} date-verified findings')
print(f'✓ Identified {len(publisher_mentions) if publisher_mentions else 0} publishers with evidence')
print(f'✓ Comprehensive analysis saved to: {analysis_file}')

# Final summary
if 'sorted_publishers' in locals() and sorted_publishers:
    top_publisher = sorted_publishers[0][0]
    top_evidence_count = len(sorted_publishers[0][1])
    top_score = sum(m['score'] for m in sorted_publishers[0][1])
    
    print(f'\n🏆 FINAL CONCLUSION:')
    print(f'Publisher: {top_publisher}')
    print(f'Evidence: {top_evidence_count} bibliographic mentions')
    print(f'Total score: {top_score}')
    print(f'Confidence: {confidence}')
else:
    print(f'\n⚠ CONCLUSION: Publisher not definitively identified from bibliographic searches')
    print('Recommend manual review of date-verified findings or direct library catalog consultation')

print('\n=== FILES CREATED ===')
for file in sorted(os.listdir('workspace')):
    if 'martineau_history' in file:
        file_path = os.path.join('workspace', file)
        file_size = os.path.getsize(file_path)
        print(f'- {file} ({file_size:,} bytes)')
```