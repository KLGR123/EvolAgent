### Development Step 17: Retrieve 2011 Bulgarian Census Data on Tertiary Education Completion by Gender

**Description**: Search for the 2011 Bulgarian census data on tertiary education completion by gender. Look for official census results from Bulgaria's National Statistical Institute or other authoritative sources that provide the specific breakdown of men and women who completed tertiary education in 2011.

**Use Cases**:
- Government education policy planning: extracting 2011 Bulgarian census tertiary education by gender to identify underrepresented groups and allocate scholarships for male or female students.
- NGO gender equality program evaluation: using official census data to measure progress in women’s higher education participation and tailor community outreach in rural Bulgaria.
- Academic comparative study in European higher education: integrating Bulgaria’s gender‐disaggregated tertiary completion rates into cross‐national analyses of educational attainment trends.
- Labor market forecasting for workforce development: correlating tertiary education by gender with employment projections to advise vocational training programs in Bulgaria.
- Data journalism feature on gender parity: sourcing primary census figures to illustrate shifts in male and female university graduation rates across Bulgarian regions.
- EdTech curriculum customization: analyzing regional gender gaps in specific fields (STEM vs. humanities) to design targeted online courses for Bulgarian learners.
- International reporting for UN Sustainable Development Goals: extracting and formatting Bulgarian 2011 tertiary education statistics by gender to include in global education equity dashboards.

```
import os
import json
from bs4 import BeautifulSoup
import re
import time

print("=== BULGARIAN 2011 CENSUS TERTIARY EDUCATION - NO SCOPING ISSUES ===")
print("Strategy: Explicit variable definitions with no comprehensions\n")

# Check workspace
workspace_path = 'workspace'
if not os.path.exists(workspace_path):
    print("No workspace directory found")
    exit()

all_files = os.listdir(workspace_path)
html_files = []

# Build HTML files list explicitly
for file in all_files:
    if file.endswith('.html'):
        html_files.append(file)

print(f"Total files: {len(all_files)}")
print(f"HTML files: {len(html_files)}")

# Show all HTML files with sizes
print("\n=== ALL HTML FILES ===\n")
for i, html_file in enumerate(html_files, 1):
    filepath = os.path.join(workspace_path, html_file)
    file_size = os.path.getsize(filepath)
    print(f"{i:2d}. {html_file}")
    print(f"    Size: {file_size:,} bytes")

# Select promising files - NO comprehensions
promising_files = []
for html_filename in html_files:
    filepath = os.path.join(workspace_path, html_filename)
    file_size = os.path.getsize(filepath)
    
    # Skip very small files
    if file_size < 40000:  # Less than 40KB likely error pages
        continue
    
    # Look for key terms in filename - explicit checks
    name_lower = html_filename.lower()
    is_demographics = 'demographics' in name_lower
    is_education = 'education' in name_lower
    is_census = 'census' in name_lower
    is_nsi = 'nsi' in name_lower
    
    if is_demographics or is_education or is_census or is_nsi:
        promising_files.append(html_filename)

print(f"\nPromising files to analyze: {len(promising_files)}")
for pf in promising_files:
    print(f"  - {pf}")

print("\n=== ANALYZING FILES WITH NO SCOPING ISSUES ===\n")

# Results storage
all_findings = []

# Analyze each promising file - limit to top 3
files_to_analyze = promising_files[:3]

for current_filename in files_to_analyze:
    print(f"Analyzing: {current_filename}")
    
    filepath = os.path.join(workspace_path, current_filename)
    
    try:
        # Read and parse HTML
        with open(filepath, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        page_title = soup.find('title')
        title_text = page_title.get_text().strip() if page_title else 'No title'
        
        # Get all text
        all_text = soup.get_text()
        text_lower = all_text.lower()
        
        print(f"  Title: {title_text}")
        print(f"  Content length: {len(all_text):,} characters")
        
        # Check relevance - explicit variables
        has_bulgaria = 'bulgaria' in text_lower or 'bulgarian' in text_lower
        has_2011 = '2011' in text_lower
        has_census = 'census' in text_lower
        has_tertiary = 'tertiary' in text_lower or 'higher education' in text_lower
        has_men = 'men' in text_lower
        has_women = 'women' in text_lower
        has_male = 'male' in text_lower
        has_female = 'female' in text_lower
        has_gender = has_men or has_women or has_male or has_female
        has_education = 'education' in text_lower
        
        relevance = 0
        if has_bulgaria:
            relevance += 1
        if has_2011:
            relevance += 1
        if has_census:
            relevance += 1
        if has_tertiary:
            relevance += 1
        if has_gender:
            relevance += 1
        if has_education:
            relevance += 1
        
        print(f"  Bulgaria: {has_bulgaria} | 2011: {has_2011} | Census: {has_census}")
        print(f"  Tertiary: {has_tertiary} | Gender: {has_gender} | Education: {has_education}")
        print(f"  Relevance: {relevance}/6")
        
        if relevance >= 3:
            print("  *** EXTRACTING DATA ***")
            
            # Look for sentences with key terms and numbers
            sentences = all_text.split('.')
            good_sentences = []
            
            for sentence in sentences:
                sentence_clean = sentence.strip()
                if len(sentence_clean) < 30:
                    continue
                    
                s_lower = sentence_clean.lower()
                
                # Check conditions explicitly
                has_bulgaria_ref = 'bulgaria' in s_lower or 'bulgarian' in s_lower
                has_education_ref = 'education' in s_lower or 'tertiary' in s_lower or 'university' in s_lower
                has_numbers = bool(re.search(r'\d+', sentence_clean))
                has_2011_ref = '2011' in s_lower
                has_men_ref = 'men' in s_lower
                has_women_ref = 'women' in s_lower
                has_male_ref = 'male' in s_lower
                has_female_ref = 'female' in s_lower
                has_gender_ref = has_men_ref or has_women_ref or has_male_ref or has_female_ref
                
                if has_bulgaria_ref and has_education_ref and has_numbers and (has_gender_ref or has_2011_ref):
                    good_sentences.append(sentence_clean)
            
            print(f"  Good sentences found: {len(good_sentences)}")
            
            # Look for statistical patterns
            stat_patterns = [
                r'tertiary education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'(?:men|women|male|female)[^.]*?tertiary education[^.]*?(\d+[.,]?\d*\s*%?)',
                r'higher education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'2011[^.]*?education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'(?:men|women)[^.]*?(?:completed|attained|achieved)[^.]*?(?:tertiary|higher|university)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'(?:tertiary|higher|university)[^.]*?(?:completed|attained|achieved)[^.]*?(?:men|women)[^.]*?(\d+[.,]?\d*\s*%?)'
            ]
            
            stat_matches = []
            for pattern in stat_patterns:
                matches = re.finditer(pattern, all_text, re.IGNORECASE)
                for match in matches:
                    context_start = max(0, match.start() - 200)
                    context_end = min(len(all_text), match.end() + 200)
                    context = all_text[context_start:context_end]
                    
                    context_lower = context.lower()
                    if 'bulgaria' in context_lower:
                        stat_matches.append({
                            'match': match.group(),
                            'context': context,
                            'file': current_filename
                        })
            
            print(f"  Statistical matches: {len(stat_matches)}")
            
            # Look for tables with education and gender data
            tables = soup.find_all('table')
            education_tables = []
            
            for table_idx, table in enumerate(tables):
                table_text = table.get_text()
                table_text_lower = table_text.lower()
                
                # Check table content explicitly
                table_has_education = 'education' in table_text_lower or 'tertiary' in table_text_lower or 'university' in table_text_lower or 'degree' in table_text_lower
                table_has_men = 'men' in table_text_lower
                table_has_women = 'women' in table_text_lower
                table_has_male = 'male' in table_text_lower
                table_has_female = 'female' in table_text_lower
                table_has_gender = table_has_men or table_has_women or table_has_male or table_has_female or 'gender' in table_text_lower
                table_has_numbers = bool(re.search(r'\d+', table_text))
                
                if table_has_education and table_has_gender and table_has_numbers:
                    # Extract table headers
                    headers = []
                    for th in table.find_all('th'):
                        headers.append(th.get_text().strip())
                    
                    # Extract sample rows
                    rows = table.find_all('tr')
                    sample_rows = []
                    
                    # Skip header row, take next 3 rows
                    for row in rows[1:4]:
                        cells = []
                        for cell in row.find_all(['td', 'th']):
                            cells.append(cell.get_text().strip())
                        if cells:
                            # Check if row has meaningful content
                            has_content = False
                            for cell in cells:
                                if cell.strip():
                                    has_content = True
                                    break
                            if has_content:
                                sample_rows.append(cells)
                    
                    education_tables.append({
                        'table_index': table_idx,
                        'headers': headers,
                        'sample_rows': sample_rows,
                        'total_rows': len(rows)
                    })
            
            print(f"  Education tables found: {len(education_tables)}")
            
            # Store findings
            file_findings = {
                'filename': current_filename,
                'title': title_text,
                'relevance_score': relevance,
                'good_sentences': good_sentences[:5],  # Top 5
                'statistical_matches': stat_matches[:3],  # Top 3
                'education_tables': education_tables[:2],  # Top 2
                'indicators': {
                    'bulgaria': has_bulgaria,
                    '2011': has_2011,
                    'census': has_census,
                    'tertiary': has_tertiary,
                    'gender': has_gender,
                    'education': has_education
                }
            }
            
            all_findings.append(file_findings)
            
            # Show key findings
            if good_sentences:
                print(f"  Sample sentence: {good_sentences[0][:200]}...")
            
            if stat_matches:
                print(f"  Sample match: {stat_matches[0]['match']}")
                print(f"  Context: {stat_matches[0]['context'][:150]}...")
            
            if education_tables:
                print(f"  Table headers: {education_tables[0]['headers'][:5]}")
                if education_tables[0]['sample_rows']:
                    print(f"  Sample row: {education_tables[0]['sample_rows'][0][:3]}")
        
        else:
            print(f"  Lower relevance - skipping detailed analysis")
        
        print()
        
    except Exception as e:
        print(f"  ERROR: {str(e)}")
        print()

# Save results
print("=== SAVING RESULTS ===\n")

results = {
    'objective': 'Bulgarian 2011 census tertiary education by gender',
    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'html_files_total': len(html_files),
    'promising_files_analyzed': len(files_to_analyze),
    'files_with_findings': len(all_findings),
    'detailed_findings': all_findings
}

results_file = os.path.join(workspace_path, 'bulgarian_census_no_scoping_analysis.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2, ensure_ascii=False)

print(f"Results saved to: {results_file}")
print(f"Files analyzed: {len(files_to_analyze)}")
print(f"Files with findings: {len(all_findings)}")

# Summary of findings
if all_findings:
    print("\n=== SUMMARY OF FINDINGS ===\n")
    
    total_sentences = 0
    total_matches = 0
    total_tables = 0
    
    for f in all_findings:
        total_sentences += len(f['good_sentences'])
        total_matches += len(f['statistical_matches'])
        total_tables += len(f['education_tables'])
    
    print(f"Total relevant sentences: {total_sentences}")
    print(f"Total statistical matches: {total_matches}")
    print(f"Total education tables: {total_tables}")
    
    print("\nDetailed findings:")
    for i, finding in enumerate(all_findings, 1):
        print(f"{i}. {finding['filename']} (Relevance: {finding['relevance_score']}/6)")
        print(f"   Title: {finding['title']}")
        print(f"   Sentences: {len(finding['good_sentences'])}, Matches: {len(finding['statistical_matches'])}, Tables: {len(finding['education_tables'])}")
        
        if finding['good_sentences']:
            print(f"   Sample sentence: {finding['good_sentences'][0][:180]}...")
        
        if finding['statistical_matches']:
            print(f"   Statistical match: {finding['statistical_matches'][0]['match']}")
        
        if finding['education_tables']:
            print(f"   Table headers: {finding['education_tables'][0]['headers'][:3]}")
        
        print()

else:
    print("\n=== NO FINDINGS ===\n")
    print("No specific tertiary education by gender data found in the analyzed files.")
    print("The data may be in a different format or require more specific sources.")

# Save file inventory for reference
file_inventory = {
    'total_files': len(all_files),
    'html_files_count': len(html_files),
    'promising_files_count': len(promising_files),
    'html_file_list': [],
    'promising_file_list': promising_files
}

for html_file in html_files:
    filepath = os.path.join(workspace_path, html_file)
    file_size = os.path.getsize(filepath)
    file_inventory['html_file_list'].append({
        'filename': html_file,
        'size': file_size
    })

inventory_file = os.path.join(workspace_path, 'file_inventory_complete.json')
with open(inventory_file, 'w', encoding='utf-8') as f:
    json.dump(file_inventory, f, indent=2, ensure_ascii=False)

print(f"\nFile inventory saved to: {inventory_file}")
print("\n=== ANALYSIS COMPLETE ===\n")
print("No scoping issues analysis completed successfully")
print("All findings systematically extracted and saved for review")
```