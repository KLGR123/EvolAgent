### Development Step 1: Comprehensive List of Non-Acting U.S. Homeland Security Secretaries Before April 2019

**Description**: Search for a comprehensive list of all United States secretaries of homeland security who served prior to April 2019, excluding those who served in an acting capacity only. Use reliable government sources or authoritative websites for this information.

**Use Cases**:
- Government watchdog research and policy timeline construction using historical DHS secretary data for accountability analysis
- Academic thesis on federal leadership turnover and department effectiveness using automated extraction of pre-2019 Secretaries of Homeland Security
- Legal compliance review for a law firm cross-referencing regulation dates with corresponding DHS secretary tenures
- Newsroom backend automation updating historical cabinet member profiles for interactive timelines on a news website
- Security consulting firm risk modeling by correlating DHS leadership changes with shifts in homeland security directives before April 2019
- Civic tech platform enrichment importing authoritative lists of DHS secretaries into a public API for civic engagement tools
- Educational e-learning module creation that visualizes U.S. Cabinet history by retrieving and displaying DHS secretary data

```
import requests
import re
import os
from bs4 import BeautifulSoup
import json

print("Searching for U.S. Secretaries of Homeland Security prior to April 2019...")

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

# Function to get HTML content from a URL with proper headers
def get_page_content(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return response.text
    except Exception as e:
        print(f"Error fetching {url}: {str(e)}")
        return None

# Function to clean up text (remove extra spaces, newlines, etc.)
def clean_text(text):
    if text is None:
        return ""
    # Remove extra whitespace
    cleaned = re.sub(r'\s+', ' ', text)
    # Remove leading/trailing whitespace
    cleaned = cleaned.strip()
    return cleaned

# Function to parse the DHS website for secretaries
def parse_dhs_website():
    print("\nTrying to fetch information from the official DHS website...")
    url = "https://www.dhs.gov/homeland-security-leadership"
    content = get_page_content(url)
    
    if not content:
        print("Could not access DHS website. Trying alternative sources.")
        return None
    
    soup = BeautifulSoup(content, 'html.parser')
    print("Successfully fetched DHS website content.")
    
    # This is a fallback that might not work directly as website structure may vary
    sections = soup.find_all(['h2', 'h3'])
    for section in sections:
        if 'secretary' in section.text.lower():
            print(f"Found section: {section.text}")
    
    print("Direct parsing of current DHS website may not provide historical data. Trying Wikipedia as an alternative.")
    return None

# Function to parse Wikipedia for the list of secretaries
def parse_wikipedia():
    print("\nTrying to fetch information from Wikipedia...")
    url = "https://en.wikipedia.org/wiki/United_States_Secretary_of_Homeland_Security"
    content = get_page_content(url)
    
    if not content:
        print("Could not access Wikipedia. Trying alternative sources.")
        return None
    
    soup = BeautifulSoup(content, 'html.parser')
    print("Successfully fetched Wikipedia content.")
    
    # Try to find the table with the list of secretaries
    tables = soup.find_all('table', class_='wikitable')
    
    secretaries = []
    found_table = False
    
    for table in tables:
        # Check if this looks like the right table
        headers = table.find_all('th')
        header_texts = [h.get_text().strip() for h in headers]
        
        # Print table headers for debugging
        print(f"Found table with headers: {header_texts}")
        
        if any('Secretary' in h for h in header_texts) and any('Term' in h for h in header_texts):
            found_table = True
            print("Found the table with Secretaries of Homeland Security.")
            
            rows = table.find_all('tr')
            # Skip the header row
            for row in rows[1:]:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 4:  # Assuming we have name, term start, term end, and president columns
                    # Extract name
                    name_cell = cells[0]
                    name = clean_text(name_cell.get_text())
                    
                    # Check if "acting" is in the name or title
                    is_acting = 'acting' in name.lower()
                    
                    # Extract term dates
                    term_start = clean_text(cells[1].get_text())
                    term_end = clean_text(cells[2].get_text())
                    
                    # Extract president
                    president = clean_text(cells[3].get_text()) if len(cells) > 3 else ""
                    
                    # Convert term dates to a standard format if possible
                    # This is simplified and might need more robust parsing
                    term_start_clean = re.sub(r'\[.*?\]'
```