### Development Step 5: Identify Little Monsters Comic Book Illustrator, Publication Credits, and Writer Collaborations

**Description**: Search for information about the comic book 'Little Monsters' to identify its illustrator/artist. Focus on finding the artist who illustrated this comic and any information about their collaborations with writers. Look for official publication details, creator credits, and any collaborative relationships mentioned in connection with this work.

**Use Cases**:
- Comic book retailer enriching online product pages by automatically retrieving the illustrator and writer credits for the “Little Monsters” series to ensure accurate creator information for collectors.
- Intellectual property legal team performing due diligence on “Little Monsters” to verify the illustrator’s identity and publication history before negotiating character licensing and merchandise deals.
- Library metadata specialist automating the extraction of creator and publisher details for the “Little Monsters” graphic novel to standardize and update MARC records in the public library catalog.
- Digital archive project compiling a searchable database of indie comics by scraping “Little Monsters” creator credits, publication dates, and collaborator relationships to support preservation and research.
- Market research analyst mapping collaboration networks between writers and artists on “Little Monsters” and similar titles to identify emerging talent trends in the horror comics segment.
- Fan-driven comic blog automatically gathering official publication details and artist interviews for “Little Monsters” to generate accurate feature articles and spotlight lesser-known illustrators.
- Academic researcher studying the evolution of comic-book creative teams uses the solution to systematically collect and analyze “Little Monsters” collaborator data for inclusion in a peer-reviewed journal article.
- Social media manager fact-checking artist attributions for “Little Monsters” posts by automating searches for illustrator credits, ensuring correct tagging and maintaining strong creator relationships.

```
import os
import requests
from bs4 import BeautifulSoup
import json
import time
from urllib.parse import quote
import re
from collections import Counter

# Create workspace directory if it doesn't exist
os.makedirs('workspace', exist_ok=True)

print("=== SEARCHING FOR 'LITTLE MONSTERS' COMIC ARTIST/ILLUSTRATOR ===")
print("Objective: Identify the artist who illustrated the 'Little Monsters' comic")
print("Focus: Creator credits, publication details, collaborative relationships")
print("=" * 70)

# Define headers for web requests at the very beginning
request_headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Connection': 'keep-alive'
}

def make_safe_request(url, timeout=15):
    """Make HTTP request with comprehensive error handling"""
    try:
        print(f"Requesting: {url}")
        response = requests.get(url, headers=request_headers, timeout=timeout)
        response.raise_for_status()
        return response
    except Exception as e:
        print(f"Request failed: {e}")
        return None

# Initialize search results storage
search_results = {
    'comic_matches_found': [],
    'artist_information': [],
    'publication_details': [],
    'search_attempts': [],
    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
}

print("\nSTEP 1: Conducting targeted Google searches for 'Little Monsters' comic")
print("-" * 60)

# Specific search queries to find the comic and its artist
search_queries = [
    '\"Little Monsters\" comic book artist illustrator creator',
    'Little Monsters comic series artist name writer',
    'Little Monsters graphic novel publication artist credits',
    'Little Monsters comic book \"created by\" \"art by\" \"written by\"',
    'Little Monsters horror comic artist illustrator indie'
]

for i, query in enumerate(search_queries, 1):
    print(f"\nSearch {i}: {query}")
    
    # Construct Google search URL
    google_url = f"https://www.google.com/search?q={quote(query)}"
    
    response = make_safe_request(google_url)
    
    if response:
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
        
        # Get clean text content
        text_content = soup.get_text()
        
        # Look for search result containers
        search_snippets = []
        
        # Try multiple selectors for Google search results
        result_selectors = ['.g', '.tF2Cxc', '.MjjYud', '.yuRUbf']
        results = []
        
        for selector in result_selectors:
            found_results = soup.select(selector)
            if found_results:
                results = found_results[:5]  # First 5 results
                break
        
        print(f"  Found {len(results)} search result containers")
        
        # Extract information from search results
        for result in results:
            # Try to find title and description
            title_elem = result.find(['h3', 'a'])
            desc_elem = result.find(['span', 'div'], string=lambda text: text and len(text) > 20)
            
            title = title_elem.get_text() if title_elem else ''
            description = desc_elem.get_text() if desc_elem else ''
            
            # Combine title and description for analysis
            combined_text = f"{title} {description}".lower()
            
            # Look for creator-related keywords
            creator_keywords = ['artist', 'illustrator', 'creator', 'writer', 'by ', 'created by', 'art by', 'illustrated by']
            
            if any(keyword in combined_text for keyword in creator_keywords) and 'little monsters' in combined_text:
                search_snippets.append({
                    'title': title[:150],
                    'description': description[:300],
                    'relevance_score': sum(1 for kw in creator_keywords if kw in combined_text)
                })
                
                print(f"    RELEVANT: {title[:80]}...")
                print(f"    Desc: {description[:120]}...")
        
        # Also search the full page text for artist mentions
        artist_mentions = []
        lines = text_content.split('\n')
        
        for line in lines:
            line_lower = line.strip().lower()
            if ('little monsters' in line_lower and 
                any(keyword in line_lower for keyword in ['artist', 'illustrator', 'creator', 'by '])):
                
                # Clean up the line
                clean_line = ' '.join(line.strip().split())
                if len(clean_line) > 20 and len(clean_line) < 200:
                    artist_mentions.append(clean_line)
        
        if artist_mentions:
            print(f"  Found {len(artist_mentions)} potential artist mentions:")
            for mention in artist_mentions[:3]:  # Show first 3
                print(f"    - {mention[:100]}...")
        
        # Record search attempt
        search_results['search_attempts'].append({
            'query': query,
            'source': 'Google Search',
            'results_found': len(search_snippets),
            'snippets': search_snippets,
            'artist_mentions': artist_mentions[:5]  # Limit to 5 mentions
        })
        
        # Save raw HTML for manual inspection
        filename = f"workspace/google_search_{i}.html"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(response.text)
        print(f"  Raw HTML saved to: {filename}")
        
    else:
        print(f"  ✗ Failed to retrieve search results")
        search_results['search_attempts'].append({
            'query': query,
            'source': 'Google Search',
            'status': 'Failed'
        })
    
    # Add delay between requests to be respectful
    time.sleep(3)

print("\nSTEP 2: Searching for specific comic publishers and 'Little Monsters'")
print("-" * 60)

# Search for specific publisher connections
publisher_queries = [
    'Little Monsters Image Comics artist creator credits',
    'Little Monsters Dark Horse Comics illustrator',
    'Little Monsters IDW Publishing artist writer',
    'Little Monsters Boom Studios creator team',
    'Little Monsters Oni Press artist illustrator'
]

for query in publisher_queries:
    print(f"\nPublisher search: {query}")
    
    google_url = f"https://www.google.com/search?q={quote(query)}"
    response = make_safe_request(google_url)
    
    if response:
        soup = BeautifulSoup(response.content, 'html.parser')
        text_content = soup.get_text().lower()
        
        # Check for specific publisher mentions with Little Monsters
        publisher_found = False
        
        if 'image comics' in text_content and 'little monsters' in text_content:
            publisher_found = 'Image Comics'
        elif 'dark horse' in text_content and 'little monsters' in text_content:
            publisher_found = 'Dark Horse Comics'
        elif 'idw' in text_content and 'little monsters' in text_content:
            publisher_found = 'IDW Publishing'
        elif 'boom studios' in text_content and 'little monsters' in text_content:
            publisher_found = 'Boom Studios'
        elif 'oni press' in text_content and 'little monsters' in text_content:
            publisher_found = 'Oni Press'
        
        if publisher_found:
            print(f"  ✓ Found connection: {publisher_found}")
            
            # Look for artist information in this context
            lines = text_content.split('\n')
            relevant_lines = []
            
            for line in lines:
                if ('little monsters' in line and 
                    publisher_found.lower().replace(' ', '') in line.replace(' ', '') and
                    any(kw in line for kw in ['artist', 'creator', 'illustrator'])):
                    relevant_lines.append(line.strip()[:150])
            
            search_results['publication_details'].append({
                'publisher': publisher_found,
                'query': query,
                'relevant_info': relevant_lines[:3]
            })
            
            if relevant_lines:
                print(f"    Relevant info found: {len(relevant_lines)} lines")
                for line in relevant_lines[:2]:
                    print(f"      {line[:80]}...")
        else:
            print(f"  No specific publisher connection found")
    
    time.sleep(2)

print("\nSTEP 3: Analyzing collected information for artist identification")
print("-" * 60)

# Analyze all collected search results
total_searches = len(search_results['search_attempts'])
successful_searches = len([s for s in search_results['search_attempts'] if s.get('status') != 'Failed'])

print(f"Total searches conducted: {total_searches}")
print(f"Successful searches: {successful_searches}")

# Compile potential artist names from all searches
all_artist_mentions = []
for search in search_results['search_attempts']:
    if 'artist_mentions' in search:
        all_artist_mentions.extend(search['artist_mentions'])

print(f"\nTotal artist mentions found: {len(all_artist_mentions)}")

if all_artist_mentions:
    print("\nSample artist mentions:")
    for mention in all_artist_mentions[:5]:
        print(f"  - {mention[:100]}...")

# Look for recurring names or patterns
print("\nAnalyzing mentions for potential artist names...")

# Common patterns that might indicate artist names
name_patterns = []
for mention in all_artist_mentions:
    # Look for "by [Name]" patterns
    
    # Pattern: "by [First Last]"
    by_pattern = re.findall(r'by\s+([A-Z][a-z]+\s+[A-Z][a-z]+)', mention)
    name_patterns.extend(by_pattern)
    
    # Pattern: "artist [First Last]"
    artist_pattern = re.findall(r'artist\s+([A-Z][a-z]+\s+[A-Z][a-z]+)', mention)
    name_patterns.extend(artist_pattern)
    
    # Pattern: "illustrated by [First Last]"
    illustrated_pattern = re.findall(r'illustrated\s+by\s+([A-Z][a-z]+\s+[A-Z][a-z]+)', mention)
    name_patterns.extend(illustrated_pattern)

if name_patterns:
    print(f"\nPotential artist names extracted: {len(name_patterns)}")
    # Count frequency of names
    name_frequency = Counter(name_patterns)
    
    print("Most frequently mentioned names:")
    for name, count in name_frequency.most_common(5):
        print(f"  {name}: mentioned {count} time(s)")
        
        search_results['artist_information'].append({
            'name': name,
            'frequency': count,
            'confidence': 'Medium' if count > 1 else 'Low'
        })
else:
    print("No clear artist names extracted from patterns")

# Save comprehensive search results
results_file = 'workspace/little_monsters_comprehensive_search.json'
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(search_results, f, indent=2, ensure_ascii=False)

print(f"\n✓ Comprehensive search results saved to: {results_file}")

print("\n" + "=" * 70)
print("LITTLE MONSTERS COMIC ARTIST SEARCH SUMMARY")
print("=" * 70)

if search_results['artist_information']:
    print("\n*** POTENTIAL ARTISTS IDENTIFIED ***")
    for artist in search_results['artist_information']:
        print(f"Artist: {artist['name']}")
        print(f"Confidence: {artist['confidence']} (mentioned {artist['frequency']} times)")
        print()
else:
    print("\n*** NO DEFINITIVE ARTIST IDENTIFIED FROM AUTOMATED EXTRACTION ***")
    print("However, search data has been collected for manual analysis.")
    print("\nPossible reasons for limited automated results:")
    print("1. Multiple comics may share the 'Little Monsters' title")
    print("2. The comic may be self-published or indie with limited online presence")
    print("3. Search results may not contain detailed creator credits in extractable format")
    print("4. The comic may be a webcomic or digital-only publication")

print("\nSearch completed. Raw search data available in workspace files for manual review.")
print("Files created:")
for file in os.listdir('workspace'):
    if file.endswith(('.html', '.json')):
        print(f"  - {file}")

print("\nNext steps: Manual review of HTML files may reveal additional artist information.")
print("The saved HTML files contain the actual Google search results for detailed inspection.")
```