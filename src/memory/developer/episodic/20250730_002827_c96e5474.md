### Development Step 5: Identify the First Name in Holabird & Roche Firm Title Order (June 2023)

**Description**: Research the architectural firm Holabird & Roche to determine the first name appearing in the firm's name as of June 2023. Focus on finding: (1) The complete firm name and any variations or successors, (2) The chronological order of names in the firm title, (3) Verify the firm's status and naming convention as of June 2023, (4) Confirm which name appears first alphabetically or positionally in the official firm designation. Look for the firm's current website, professional directories, architectural databases, and recent project listings to establish the exact naming format used in 2023.

**Use Cases**:
- Legal due diligence automation verifying the correct legal name of Holabird & Roche in municipal bidding documents for a Chicago construction contract.
- Architecture journalism fact-checking tool that scrapes firm websites and directories to confirm the positional ordering of partner names in “Holabird & Roche” for an upcoming Architectural Digest feature.
- Membership directory platform for the American Institute of Architects that uses web scraping and SERP API queries to populate and validate 2023 firm names and metadata.
- SEO auditing script targeting architectural firm websites, extracting title tags and meta descriptions from Holabird & Roche’s site to ensure consistent branding and keyword usage as of June 2023.
- Knowledge graph builder for an engineering reference database that extracts accurate firm name entities and tracks chronological name changes of Holabird & Roche from multiple web sources.
- Academic research assistant compiling a timeline of Chicago architectural firms by extracting and verifying firm name formats and succession data for a scholarly paper on early 20th-century architecture.
- CRM enrichment workflow that automatically updates account records with the current official name of Holabird & Roche as of June 2023, ensuring accurate partner identification in marketing automation.
- Chatbot training pipeline that pulls validated firm naming conventions and website metadata to provide reliable responses about architectural firms in user queries.

```
import os
import requests
from bs4 import BeautifulSoup
import time
import json

# Research the architectural firm Holabird & Roche
print('=== HOLABIRD & ROCHE ARCHITECTURAL FIRM RESEARCH ===')
print('Starting comprehensive research to determine firm name as of June 2023...')

# Get SerpAPI key for Google search
api_key = os.getenv("SERPAPI_API_KEY")

if api_key is None:
    print("Warning: No SERPAPI_API_KEY found. Will attempt direct web research.")
    
    # Direct web research approach - try to find the firm's official website
    print('\n=== DIRECT WEB RESEARCH APPROACH ===')
    
    # List of potential URLs for the firm
    potential_urls = [
        'https://www.holabirdroche.com',
        'https://www.hbr.com',
        'https://holabird-roche.com',
        'https://www.holabird-roche.com'
    ]
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    firm_info = {}
    
    for url in potential_urls:
        print(f'\nTrying URL: {url}')
        try:
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                print(f'SUCCESS: Found website at {url}')
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Extract title
                title = soup.find('title')
                if title:
                    print(f'Page title: {title.get_text().strip()}')
                    firm_info['page_title'] = title.get_text().strip()
                
                # Look for firm name in various places
                firm_name_indicators = []
                
                # Check meta tags
                meta_desc = soup.find('meta', attrs={'name': 'description'})
                if meta_desc and meta_desc.get('content'):
                    print(f'Meta description: {meta_desc.get("content")}')
                    firm_info['meta_description'] = meta_desc.get('content')
                
                # Look for h1 tags that might contain firm name
                h1_tags = soup.find_all('h1')
                for h1 in h1_tags[:3]:  # First 3 h1 tags
                    h1_text = h1.get_text().strip()
                    if h1_text:
                        print(f'H1 tag: {h1_text}')
                        firm_name_indicators.append(h1_text)
                
                # Look for navigation or header elements
                nav_elements = soup.find_all(['nav', 'header'])
                for nav in nav_elements[:2]:
                    nav_text = nav.get_text()[:200]  # First 200 chars
                    print(f'Navigation/Header snippet: {nav_text.strip()}')
                
                # Save the full HTML content for analysis
                firm_info['html_content'] = response.text
                firm_info['successful_url'] = url
                
                # Save findings to workspace
                with open('workspace/holabird_roche_website_data.json', 'w') as f:
                    json.dump({
                        'url': url,
                        'title': firm_info.get('page_title', ''),
                        'meta_description': firm_info.get('meta_description', ''),
                        'firm_name_indicators': firm_name_indicators,
                        'research_date': '2024',
                        'status': 'success'
                    }, f, indent=2)
                
                print(f'Website data saved to workspace/holabird_roche_website_data.json')
                break  # Found a working website, no need to try others
                
            else:
                print(f'Failed to access {url}: Status {response.status_code}')
        except Exception as e:
            print(f'Error accessing {url}: {e}')
    
    if 'successful_url' not in firm_info:
        print('\nNo direct website access successful. Will try alternative research methods.')
        
else:
    # Use SerpAPI for Google search
    print('\n=== GOOGLE SEARCH RESEARCH ===')
    
    # Search for the firm with various queries
    search_queries = [
        'Holabird Roche architectural firm 2023',
        'Holabird & Roche architects Chicago',
        '"Holabird & Roche" OR "Holabird Roche" architects website'
    ]
    
    search_results = []
    
    for query in search_queries:
        print(f'\nSearching: {query}')
        
        params = {
            "q": query,
            "api_key": api_key,
            "engine": "google",
            "google_domain": "google.com",
            "safe": "off",
            "num": 10,
        }
        
        try:
            response = requests.get("https://serpapi.com/search.json", params=params)
            
            if response.status_code == 200:
                results = response.json()
                
                if results.get("organic_results"):
                    print(f'Found {len(results["organic_results"])} results')
                    
                    for i, result in enumerate(results["organic_results"][:5]):  # Top 5 results
                        print(f'  {i+1}. {result.get("title", "No title")}')
                        print(f'     URL: {result.get("link", "No URL")}')
                        print(f'     Snippet: {result.get("snippet", "No snippet")[:150]}...')
                    
                    search_results.append({
                        'query': query,
                        'results': results["organic_results"][:5]
                    })
                else:
                    print(f'No results found for: {query}')
            else:
                print(f'Search API error: {response.status_code}')
                
        except Exception as e:
            print(f'Search error for "{query}": {e}')
        
        time.sleep(1)  # Be respectful to API
    
    # Save search results
    if search_results:
        with open('workspace/holabird_roche_search_results.json', 'w') as f:
            json.dump({
                'search_results': search_results,
                'research_date': '2024',
                'purpose': 'Determine Holabird & Roche firm name as of June 2023'
            }, f, indent=2)
        print(f'\nSearch results saved to workspace/holabird_roche_search_results.json')

print('\n=== INITIAL RESEARCH PHASE COMPLETE ===')
print('Next step: Analyze findings to determine the exact firm name format as of June 2023')
```