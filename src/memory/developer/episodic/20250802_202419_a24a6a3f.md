### Development Step 12: Locate 2011 Bulgarian Census Data on Tertiary Education Completion by Gender

**Description**: Search for the 2011 Bulgarian census data on tertiary education completion by gender. Look for official census results from Bulgaria's National Statistical Institute or other authoritative sources that provide the specific breakdown of men and women who completed tertiary education in 2011.

**Use Cases**:
- Government education policy analysis for the Bulgarian Ministry of Education to allocate funding where gender gaps in 2011 tertiary completion are highest
- Market research for an HR consultancy mapping regional tertiary education levels by gender to advise multinational employers entering Bulgaria
- NGO program planning that targets districts with low female university graduation rates for girlsâ€™ scholarship initiatives
- Academic comparative study on EU gender parity in higher education by aggregating 2011 census stats from Bulgaria alongside other member states
- Data journalism workflow automating extraction of Bulgarian NSI tables to power interactive online visualizations of tertiary education trends
- Business intelligence dashboard integration that enriches workforce talent data with gender-segmented tertiary education completion rates in Bulgaria
- ETL automation in a demographic data warehouse, ingesting and normalizing 2011 Bulgarian census education tables nightly
- Open-data platform development exposing cleaned Bulgarian tertiary education by gender via REST APIs for third-party app developers

```
import os
import json
from bs4 import BeautifulSoup
import re
import time

print("=== BULGARIAN 2011 CENSUS TERTIARY EDUCATION BY GENDER - CORRECTED ANALYSIS ===")
print("Objective: Extract tertiary education completion statistics by gender from 2011 Bulgarian census")
print("Strategy: Fixed variable scoping with immediate lowercase creation\n")

# Check workspace
workspace_path = 'workspace'
if not os.path.exists(workspace_path):
    print("No workspace directory found")
    exit()

all_files = os.listdir(workspace_path)
html_files = [f for f in all_files if f.endswith('.html')]

print(f"Total files in workspace: {len(all_files)}")
print(f"HTML files available: {len(html_files)}")

# Show all HTML files to understand what we have
print("\n=== HTML FILES INVENTORY ===\n")
for i, html_file in enumerate(html_files, 1):
    filepath = os.path.join(workspace_path, html_file)
    file_size = os.path.getsize(filepath)
    print(f"{i:2d}. {html_file}")
    print(f"    Size: {file_size:,} bytes")

# Identify most promising files
priority_files = []
for filename in html_files:
    filepath = os.path.join(workspace_path, filename)
    file_size = os.path.getsize(filepath)
    
    # Skip very small files
    if file_size < 20000:  # Less than 20KB likely error pages
        continue
    
    filename_lower = filename.lower()
    score = 0
    
    if 'demographics' in filename_lower:
        score += 5
    if 'education' in filename_lower:
        score += 5
    if 'census' in filename_lower:
        score += 4
    if 'bulgaria' in filename_lower:
        score += 3
    if 'nsi' in filename_lower:
        score += 3
    if 'eurostat' in filename_lower:
        score += 2
    
    if score > 0:
        priority_files.append({
            'filename': filename,
            'score': score,
            'size': file_size
        })

priority_files.sort(key=lambda x: x['score'], reverse=True)

print(f"\nPriority files for analysis: {len(priority_files)}")
for i, pf in enumerate(priority_files[:5], 1):
    print(f"{i}. {pf['filename']} (Score: {pf['score']}, Size: {pf['size']:,} bytes)")

print("\n=== ANALYZING TOP FILES WITH CORRECTED VARIABLE HANDLING ===\n")

# Results storage
analysis_results = []
tertiary_education_findings = []

# Analyze top 3 files
for file_info in priority_files[:3]:
    filename = file_info['filename']
    print(f"Analyzing: {filename}")
    
    filepath = os.path.join(workspace_path, filename)
    
    try:
        # Read HTML file
        with open(filepath, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        # Parse HTML
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Get page title
        title_element = soup.find('title')
        page_title = title_element.get_text().strip() if title_element else 'No title'
        
        # Extract all text content
        page_text = soup.get_text()
        
        # CRITICAL FIX: Create lowercase version IMMEDIATELY after page_text extraction
        page_text_lower = page_text.lower()
        
        print(f"  Title: {page_title}")
        print(f"  Content length: {len(page_text):,} characters")
        
        # Now check for key indicators using the properly defined variable
        has_bulgaria = 'bulgaria' in page_text_lower or 'bulgarian' in page_text_lower
        has_2011 = '2011' in page_text_lower
        has_census = 'census' in page_text_lower
        has_tertiary = any(term in page_text_lower for term in ['tertiary', 'tertiary education', 'higher education'])
        has_gender = any(term in page_text_lower for term in ['men', 'women', 'male', 'female', 'gender', 'sex'])
        has_education = 'education' in page_text_lower
        
        relevance_score = sum([has_bulgaria, has_2011, has_census, has_tertiary, has_gender, has_education])
        
        print(f"  Bulgaria: {has_bulgaria} | 2011: {has_2011} | Census: {has_census}")
        print(f"  Tertiary: {has_tertiary} | Gender: {has_gender} | Education: {has_education}")
        print(f"  Relevance score: {relevance_score}/6")
        
        if relevance_score >= 3:  # Lower threshold to catch more data
            print(f"  *** RELEVANT SOURCE - EXTRACTING DATA ***")
            
            # Search for tertiary education statistics by gender
            education_patterns = [
                r'tertiary education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'(?:men|women|male|female)[^.]*?tertiary education[^.]*?(\d+[.,]?\d*\s*%?)',
                r'higher education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'(?:men|women|male|female)[^.]*?higher education[^.]*?(\d+[.,]?\d*\s*%?)',
                r'university[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'completed[^.]*?tertiary[^.]*?(\d+[.,]?\d*\s*%?)',
                r'2011[^.]*?education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'census[^.]*?2011[^.]*?education[^.]*?(\d+[.,]?\d*\s*%?)'
            ]
            
            pattern_matches = []
            for pattern in education_patterns:
                matches = re.finditer(pattern, page_text, re.IGNORECASE | re.DOTALL)
                for match in matches:
                    # Get context around the match
                    start = max(0, match.start() - 250)
                    end = min(len(page_text), match.end() + 250)
                    context = page_text[start:end].strip()
                    
                    # Ensure context mentions Bulgaria
                    context_lower = context.lower()
                    if 'bulgaria' in context_lower or 'bulgarian' in context_lower:
                        pattern_matches.append({
                            'match_text': match.group(),
                            'context': context,
                            'pattern_used': pattern,
                            'source_file': filename
                        })
            
            print(f"  Pattern matches found: {len(pattern_matches)}")
            
            # Look for sentences with education and gender data
            relevant_sentences = []
            sentences = page_text.split('.')
            
            for sentence in sentences:
                sentence_clean = sentence.strip()
                if len(sentence_clean) < 30:  # Skip very short sentences
                    continue
                
                sentence_lower = sentence_clean.lower()
                
                # Check for Bulgaria + education + numbers + gender
                has_bulgaria_ref = 'bulgaria' in sentence_lower or 'bulgarian' in sentence_lower
                has_education_ref = any(term in sentence_lower for term in 
                                      ['education', 'tertiary', 'university', 'higher', 'degree', 'graduate'])
                has_numbers = bool(re.search(r'\d+[.,]?\d*\s*%?', sentence_clean))
                has_gender_ref = any(term in sentence_lower for term in ['men', 'women', 'male', 'female'])
                has_year_ref = '2011' in sentence_lower
                
                if has_bulgaria_ref and has_education_ref and has_numbers and (has_gender_ref or has_year_ref):
                    relevant_sentences.append(sentence_clean)
            
            print(f"  Relevant sentences: {len(relevant_sentences)}")
            
            # Look for tables with education data
            tables = soup.find_all('table')
            education_tables = []
            
            for table_idx, table in enumerate(tables):
                table_text = table.get_text().lower()
                
                # Check if table has education and gender information
                has_education_content = any(term in table_text for term in 
                                          ['education', 'tertiary', 'university', 'degree'])
                has_gender_content = any(term in table_text for term in 
                                       ['men', 'women', 'male', 'female', 'gender'])
                
                if has_education_content and has_gender_content:
                    # Extract table headers
                    headers = [th.get_text().strip() for th in table.find_all('th')]
                    
                    # Extract sample rows
                    rows = table.find_all('tr')
                    sample_rows = []
                    
                    for row in rows[1:4]:  # Skip header, take next 3 rows
                        cells = [cell.get_text().strip() for cell in row.find_all(['td', 'th'])]
                        if cells and any(cell for cell in cells if cell.strip()):
                            sample_rows.append(cells)
                    
                    education_tables.append({
                        'table_index': table_idx,
                        'headers': headers,
                        'sample_rows': sample_rows,
                        'total_rows': len(rows)
                    })
            
            print(f"  Education tables found: {len(education_tables)}")
            
            # Store analysis results
            analysis_result = {
                'filename': filename,
                'title': page_title,
                'content_length': len(page_text),
                'relevance_score': relevance_score,
                'pattern_matches': pattern_matches[:3],  # Top 3 matches
                'relevant_sentences': relevant_sentences[:3],  # Top 3 sentences
                'education_tables': education_tables[:2],  # Top 2 tables
                'indicators': {
                    'bulgaria': has_bulgaria,
                    '2011': has_2011,
                    'census': has_census,
                    'tertiary': has_tertiary,
                    'gender': has_gender,
                    'education': has_education
                }
            }
            
            analysis_results.append(analysis_result)
            
            # Add findings to main list
            for match in pattern_matches:
                tertiary_education_findings.append({
                    'type': 'statistical_pattern',
                    'source_file': filename,
                    'match': match['match_text'],
                    'context': match['context'],
                    'pattern': match['pattern_used']
                })
            
            for sentence in relevant_sentences:
                tertiary_education_findings.append({
                    'type': 'relevant_sentence',
                    'source_file': filename,
                    'content': sentence
                })
            
            # Display key findings
            if pattern_matches:
                print(f"  Key match: {pattern_matches[0]['match_text']}")
                print(f"  Context: {pattern_matches[0]['context'][:150]}...")
            
            if relevant_sentences:
                print(f"  Key sentence: {relevant_sentences[0][:200]}...")
            
            if education_tables:
                print(f"  Table headers: {education_tables[0]['headers'][:5]}")
        
        else:
            print(f"  Lower relevance (score {relevance_score}) - basic analysis only")
            analysis_results.append({
                'filename': filename,
                'title': page_title,
                'content_length': len(page_text),
                'relevance_score': relevance_score,
                'basic_analysis': True
            })
        
        print()
        
    except Exception as e:
        print(f"  ERROR analyzing {filename}: {str(e)}")
        print()

# Save results
print("=== SAVING FINAL RESULTS ===\n")

final_results = {
    'search_objective': 'Bulgarian 2011 census tertiary education completion by gender',
    'analysis_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'html_files_total': len(html_files),
    'priority_files_identified': len(priority_files),
    'files_successfully_analyzed': len(analysis_results),
    'tertiary_education_findings_count': len(tertiary_education_findings),
    'detailed_analysis_results': analysis_results,
    'tertiary_education_findings': tertiary_education_findings
}

results_file = os.path.join(workspace_path, 'bulgarian_2011_census_tertiary_education_final_results.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(final_results, f, indent=2, ensure_ascii=False)

print(f"Final results saved to: {results_file}")
print(f"Total HTML files: {len(html_files)}")
print(f"Files analyzed: {len(analysis_results)}")
print(f"Tertiary education findings: {len(tertiary_education_findings)}")

# Display summary of findings
if tertiary_education_findings:
    print("\n=== TERTIARY EDUCATION FINDINGS SUMMARY ===\n")
    
    statistical_patterns = [f for f in tertiary_education_findings if f['type'] == 'statistical_pattern']
    relevant_sentences = [f for f in tertiary_education_findings if f['type'] == 'relevant_sentence']
    
    print(f"Statistical patterns found: {len(statistical_patterns)}")
    print(f"Relevant sentences found: {len(relevant_sentences)}")
    
    # Show top findings
    print("\nTop findings:")
    for i, finding in enumerate(tertiary_education_findings[:6], 1):
        print(f"{i}. Type: {finding['type']}")
        print(f"   Source: {finding['source_file']}")
        
        if finding['type'] == 'statistical_pattern':
            print(f"   Match: {finding['match']}")
            print(f"   Context: {finding['context'][:150]}...")
        else:
            print(f"   Content: {finding['content'][:180]}...")
        print()

else:
    print("\n=== NO SPECIFIC FINDINGS ===\n")
    print("The analyzed files did not contain specific 2011 Bulgarian census")
    print("tertiary education completion statistics by gender.")
    print("This suggests the data may be:")
    print("1. In a different format or section")
    print("2. Using different terminology")
    print("3. Requiring more specific official sources")

print("\n=== ANALYSIS COMPLETE ===\n")
print("Bulgarian 2011 census tertiary education analysis completed successfully")
print("All findings systematically extracted and saved for review")
```