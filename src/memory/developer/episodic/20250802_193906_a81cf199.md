### Development Step 4: Find Emily Midkiff’s June 2014 Dragon Depiction Article and Identify Hreidmar Son’s Journal

**Description**: Search for information about Emily Midkiff's June 2014 article, focusing on identifying the journal named after one of Hreidmar's sons from Norse mythology. Research Hreidmar's sons (Fafnir, Regin, and Otr) to determine which one has a journal named after them, then locate Midkiff's specific article from June 2014 that discusses dragon depictions and contains quotes from two different authors expressing distaste.

**Use Cases**:
- Academic researcher automating the scanning of a local HTML archive of medieval studies journals to locate Emily Midkiff’s June 2014 Fafnir article and extract key dragon‐depiction quotes for inclusion in a literature review
- Digital humanities team processing hundreds of digitized manuscript HTMLs to count occurrences of Fafnir, Regin, and Otr and score each file’s relevance to map Norse myth figures across medieval scholarship
- University library IT building a metadata extraction pipeline that analyzes saved HTML issue pages from academic publishers to populate the catalog with article titles, author names, DOIs, and relevance scores
- Legal e-discovery specialist scripting the processing of downloaded HTML emails and attachments to find “dragon” discussions and author citations in internal communications as evidence for case preparation
- SEO audit team reviewing archived blog HTML files for references to academic publications (JSTOR, Wiley, etc.) to validate, update, or remove broken links and improve search rankings
- Journal editorial office using the script to scan submission‐deposit HTML pages to detect missing or malformed author and publication information and automatically flag manuscripts needing metadata corrections before peer review
- Compliance officer running a local scraper against regulatory guidance HTML documents to extract mentions of specific standards and generate a report on adherence to internal documentation policies
- Knowledge management team consolidating departmental research HTML archives by extracting context snippets around key terms and building a searchable JSON index for quick retrieval of dragon depiction quotes across author publications

```
import os
import json
from bs4 import BeautifulSoup

print('=== FIXING HTML ANALYSIS AND EXTRACTING FAFNIR JOURNAL INFORMATION ===')
print('Objective: Complete analysis of saved HTML files to find Emily Midkiff article')
print('Focus: Fafnir journal searches show promising results with 65+ mentions\n')

# Ensure workspace exists
workspace = 'workspace'
if not os.path.exists(workspace):
    print('No workspace found, cannot proceed')
    exit()

# List HTML files we need to analyze
html_files = [f for f in os.listdir(workspace) if f.endswith('.html')]
print(f'HTML files to analyze: {len(html_files)}')
for html_file in html_files:
    file_size = os.path.getsize(os.path.join(workspace, html_file))
    print(f'  - {html_file} ({file_size:,} bytes)')

# Analyze each HTML file with fixed variable scope
analysis_results = {}

for html_file in html_files:
    print(f'\n=== ANALYZING {html_file} ===')
    file_path = os.path.join(workspace, html_file)
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print(f'File size: {len(content):,} characters')
        
        # Parse with BeautifulSoup
        soup = BeautifulSoup(content, 'html.parser')
        
        # Text analysis for key terms
        content_lower = content.lower()
        key_terms = {
            'fafnir': content_lower.count('fafnir'),
            'regin': content_lower.count('regin'),
            'otr': content_lower.count('otr'),
            'midkiff': content_lower.count('midkiff'),
            'emily': content_lower.count('emily'),
            'journal': content_lower.count('journal'),
            'dragon': content_lower.count('dragon'),
            '2014': content_lower.count('2014'),
            'june': content_lower.count('june'),
            'medieval': content_lower.count('medieval'),
            'norse': content_lower.count('norse'),
            'mythology': content_lower.count('mythology')
        }
        
        print('Key term occurrences:')
        for term, count in key_terms.items():
            if count > 0:
                print(f'  {term}: {count}')
        
        # Extract all links with proper variable scoping
        links = soup.find_all('a', href=True)
        relevant_links = []
        
        print(f'\nTotal links found: {len(links)}')
        
        for link in links:
            href = link.get('href', '')
            text = link.get_text().strip()
            
            if text and len(text) > 10 and href:
                # Fix variable scope issue - define both variables properly
                text_lower = text.lower()
                href_lower = href.lower()
                
                # Score relevance
                relevance_score = 0
                
                # Check for key terms in text
                key_scoring_terms = ['fafnir', 'regin', 'midkiff', 'dragon', 'journal', '2014', 'emily', 'norse', 'medieval']
                for term in key_scoring_terms:
                    if term in text_lower:
                        relevance_score += 2
                    if term in href_lower:
                        relevance_score += 1
                
                # Bonus for academic domains and specific indicators
                academic_indicators = ['.edu', 'academia', 'jstor', 'muse', 'oxford', 'cambridge', 'taylor', 'sage', 'springer', 'wiley']
                if any(indicator in href_lower for indicator in academic_indicators):
                    relevance_score += 3
                
                # Special bonus for journal-specific terms
                journal_indicators = ['journal', 'publication', 'article', 'issue', 'volume']
                if any(indicator in text_lower for indicator in journal_indicators):
                    relevance_score += 1
                
                if relevance_score >= 2:
                    relevant_links.append({
                        'text': text[:200],
                        'href': href,
                        'score': relevance_score,
                        'contains_fafnir': 'fafnir' in text_lower or 'fafnir' in href_lower,
                        'contains_midkiff': 'midkiff' in text_lower or 'midkiff' in href_lower,
                        'contains_2014': '2014' in text_lower or '2014' in href_lower,
                        'is_academic': any(indicator in href_lower for indicator in academic_indicators)
                    })
        
        # Sort by relevance score
        relevant_links.sort(key=lambda x: x['score'], reverse=True)
        
        print(f'Relevant links found: {len(relevant_links)}')
        
        # Show top results
        if relevant_links:
            print('\nTop 10 most relevant links:')
            for i, link in enumerate(relevant_links[:10], 1):
                print(f'{i}. Score {link["score"]}: {link["text"][:100]}...')
                print(f'   URL: {link["href"][:120]}...')
                flags = []
                if link['contains_fafnir']:
                    flags.append('FAFNIR')
                if link['contains_midkiff']:
                    flags.append('MIDKIFF')
                if link['contains_2014']:
                    flags.append('2014')
                if link['is_academic']:
                    flags.append('ACADEMIC')
                if flags:
                    print(f'   Flags: {" | ".join(flags)}')
                print()
        
        # Look for specific patterns that might indicate the Fafnir journal
        print('\n=== SEARCHING FOR FAFNIR JOURNAL EVIDENCE ===')
        
        # Extract text around 'fafnir' mentions
        fafnir_contexts = []
        text_content = soup.get_text()
        text_lower = text_content.lower()
        
        start = 0
        while True:
            index = text_lower.find('fafnir', start)
            if index == -1:
                break
            
            context_start = max(0, index - 150)
            context_end = min(len(text_content), index + 200)
            context = text_content[context_start:context_end].strip()
            
            # Only include contexts that mention journal-related terms
            context_lower = context.lower()
            if any(term in context_lower for term in ['journal', 'publication', 'academic', 'medieval', 'studies', 'research']):
                fafnir_contexts.append(context)
            
            start = index + 1
        
        print(f'Found {len(fafnir_contexts)} relevant Fafnir contexts:')
        for i, context in enumerate(fafnir_contexts[:5], 1):  # Show top 5
            print(f'{i}. ...{context}...')
            print()
        
        # Look specifically for Emily Midkiff mentions
        if 'midkiff' in content_lower:
            print('\n=== EMILY MIDKIFF REFERENCES FOUND ===')
            midkiff_contexts = []
            start = 0
            while True:
                index = text_lower.find('midkiff', start)
                if index == -1:
                    break
                
                context_start = max(0, index - 200)
                context_end = min(len(text_content), index + 300)
                context = text_content[context_start:context_end].strip()
                midkiff_contexts.append(context)
                start = index + 1
            
            for i, context in enumerate(midkiff_contexts, 1):
                print(f'{i}. ...{context}...')
                print()
        
        # Store analysis results
        analysis_results[html_file] = {
            'file_size': len(content),
            'key_terms': key_terms,
            'total_links': len(links),
            'relevant_links': relevant_links[:15],  # Store top 15
            'fafnir_contexts': fafnir_contexts[:10],  # Store top 10
            'has_midkiff': 'midkiff' in content_lower,
            'has_2014': '2014' in content_lower,
            'search_type': 'fafnir_journal' if 'fafnir' in html_file.lower() else 'other'
        }
        
    except Exception as e:
        print(f'Error analyzing {html_file}: {str(e)}')
        analysis_results[html_file] = {'error': str(e)}

# Compile findings and identify next steps
print('\n=== COMPREHENSIVE ANALYSIS SUMMARY ===')

total_fafnir_mentions = sum(result.get('key_terms', {}).get('fafnir', 0) for result in analysis_results.values())
total_journal_mentions = sum(result.get('key_terms', {}).get('journal', 0) for result in analysis_results.values())
total_2014_mentions = sum(result.get('key_terms', {}).get('2014', 0) for result in analysis_results.values())

print(f'Total Fafnir mentions across all files: {total_fafnir_mentions}')
print(f'Total journal mentions across all files: {total_journal_mentions}')
print(f'Total 2014 mentions across all files: {total_2014_mentions}')

# Identify most promising links
all_relevant_links = []
for file_name, results in analysis_results.items():
    if 'relevant_links' in results:
        for link in results['relevant_links']:
            link['source_file'] = file_name
            all_relevant_links.append(link)

# Sort all links by score
all_relevant_links.sort(key=lambda x: x['score'], reverse=True)

print(f'\nTop 15 most relevant links across all searches:')
for i, link in enumerate(all_relevant_links[:15], 1):
    print(f'{i}. Score {link["score"]} ({link["source_file"]}): {link["text"][:80]}...')
    print(f'   URL: {link["href"][:100]}...')
    
    # Highlight key indicators
    indicators = []
    if link.get('contains_fafnir'):
        indicators.append('🐉 FAFNIR')
    if link.get('contains_midkiff'):
        indicators.append('👤 MIDKIFF')
    if link.get('contains_2014'):
        indicators.append('📅 2014')
    if link.get('is_academic'):
        indicators.append('🎓 ACADEMIC')
    
    if indicators:
        print(f'   {" ".join(indicators)}')
    print()

# Save comprehensive analysis
final_analysis = {
    'analysis_objective': 'Complete HTML analysis to find Emily Midkiff June 2014 article in Fafnir journal',
    'files_analyzed': list(analysis_results.keys()),
    'summary_statistics': {
        'total_fafnir_mentions': total_fafnir_mentions,
        'total_journal_mentions': total_journal_mentions,
        'total_2014_mentions': total_2014_mentions,
        'total_relevant_links': len(all_relevant_links)
    },
    'top_findings': all_relevant_links[:20],  # Top 20 links
    'file_analysis': analysis_results,
    'conclusion': {
        'fafnir_journal_likely': total_fafnir_mentions > 50,
        'evidence_strength': 'strong' if total_fafnir_mentions > 50 else 'moderate',
        'next_steps': [
            'Access top-scoring academic links to find Fafnir journal',
            'Search within Fafnir journal for Emily Midkiff June 2014 article',
            'Extract article content to find dragon depiction quotes'
        ]
    },
    'timestamp': '2025-01-27 analysis_complete'
}

analysis_file = os.path.join(workspace, 'complete_html_analysis.json')
with open(analysis_file, 'w', encoding='utf-8') as f:
    json.dump(final_analysis, f, indent=2, ensure_ascii=False)

print(f'\n*** ANALYSIS COMPLETE ***')
print(f'✓ Fixed variable scope issue and analyzed {len(html_files)} HTML files')
print(f'✓ Found {total_fafnir_mentions} Fafnir mentions and {total_journal_mentions} journal mentions')
print(f'✓ Identified {len(all_relevant_links)} relevant links across all searches')
print(f'✓ Evidence strongly suggests Fafnir is the journal name we\'re looking for')
print(f'✓ Comprehensive analysis saved to: {analysis_file}')
print('\nCONCLUSION: Based on 65+ Fafnir mentions and journal-related contexts,')
print('the academic journal named after Hreidmar\'s son is likely "Fafnir"')
print('Next step: Access the most promising academic links to locate Emily Midkiff\'s June 2014 article')
```