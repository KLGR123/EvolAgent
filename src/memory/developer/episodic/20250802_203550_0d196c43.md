### Development Step 33: Locate 2011 Bulgarian Census Tertiary Education Completion by Gender

**Description**: Search for the official 2011 Bulgarian census data from the Bulgarian National Statistical Institute (NSI) or other authoritative government sources that specifically contain the tertiary education completion numbers by gender. Focus on finding the exact counts or percentages of men and women who completed tertiary education according to the 2011 census results.

**Use Cases**:
- Gender gap policy evaluation and regional disparity mapping for government education ministries
- Higher education enrollment forecasting and capacity planning for Bulgarian universities
- Labor market skills development analysis and targeted training program design for workforce agencies
- EdTech product market segmentation by gender and regional uptake trends for online learning platforms
- Sociological research on educational attainment and gender parity progression in academic studies
- Data journalism dashboard creation and interactive visualization of tertiary education gender statistics
- NGO program impact assessment and advocacy reporting on women’s access to higher education

```
import os
import requests
from bs4 import BeautifulSoup
import time
import json
import re

# Create workspace directory
workspace_dir = 'workspace'
os.makedirs(workspace_dir, exist_ok=True)

print("=== SEARCHING FOR OFFICIAL 2011 BULGARIAN CENSUS TERTIARY EDUCATION DATA BY GENDER ===")
print("\nObjective: Find exact counts/percentages of men and women who completed tertiary education")
print("Source target: Bulgarian National Statistical Institute (NSI) official census data\n")

# Set up headers for web requests
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Connection': 'keep-alive'
}

# Official NSI URLs to search for 2011 census education data
nsi_urls = [
    'https://www.nsi.bg/en/content/6704/population-census-2011',
    'https://www.nsi.bg/en/content/6710/population-education',
    'https://www.nsi.bg/en/content/census-2011',
    'https://www.nsi.bg/en',
    'https://www.nsi.bg/census2011/indexen.php',
    'https://www.nsi.bg/en/content/population-census-2011-main-results'
]

print("=== PHASE 1: ACCESSING OFFICIAL NSI CENSUS SOURCES ===")

successful_sources = []
failed_sources = []

for i, url in enumerate(nsi_urls, 1):
    print(f"\n{i}. Attempting to access: {url}")
    
    try:
        response = requests.get(url, headers=headers, timeout=20)
        print(f"   Status code: {response.status_code}")
        
        if response.status_code == 200:
            print(f"   ✓ Successfully accessed")
            
            # Save the HTML content
            filename = url.replace('https://', '').replace('http://', '').replace('/', '_').replace('.', '_').replace(':', '_') + '.html'
            filepath = os.path.join(workspace_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            print(f"   Content saved to: {filename}")
            print(f"   Content length: {len(response.text):,} characters")
            
            # Quick analysis for education/census content
            soup = BeautifulSoup(response.content, 'html.parser')
            title = soup.find('title')
            title_text = title.get_text().strip() if title else 'No title'
            
            # Check for relevant content indicators
            content_text = soup.get_text().lower()
            
            # Key indicators for our target data
            indicators = {
                'census_2011': content_text.count('2011'),
                'education': content_text.count('education'),
                'tertiary': content_text.count('tertiary'),
                'higher_education': content_text.count('higher education'),
                'university': content_text.count('university'),
                'gender': content_text.count('gender'),
                'male': content_text.count('male'),
                'female': content_text.count('female'),
                'men': content_text.count(' men '),
                'women': content_text.count('women')
            }
            
            # Count tables (potential data containers)
            tables = soup.find_all('table')
            table_count = len(tables)
            
            # Calculate relevance score
            relevance_score = sum(indicators.values()) + (table_count * 2)
            
            source_info = {
                'url': url,
                'filename': filename,
                'title': title_text,
                'content_length': len(response.text),
                'table_count': table_count,
                'indicators': indicators,
                'relevance_score': relevance_score,
                'status': 'success'
            }
            
            successful_sources.append(source_info)
            
            print(f"   Title: {title_text}")
            print(f"   Tables found: {table_count}")
            print(f"   Relevance score: {relevance_score}")
            
            # Show key indicator counts
            relevant_indicators = {k: v for k, v in indicators.items() if v > 0}
            if relevant_indicators:
                print(f"   Key terms found: {relevant_indicators}")
            
        else:
            print(f"   ✗ Failed - Status: {response.status_code}")
            failed_sources.append({'url': url, 'status': response.status_code, 'error': 'HTTP error'})
            
    except requests.exceptions.RequestException as e:
        print(f"   ✗ Request failed: {str(e)}")
        failed_sources.append({'url': url, 'error': str(e), 'status': 'request_failed'})
    
    # Be respectful to the server
    time.sleep(2)

print(f"\n=== PHASE 1 RESULTS ===")
print(f"Successfully accessed: {len(successful_sources)} sources")
print(f"Failed to access: {len(failed_sources)} sources")

# Sort sources by relevance score
if successful_sources:
    successful_sources.sort(key=lambda x: x['relevance_score'], reverse=True)
    
    print(f"\n=== TOP PRIORITY SOURCES (by relevance score) ===")
    for i, source in enumerate(successful_sources[:3], 1):
        print(f"\n{i}. {source['url']}")
        print(f"   Title: {source['title']}")
        print(f"   Relevance score: {source['relevance_score']}")
        print(f"   Tables: {source['table_count']}")
        print(f"   Key indicators: {source['indicators']}")
        
        if source['relevance_score'] > 10:
            print(f"   *** HIGH PRIORITY - Contains multiple education/census indicators ***")

# Save search results summary
search_summary = {
    'search_objective': '2011 Bulgarian Census - Tertiary Education Completion by Gender',
    'search_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'urls_attempted': len(nsi_urls),
    'successful_sources': len(successful_sources),
    'failed_sources': len(failed_sources),
    'source_details': successful_sources,
    'failed_attempts': failed_sources
}

summary_file = os.path.join(workspace_dir, 'nsi_census_search_results.json')
with open(summary_file, 'w', encoding='utf-8') as f:
    json.dump(search_summary, f, indent=2, ensure_ascii=False)

print(f"\nSearch results saved to: {summary_file}")

if successful_sources:
    print(f"\n=== NEXT PHASE ===")
    print(f"Will analyze the {len(successful_sources)} successfully downloaded NSI sources")
    print(f"Priority focus on sources with highest relevance scores")
    print(f"Looking for census tables with tertiary education data broken down by gender")
else:
    print(f"\n=== NO SOURCES ACCESSED ===")
    print(f"All NSI URLs failed to load. May need to try alternative search methods.")
    print(f"Consider searching for Bulgarian census publications or statistical yearbooks.")

print(f"\n=== FILES CREATED IN WORKSPACE ===")
for filename in os.listdir(workspace_dir):
    filepath = os.path.join(workspace_dir, filename)
    if os.path.isfile(filepath):
        size = os.path.getsize(filepath)
        print(f"  {filename} ({size:,} bytes)")
```