### Development Step 7: Extract Moon’s Minimum Perigee Distance from Wikipedia for Earth-Moon Closest Approach Calculation

**Description**: Access the Wikipedia page for the Moon and locate the minimum perigee distance value in the orbital characteristics or distance data section. Extract this specific measurement and note the units (likely in kilometers) for use in calculating the Earth-Moon distance at closest approach.

**Use Cases**:
- Lunar mission planning and trajectory optimization in aerospace engineering platforms using automated perigee distance updates
- Satellite orbit perturbation analysis for Earth observation companies assessing lunar gravitational influences at closest approach
- Live planetarium projection systems automatically updating Earth–Moon separation visuals based on the current minimum perigee distance
- Educational mobile and web applications generating interactive supermoon countdowns with accurate perigee measurements
- Data journalism pipelines producing automated infographics for news outlets covering supermoon events and lunar exploration milestones
- Virtual reality spacewalk experiences adjusting scale and distance to the Moon for immersive astronaut training modules
- Oceanographic research tools correlating extreme tidal events with lunar perigee distances for coastal risk management studies
- Realistic space exploration game engines fetching authentic lunar orbital parameters to enhance in-game physics fidelity

```
import requests
from bs4 import BeautifulSoup
import json
import re
import os

print("=== MOON WIKIPEDIA PAGE ACCESS AND PERIGEE DISTANCE EXTRACTION ===")
print("Objective: Find minimum perigee distance from Moon's Wikipedia page")
print("Focus: Locate orbital characteristics section and extract distance measurement\n")

# Create workspace directory if it doesn't exist
os.makedirs('workspace', exist_ok=True)

# Access the Wikipedia page for the Moon
url = "https://en.wikipedia.org/wiki/Moon"
print(f"Accessing Wikipedia page: {url}")

# Set up headers to mimic browser request
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Accept-Encoding': 'gzip, deflate',
    'Connection': 'keep-alive'
}

try:
    response = requests.get(url, headers=headers, timeout=30)
    
    if response.status_code == 200:
        print(f"✓ Successfully accessed Moon Wikipedia page")
        print(f"Content length: {len(response.content):,} bytes")
        
        # Save the HTML content
        html_file = 'workspace/moon_wikipedia.html'
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(response.text)
        print(f"HTML content saved to: {html_file}")
        
        # Parse the HTML content
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Extract the page title for verification
        page_title = soup.find('title')
        if page_title:
            print(f"Page title: {page_title.get_text().strip()}")
        
        # Look for orbital characteristics or distance-related sections
        print(f"\n=== SEARCHING FOR ORBITAL CHARACTERISTICS SECTIONS ===")
        
        # Find headings that might contain orbital data
        orbital_headings = []
        headings = soup.find_all(['h1', 'h2', 'h3', 'h4'], string=re.compile(r'orbit|distance|characteristic|perigee|apogee', re.IGNORECASE))
        
        for heading in headings:
            heading_text = heading.get_text().strip()
            print(f"Found relevant heading: {heading_text}")
            orbital_headings.append({
                'text': heading_text,
                'tag': heading.name,
                'element': heading
            })
        
        # Also look for infobox which typically contains orbital data
        print(f"\n=== SEARCHING FOR INFOBOX DATA ===")
        
        infobox = soup.find('table', class_=re.compile(r'infobox', re.IGNORECASE))
        if infobox:
            print("✓ Found infobox table")
            
            # Extract all rows from infobox
            infobox_data = []
            rows = infobox.find_all('tr')
            
            for row in rows:
                # Get the label and value from each row
                cells = row.find_all(['th', 'td'])
                if len(cells) >= 2:
                    label = cells[0].get_text().strip()
                    value = cells[1].get_text().strip()
                    
                    # Look for distance, perigee, or orbital data
                    if any(keyword in label.lower() for keyword in ['distance', 'perigee', 'apogee', 'orbit', 'semi-major']):
                        print(f"Orbital data found - {label}: {value}")
                        infobox_data.append({
                            'label': label,
                            'value': value,
                            'raw_html': str(row)
                        })
        
        # Search for specific perigee distance patterns in the entire page text
        print(f"\n=== SEARCHING FOR PERIGEE DISTANCE PATTERNS ===")
        
        page_text = soup.get_text()
        
        # Common patterns for perigee distance
        perigee_patterns = [
            r'perigee[^\n]*?(\d+[,\d]*\.?\d*)\s*km',
            r'minimum distance[^\n]*?(\d+[,\d]*\.?\d*)\s*km',
            r'closest approach[^\n]*?(\d+[,\d]*\.?\d*)\s*km',
            r'(\d+[,\d]*\.?\d*)\s*km[^\n]*perigee',
            r'perigee.*?(\d+[,\d]*\.?\d*)\s*kilometres',
            r'356[,\d]*\s*km'  # Common approximate perigee distance
        ]
        
        perigee_matches = []
        for pattern in perigee_patterns:
            matches = re.finditer(pattern, page_text, re.IGNORECASE)
            for match in matches:
                context_start = max(0, match.start() - 100)
                context_end = min(len(page_text), match.end() + 100)
                context = page_text[context_start:context_end].strip()
                
                perigee_matches.append({
                    'pattern': pattern,
                    'match': match.group(),
                    'context': context,
                    'distance_value': match.group(1) if match.groups() else match.group()
                })
                
                print(f"Perigee match found: {match.group()}")
                print(f"Context: ...{context}...")
                print()
        
        # Look for specific sections about orbital mechanics
        print(f"\n=== EXAMINING ORBITAL MECHANICS SECTIONS ===")
        
        orbital_sections = []
        for heading in orbital_headings:
            # Get content following this heading
            current = heading['element']
            section_content = []
            
            # Collect paragraphs following the heading
            for _ in range(10):  # Look at next 10 elements
                current = current.find_next_sibling()
                if current is None:
                    break
                if current.name == 'p':
                    text = current.get_text().strip()
                    section_content.append(text)
                elif current.name in ['h1', 'h2', 'h3', 'h4']:  # Hit next major section
                    break
            
            if section_content:
                full_content = ' '.join(section_content)
                orbital_sections.append({
                    'heading': heading['text'],
                    'content': full_content
                })
                
                # Check if this section contains perigee information
                if any(keyword in full_content.lower() for keyword in ['perigee', 'distance', 'km', 'closest']):
                    print(f"Section '{heading['text']}' contains distance information:")
                    print(f"Content preview: {full_content[:300]}...")
                    print()
        
        # Save all extracted data
        extraction_data = {
            'page_url': url,
            'extraction_timestamp': response.headers.get('date', 'unknown'),
            'infobox_data': infobox_data if 'infobox_data' in locals() else [],
            'perigee_matches': perigee_matches,
            'orbital_sections': orbital_sections,
            'orbital_headings': [h['text'] for h in orbital_headings]
        }
        
        results_file = 'workspace/moon_perigee_extraction.json'
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(extraction_data, f, indent=2, ensure_ascii=False)
        
        print(f"\n=== EXTRACTION SUMMARY ===")
        print(f"Infobox orbital data entries: {len(infobox_data) if 'infobox_data' in locals() else 0}")
        print(f"Perigee pattern matches: {len(perigee_matches)}")
        print(f"Orbital sections found: {len(orbital_sections)}")
        print(f"Results saved to: {results_file}")
        
    else:
        print(f"Failed to access Wikipedia page. Status code: {response.status_code}")
        print(f"Response headers: {dict(response.headers)}")
        
except requests.exceptions.RequestException as e:
    print(f"Error accessing Wikipedia page: {e}")

print(f"\n=== MOON WIKIPEDIA ACCESS COMPLETE ===")
print("Next step: Analyze extracted data to identify the minimum perigee distance value")
```