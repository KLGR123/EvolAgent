### Development Step 10: Identify Zamboanga del Sur Governor Serving 1998–2007 via Official COMELEC Records

**Description**: Contact the Commission on Elections (COMELEC) of the Philippines or search official Philippine government records to identify the specific governor of Zamboanga del Sur Province who served from 1998 to 2007. Focus on finding official election results from the 1998 gubernatorial election and verify the person who held this position for the entire 9-year period through three consecutive terms (1998-2001, 2001-2004, 2004-2007).

**Use Cases**:
- Government transparency dashboard refresh: automated script scrapes COMELEC election archives and Wikipedia to update the official list of Zamboanga del Sur governors (1998–2007) for a public-facing portal
- Investigative journalism fact-checker: pipeline cross-references 1998–2007 election results from COMELEC and Wikipedia to verify claims about the governor’s tenure in news articles
- Political science research aggregator: batch processes election pages to extract gubernatorial service data across provinces for a longitudinal study on political dynasties
- Civic tech interactive timeline: back-end scraper populates a web-based timeline of provincial leadership changes, focusing on Zamboanga del Sur governors across three consecutive terms
- Academic data analysis assignment: university uses the code to teach students web scraping, text parsing, and data validation by extracting gubernatorial election data from government and Wikipedia sources
- Archival preservation system: scheduled ETL workflow captures and version-controls HTML snapshots of COMELEC results and governor lists for long-term digital preservation
- Machine learning dataset builder: collects labeled mentions of political figures and service periods from scraped content to train NER and relation extraction models for Philippine politics
- Government audit support tool: extracts and consolidates official records of provincial executives to verify compliance with term limits and support audit reports

```
# Direct approach to find Zamboanga del Sur governor who served 1998-2007
# Using Wikipedia and other reliable sources for Philippine political history

import requests
import json
import os
from datetime import datetime
from bs4 import BeautifulSoup
import time

print('=== ZAMBOANGA DEL SUR GOVERNOR RESEARCH - ITERATION 3 ===') 
print('Goal: Direct search for governor who served 1998-2007 using reliable sources')
print('=' * 70)

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')
    print('Created workspace directory')

# First, let's inspect any previous research files to understand what we've tried
print('\n🔍 INSPECTING PREVIOUS RESEARCH FILES:')
print('-' * 50)

# Check for previous research files
workspace_files = [f for f in os.listdir('workspace') if f.endswith('.json')]
print(f'Found {len(workspace_files)} JSON files in workspace:')
for file in workspace_files:
    print(f'  - {file}')
    # Get file size for context
    file_path = os.path.join('workspace', file)
    file_size = os.path.getsize(file_path)
    print(f'    Size: {file_size} bytes')

print('\n' + '=' * 70)
print('STRATEGY: DIRECT WIKIPEDIA AND RELIABLE SOURCE ACCESS')
print('=' * 70)

# Function to safely get web content
def get_web_content(url, description=""):
    """Safely fetch web content with proper error handling"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Connection': 'keep-alive'
    }
    
    try:
        print(f'📡 Fetching: {description if description else url}')
        print(f'    URL: {url}')
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        print(f'✅ Success! Status: {response.status_code}, Content: {len(response.text)} chars')
        return response.text
        
    except requests.exceptions.RequestException as e:
        print(f'❌ Request failed: {str(e)}')
        return None
    except Exception as e:
        print(f'❌ Unexpected error: {str(e)}')
        return None

# Target sources for Philippine political information
target_sources = [
    {
        'name': 'Wikipedia - Zamboanga del Sur',
        'url': 'https://en.wikipedia.org/wiki/Zamboanga_del_Sur',
        'description': 'Main Wikipedia page for the province'
    },
    {
        'name': 'Wikipedia - List of Zamboanga del Sur governors',
        'url': 'https://en.wikipedia.org/wiki/List_of_governors_of_Zamboanga_del_Sur',
        'description': 'Specific list of governors (if exists)'
    },
    {
        'name': 'Wikipedia - Governors of Philippine provinces',
        'url': 'https://en.wikipedia.org/wiki/Category:Governors_of_provinces_of_the_Philippines',
        'description': 'Category page for Philippine governors'
    },
    {
        'name': 'Wikipedia - 1998 Philippine elections',
        'url': 'https://en.wikipedia.org/wiki/1998_Philippine_general_election',
        'description': '1998 election results including local positions'
    },
    {
        'name': 'Wikipedia - 2001 Philippine elections',
        'url': 'https://en.wikipedia.org/wiki/2001_Philippine_general_election',
        'description': '2001 election results including local positions'
    }
]

research_results = {
    'research_date': datetime.now().isoformat(),
    'iteration': 3,
    'objective': 'Find Zamboanga del Sur governor who served 1998-2007',
    'strategy': 'Direct Wikipedia and reliable source access',
    'sources_attempted': [],
    'successful_sources': [],
    'failed_sources': [],
    'content_analysis': {},
    'potential_governors_found': [],
    'files_created': []
}

print(f'\n🎯 ATTEMPTING TO ACCESS {len(target_sources)} RELIABLE SOURCES:')
print('-' * 60)

# Process each target source
for i, source in enumerate(target_sources, 1):
    print(f'\n--- SOURCE {i}/{len(target_sources)}: {source["name"]} ---')
    
    research_results['sources_attempted'].append({
        'name': source['name'],
        'url': source['url'],
        'attempt_time': datetime.now().isoformat()
    })
    
    # Attempt to fetch content
    content = get_web_content(source['url'], source['description'])
    
    if content:
        # Save successful access
        research_results['successful_sources'].append({
            'name': source['name'],
            'url': source['url'],
            'content_length': len(content),
            'access_time': datetime.now().isoformat()
        })
        
        # Save content to file
        safe_filename = source['name'].lower().replace(' ', '_').replace('-', '_').replace(',', '')
        content_file = f'workspace/{safe_filename}_content.html'
        
        try:
            with open(content_file, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f'💾 Content saved to: {content_file}')
            research_results['files_created'].append(content_file)
            
            # Analyze content for relevant information
            print('🔍 Analyzing content...')
            content_lower = content.lower()
            
            # Count relevant mentions
            zamboanga_mentions = content_lower.count('zamboanga del sur')
            governor_mentions = content_lower.count('governor')
            election_mentions = content_lower.count('election')
            
            # Look for years 1998-2007
            year_mentions = {}
            for year in ['1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007']:
                count = content_lower.count(year)
                if count > 0:
                    year_mentions[year] = count
            
            # Look for common Filipino political names
            political_names = [
                'antonio', 'jose', 'maria', 'juan', 'pedro', 'miguel', 'francisco', 'luis', 'carlos', 'manuel',
                'cerilles', 'jalosjos', 'lobregat', 'climaco', 'dimaporo', 'pinol', 'hataman', 'cua',
                'aurora', 'rommel', 'vicente', 'dakila', 'celso', 'isabelle', 'rosalinda', 'emmanuel', 'mujiv'
            ]
            
            names_found = {}
            for name in political_names:
                count = content_lower.count(name)
                if count > 0:
                    names_found[name] = count
            
            # Store analysis results
            analysis = {
                'zamboanga_mentions': zamboanga_mentions,
                'governor_mentions': governor_mentions,
                'election_mentions': election_mentions,
                'year_mentions': year_mentions,
                'political_names_found': names_found,
                'content_file': content_file,
                'relevance_score': zamboanga_mentions * 5 + governor_mentions * 3 + election_mentions * 2 + len(year_mentions) * 2
            }
            
            research_results['content_analysis'][source['name']] = analysis
            
            print(f'📊 Content Analysis:')
            print(f'   - Zamboanga del Sur mentions: {zamboanga_mentions}')
            print(f'   - Governor mentions: {governor_mentions}')
            print(f'   - Election mentions: {election_mentions}')
            print(f'   - Target years found: {list(year_mentions.keys())}')
            print(f'   - Political names found: {len(names_found)}')
            print(f'   - Relevance score: {analysis["relevance_score"]}')
            
            if names_found:
                print(f'   - Top names: {list(sorted(names_found.items(), key=lambda x: x[1], reverse=True)[:5])}')
            
            # If this looks very promising, try to extract more specific information
            if analysis['relevance_score'] > 10:
                print('🎯 HIGH RELEVANCE DETECTED - Attempting detailed extraction...')
                
                # Use BeautifulSoup for better parsing
                try:
                    soup = BeautifulSoup(content, 'html.parser')
                    
                    # Look for tables that might contain governor information
                    tables = soup.find_all('table')
                    print(f'   Found {len(tables)} tables in content')
                    
                    # Look for lists that might contain governor names
                    lists = soup.find_all(['ul', 'ol'])
                    print(f'   Found {len(lists)} lists in content')
                    
                    # Search for text containing both "governor" and years
                    text_content = soup.get_text()
                    paragraphs = text_content.split('\n')
                    
                    relevant_paragraphs = []
                    for para in paragraphs:
                        para_lower = para.lower()
                        if ('governor' in para_lower and 'zamboanga del sur' in para_lower) or \
                           ('governor' in para_lower and any(year in para for year in ['1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007'])):
                            relevant_paragraphs.append(para.strip())
                    
                    if relevant_paragraphs:
                        print(f'   🎯 Found {len(relevant_paragraphs)} potentially relevant paragraphs:')
                        for j, para in enumerate(relevant_paragraphs[:3], 1):  # Show first 3
                            print(f'      {j}. {para[:200]}...' if len(para) > 200 else f'      {j}. {para}')
                        
                        research_results['potential_governors_found'].extend(relevant_paragraphs)
                    
                except Exception as e:
                    print(f'   ❌ Error in detailed extraction: {str(e)}')
            
        except Exception as e:
            print(f'❌ Error saving/analyzing content: {str(e)}')
    
    else:
        # Record failed access
        research_results['failed_sources'].append({
            'name': source['name'],
            'url': source['url'],
            'failure_time': datetime.now().isoformat(),
            'reason': 'Could not access URL'
        })
    
    # Brief pause between requests
    if i < len(target_sources):
        print('⏳ Pausing briefly before next request...')
        time.sleep(2)

print('\n' + '=' * 70)
print('COMPREHENSIVE ANALYSIS AND FINDINGS')
print('=' * 70)

# Analyze all results
successful_count = len(research_results['successful_sources'])
failed_count = len(research_results['failed_sources'])

print(f'\n📊 ACCESS SUMMARY:')
print(f'   Sources attempted: {len(research_results["sources_attempted"])}')
print(f'   Successfully accessed: {successful_count}')
print(f'   Failed to access: {failed_count}')
print(f'   Files created: {len(research_results["files_created"])}')

if successful_count > 0:
    print(f'\n✅ SUCCESSFUL SOURCES:')
    for source in research_results['successful_sources']:
        print(f'   - {source["name"]} ({source["content_length"]} chars)')

if failed_count > 0:
    print(f'\n❌ FAILED SOURCES:')
    for source in research_results['failed_sources']:
        print(f'   - {source["name"]}')

# Find most relevant sources
if research_results['content_analysis']:
    print(f'\n🎯 RELEVANCE ANALYSIS:')
    
    # Sort sources by relevance score
    sorted_sources = sorted(
        research_results['content_analysis'].items(), 
        key=lambda x: x[1]['relevance_score'], 
        reverse=True
    )
    
    for source_name, analysis in sorted_sources:
        print(f'\n   {source_name}:')
        print(f'     Relevance Score: {analysis["relevance_score"]}')
        print(f'     Zamboanga mentions: {analysis["zamboanga_mentions"]}')
        print(f'     Governor mentions: {analysis["governor_mentions"]}')
        print(f'     Years found: {list(analysis["year_mentions"].keys())}')
        print(f'     File: {analysis["content_file"]}')
        
        if analysis['relevance_score'] > 0:
            print(f'     🌟 PROMISING SOURCE - Contains relevant information')

# Check for potential governor information found
if research_results['potential_governors_found']:
    print(f'\n🏆 POTENTIAL GOVERNOR INFORMATION FOUND:')
    print(f'   Found {len(research_results["potential_governors_found"])} relevant text segments')
    
    for i, info in enumerate(research_results['potential_governors_found'][:5], 1):  # Show first 5
        print(f'\n   {i}. {info[:300]}...' if len(info) > 300 else f'\n   {i}. {info}')
else:
    print(f'\n❌ No specific governor information found in this iteration')

# Save comprehensive results
results_file = 'workspace/zamboanga_governor_research_iteration3.json'
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(research_results, f, indent=2, ensure_ascii=False)

print(f'\n💾 Complete research results saved to: {results_file}')
research_results['files_created'].append(results_file)

# Create detailed summary
summary_file = 'workspace/iteration3_detailed_summary.txt'
with open(summary_file, 'w', encoding='utf-8') as f:
    f.write('ZAMBOANGA DEL SUR GOVERNOR RESEARCH - ITERATION 3 DETAILED SUMMARY\n')
    f.write('=' * 70 + '\n\n')
    f.write(f'Research Date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n')
    f.write('Objective: Find governor who served 1998-2007\n')
    f.write('Strategy: Direct Wikipedia and reliable source access\n\n')
    
    f.write(f'RESULTS:\n')
    f.write(f'- Sources attempted: {len(research_results["sources_attempted"])}\n')
    f.write(f'- Successfully accessed: {successful_count}\n')
    f.write(f'- Failed to access: {failed_count}\n')
    f.write(f'- Files created: {len(research_results["files_created"])}\n\n')
    
    if research_results['content_analysis']:
        f.write('CONTENT ANALYSIS RESULTS:\n')
        for source_name, analysis in sorted_sources:
            f.write(f'\n{source_name}:\n')
            f.write(f'  - Relevance Score: {analysis["relevance_score"]}\n')
            f.write(f'  - Zamboanga mentions: {analysis["zamboanga_mentions"]}\n')
            f.write(f'  - Governor mentions: {analysis["governor_mentions"]}\n')
            f.write(f'  - Target years: {list(analysis["year_mentions"].keys())}\n')
            f.write(f'  - Content file: {analysis["content_file"]}\n')
    
    if research_results['potential_governors_found']:
        f.write(f'\nPOTENTIAL GOVERNOR INFORMATION:\n')
        for i, info in enumerate(research_results['potential_governors_found'], 1):
            f.write(f'\n{i}. {info}\n')
    
    f.write('\nNEXT STEPS:\n')
    f.write('1. Manually analyze the most relevant content files\n')
    f.write('2. Search for specific governor names in the downloaded content\n')
    f.write('3. Cross-reference information across sources\n')
    f.write('4. If no clear answer found, try additional specific searches\n')

print(f'📄 Detailed summary saved to: {summary_file}')
research_results['files_created'].append(summary_file)

print('\n' + '=' * 70)
print('ITERATION 3 COMPLETED - DIRECT SOURCE ACCESS STRATEGY')
print('=' * 70)

print(f'\n🚀 KEY ACHIEVEMENTS:')
print(f'✅ Attempted access to {len(target_sources)} reliable sources')
print(f'✅ Successfully accessed {successful_count} sources')
print(f'✅ Created {len(research_results["files_created"])} files for analysis')
print(f'✅ Implemented relevance scoring system')
print(f'✅ Performed detailed content analysis with BeautifulSoup')

if research_results['potential_governors_found']:
    print(f'✅ Found {len(research_results["potential_governors_found"])} potentially relevant text segments')

# Determine next steps based on results
if any(analysis['relevance_score'] > 5 for analysis in research_results['content_analysis'].values()):
    print(f'\n🎯 HIGH-RELEVANCE SOURCES FOUND!')
    print('Next iteration should focus on detailed manual analysis of the most promising files.')
elif successful_count > 0:
    print(f'\n📋 MODERATE SUCCESS - CONTENT DOWNLOADED')
    print('Next iteration should analyze downloaded content and try additional specific searches.')
else:
    print(f'\n⚠️  LIMITED SUCCESS - FEW SOURCES ACCESSED')
    print('Next iteration should try alternative approaches or different source types.')

print(f'\n📁 FILES AVAILABLE FOR ANALYSIS:')
for i, file in enumerate(research_results['files_created'], 1):
    print(f'   {i}. {file}')

print('\nThis systematic approach provides a solid foundation for identifying')
print('the Zamboanga del Sur governor who served from 1998-2007.')
```