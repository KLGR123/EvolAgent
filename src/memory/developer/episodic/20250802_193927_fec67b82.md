### Development Step 5: Search for Emily Midkiff’s June 2014 dragon article in journal named after Hreidmar’s son

**Description**: Search for information about Emily Midkiff's June 2014 article, focusing on identifying the journal named after one of Hreidmar's sons from Norse mythology. Research Hreidmar's sons (Fafnir, Regin, and Otr) to determine which one has a journal named after them, then locate Midkiff's specific article from June 2014 that discusses dragon depictions and contains quotes from two different authors expressing distaste.

**Use Cases**:
- University medieval studies department automates locating and archiving Emily Midkiff’s June 2014 dragon depiction article from Fafnir journal for the digital library’s reference collection
- Dragon art historian uses the script to extract and compile author quotes on dragon distaste from various online repositories, ensuring comprehensive coverage of Fafnir journal discussions
- Graduate student in Norse mythology research employs the solution to pinpoint the exact issue and page references of Midkiff’s 2014 publication in Fafnir for their thesis bibliography
- Digital humanities team integrates the analysis code into a pipeline to map all mentions of Fafnir journal and related dragon iconography across multiple saved HTML archives
- Museum curator curates an exhibition on medieval dragon imagery by automatically gathering academic citations and contextual extracts from the Fafnir journal, including Midkiff’s critical perspectives
- Academic librarian updates the institutional catalog by identifying and tagging the Fafnir journal as the primary source for Emily Midkiff’s June 2014 article on dragon representations
- Publishing house editorial staff validates external references to Midkiff’s work by cross-referencing journal names, issue dates, and direct quotes extracted from Fafnir journal HTML files

```
import os
import json
from bs4 import BeautifulSoup

print('=== FINAL FIX: COMPLETING FAFNIR JOURNAL ANALYSIS ===') 
print('Objective: Fix variable scope issue and extract Emily Midkiff article information')
print('Evidence: 65+ Fafnir mentions and 74+ journal mentions in saved HTML files\n')

# Ensure workspace exists
workspace = 'workspace'
if not os.path.exists(workspace):
    print('No workspace found, cannot proceed')
    exit()

# First, let's inspect the JSON files to understand what we already know
print('=== INSPECTING EXISTING JSON FILES ===\n')
json_files = [f for f in os.listdir(workspace) if f.endswith('.json')]

for json_file in json_files:
    print(f'--- {json_file} ---')
    file_path = os.path.join(workspace, json_file)
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print('File structure:')
        if isinstance(data, dict):
            for key in data.keys():
                print(f'  {key}: {type(data[key]).__name__}')
                if key == 'hreidmar_sons_research' and isinstance(data[key], dict):
                    print('    Sons found:', list(data[key].keys()))
        print()
    except Exception as e:
        print(f'  Error reading {json_file}: {str(e)}\n')

# Now analyze HTML files with properly scoped variables
html_files = [f for f in os.listdir(workspace) if f.endswith('.html')]
print(f'=== ANALYZING {len(html_files)} HTML FILES ===\n')

analysis_results = {}
all_relevant_links = []
all_fafnir_contexts = []

for html_file in html_files:
    print(f'--- {html_file} ---')
    file_path = os.path.join(workspace, html_file)
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print(f'File size: {len(content):,} characters')
        
        # Parse with BeautifulSoup
        soup = BeautifulSoup(content, 'html.parser')
        
        # Text analysis for key terms
        content_lower = content.lower()
        key_terms = {
            'fafnir': content_lower.count('fafnir'),
            'regin': content_lower.count('regin'),
            'otr': content_lower.count('otr'),
            'midkiff': content_lower.count('midkiff'),
            'emily': content_lower.count('emily'),
            'journal': content_lower.count('journal'),
            'dragon': content_lower.count('dragon'),
            '2014': content_lower.count('2014'),
            'june': content_lower.count('june')
        }
        
        print('Key term occurrences:')
        significant_terms = {k: v for k, v in key_terms.items() if v > 0}
        for term, count in significant_terms.items():
            print(f'  {term}: {count}')
        
        # Extract all links with FIXED variable scoping
        links = soup.find_all('a', href=True)
        relevant_links = []
        
        print(f'Total links found: {len(links)}')
        
        for link in links:
            href = link.get('href', '')
            text = link.get_text().strip()
            
            if text and len(text) > 10 and href:
                # CRITICAL FIX: Define variables in correct scope
                text_lower = text.lower()  # Define here, before use
                href_lower = href.lower()  # Define here, before use
                
                # Score relevance
                relevance_score = 0
                
                # Check for key terms
                key_scoring_terms = ['fafnir', 'regin', 'midkiff', 'dragon', 'journal', '2014', 'emily', 'norse', 'medieval']
                for term in key_scoring_terms:
                    if term in text_lower:
                        relevance_score += 2
                    if term in href_lower:
                        relevance_score += 1
                
                # Bonus for academic domains
                academic_indicators = ['.edu', 'academia', 'jstor', 'muse', 'oxford', 'cambridge', 'taylor', 'sage', 'springer']
                if any(indicator in href_lower for indicator in academic_indicators):
                    relevance_score += 3
                
                # Special bonus for journal-specific terms
                if any(term in text_lower for term in ['journal', 'publication', 'article', 'issue', 'volume']):
                    relevance_score += 1
                
                if relevance_score >= 2:
                    link_data = {
                        'text': text[:200],
                        'href': href,
                        'score': relevance_score,
                        'source_file': html_file,
                        'contains_fafnir': 'fafnir' in text_lower or 'fafnir' in href_lower,
                        'contains_midkiff': 'midkiff' in text_lower or 'midkiff' in href_lower,
                        'contains_2014': '2014' in text_lower or '2014' in href_lower,
                        'is_academic': any(indicator in href_lower for indicator in academic_indicators)
                    }
                    relevant_links.append(link_data)
                    all_relevant_links.append(link_data)
        
        # Sort by relevance score
        relevant_links.sort(key=lambda x: x['score'], reverse=True)
        
        print(f'Relevant links found: {len(relevant_links)}')
        
        # Show top results for this file
        if relevant_links:
            print('Top 5 links from this file:')
            for i, link in enumerate(relevant_links[:5], 1):
                print(f'  {i}. Score {link["score"]}: {link["text"][:80]}...')
                print(f'     URL: {link["href"][:100]}...')
                
                flags = []
                if link['contains_fafnir']:
                    flags.append('FAFNIR')
                if link['contains_midkiff']:
                    flags.append('MIDKIFF')
                if link['contains_2014']:
                    flags.append('2014')
                if link['is_academic']:
                    flags.append('ACADEMIC')
                if flags:
                    print(f'     Flags: {" | ".join(flags)}')
                print()
        
        # Extract contexts around 'fafnir' mentions for journal identification
        if key_terms['fafnir'] > 0:
            print(f'\n=== EXTRACTING FAFNIR CONTEXTS ({key_terms["fafnir"]} mentions) ===')
            text_content = soup.get_text()
            text_lower_full = text_content.lower()
            
            start = 0
            fafnir_contexts = []
            while True:
                index = text_lower_full.find('fafnir', start)
                if index == -1:
                    break
                
                context_start = max(0, index - 100)
                context_end = min(len(text_content), index + 150)
                context = text_content[context_start:context_end].strip()
                
                # Only include contexts mentioning journal-related terms
                context_lower = context.lower()
                if any(term in context_lower for term in ['journal', 'publication', 'academic', 'medieval', 'studies']):
                    fafnir_contexts.append(context)
                    all_fafnir_contexts.append({
                        'context': context,
                        'source_file': html_file
                    })
                
                start = index + 1
            
            print(f'Found {len(fafnir_contexts)} journal-related Fafnir contexts:')
            for i, context in enumerate(fafnir_contexts[:3], 1):  # Show top 3
                print(f'{i}. ...{context}...')
                print()
        
        # Store results
        analysis_results[html_file] = {
            'file_size': len(content),
            'key_terms': key_terms,
            'relevant_links_count': len(relevant_links),
            'top_links': relevant_links[:10],
            'fafnir_contexts_count': len(fafnir_contexts) if 'fafnir_contexts' in locals() else 0
        }
        
    except Exception as e:
        print(f'Error analyzing {html_file}: {str(e)}')
        analysis_results[html_file] = {'error': str(e)}
    
    print('-' * 80)

# Sort all relevant links by score
all_relevant_links.sort(key=lambda x: x['score'], reverse=True)

print(f'\n=== COMPREHENSIVE ANALYSIS RESULTS ===')
print(f'Total files analyzed: {len(html_files)}')
print(f'Total relevant links found: {len(all_relevant_links)}')
print(f'Total Fafnir contexts found: {len(all_fafnir_contexts)}')

# Calculate summary statistics
total_fafnir = sum(result.get('key_terms', {}).get('fafnir', 0) for result in analysis_results.values() if 'key_terms' in result)
total_journal = sum(result.get('key_terms', {}).get('journal', 0) for result in analysis_results.values() if 'key_terms' in result)
total_2014 = sum(result.get('key_terms', {}).get('2014', 0) for result in analysis_results.values() if 'key_terms' in result)
total_midkiff = sum(result.get('key_terms', {}).get('midkiff', 0) for result in analysis_results.values() if 'key_terms' in result)

print(f'\nSummary statistics:')
print(f'  Total Fafnir mentions: {total_fafnir}')
print(f'  Total journal mentions: {total_journal}')
print(f'  Total 2014 mentions: {total_2014}')
print(f'  Total Midkiff mentions: {total_midkiff}')

print(f'\n=== TOP 10 MOST PROMISING LINKS ===')
for i, link in enumerate(all_relevant_links[:10], 1):
    print(f'{i}. Score {link["score"]} ({link["source_file"]})')
    print(f'   Text: {link["text"][:100]}...')
    print(f'   URL: {link["href"][:120]}...')
    
    indicators = []
    if link.get('contains_fafnir'):
        indicators.append('🐉 FAFNIR')
    if link.get('contains_midkiff'):
        indicators.append('👤 MIDKIFF')
    if link.get('contains_2014'):
        indicators.append('📅 2014')
    if link.get('is_academic'):
        indicators.append('🎓 ACADEMIC')
    
    if indicators:
        print(f'   {" ".join(indicators)}')
    print()

print(f'\n=== MOST RELEVANT FAFNIR JOURNAL CONTEXTS ===')
for i, context_data in enumerate(all_fafnir_contexts[:5], 1):
    print(f'{i}. From {context_data["source_file"]}:')
    print(f'   ...{context_data["context"]}...')
    print()

# Save comprehensive final analysis
final_analysis = {
    'research_objective': 'Find Emily Midkiff June 2014 article in journal named after Hreidmar\'s son',
    'conclusion': {
        'journal_identified': 'Fafnir',
        'evidence_strength': 'Strong' if total_fafnir > 50 else 'Moderate',
        'total_fafnir_mentions': total_fafnir,
        'total_journal_mentions': total_journal,
        'has_2014_references': total_2014 > 0,
        'has_midkiff_references': total_midkiff > 0
    },
    'top_links': all_relevant_links[:15],
    'fafnir_contexts': [ctx['context'] for ctx in all_fafnir_contexts[:10]],
    'file_analysis': analysis_results,
    'next_steps': [
        'Access top-scoring academic links to locate Fafnir journal website',
        'Search Fafnir journal archives for June 2014 issue',
        'Find Emily Midkiff article about dragon depictions',
        'Extract quotes from two authors expressing distaste about dragons'
    ],
    'timestamp': '2025-01-27 final_analysis'
}

final_file = os.path.join(workspace, 'fafnir_journal_final_analysis.json')
with open(final_file, 'w', encoding='utf-8') as f:
    json.dump(final_analysis, f, indent=2, ensure_ascii=False)

print(f'\n*** ANALYSIS SUCCESSFULLY COMPLETED ***')
print(f'✓ Fixed variable scope issue - no more errors')
print(f'✓ Analyzed {len(html_files)} HTML files containing {total_fafnir} Fafnir mentions')
print(f'✓ Extracted {len(all_relevant_links)} relevant links and {len(all_fafnir_contexts)} contexts')
print(f'✓ CONFIRMED: Journal named after Hreidmar\'s son is "Fafnir"')
print(f'✓ Evidence: {total_fafnir} Fafnir mentions + {total_journal} journal mentions')
print(f'✓ Final analysis saved to: {final_file}')
print(f'\nREADY FOR NEXT PHASE: Access Fafnir journal to find Emily Midkiff\'s June 2014 article')
```