### Development Step 4: Title: Extract and Clean Phrase Removed by Timwi in 2004 Wikipedia Joke Removal Edit

**Description**: Access the specific Wikipedia revision from February 29, 2004 (revision ID 2580816) and the preceding revision to perform a detailed content comparison. Extract the exact text that was removed by user 'Timwi' during the joke removal edit, focusing on identifying the complete phrase that was deleted. Clean the extracted phrase by removing all punctuation marks as requested in the TASK.

**Use Cases**:
- Academic research on the evolution of Wikipedia articles to study how humor and non-encyclopedic content are removed over time
- Automated quality assurance for Wikipedia editors to detect and catalog joke or vandalism removals for moderation reports
- Digital humanities projects analyzing the cultural history of Wikipedia edits, focusing on the lifecycle of jokes and informal content
- Legal or compliance audits requiring documentation of exactly what information was removed from public knowledge bases at specific times
- Training datasets for machine learning models aiming to classify and filter out non-factual or humorous content from collaborative platforms
- Media fact-checking workflows that need to reconstruct the precise text removed from high-profile Wikipedia articles for transparency
- Historical linguistics research examining how language, tone, and humor usage change in collaborative online encyclopedias
- Automated tools for educators to demonstrate real-world examples of editorial processes and content moderation in open-source communities

```
import os
import requests
import json
from datetime import datetime
import time

print("=== ACCESSING SPECIFIC WIKIPEDIA REVISION CONTENT FOR COMPARISON ===\n")
print("Objective: Access revision ID 2580816 (Feb 29, 2004) and its parent to extract removed text")
print("Focus: Find the exact phrase that was deleted by user 'Timwi' and clean it of punctuation\n")

# Based on the HISTORY, we know the target revision details
TARGET_REVISION_ID = 2580816  # The leap day revision
PARENT_REVISION_ID = 2572029  # The parent revision
USER = 'Timwi'
COMMENT = 'I admit, I did laugh. :-)'
DATE = '2004-02-29T15:41:25Z'

print(f"Target revision details:")
print(f"  Revision ID: {TARGET_REVISION_ID}")
print(f"  Parent ID: {PARENT_REVISION_ID}")
print(f"  User: {USER}")
print(f"  Date: {DATE}")
print(f"  Comment: '{COMMENT}'")

# Create workspace directory if needed
workspace_dir = 'workspace'
if not os.path.exists(workspace_dir):
    os.makedirs(workspace_dir)
    print(f"\nCreated workspace directory: {workspace_dir}")
else:
    print(f"\nUsing workspace directory: {workspace_dir}")

# Wikipedia API endpoint
api_url = "https://en.wikipedia.org/w/api.php"

def get_revision_content(revid, description=""):
    """Get the full content of a specific revision with detailed logging"""
    params = {
        'action': 'query',
        'format': 'json',
        'prop': 'revisions',
        'revids': revid,
        'rvprop': 'content|timestamp|user|comment|ids|size'
    }
    
    try:
        print(f"  Fetching {description} revision {revid}...")
        response = requests.get(api_url, params=params, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        
        if 'query' in data and 'pages' in data['query']:
            pages = data['query']['pages']
            page_id = list(pages.keys())[0]
            
            if page_id == '-1':
                print(f"    ‚ùå Revision {revid} not found")
                return None
                
            if 'revisions' in pages[page_id] and len(pages[page_id]['revisions']) > 0:
                revision = pages[page_id]['revisions'][0]
                if '*' in revision:  # Content is in the '*' field
                    content = revision['*']
                    print(f"    ‚úì Retrieved content: {len(content):,} characters")
                    
                    return {
                        'content': content,
                        'revid': revision.get('revid'),
                        'timestamp': revision.get('timestamp'),
                        'user': revision.get('user'),
                        'comment': revision.get('comment'),
                        'size': revision.get('size')
                    }
                else:
                    print(f"    ‚ùå No content field found in revision")
                    return None
            else:
                print(f"    ‚ùå No revision data found")
                return None
        else:
            print(f"    ‚ùå No page data in API response")
            return None
            
    except Exception as e:
        print(f"    ‚ùå Error fetching revision {revid}: {str(e)}")
        return None

print("\n=== STEP 1: FETCHING REVISION CONTENT ===\n")

# Get content for both revisions
print("Fetching target revision (joke removal)...")
target_content = get_revision_content(TARGET_REVISION_ID, "target")
time.sleep(1)  # Be respectful to Wikipedia's servers

print("\nFetching parent revision (before joke removal)...")
parent_content = get_revision_content(PARENT_REVISION_ID, "parent")
time.sleep(1)

if not target_content or not parent_content:
    print("‚ùå Could not retrieve both revisions. Cannot proceed with comparison.")
else:
    print("\n‚úÖ Successfully retrieved both revisions")
    
    target_text = target_content['content']
    parent_text = parent_content['content']
    
    print(f"\nRevision details:")
    print(f"  Target ({TARGET_REVISION_ID}): {len(target_text):,} characters")
    print(f"  Parent ({PARENT_REVISION_ID}): {len(parent_text):,} characters")
    print(f"  Difference: {len(target_text) - len(parent_text):+,} characters")
    
    print("\n=== STEP 2: PERFORMING DETAILED CONTENT COMPARISON ===\n")
    
    # Save both versions for analysis
    target_file = os.path.join(workspace_dir, f'revision_{TARGET_REVISION_ID}_content.txt')
    parent_file = os.path.join(workspace_dir, f'revision_{PARENT_REVISION_ID}_content.txt')
    
    with open(target_file, 'w', encoding='utf-8') as f:
        f.write(target_text)
    print(f"‚úì Saved target revision content to: {os.path.basename(target_file)}")
    
    with open(parent_file, 'w', encoding='utf-8') as f:
        f.write(parent_text)
    print(f"‚úì Saved parent revision content to: {os.path.basename(parent_file)}")
    
    # Perform line-by-line comparison to find exact differences
    target_lines = target_text.split('\n')
    parent_lines = parent_text.split('\n')
    
    print(f"\nLine comparison:")
    print(f"  Target: {len(target_lines)} lines")
    print(f"  Parent: {len(parent_lines)} lines")
    
    # Find lines that were removed (in parent but not in target)
    target_line_set = set(target_lines)
    parent_line_set = set(parent_lines)
    
    removed_lines = parent_line_set - target_line_set
    added_lines = target_line_set - parent_line_set
    
    print(f"  Lines removed: {len(removed_lines)}")
    print(f"  Lines added: {len(added_lines)}")
    
    print("\n=== STEP 3: EXTRACTING REMOVED TEXT ===\n")
    
    if removed_lines:
        print(f"üìâ CONTENT REMOVED BY USER '{USER}':")
        print(f"    (From revision {PARENT_REVISION_ID} to {TARGET_REVISION_ID})\n")
        
        removed_phrases = []
        
        for i, line in enumerate(removed_lines, 1):
            if line.strip():  # Skip empty lines
                print(f"{i}. '{line}'")
                print(f"   Length: {len(line)} characters")
                removed_phrases.append(line)
        
        # Based on HISTORY, we know 'Here be dragons:' was removed
        # Let's focus on extracting the complete phrase
        
        print("\n=== STEP 4: IDENTIFYING THE SPECIFIC JOKE PHRASE ===\n")
        
        # Look for the "Here be dragons" phrase specifically
        dragons_phrase = None
        for line in removed_lines:
            if 'here be dragons' in line.lower():
                dragons_phrase = line
                break
        
        if dragons_phrase:
            print(f"üéØ FOUND THE JOKE PHRASE:")
            print(f"   Original: '{dragons_phrase}'")
            print(f"   Length: {len(dragons_phrase)} characters")
            
            # Clean the phrase by removing punctuation as requested
            import string
            
            # Remove all punctuation marks
            cleaned_phrase = dragons_phrase.translate(str.maketrans('', '', string.punctuation))
            
            # Also remove extra whitespace
            cleaned_phrase = ' '.join(cleaned_phrase.split())
            
            print(f"\nüßπ CLEANED PHRASE (punctuation removed):")
            print(f"   Cleaned: '{cleaned_phrase}'")
            print(f"   Length: {len(cleaned_phrase)} characters")
            
            # Show what punctuation was removed
            removed_chars = []
            for char in dragons_phrase:
                if char in string.punctuation:
                    removed_chars.append(char)
            
            if removed_chars:
                print(f"   Punctuation removed: {removed_chars}")
            else:
                print(f"   No punctuation found to remove")
            
        else:
            print(f"‚ùå 'Here be dragons' phrase not found in removed lines")
            print(f"Available removed lines:")
            for line in removed_lines:
                if line.strip():
                    print(f"  - '{line[:100]}'")
        
        # Save the analysis results
        comparison_results = {
            'analysis_metadata': {
                'analysis_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'target_revision_id': TARGET_REVISION_ID,
                'parent_revision_id': PARENT_REVISION_ID,
                'user': USER,
                'comment': COMMENT,
                'date': DATE
            },
            'content_comparison': {
                'target_size': len(target_text),
                'parent_size': len(parent_text),
                'size_difference': len(target_text) - len(parent_text),
                'target_lines': len(target_lines),
                'parent_lines': len(parent_lines),
                'lines_removed': len(removed_lines),
                'lines_added': len(added_lines)
            },
            'removed_content': {
                'all_removed_lines': list(removed_lines),
                'joke_phrase_found': dragons_phrase is not None,
                'original_joke_phrase': dragons_phrase,
                'cleaned_joke_phrase': cleaned_phrase if dragons_phrase else None,
                'punctuation_removed': removed_chars if dragons_phrase else None
            },
            'added_content': {
                'all_added_lines': list(added_lines)
            }
        }
        
        results_file = os.path.join(workspace_dir, 'revision_comparison_results.json')
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(comparison_results, f, indent=2, ensure_ascii=False)
        
        print(f"\n‚úÖ Comparison results saved to: {os.path.basename(results_file)}")
        
    else:
        print(f"‚ùå No removed lines found in comparison")
    
    print("\n=== STEP 5: SUMMARY OF FINDINGS ===\n")
    
    print(f"üéØ REVISION COMPARISON COMPLETE")
    print(f"\nüìã KEY FINDINGS:")
    print(f"- Target revision: {TARGET_REVISION_ID} (Feb 29, 2004)")
    print(f"- User: {USER}")
    print(f"- Comment: '{COMMENT}'")
    print(f"- Content change: {len(target_text) - len(parent_text):+,} characters")
    
    if dragons_phrase:
        print(f"\nüé≠ JOKE PHRASE EXTRACTED:")
        print(f"- Original phrase: '{dragons_phrase}'")
        print(f"- Cleaned phrase: '{cleaned_phrase}'")
        print(f"- This phrase was REMOVED by the user on the leap day")
    
    print(f"\nüìÅ FILES CREATED:")
    print(f"- Target revision content: {os.path.basename(target_file)}")
    print(f"- Parent revision content: {os.path.basename(parent_file)}")
    print(f"- Comparison results: revision_comparison_results.json")
    
    print(f"\n‚úÖ PLAN OBJECTIVE ACHIEVED:")
    print(f"Successfully accessed the specific Wikipedia revision from February 29, 2004")
    print(f"and extracted the exact text that was removed by user 'Timwi' during the")
    print(f"joke removal edit, with punctuation cleaned as requested.")
```