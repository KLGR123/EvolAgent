### Development Step 11: Identify organization & advocate behind 505-municipality S√£o Francisco Basin environmental plan for Sobradinho Dam displaced

**Description**: Conduct a comprehensive web search to identify the organization that launched the 'Plano de Educa√ß√£o Ambiental da Bacia do Rio S√£o Francisco' covering 505 municipalities and collaborates with Minist√©rios P√∫blicos. Search for keywords including 'Plano de Educa√ß√£o Ambiental Bacia Rio S√£o Francisco 505 munic√≠pios', 'Minist√©rios P√∫blicos S√£o Francisco basin', 'environmental education plan S√£o Francisco river', and 'Sobradinho Dam displaced people advocacy'. Focus on identifying the specific organization and then finding which individual within that organization advocated for people displaced by the Sobradinho Dam construction.

**Use Cases**:
- Environmental NGO partnership outreach by validating the Plano de Educa√ß√£o Ambiental da Bacia do Rio S√£o Francisco launch details and identifying CBHSF leadership contacts for joint program development.
- Legal aid organizations automating research on Sobradinho Dam displacement advocates to compile evidence and contact information for compensation and resettlement claims.
- Government audit teams conducting compliance checks on the implementation of the environmental education plan across 505 municipalities in collaboration with Minist√©rios P√∫blicos.
- Academic research groups mapping the governance structure of the Comit√™ da Bacia Hidrogr√°fica do Rio S√£o Francisco and profiling individual roles for a study on watershed participatory management.
- Investigative journalists profiling CBHSF members and Sobradinho Dam advocates to produce in-depth reporting on environmental justice and displaced communities.
- Environmental consulting firms extracting stakeholder and advocacy data from targeted web searches to inform strategic planning for river basin education and conservation projects.
- Data science teams building a searchable database of committee representatives, advocacy events, and ministry collaborations in the S√£o Francisco basin for policy analysis and impact assessment.

```
from ddgs import DDGS
import json
import os
from datetime import datetime
import time

print("Conducting targeted search for CBHSF individuals involved in Sobradinho Dam displaced people advocacy...")

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')
    print("Created workspace directory")

# First, let's inspect the previous analysis to understand what we found
print("\n=== INSPECTING PREVIOUS ANALYSIS ===")
analysis_files = []
for workspace_dir in ['workspace', 'workspace_webshaper_68', 'workspace_webshaper_65']:
    if os.path.exists(workspace_dir):
        files = os.listdir(workspace_dir)
        for file in files:
            if 'sao_francisco' in file and 'analysis' in file:
                analysis_files.append(os.path.join(workspace_dir, file))
                print(f"Found analysis file: {os.path.join(workspace_dir, file)}")

# Load the most recent analysis if available
previous_analysis = None
if analysis_files:
    latest_analysis_file = analysis_files[-1]  # Get the most recent one
    print(f"\nLoading previous analysis from: {latest_analysis_file}")
    
    with open(latest_analysis_file, 'r', encoding='utf-8') as f:
        previous_analysis = json.load(f)
    
    print("Previous analysis structure:")
    for key, value in previous_analysis.items():
        if isinstance(value, dict):
            print(f"  - {key}: dict with {len(value)} keys")
        elif isinstance(value, list):
            print(f"  - {key}: list with {len(value)} items")
        else:
            print(f"  - {key}: {type(value).__name__}")

# Define targeted search queries for CBHSF individuals and Sobradinho advocacy
targeted_queries = [
    "CBHSF Comit√™ Bacia S√£o Francisco Sobradinho deslocados",
    "Sobradinho Dam advocacy CBHSF members directors",
    "Barragem Sobradinho CBHSF advogados representantes",
    "CBHSF diretoria Sobradinho reassentamento",
    "Comit√™ S√£o Francisco Sobradinho indeniza√ß√£o",
    "CBHSF presidente coordenador Sobradinho displaced",
    "S√£o Francisco basin committee Sobradinho compensation",
    "CBHSF membros Sobradinho atingidos barragem"
]

print(f"\n=== CONDUCTING {len(targeted_queries)} TARGETED SEARCHES ===")

# Initialize DDGS searcher
searcher = DDGS(timeout=15)
targeted_results = {}

# Conduct targeted searches
for i, query in enumerate(targeted_queries, 1):
    print(f"\n[{i}/{len(targeted_queries)}] Searching: {query}")
    
    try:
        # Search with multiple backends for reliability
        results = searcher.text(
            query, 
            max_results=8, 
            page=1, 
            backend=["google", "duckduckgo", "bing", "yahoo"], 
            safesearch="off", 
            region="pt-br"
        )
        
        if results:
            targeted_results[f"targeted_query_{i}"] = {
                'query': query,
                'results_count': len(results),
                'results': results
            }
            print(f"‚úì Found {len(results)} results")
            
            # Display top results for immediate analysis
            for j, result in enumerate(results[:2], 1):
                print(f"  {j}. {result.get('title', 'No title')[:70]}...")
                print(f"     URL: {result.get('href', 'No URL')[:80]}...")
                snippet = result.get('body', 'No snippet')[:120].replace('\n', ' ')
                print(f"     Snippet: {snippet}...")
        else:
            print(f"‚úó No results found")
            targeted_results[f"targeted_query_{i}"] = {
                'query': query,
                'results_count': 0,
                'results': []
            }
            
    except Exception as e:
        print(f"‚úó Error searching '{query}': {str(e)}")
        targeted_results[f"targeted_query_{i}"] = {
            'query': query,
            'error': str(e),
            'results_count': 0,
            'results': []
        }
    
    # Add delay between searches
    time.sleep(2)

print(f"\n{'='*80}")
print("ANALYZING TARGETED SEARCH RESULTS")
print(f"{'='*80}")

# Save targeted search results
targeted_results_file = "workspace/cbhsf_sobradinho_targeted_search.json"
with open(targeted_results_file, 'w', encoding='utf-8') as f:
    json.dump(targeted_results, f, indent=2, ensure_ascii=False)
print(f"\nTargeted search results saved to {targeted_results_file}")

# Analyze results for specific individuals
cbhsf_individuals = []
sobradinho_advocates = []
key_findings = []

# Keywords for individual identification
individual_keywords = ['presidente', 'diretor', 'coordenador', 'secret√°rio', 'advogado', 'representante', 'membro']
name_indicators = ['dr.', 'dra.', 'prof.', 'eng.', 'adv.']

total_targeted_results = 0

print(f"\nüìä ANALYZING TARGETED RESULTS...")

for query_key, query_data in targeted_results.items():
    if query_data.get('results'):
        query_text = query_data.get('query', 'Unknown query')
        results = query_data.get('results', [])
        total_targeted_results += len(results)
        
        print(f"\nAnalyzing {len(results)} results from: {query_text[:50]}...")
        
        for result in results:
            title = result.get('title', '').lower()
            body = result.get('body', '').lower()
            url = result.get('href', '')
            
            # Look for CBHSF individuals
            if 'cbhsf' in title or 'cbhsf' in body or 'comit√™' in title or 'comit√™' in body:
                for keyword in individual_keywords:
                    if keyword in title or keyword in body:
                        cbhsf_individuals.append({
                            'title': result.get('title', ''),
                            'url': url,
                            'snippet': result.get('body', '')[:400],
                            'query': query_text,
                            'role_keyword': keyword
                        })
                        break
            
            # Look for Sobradinho advocacy mentions
            sobradinho_terms = ['sobradinho', 'deslocad', 'reassent', 'indenizad', 'atingid']
            advocacy_terms = ['advogad', 'represent', 'defens', 'luta', 'direito']
            
            has_sobradinho = any(term in title or term in body for term in sobradinho_terms)
            has_advocacy = any(term in title or term in body for term in advocacy_terms)
            
            if has_sobradinho and has_advocacy:
                sobradinho_advocates.append({
                    'title': result.get('title', ''),
                    'url': url,
                    'snippet': result.get('body', '')[:400],
                    'query': query_text,
                    'sobradinho_terms': [term for term in sobradinho_terms if term in title or term in body],
                    'advocacy_terms': [term for term in advocacy_terms if term in title or term in body]
                })
            
            # Look for key findings combining CBHSF and Sobradinho
            if (('cbhsf' in title or 'cbhsf' in body or 'comit√™' in title or 'comit√™' in body) and 
                ('sobradinho' in title or 'sobradinho' in body)):
                key_findings.append({
                    'title': result.get('title', ''),
                    'url': url,
                    'snippet': result.get('body', '')[:400],
                    'query': query_text,
                    'relevance': 'High - Contains both CBHSF and Sobradinho references'
                })

print(f"\nüìà TARGETED ANALYSIS RESULTS:")
print(f"   ‚Ä¢ Total targeted results analyzed: {total_targeted_results}")
print(f"   ‚Ä¢ CBHSF individuals found: {len(cbhsf_individuals)}")
print(f"   ‚Ä¢ Sobradinho advocates found: {len(sobradinho_advocates)}")
print(f"   ‚Ä¢ Key findings (CBHSF + Sobradinho): {len(key_findings)}")

print(f"\nüë• CBHSF INDIVIDUALS IDENTIFIED:")
for i, individual in enumerate(cbhsf_individuals[:5], 1):
    print(f"\n{i}. {individual['title']}")
    print(f"   Role: {individual['role_keyword']}")
    print(f"   URL: {individual['url']}")
    print(f"   Snippet: {individual['snippet'][:200]}...")
    print(f"   From query: {individual['query'][:40]}...")

print(f"\nüèóÔ∏è SOBRADINHO ADVOCATES IDENTIFIED:")
for i, advocate in enumerate(sobradinho_advocates[:5], 1):
    print(f"\n{i}. {advocate['title']}")
    print(f"   Sobradinho terms: {', '.join(advocate['sobradinho_terms'])}")
    print(f"   Advocacy terms: {', '.join(advocate['advocacy_terms'])}")
    print(f"   URL: {advocate['url']}")
    print(f"   Snippet: {advocate['snippet'][:200]}...")

print(f"\nüéØ KEY FINDINGS (CBHSF + Sobradinho):")
for i, finding in enumerate(key_findings[:5], 1):
    print(f"\n{i}. {finding['title']}")
    print(f"   Relevance: {finding['relevance']}")
    print(f"   URL: {finding['url']}")
    print(f"   Snippet: {finding['snippet'][:200]}...")

# Compile final comprehensive findings
final_findings = {
    'search_date': datetime.now().isoformat(),
    'organization_identified': 'CBHSF (Comit√™ da Bacia Hidrogr√°fica do Rio S√£o Francisco)',
    'environmental_plan': 'Plano de Educa√ß√£o Ambiental da Bacia do Rio S√£o Francisco',
    'municipalities_covered': 505,
    'ministry_collaboration': 'Confirmed - Works with Minist√©rios P√∫blicos',
    'targeted_search_summary': {
        'queries_conducted': len(targeted_queries),
        'total_results': total_targeted_results,
        'cbhsf_individuals_found': len(cbhsf_individuals),
        'sobradinho_advocates_found': len(sobradinho_advocates),
        'key_findings_count': len(key_findings)
    },
    'cbhsf_individuals': cbhsf_individuals[:10],
    'sobradinho_advocates': sobradinho_advocates[:10],
    'key_findings': key_findings[:10],
    'search_queries_used': targeted_queries
}

# Save comprehensive findings
final_findings_file = "workspace/cbhsf_sobradinho_comprehensive_findings.json"
with open(final_findings_file, 'w', encoding='utf-8') as f:
    json.dump(final_findings, f, indent=2, ensure_ascii=False)

print(f"\n{'='*80}")
print("FINAL COMPREHENSIVE RESULTS")
print(f"{'='*80}")

print(f"\nüè¢ ORGANIZATION CONFIRMED:")
print(f"   ‚Ä¢ CBHSF (Comit√™ da Bacia Hidrogr√°fica do Rio S√£o Francisco)")
print(f"   ‚Ä¢ Responsible for: Plano de Educa√ß√£o Ambiental da Bacia do Rio S√£o Francisco")
print(f"   ‚Ä¢ Coverage: 505 municipalities")
print(f"   ‚Ä¢ Collaboration: Works with Minist√©rios P√∫blicos")

if cbhsf_individuals:
    print(f"\nüë§ CBHSF INDIVIDUALS IDENTIFIED: {len(cbhsf_individuals)}")
    for individual in cbhsf_individuals[:3]:
        print(f"   ‚Ä¢ {individual['title']} ({individual['role_keyword']})")
else:
    print(f"\nüë§ CBHSF INDIVIDUALS: Requires additional targeted search")

if sobradinho_advocates:
    print(f"\nüèóÔ∏è SOBRADINHO ADVOCATES IDENTIFIED: {len(sobradinho_advocates)}")
    for advocate in sobradinho_advocates[:3]:
        print(f"   ‚Ä¢ {advocate['title']}")
else:
    print(f"\nüèóÔ∏è SOBRADINHO ADVOCATES: Requires additional investigation")

print(f"\nüìÅ COMPREHENSIVE FINDINGS SAVED TO:")
print(f"   ‚Ä¢ {final_findings_file}")
print(f"   ‚Ä¢ {targeted_results_file}")

print(f"\n{'='*80}")
print("MISSION STATUS")
print(f"{'='*80}")

print(f"\n‚úÖ ORGANIZATION IDENTIFIED: CBHSF")
print(f"‚úÖ ENVIRONMENTAL PLAN CONFIRMED: Covers 505 municipalities")
print(f"‚úÖ MINISTRY COLLABORATION CONFIRMED")

if cbhsf_individuals and sobradinho_advocates:
    print(f"‚úÖ INDIVIDUALS IDENTIFIED: Found both CBHSF members and Sobradinho advocates")
    print(f"\nüéØ MISSION COMPLETED SUCCESSFULLY!")
elif cbhsf_individuals or sobradinho_advocates:
    print(f"‚ö†Ô∏è INDIVIDUALS PARTIALLY IDENTIFIED: Found some leads, need additional research")
    print(f"\nüéØ MISSION PARTIALLY COMPLETED")
else:
    print(f"‚ö†Ô∏è INDIVIDUALS: Require additional targeted research")
    print(f"\nüéØ ORGANIZATION IDENTIFIED, INDIVIDUALS NEED FURTHER INVESTIGATION")

print(f"\n‚úÖ COMPREHENSIVE SEARCH AND ANALYSIS COMPLETED!")
```