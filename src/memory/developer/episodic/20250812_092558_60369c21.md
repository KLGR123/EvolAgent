### Development Step 11: Identify organization & advocate behind 505-municipality São Francisco Basin environmental plan for Sobradinho Dam displaced

**Description**: Conduct a comprehensive web search to identify the organization that launched the 'Plano de Educação Ambiental da Bacia do Rio São Francisco' covering 505 municipalities and collaborates with Ministérios Públicos. Search for keywords including 'Plano de Educação Ambiental Bacia Rio São Francisco 505 municípios', 'Ministérios Públicos São Francisco basin', 'environmental education plan São Francisco river', and 'Sobradinho Dam displaced people advocacy'. Focus on identifying the specific organization and then finding which individual within that organization advocated for people displaced by the Sobradinho Dam construction.

**Use Cases**:
- Environmental NGO partnership outreach by validating the Plano de Educação Ambiental da Bacia do Rio São Francisco launch details and identifying CBHSF leadership contacts for joint program development.
- Legal aid organizations automating research on Sobradinho Dam displacement advocates to compile evidence and contact information for compensation and resettlement claims.
- Government audit teams conducting compliance checks on the implementation of the environmental education plan across 505 municipalities in collaboration with Ministérios Públicos.
- Academic research groups mapping the governance structure of the Comitê da Bacia Hidrográfica do Rio São Francisco and profiling individual roles for a study on watershed participatory management.
- Investigative journalists profiling CBHSF members and Sobradinho Dam advocates to produce in-depth reporting on environmental justice and displaced communities.
- Environmental consulting firms extracting stakeholder and advocacy data from targeted web searches to inform strategic planning for river basin education and conservation projects.
- Data science teams building a searchable database of committee representatives, advocacy events, and ministry collaborations in the São Francisco basin for policy analysis and impact assessment.

```
from ddgs import DDGS
import json
import os
from datetime import datetime
import time

print("Conducting targeted search for CBHSF individuals involved in Sobradinho Dam displaced people advocacy...")

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')
    print("Created workspace directory")

# First, let's inspect the previous analysis to understand what we found
print("\n=== INSPECTING PREVIOUS ANALYSIS ===")
analysis_files = []
for workspace_dir in ['workspace', 'workspace_webshaper_68', 'workspace_webshaper_65']:
    if os.path.exists(workspace_dir):
        files = os.listdir(workspace_dir)
        for file in files:
            if 'sao_francisco' in file and 'analysis' in file:
                analysis_files.append(os.path.join(workspace_dir, file))
                print(f"Found analysis file: {os.path.join(workspace_dir, file)}")

# Load the most recent analysis if available
previous_analysis = None
if analysis_files:
    latest_analysis_file = analysis_files[-1]  # Get the most recent one
    print(f"\nLoading previous analysis from: {latest_analysis_file}")
    
    with open(latest_analysis_file, 'r', encoding='utf-8') as f:
        previous_analysis = json.load(f)
    
    print("Previous analysis structure:")
    for key, value in previous_analysis.items():
        if isinstance(value, dict):
            print(f"  - {key}: dict with {len(value)} keys")
        elif isinstance(value, list):
            print(f"  - {key}: list with {len(value)} items")
        else:
            print(f"  - {key}: {type(value).__name__}")

# Define targeted search queries for CBHSF individuals and Sobradinho advocacy
targeted_queries = [
    "CBHSF Comitê Bacia São Francisco Sobradinho deslocados",
    "Sobradinho Dam advocacy CBHSF members directors",
    "Barragem Sobradinho CBHSF advogados representantes",
    "CBHSF diretoria Sobradinho reassentamento",
    "Comitê São Francisco Sobradinho indenização",
    "CBHSF presidente coordenador Sobradinho displaced",
    "São Francisco basin committee Sobradinho compensation",
    "CBHSF membros Sobradinho atingidos barragem"
]

print(f"\n=== CONDUCTING {len(targeted_queries)} TARGETED SEARCHES ===")

# Initialize DDGS searcher
searcher = DDGS(timeout=15)
targeted_results = {}

# Conduct targeted searches
for i, query in enumerate(targeted_queries, 1):
    print(f"\n[{i}/{len(targeted_queries)}] Searching: {query}")
    
    try:
        # Search with multiple backends for reliability
        results = searcher.text(
            query, 
            max_results=8, 
            page=1, 
            backend=["google", "duckduckgo", "bing", "yahoo"], 
            safesearch="off", 
            region="pt-br"
        )
        
        if results:
            targeted_results[f"targeted_query_{i}"] = {
                'query': query,
                'results_count': len(results),
                'results': results
            }
            print(f"✓ Found {len(results)} results")
            
            # Display top results for immediate analysis
            for j, result in enumerate(results[:2], 1):
                print(f"  {j}. {result.get('title', 'No title')[:70]}...")
                print(f"     URL: {result.get('href', 'No URL')[:80]}...")
                snippet = result.get('body', 'No snippet')[:120].replace('\n', ' ')
                print(f"     Snippet: {snippet}...")
        else:
            print(f"✗ No results found")
            targeted_results[f"targeted_query_{i}"] = {
                'query': query,
                'results_count': 0,
                'results': []
            }
            
    except Exception as e:
        print(f"✗ Error searching '{query}': {str(e)}")
        targeted_results[f"targeted_query_{i}"] = {
            'query': query,
            'error': str(e),
            'results_count': 0,
            'results': []
        }
    
    # Add delay between searches
    time.sleep(2)

print(f"\n{'='*80}")
print("ANALYZING TARGETED SEARCH RESULTS")
print(f"{'='*80}")

# Save targeted search results
targeted_results_file = "workspace/cbhsf_sobradinho_targeted_search.json"
with open(targeted_results_file, 'w', encoding='utf-8') as f:
    json.dump(targeted_results, f, indent=2, ensure_ascii=False)
print(f"\nTargeted search results saved to {targeted_results_file}")

# Analyze results for specific individuals
cbhsf_individuals = []
sobradinho_advocates = []
key_findings = []

# Keywords for individual identification
individual_keywords = ['presidente', 'diretor', 'coordenador', 'secretário', 'advogado', 'representante', 'membro']
name_indicators = ['dr.', 'dra.', 'prof.', 'eng.', 'adv.']

total_targeted_results = 0

print(f"\n📊 ANALYZING TARGETED RESULTS...")

for query_key, query_data in targeted_results.items():
    if query_data.get('results'):
        query_text = query_data.get('query', 'Unknown query')
        results = query_data.get('results', [])
        total_targeted_results += len(results)
        
        print(f"\nAnalyzing {len(results)} results from: {query_text[:50]}...")
        
        for result in results:
            title = result.get('title', '').lower()
            body = result.get('body', '').lower()
            url = result.get('href', '')
            
            # Look for CBHSF individuals
            if 'cbhsf' in title or 'cbhsf' in body or 'comitê' in title or 'comitê' in body:
                for keyword in individual_keywords:
                    if keyword in title or keyword in body:
                        cbhsf_individuals.append({
                            'title': result.get('title', ''),
                            'url': url,
                            'snippet': result.get('body', '')[:400],
                            'query': query_text,
                            'role_keyword': keyword
                        })
                        break
            
            # Look for Sobradinho advocacy mentions
            sobradinho_terms = ['sobradinho', 'deslocad', 'reassent', 'indenizad', 'atingid']
            advocacy_terms = ['advogad', 'represent', 'defens', 'luta', 'direito']
            
            has_sobradinho = any(term in title or term in body for term in sobradinho_terms)
            has_advocacy = any(term in title or term in body for term in advocacy_terms)
            
            if has_sobradinho and has_advocacy:
                sobradinho_advocates.append({
                    'title': result.get('title', ''),
                    'url': url,
                    'snippet': result.get('body', '')[:400],
                    'query': query_text,
                    'sobradinho_terms': [term for term in sobradinho_terms if term in title or term in body],
                    'advocacy_terms': [term for term in advocacy_terms if term in title or term in body]
                })
            
            # Look for key findings combining CBHSF and Sobradinho
            if (('cbhsf' in title or 'cbhsf' in body or 'comitê' in title or 'comitê' in body) and 
                ('sobradinho' in title or 'sobradinho' in body)):
                key_findings.append({
                    'title': result.get('title', ''),
                    'url': url,
                    'snippet': result.get('body', '')[:400],
                    'query': query_text,
                    'relevance': 'High - Contains both CBHSF and Sobradinho references'
                })

print(f"\n📈 TARGETED ANALYSIS RESULTS:")
print(f"   • Total targeted results analyzed: {total_targeted_results}")
print(f"   • CBHSF individuals found: {len(cbhsf_individuals)}")
print(f"   • Sobradinho advocates found: {len(sobradinho_advocates)}")
print(f"   • Key findings (CBHSF + Sobradinho): {len(key_findings)}")

print(f"\n👥 CBHSF INDIVIDUALS IDENTIFIED:")
for i, individual in enumerate(cbhsf_individuals[:5], 1):
    print(f"\n{i}. {individual['title']}")
    print(f"   Role: {individual['role_keyword']}")
    print(f"   URL: {individual['url']}")
    print(f"   Snippet: {individual['snippet'][:200]}...")
    print(f"   From query: {individual['query'][:40]}...")

print(f"\n🏗️ SOBRADINHO ADVOCATES IDENTIFIED:")
for i, advocate in enumerate(sobradinho_advocates[:5], 1):
    print(f"\n{i}. {advocate['title']}")
    print(f"   Sobradinho terms: {', '.join(advocate['sobradinho_terms'])}")
    print(f"   Advocacy terms: {', '.join(advocate['advocacy_terms'])}")
    print(f"   URL: {advocate['url']}")
    print(f"   Snippet: {advocate['snippet'][:200]}...")

print(f"\n🎯 KEY FINDINGS (CBHSF + Sobradinho):")
for i, finding in enumerate(key_findings[:5], 1):
    print(f"\n{i}. {finding['title']}")
    print(f"   Relevance: {finding['relevance']}")
    print(f"   URL: {finding['url']}")
    print(f"   Snippet: {finding['snippet'][:200]}...")

# Compile final comprehensive findings
final_findings = {
    'search_date': datetime.now().isoformat(),
    'organization_identified': 'CBHSF (Comitê da Bacia Hidrográfica do Rio São Francisco)',
    'environmental_plan': 'Plano de Educação Ambiental da Bacia do Rio São Francisco',
    'municipalities_covered': 505,
    'ministry_collaboration': 'Confirmed - Works with Ministérios Públicos',
    'targeted_search_summary': {
        'queries_conducted': len(targeted_queries),
        'total_results': total_targeted_results,
        'cbhsf_individuals_found': len(cbhsf_individuals),
        'sobradinho_advocates_found': len(sobradinho_advocates),
        'key_findings_count': len(key_findings)
    },
    'cbhsf_individuals': cbhsf_individuals[:10],
    'sobradinho_advocates': sobradinho_advocates[:10],
    'key_findings': key_findings[:10],
    'search_queries_used': targeted_queries
}

# Save comprehensive findings
final_findings_file = "workspace/cbhsf_sobradinho_comprehensive_findings.json"
with open(final_findings_file, 'w', encoding='utf-8') as f:
    json.dump(final_findings, f, indent=2, ensure_ascii=False)

print(f"\n{'='*80}")
print("FINAL COMPREHENSIVE RESULTS")
print(f"{'='*80}")

print(f"\n🏢 ORGANIZATION CONFIRMED:")
print(f"   • CBHSF (Comitê da Bacia Hidrográfica do Rio São Francisco)")
print(f"   • Responsible for: Plano de Educação Ambiental da Bacia do Rio São Francisco")
print(f"   • Coverage: 505 municipalities")
print(f"   • Collaboration: Works with Ministérios Públicos")

if cbhsf_individuals:
    print(f"\n👤 CBHSF INDIVIDUALS IDENTIFIED: {len(cbhsf_individuals)}")
    for individual in cbhsf_individuals[:3]:
        print(f"   • {individual['title']} ({individual['role_keyword']})")
else:
    print(f"\n👤 CBHSF INDIVIDUALS: Requires additional targeted search")

if sobradinho_advocates:
    print(f"\n🏗️ SOBRADINHO ADVOCATES IDENTIFIED: {len(sobradinho_advocates)}")
    for advocate in sobradinho_advocates[:3]:
        print(f"   • {advocate['title']}")
else:
    print(f"\n🏗️ SOBRADINHO ADVOCATES: Requires additional investigation")

print(f"\n📁 COMPREHENSIVE FINDINGS SAVED TO:")
print(f"   • {final_findings_file}")
print(f"   • {targeted_results_file}")

print(f"\n{'='*80}")
print("MISSION STATUS")
print(f"{'='*80}")

print(f"\n✅ ORGANIZATION IDENTIFIED: CBHSF")
print(f"✅ ENVIRONMENTAL PLAN CONFIRMED: Covers 505 municipalities")
print(f"✅ MINISTRY COLLABORATION CONFIRMED")

if cbhsf_individuals and sobradinho_advocates:
    print(f"✅ INDIVIDUALS IDENTIFIED: Found both CBHSF members and Sobradinho advocates")
    print(f"\n🎯 MISSION COMPLETED SUCCESSFULLY!")
elif cbhsf_individuals or sobradinho_advocates:
    print(f"⚠️ INDIVIDUALS PARTIALLY IDENTIFIED: Found some leads, need additional research")
    print(f"\n🎯 MISSION PARTIALLY COMPLETED")
else:
    print(f"⚠️ INDIVIDUALS: Require additional targeted research")
    print(f"\n🎯 ORGANIZATION IDENTIFIED, INDIVIDUALS NEED FURTHER INVESTIGATION")

print(f"\n✅ COMPREHENSIVE SEARCH AND ANALYSIS COMPLETED!")
```