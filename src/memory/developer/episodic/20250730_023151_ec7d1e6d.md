### Development Step 5: July 3, 2023 LOTR Wiki Links Toward ‚ÄúA Song of Ice and Fire‚Äù Pathfinding

**Description**: Access the archived Wikipedia page for 'The Lord of the Rings' (book) as it appeared at the end of July 3, 2023. Use the Wayback Machine or Wikipedia's revision history to retrieve the specific version from that date. Extract all outbound links from the page content, focusing on internal Wikipedia links that could potentially lead toward 'A Song of Ice and Fire'. Create a comprehensive list of linked pages including literature, fantasy, author, publisher, and genre-related links that might serve as stepping stones in the path-finding process.

**Use Cases**:
- Academic literature review for comparative mythology and fantasy narrative structures: using archived Wikipedia BFS analysis to identify key thematic and authorial links between ‚ÄúThe Lord of the Rings‚Äù and ‚ÄúA Song of Ice and Fire‚Äù for a peer-reviewed journal article
- Fan-curated digital reading guide automation: extracting and categorizing intermediary Wikipedia pages to generate a step-by-step exploration path from Tolkien‚Äôs works to George R.R. Martin‚Äôs saga for community websites
- Publishing industry network analysis: mapping out internal Wikipedia links to evaluate cross-references between Tolkien‚Äôs publishers (Allen & Unwin) and Martin‚Äôs publishers (Bantam Books) to inform partnership opportunities
- SEO optimization for fantasy content blogs: analyzing BFS-derived outbound links as high-priority internal Wikipedia pages to inform backlink strategies and increase organic traffic for fantasy literature websites
- Digital humanities knowledge graph construction: leveraging archived page BFS results to programmatically build relationships among fantasy authors, novels, genres, and publishers in an RDF-based graph for scholarly open data
- Library cataloging automation and subject heading mapping: using extracted Wikipedia link networks to align Library of Congress subject headings for epic fantasy literature, improving metadata consistency across catalogs
- Educational curriculum development in literature courses: identifying critical thematic and authorial linkages via BFS analysis to design lecture modules that trace the evolution of epic fantasy from Tolkien to Martin
- Market research on genre trends: tracking the frequency and depth of interlinked Wikipedia pages over time to analyze shifting popularity of fantasy subgenres and strategize new series launches

```
import os
import json
from datetime import datetime

print("=== ANALYZING BFS SEARCH RESULTS AND PROMISING LEADS ===")
print("Objective: Extract and analyze promising leads for manual path exploration\n")

# First, locate the workspace directory
workspace_dirs = [d for d in os.listdir('.') if d.startswith('workspace')]
if not workspace_dirs:
    print("‚ùå No workspace directory found")
    exit()

workspace_dir = workspace_dirs[0]
print(f"Using workspace directory: {workspace_dir}\n")

# List all available files
print("Available files in workspace:")
for file in os.listdir(workspace_dir):
    file_path = os.path.join(workspace_dir, file)
    file_size = os.path.getsize(file_path)
    print(f"  - {file} ({file_size:,} bytes)")

# First, inspect the structure of the BFS results file
bfs_results_file = os.path.join(workspace_dir, 'bfs_html_scraping_results.json')
if not os.path.exists(bfs_results_file):
    print("\n‚ùå BFS results file not found")
    exit()

print(f"\n=== INSPECTING BFS RESULTS FILE STRUCTURE ===")
print(f"File: {os.path.basename(bfs_results_file)}")
print(f"Size: {os.path.getsize(bfs_results_file):,} bytes\n")

# Load and inspect the JSON structure without assumptions
with open(bfs_results_file, 'r', encoding='utf-8') as f:
    bfs_data = json.load(f)

print("Top-level keys in BFS results:")
for key, value in bfs_data.items():
    if isinstance(value, dict):
        print(f"  {key}: Dictionary with {len(value)} keys")
        for nested_key, nested_value in value.items():
            if isinstance(nested_value, list):
                print(f"    {nested_key}: List with {len(nested_value)} items")
            elif isinstance(nested_value, dict):
                print(f"    {nested_key}: Dictionary with {len(nested_value)} keys")
            else:
                print(f"    {nested_key}: {type(nested_value).__name__} = {nested_value}")
    elif isinstance(value, list):
        print(f"  {key}: List with {len(value)} items")
        if value and isinstance(value[0], dict):
            print(f"    Sample item keys: {list(value[0].keys())}")
    else:
        print(f"  {key}: {type(value).__name__} = {value}")

print(f"\n=== EXAMINING SEARCH METADATA ===")
if 'search_metadata' in bfs_data:
    metadata = bfs_data['search_metadata']
    print("Search execution details:")
    for key, value in metadata.items():
        print(f"  {key}: {value}")
else:
    print("No search metadata found")

print(f"\n=== ANALYZING PROMISING LEADS ===")
if 'promising_leads' in bfs_data:
    promising_leads = bfs_data['promising_leads']
    print(f"Total promising leads found: {len(promising_leads)}\n")
    
    if promising_leads:
        print("Structure of first promising lead:")
        first_lead = promising_leads[0]
        for key, value in first_lead.items():
            print(f"  {key}: {value}")
        
        print(f"\n=== TOP 20 MOST PROMISING LEADS FOR MANUAL EXPLORATION ===\n")
        
        # Categorize leads by potential relevance to fantasy literature
        fantasy_keywords = ['fantasy', 'epic', 'saga', 'series', 'novel', 'literature', 'author', 'writer', 'martin', 'george']
        
        categorized_leads = {
            'high_priority': [],
            'medium_priority': [],
            'low_priority': []
        }
        
        for lead in promising_leads:
            if isinstance(lead, dict) and 'node' in lead:
                node_name = lead['node'].lower()
                
                # High priority: Contains multiple fantasy keywords or author names
                if (sum(1 for keyword in fantasy_keywords if keyword in node_name) >= 2 or 
                    any(author in node_name for author in ['martin', 'george']) or
                    any(term in node_name for term in ['song of ice', 'game of thrones', 'fantasy literature', 'fantasy author'])):
                    categorized_leads['high_priority'].append(lead)
                
                # Medium priority: Contains single fantasy keyword
                elif any(keyword in node_name for keyword in fantasy_keywords):
                    categorized_leads['medium_priority'].append(lead)
                
                # Low priority: Everything else
                else:
                    categorized_leads['low_priority'].append(lead)
        
        print("CATEGORIZED PROMISING LEADS:\n")
        
        for priority, leads in categorized_leads.items():
            print(f"{priority.upper().replace('_', ' ')}: {len(leads)} leads")
            for i, lead in enumerate(leads[:10], 1):  # Show top 10 in each category
                node = lead.get('node', 'Unknown')
                parent = lead.get('parent', 'Unknown')
                depth = lead.get('depth', 'Unknown')
                print(f"  {i:2d}. {node}")
                print(f"      From: {parent} (depth {depth})")
            if len(leads) > 10:
                print(f"      ... and {len(leads) - 10} more")
            print()
        
        # Now let's look for the most direct paths to fantasy literature
        print("=== MOST DIRECT FANTASY LITERATURE CONNECTIONS ===\n")
        
        direct_fantasy_connections = []
        for lead in promising_leads:
            if isinstance(lead, dict) and 'node' in lead:
                node_name = lead['node'].lower()
                if any(term in node_name for term in ['fantasy literature', 'fantasy author', 'epic fantasy', 'high fantasy', 'fantasy series', 'fantasy novel']):
                    direct_fantasy_connections.append(lead)
        
        if direct_fantasy_connections:
            print(f"Found {len(direct_fantasy_connections)} direct fantasy literature connections:")
            for i, connection in enumerate(direct_fantasy_connections, 1):
                print(f"  {i}. {connection['node']} (depth {connection['depth']})")
                print(f"     Path: {connection['parent']} ‚Üí {connection['node']}")
        else:
            print("No direct fantasy literature connections found in promising leads")
            
        # Create a manual exploration guide
        print(f"\n=== MANUAL EXPLORATION RECOMMENDATIONS ===\n")
        
        manual_targets = []
        
        # Add high-priority leads
        for lead in categorized_leads['high_priority'][:5]:
            manual_targets.append({
                'target': lead['node'],
                'reason': 'High fantasy relevance - multiple keywords match',
                'path_so_far': f"{lead['parent']} ‚Üí {lead['node']}",
                'next_steps': ['Check for George R.R. Martin mentions', 'Look for fantasy literature connections', 'Search for A Song of Ice and Fire references']
            })
        
        # Add some medium-priority leads as backup
        for lead in categorized_leads['medium_priority'][:3]:
            manual_targets.append({
                'target': lead['node'],
                'reason': 'Moderate fantasy relevance - single keyword match',
                'path_so_far': f"{lead['parent']} ‚Üí {lead['node']}",
                'next_steps': ['Scan for fantasy author links', 'Check literature sections']
            })
        
        print("RECOMMENDED MANUAL EXPLORATION TARGETS:\n")
        for i, target in enumerate(manual_targets, 1):
            print(f"{i}. TARGET: {target['target']}")
            print(f"   Reason: {target['reason']}")
            print(f"   Path: {target['path_so_far']}")
            print(f"   Next steps: {', '.join(target['next_steps'])}")
            print()
        
        # Save the analysis results
        analysis_results = {
            'analysis_metadata': {
                'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'source_file': os.path.basename(bfs_results_file),
                'total_promising_leads': len(promising_leads),
                'search_method': bfs_data.get('search_metadata', {}).get('method', 'unknown')
            },
            'lead_categorization': {
                'high_priority_count': len(categorized_leads['high_priority']),
                'medium_priority_count': len(categorized_leads['medium_priority']),
                'low_priority_count': len(categorized_leads['low_priority'])
            },
            'categorized_leads': categorized_leads,
            'direct_fantasy_connections': direct_fantasy_connections,
            'manual_exploration_targets': manual_targets
        }
        
        analysis_file = os.path.join(workspace_dir, 'promising_leads_analysis.json')
        with open(analysis_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_results, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"üìÅ Analysis results saved to: {os.path.basename(analysis_file)}")
        
else:
    print("No promising leads found in the BFS results")

print(f"\n=== CHECKING FOR ACTUAL PATHS FOUND ===")
if 'paths_found' in bfs_data:
    paths_found = bfs_data['paths_found']
    if paths_found:
        print(f"üéâ SUCCESS: {len(paths_found)} actual paths to target were discovered!")
        for i, path in enumerate(paths_found, 1):
            print(f"\nPath {i}:")
            for key, value in path.items():
                print(f"  {key}: {value}")
    else:
        print("‚ùå No complete paths to 'A Song of Ice and Fire' were found")
        print("   This indicates we need deeper exploration or different starting points")
else:
    print("No paths_found data in results")

print(f"\n=== SUMMARY AND NEXT STEPS ===\n")
print("‚úÖ Successfully analyzed BFS search results")
if 'promising_leads' in bfs_data:
    print(f"üìä Identified {len(bfs_data['promising_leads'])} promising leads for further exploration")
    print(f"üéØ Created {len(manual_targets) if 'manual_targets' in locals() else 0} specific manual exploration targets")
print(f"üìù Next steps: Manual exploration of high-priority fantasy literature connections")
print(f"üîÑ Alternative: Extended BFS search with increased depth/request limits")
```