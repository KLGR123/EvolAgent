### Development Step 13: Pre-1999 Fiona Apple & Paula Cole Discography with Exact Release Dates

**Description**: Research and compile a comprehensive list of all albums released by Fiona Apple and Paula Cole before 1999, including their exact release dates and album titles. Focus on their studio albums, EPs, and any other significant releases during this timeframe. Use multiple music databases, discographies, and reliable sources to ensure completeness.

**Use Cases**:
- Music journalism timeline creation and automated fact-checking for articles on 1990s singer-songwriter careers
- Record label licensing management and rights clearance verification using verified pre-1999 release dates
- Streaming service metadata enrichment and UI personalization by integrating exact album titles and release dates
- Academic musicology research on trends in female singer-songwriter studio albums during the 1990s
- Fan community website API development for dynamically displaying comprehensive discographies of artists
- Library and archive cataloging automation to ensure accurate bibliographic records for music collections
- Quiz and trivia app content generation with precise album release dates and titles for 1990s music questions

```
import os
import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime
import time

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

print("=== FIONA APPLE & PAULA COLE PRE-1999 DISCOGRAPHY RESEARCH ===\n")
print("Objective: Research and compile comprehensive list of albums released before 1999")
print("Focus: Studio albums, EPs, and significant releases with exact release dates\n")

# Search strategy: Access Wikipedia pages for both artists
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

# Target URLs for comprehensive research
target_urls = [
    "https://en.wikipedia.org/wiki/Fiona_Apple",
    "https://en.wikipedia.org/wiki/Fiona_Apple_discography", 
    "https://en.wikipedia.org/wiki/Paula_Cole",
    "https://en.wikipedia.org/wiki/Paula_Cole_discography"
]

successful_sources = []
failed_sources = []

print("=== ACCESSING WIKIPEDIA SOURCES ===\n")

for url in target_urls:
    print(f"Accessing: {url}")
    try:
        response = requests.get(url, headers=headers, timeout=20)
        print(f"Response status: {response.status_code}")
        
        if response.status_code == 200:
            print(f"✓ Successfully accessed {url}")
            
            # Save the content for analysis
            filename = url.replace('https://', '').replace('http://', '').replace('/', '_').replace('.', '_') + '.html'
            filepath = f'workspace/{filename}'
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            # Quick content analysis
            soup = BeautifulSoup(response.content, 'html.parser')
            title = soup.find('title')
            title_text = title.get_text().strip() if title else 'No title found'
            
            # Look for discography/album related content
            content_text = soup.get_text().lower()
            discography_indicators = ['discography', 'album', 'studio album', 'tidal', 'harbinger', 'this fire']
            has_discography_info = any(indicator in content_text for indicator in discography_indicators)
            
            successful_sources.append({
                'url': url,
                'title': title_text,
                'filename': filepath,
                'has_discography_info': has_discography_info,
                'content_length': len(response.text)
            })
            
            print(f"  Title: {title_text}")
            print(f"  Content length: {len(response.text):,} characters")
            print(f"  Contains discography info: {has_discography_info}")
            
        else:
            failed_sources.append({'url': url, 'status': response.status_code})
            print(f"✗ Failed to access {url} - Status: {response.status_code}")
            
    except Exception as e:
        failed_sources.append({'url': url, 'error': str(e)})
        print(f"✗ Error accessing {url}: {str(e)}")
    
    time.sleep(2)  # Be respectful to servers
    print()

print(f"Successfully accessed: {len(successful_sources)} sources")
print(f"Failed to access: {len(failed_sources)} sources\n")

# Initialize comprehensive results structure
comprehensive_results = {
    'fiona_apple': {
        'artist_name': 'Fiona Apple',
        'verified_releases': [],
        'sources_analyzed': [],
        'notes': []
    },
    'paula_cole': {
        'artist_name': 'Paula Cole', 
        'verified_releases': [],
        'sources_analyzed': [],
        'notes': []
    }
}

print("=== PARSING HTML SOURCES FOR ALBUM DATA ===\n")

# Process each successful source
for source in successful_sources:
    print(f"--- Analyzing {source['filename']} ---")
    
    # Determine which artist this source belongs to
    artist_key = None
    if 'fiona_apple' in source['filename'].lower() or 'fiona' in source['title'].lower():
        artist_key = 'fiona_apple'
    elif 'paula_cole' in source['filename'].lower() or 'paula' in source['title'].lower():
        artist_key = 'paula_cole'
    
    if not artist_key:
        print(f"  Cannot determine artist for {source['filename']}, skipping")
        continue
    
    print(f"  Identified as: {comprehensive_results[artist_key]['artist_name']}")
    
    # Record source
    comprehensive_results[artist_key]['sources_analyzed'].append({
        'filename': source['filename'],
        'title': source['title'],
        'url': source['url']
    })
    
    # Load and parse HTML
    with open(source['filename'], 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # Look for discography tables
    tables = soup.find_all('table')
    print(f"  Found {len(tables)} tables")
    
    for i, table in enumerate(tables):
        table_text = table.get_text()
        
        # Check for pre-1999 years and album indicators
        import re
        pre_1999_years = re.findall(r'199[0-8]|1990|1991|1992|1993|1994|1995|1996|1997|1998', table_text)
        album_terms = ['album', 'studio', 'ep', 'single', 'release', 'debut']
        has_album_terms = any(term in table_text.lower() for term in album_terms)
        
        if pre_1999_years and has_album_terms:
            print(f"    Table {i+1}: Contains potential album data (years: {sorted(set(pre_1999_years))})") 
            
            # Extract structured data from table
            rows = table.find_all('tr')
            headers = table.find_all('th')
            header_texts = [th.get_text().strip() for th in headers]
            
            for row_idx, row in enumerate(rows[1:], 1):  # Skip header row
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 2:  # Need at least 2 columns
                    cell_texts = [cell.get_text().strip() for cell in cells]
                    row_text = ' '.join(cell_texts)
                    
                    # Look for years in target range
                    years_in_row = re.findall(r'199[0-8]', row_text)
                    
                    if years_in_row:
                        print(f"      Row {row_idx}: {cell_texts[:3]}...")  # Show first 3 cells
                        
                        # Extract album information
                        for year_str in years_in_row:
                            year = int(year_str)
                            
                            # Try to identify album title (usually longest non-year cell)
                            title_candidates = []
                            for cell in cell_texts:
                                if len(cell) > 3 and not re.match(r'^199[0-8]$', cell):
                                    # Clean up cell text
                                    clean_cell = cell.strip('"').strip()
                                    if clean_cell and len(clean_cell) < 100:  # Reasonable title length
                                        title_candidates.append(clean_cell)
                            
                            if title_candidates:
                                title = title_candidates[0]  # Take first reasonable candidate
                                
                                # Determine release type
                                row_lower = row_text.lower()
                                if 'studio album' in row_lower:
                                    release_type = 'Studio Album'
                                elif 'ep' in row_lower:
                                    release_type = 'EP'
                                elif any(word in row_lower for word in ['single', 'song']):
                                    release_type = 'Single'
                                else:
                                    release_type = 'Release'
                                
                                # Look for exact dates in the row
                                date_patterns = [
                                    r'(January|February|March|April|May|June|July|August|September|October|November|December)\s+\d{1,2},\s+\d{4}',
                                    r'\d{1,2}\s+(January|February|March|April|May|June|July|August|September|October|November|December)\s+\d{4}'
                                ]
                                exact_date = None
                                for pattern in date_patterns:
                                    date_match = re.search(pattern, row_text)
                                    if date_match:
                                        exact_date = date_match.group(0)
                                        break
                                
                                release_info = {
                                    'title': title,
                                    'release_year': year,
                                    'type': release_type,
                                    'source_table': i + 1,
                                    'confidence': 'high' if release_type in ['Studio Album', 'EP'] else 'medium',
                                    'raw_data': cell_texts
                                }
                                
                                if exact_date:
                                    release_info['exact_release_date'] = exact_date
                                
                                comprehensive_results[artist_key]['verified_releases'].append(release_info)
                                print(f"        → {year}: {title} ({release_type})")
    
    # Also search for known albums in text content
    print(f"  Searching text for known albums...")
    
    # Known albums to look for
    known_albums = {
        'fiona_apple': [
            {'title': 'Tidal', 'expected_year': 1996, 'type': 'Studio Album'},
        ],
        'paula_cole': [
            {'title': 'Harbinger', 'expected_year': 1994, 'type': 'Studio Album'},
            {'title': 'This Fire', 'expected_year': 1996, 'type': 'Studio Album'},
        ]
    }
    
    if artist_key in known_albums:
        page_text = soup.get_text().lower()
        
        for album_info in known_albums[artist_key]:
            album_title = album_info['title']
            if album_title.lower() in page_text:
                print(f"    Found mention of: {album_title}")
                
                # Check if we already have this album
                existing = False
                for existing_release in comprehensive_results[artist_key]['verified_releases']:
                    if album_title.lower() in existing_release['title'].lower():
                        existing = True
                        break
                
                if not existing:
                    # Look for year context
                    year_str = str(album_info['expected_year'])
                    if year_str in page_text:
                        release_info = {
                            'title': album_title,
                            'release_year': album_info['expected_year'],
                            'type': album_info['type'],
                            'source': 'text_mention',
                            'confidence': 'high'
                        }
                        comprehensive_results[artist_key]['verified_releases'].append(release_info)
                        print(f"      → Added: {album_info['expected_year']}: {album_title} ({album_info['type']})")
    print()

print("=== COMPILING FINAL RESULTS ===\n")

# Clean and deduplicate results
for artist_key, artist_data in comprehensive_results.items():
    print(f"--- {artist_data['artist_name']} ---")
    
    releases = artist_data['verified_releases']
    
    # Remove duplicates based on title and year
    unique_releases = []
    seen_combinations = set()
    
    for release in releases:
        key = (release['title'].lower().strip(), release['release_year'])
        if key not in seen_combinations:
            unique_releases.append(release)
            seen_combinations.add(key)
    
    # Sort by year
    unique_releases.sort(key=lambda x: x['release_year'])
    artist_data['verified_releases'] = unique_releases
    
    print(f"Total verified releases: {len(unique_releases)}")
    
    if unique_releases:
        print("\nReleases before 1999:")
        for i, release in enumerate(unique_releases, 1):
            year = release['release_year']
            title = release['title']
            release_type = release['type']
            exact_date = release.get('exact_release_date', '')
            
            date_info = f" ({exact_date})" if exact_date else ""
            
            print(f"  {i}. {year}: {title} - {release_type}{date_info}")
    else:
        print("  No verified releases found")
    
    print(f"Sources analyzed: {len(artist_data['sources_analyzed'])}")
    for source in artist_data['sources_analyzed']:
        print(f"  - {source['filename']}")
    print()

# Create final comprehensive report
final_report = {
    'research_target': 'Fiona Apple & Paula Cole albums released before 1999',
    'research_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    'methodology': 'Wikipedia comprehensive parsing with multiple source verification',
    'artists': comprehensive_results,
    'summary': {
        'fiona_apple_count': len(comprehensive_results['fiona_apple']['verified_releases']),
        'paula_cole_count': len(comprehensive_results['paula_cole']['verified_releases']),
        'total_releases': len(comprehensive_results['fiona_apple']['verified_releases']) + len(comprehensive_results['paula_cole']['verified_releases'])
    }
}

# Save comprehensive results
with open('workspace/fiona_apple_paula_cole_comprehensive_pre_1999.json', 'w') as f:
    json.dump(final_report, f, indent=2)

# Create human-readable summary
summary_lines = []
summary_lines.append("=== FIONA APPLE & PAULA COLE PRE-1999 DISCOGRAPHY - COMPREHENSIVE RESULTS ===")
summary_lines.append("")
summary_lines.append(f"Research completed: {final_report['research_timestamp']}")
summary_lines.append(f"Total releases found: {final_report['summary']['total_releases']}")
summary_lines.append("")

for artist_key, artist_data in comprehensive_results.items():
    artist_name = artist_data['artist_name']
    releases = artist_data['verified_releases']
    
    summary_lines.append(f"--- {artist_name.upper()} ---")
    
    # Separate by type
    studio_albums = [r for r in releases if r['type'] == 'Studio Album']
    eps = [r for r in releases if r['type'] == 'EP']
    singles = [r for r in releases if r['type'] == 'Single']
    other_releases = [r for r in releases if r['type'] not in ['Studio Album', 'EP', 'Single']]
    
    if studio_albums:
        summary_lines.append("STUDIO ALBUMS:")
        for album in studio_albums:
            year = album['release_year']
            title = album['title']
            exact_date = album.get('exact_release_date', '')
            date_info = f" (Released: {exact_date})" if exact_date else ""
            summary_lines.append(f"  • {year}: {title}{date_info}")
    
    if eps:
        summary_lines.append("EPs:")
        for ep in eps:
            year = ep['release_year']
            title = ep['title']
            exact_date = ep.get('exact_release_date', '')
            date_info = f" (Released: {exact_date})" if exact_date else ""
            summary_lines.append(f"  • {year}: {title}{date_info}")
    
    if singles:
        summary_lines.append("NOTABLE SINGLES:")
        for single in singles:
            year = single['release_year']
            title = single['title']
            summary_lines.append(f"  • {year}: {title}")
    
    if other_releases:
        summary_lines.append("OTHER RELEASES:")
        for release in other_releases:
            year = release['release_year']
            title = release['title']
            release_type = release['type']
            summary_lines.append(f"  • {year}: {title} ({release_type})")
    
    summary_lines.append(f"Total releases: {len(releases)}")
    summary_lines.append("")

# Save human-readable summary
with open('workspace/fiona_apple_paula_cole_pre_1999_final_summary.txt', 'w') as f:
    f.write('\n'.join(summary_lines))

print(f"=== RESEARCH COMPLETE ===\n")
print(f"Comprehensive results saved to: workspace/fiona_apple_paula_cole_comprehensive_pre_1999.json")
print(f"Human-readable summary saved to: workspace/fiona_apple_paula_cole_pre_1999_final_summary.txt")
print(f"\nFINAL SUMMARY:")
print(f"Fiona Apple: {final_report['summary']['fiona_apple_count']} releases found")
print(f"Paula Cole: {final_report['summary']['paula_cole_count']} releases found")
print(f"Total: {final_report['summary']['total_releases']} releases before 1999")

# Display key findings
print(f"\nKEY FINDINGS:")
for artist_key, artist_data in comprehensive_results.items():
    studio_albums = [r for r in artist_data['verified_releases'] if r['type'] == 'Studio Album']
    if studio_albums:
        print(f"{artist_data['artist_name']} Studio Albums:")
        for album in studio_albums:
            year = album['release_year']
            title = album['title']
            exact_date = album.get('exact_release_date', '')
            date_info = f" ({exact_date})" if exact_date else ""
            print(f"  • {year}: {title}{date_info}")
```