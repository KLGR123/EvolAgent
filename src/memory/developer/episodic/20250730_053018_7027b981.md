### Development Step 1: Find Bibliographic Details of Neurologist-Focused Book via DOI 10.1353/book.24372

**Description**: Search for the book with DOI 10.1353/book.24372 to identify the title, author, and subject neurologist. Use multiple search approaches: (1) Direct DOI resolution through doi.org, (2) Academic database searches using the DOI, (3) Google Scholar search with the DOI string, (4) Publisher database searches focusing on the '10.1353' prefix which typically indicates Project MUSE publications. Extract complete bibliographic information including title, author, publication year, publisher, and any available abstract or description that identifies which neurologist the book concerns.

**Use Cases**:
- University library catalog integration for automated ingestion of new monographs by resolving DOIs, extracting complete bibliographic metadata, and populating catalog records
- Reference management software enhancement that auto-fills title, author, publication year, and subject area for books by querying DOI.org and academic databases
- Bibliometric research pipeline in neuroscience studies that aggregates publication metrics and author profiles for books on neurologists using Google Scholar DOI searches
- Digital humanities project compiling biographical data on historical neurologists by scraping abstracts and descriptions from Project MUSE entries resolved via the ‘10.1353’ DOI prefix
- Curriculum development tool for medical schools that retrieves book summaries, publisher details, and recommended readings in neurology courses through automated DOI lookups
- Academic journal editorial workflow that validates submitted book citations by cross-checking DOIs against doi.org redirects and Google search results to ensure metadata accuracy
- Biomedical publishing quality assurance system that verifies DOI-to-title/author mappings before printing new neurology textbooks by performing scripted resolution and pattern extraction
- Patent analysis software for medical device innovation that identifies foundational neurological texts cited in filings by resolving book DOIs and extracting publication information for citation networks

```
import os
import re
import requests
import time
from urllib.parse import quote

# DOI to search for
doi = "10.1353/book.24372"
print(f"Searching for book with DOI: {doi}")
print("="*60)

# Method 1: Direct DOI resolution through doi.org
print("\nMethod 1: Direct DOI Resolution")
print("-" * 40)
try:
    doi_url = f"https://doi.org/{doi}"
    print(f"Attempting to resolve DOI: {doi_url}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'
    }
    
    response = requests.get(doi_url, headers=headers, timeout=10, allow_redirects=True)
    print(f"DOI resolution status: {response.status_code}")
    print(f"Final URL after redirect: {response.url}")
    
    if response.status_code == 200:
        # Save the DOI resolution page content
        with open('workspace/doi_resolution_page.html', 'w', encoding='utf-8') as f:
            f.write(response.text)
        print("DOI resolution page saved to workspace/doi_resolution_page.html")
        
        # Extract key information from the page
        content = response.text.lower()
        
        # Look for title patterns
        title_patterns = [
            r'<title[^>]*>([^<]+)</title>',
            r'<h1[^>]*>([^<]+)</h1>',
            r'"title"\s*:\s*"([^"]+)"',
            r'<meta[^>]*name=["\']title["\'][^>]*content=["\']([^"\'>]+)["\']',
            r'<meta[^>]*property=["\']og:title["\'][^>]*content=["\']([^"\'>]+)["\']'
        ]
        
        for pattern in title_patterns:
            matches = re.findall(pattern, response.text, re.IGNORECASE | re.DOTALL)
            if matches:
                print(f"Title candidates found: {matches[:3]}")
                break
        
        # Look for author patterns
        author_patterns = [
            r'<meta[^>]*name=["\']author["\'][^>]*content=["\']([^"\'>]+)["\']',
            r'"author"\s*:\s*"([^"]+)"',
            r'by\s+([A-Z][a-zA-Z\s,\.]+)',
            r'<span[^>]*class=["\'][^"\'>]*author[^"\'>]*["\'][^>]*>([^<]+)</span>'
        ]
        
        for pattern in author_patterns:
            matches = re.findall(pattern, response.text, re.IGNORECASE)
            if matches:
                print(f"Author candidates found: {matches[:3]}")
                break
                
        # Check if this is Project MUSE (based on 10.1353 prefix)
        if 'muse.jhu.edu' in response.url or 'project muse' in content:
            print("*** CONFIRMED: This is a Project MUSE publication ***")
            
    else:
        print(f"DOI resolution failed with status {response.status_code}")
        
except Exception as e:
    print(f"Error in DOI resolution: {str(e)}")

time.sleep(1)  # Brief pause between requests

# Method 2: Google Scholar search with DOI
print("\n" + "="*60)
print("Method 2: Google Scholar Search")
print("-" * 40)

# Check if SerpAPI key is available
api_key = os.getenv("SERPAPI_API_KEY")
if api_key:
    print(f"SerpAPI key available: {api_key[:10]}...")
    
    # Search Google Scholar for the DOI
    scholar_query = f'"10.1353/book.24372" OR "doi:10.1353/book.24372"'
    
    params = {
        "q": scholar_query,
        "api_key": api_key,
        "engine": "google_scholar",
        "num": 10
    }
    
    try:
        print(f"Searching Google Scholar for: {scholar_query}")
        response = requests.get("https://serpapi.com/search.json", params=params)
        
        if response.status_code == 200:
            scholar_results = response.json()
            
            if scholar_results.get("organic_results"):
                print(f"Found {len(scholar_results['organic_results'])} results on Google Scholar")
                
                for i, result in enumerate(scholar_results['organic_results'][:3]):
                    title = result.get('title', 'No title')
                    authors = result.get('authors', 'No authors')
                    publication_info = result.get('publication_info', {}).get('summary', 'No publication info')
                    link = result.get('link', 'No link')
                    
                    print(f"\nScholar Result {i+1}:")
                    print(f"Title: {title}")
                    print(f"Authors: {authors}")
                    print(f"Publication: {publication_info}")
                    print(f"Link: {link}")
                    print("-" * 30)
                    
                # Save Google Scholar results
                with open('workspace/google_scholar_results.json', 'w') as f:
                    import json
                    json.dump(scholar_results, f, indent=2)
                print("Google Scholar results saved to workspace/google_scholar_results.json")
                
            else:
                print("No results found on Google Scholar")
                if 'error' in scholar_results:
                    print(f"Scholar API Error: {scholar_results['error']}")
                    
        else:
            print(f"Google Scholar search failed with status {response.status_code}")
            
    except Exception as e:
        print(f"Error in Google Scholar search: {str(e)}")
else:
    print("SerpAPI key not available - skipping Google Scholar search")

time.sleep(1)  # Brief pause between requests

# Method 3: General Google search with DOI
print("\n" + "="*60)
print("Method 3: General Google Search")
print("-" * 40)

if api_key:
    # Search regular Google for the DOI
    google_query = f'"10.1353/book.24372" book title author neurologist'
    
    params = {
        "q": google_query,
        "api_key": api_key,
        "engine": "google",
        "num": 15
    }
    
    try:
        print(f"Searching Google for: {google_query}")
        response = requests.get("https://serpapi.com/search.json", params=params)
        
        if response.status_code == 200:
            google_results = response.json()
            
            if google_results.get("organic_results"):
                print(f"Found {len(google_results['organic_results'])} results on Google")
                
                # Look for academic/book-related results
                academic_results = []
                
                for i, result in enumerate(google_results['organic_results']):
                    title = result.get('title', 'No title')
                    link = result.get('link', 'No link')
                    snippet = result.get('snippet', 'No snippet')
                    
                    # Check for academic indicators
                    academic_indicators = [
                        'book', 'author', 'publisher', 'muse.jhu.edu', 'project muse',
                        'neurologist', 'neurology', 'medicine', 'biography', 'doi'
                    ]
                    
                    is_academic = any(indicator in (title + link + snippet).lower() for indicator in academic_indicators)
                    
                    print(f"\nGoogle Result {i+1}:")
                    print(f"Title: {title}")
                    print(f"Link: {link}")
                    print(f"Snippet: {snippet}")
                    
                    if is_academic:
                        print("*** POTENTIALLY RELEVANT ACADEMIC SOURCE ***")
                        academic_results.append(result)
                    
                    print("-" * 30)
                    
                    if i >= 4:  # Show first 5 results in detail
                        break
                
                print(f"\nTotal potentially relevant academic results: {len(academic_results)}")
                
                # Save Google search results
                with open('workspace/google_search_results.json', 'w') as f:
                    import json
                    json.dump(google_results, f, indent=2)
                print("Google search results saved to workspace/google_search_results.json")
                
            else:
                print("No results found on Google")
                if 'error' in google_results:
                    print(f"Google API Error: {google_results['error']}")
                    
        else:
            print(f"Google search failed with status {response.status_code}")
            
    except Exception as e:
        print(f"Error in Google search: {str(e)}")

time.sleep(1)  # Brief pause between requests

# Method 4: Project MUSE specific search
print("\n" + "="*60)
print("Method 4: Project MUSE Specific Search")
print("-" * 40)

if api_key:
    # Search specifically for Project MUSE with this DOI
    muse_query = f'site:muse.jhu.edu "10.1353/book.24372" OR "book.24372"'
    
    params = {
        "q": muse_query,
        "api_key": api_key,
        "engine": "google",
        "num": 10
    }
    
    try:
        print(f"Searching Project MUSE for: {muse_query}")
        response = requests.get("https://serpapi.com/search.json", params=params)
        
        if response.status_code == 200:
            muse_results = response.json()
            
            if muse_results.get("organic_results"):
                print(f"Found {len(muse_results['organic_results'])} results on Project MUSE")
                
                for i, result in enumerate(muse_results['organic_results']):
                    title = result.get('title', 'No title')
                    link = result.get('link', 'No link')
                    snippet = result.get('snippet', 'No snippet')
                    
                    print(f"\nProject MUSE Result {i+1}:")
                    print(f"Title: {title}")
                    print(f"Link: {link}")
                    print(f"Snippet: {snippet}")
                    print("-" * 30)
                    
                # Save Project MUSE results
                with open('workspace/project_muse_results.json', 'w') as f:
                    import json
                    json.dump(muse_results, f, indent=2)
                print("Project MUSE search results saved to workspace/project_muse_results.json")
                
            else:
                print("No results found on Project MUSE")
                if 'error' in muse_results:
                    print(f"Project MUSE API Error: {muse_results['error']}")
                    
        else:
            print(f"Project MUSE search failed with status {response.status_code}")
            
    except Exception as e:
        print(f"Error in Project MUSE search: {str(e)}")

# Summary of search approach
print("\n" + "="*60)
print("SEARCH SUMMARY")
print("="*60)
print(f"DOI searched: {doi}")
print(f"Publisher prefix: 10.1353 (Project MUSE)")
print("\nSearch methods completed:")
print("1. Direct DOI resolution through doi.org")
print("2. Google Scholar search with DOI")
print("3. General Google search with DOI + keywords")
print("4. Project MUSE specific search")
print("\nResults saved to workspace/ directory for analysis")
print("Files created:")
print("- doi_resolution_page.html (if DOI resolved)")
print("- google_scholar_results.json (if Scholar search successful)")
print("- google_search_results.json (if Google search successful)")
print("- project_muse_results.json (if MUSE search successful)")
```