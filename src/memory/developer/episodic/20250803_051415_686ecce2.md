### Development Step 25: Robert Christgau’s Letter Grades for Pre-1999 Fiona Apple and Paula Cole Albums

**Description**: Research Robert Christgau's reviews and letter grades for all the pre-1999 albums by Fiona Apple and Paula Cole that were identified in the previous research. Search Christgau's Consumer Guide database, his official website, and archived reviews to determine which albums received letter grades (A+, A, A-, B+, B, B-, C+, C, C-, D+, D, etc.) and which albums were not reviewed or did not receive letter grades. Focus on finding his specific reviews for albums like Fiona Apple's 'Tidal' (1996) and Paula Cole's 'Harbinger' (1994) and 'This Fire' (1996), among others from the compiled list.

**Use Cases**:
- Music journalism archival fact-checking: a magazine’s editorial team uses the script to verify Robert Christgau’s original letter grades for Fiona Apple’s “Tidal” and Paula Cole’s early albums when preparing a retrospective feature.
- Streaming service metadata enrichment: a music platform automates the extraction of Christgau’s 1990s consumer guide grades to tag pre-1999 album entries with critic ratings for improved user discovery.
- Academic study of music criticism trends: university researchers deploy the code to compile letter-grade data across decades and analyze shifts in critical opinion on female singer-songwriters in the 1990s.
- Digital library catalog curation: a public library’s digital archive runs the script to fill missing review metadata for its collection of 1990s pop albums, ensuring each title has documented critique information.
- Music blog content generation: a blogger integrates the tool to auto-retrieve Christgau’s grades and excerpts when crafting “Top 10 Pre-Millennial Albums” lists, saving hours of manual lookup.
- Recommendation engine training dataset creation: a startup collects historical critic scores using the solution to augment its machine learning model for personalized album suggestions based on expert evaluations.
- Data journalism on critic bias: a news outlet’s data team uses the script to aggregate Christgau’s grades by artist, album, and year, then visualizes patterns to explore potential biases in 1990s music reviews.

```
import os
import json
from bs4 import BeautifulSoup
import requests
import time
import re

print('=== ROBERT CHRISTGAU REVIEWS SEARCH: PHASE 7 ===')
print('Objective: Fix all variable errors and access the correct Consumer Guide grade databases')
print('Strategy: Use discovered URLs to access 1990s grades and extract actual reviews\n')

# Step 1: Load the research targets to know what albums we're looking for
workspace_dir = 'workspace'
targets_file = 'christgau_research_comprehensive_targets.json'
targets_path = os.path.join(workspace_dir, targets_file)

print('=== STEP 1: LOADING ALBUM RESEARCH TARGETS ===')
print()

if os.path.exists(targets_path):
    print(f'✓ Found research targets file: {targets_file}')
    
    with open(targets_path, 'r', encoding='utf-8') as f:
        research_data = json.load(f)
    
    target_albums = research_data.get('target_albums', [])
    print(f'Albums to search for Christgau reviews: {len(target_albums)}')
    
    # Display key albums mentioned in the PLAN
    key_albums = ['Tidal', 'Harbinger', 'This Fire']
    print('\nKey albums mentioned in PLAN:')
    for album in target_albums:
        if any(key_album.lower() in album['title'].lower() for key_album in key_albums):
            print(f'  - {album["artist"]}: "{album["title"]}" ({album["year"]})')
else:
    print(f'✗ Research targets file not found: {targets_file}')
    print('Cannot proceed without album list.')
    exit()

print('\n=== STEP 2: ACCESS CHRISTGAU GRADES DATABASES ===')
print()

# Based on previous analysis, we found these are the correct URLs
christgau_grade_urls = {
    'grades_1990s': 'https://www.robertchristgau.com/xg/bk-cg90/grades-90s.php',
    'grades_1969_89': 'https://www.robertchristgau.com/xg/bk-cg70/grades.php',
    'main_consumer_guide': 'https://www.robertchristgau.com/cg.php'
}

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

grade_results = {}

for db_name, url in christgau_grade_urls.items():
    print(f'Accessing {db_name}: {url}')
    
    try:
        response = requests.get(url, headers=headers, timeout=20)
        print(f'  Response: {response.status_code}')
        
        if response.status_code == 200:
            print(f'  ✓ Successfully accessed {db_name}')
            print(f'  Content length: {len(response.text):,} characters')
            
            # Save the grades database
            db_filename = f'christgau_{db_name.replace("_", "_")}.html'
            db_path = os.path.join(workspace_dir, db_filename)
            
            with open(db_path, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            # Quick analysis for target artists
            content_text = response.text.lower()
            has_fiona = 'fiona apple' in content_text
            has_paula = 'paula cole' in content_text
            has_tidal = 'tidal' in content_text
            has_harbinger = 'harbinger' in content_text
            has_this_fire = 'this fire' in content_text
            
            print(f'  Contains Fiona Apple: {has_fiona}')
            print(f'  Contains Paula Cole: {has_paula}')
            print(f'  Contains "Tidal": {has_tidal}')
            print(f'  Contains "Harbinger": {has_harbinger}')
            print(f'  Contains "This Fire": {has_this_fire}')
            
            # Count letter grades to verify this is a grades database
            grade_pattern = r'\b[A-E][+-]?\b'
            grades_found = re.findall(grade_pattern, response.text)
            unique_grades = list(set(grades_found))
            
            print(f'  Letter grades found: {len(grades_found)} total, {len(unique_grades)} unique')
            print(f'  Sample grades: {unique_grades[:10]}')
            
            grade_results[db_name] = {
                'url': url,
                'filename': db_filename,
                'content_length': len(response.text),
                'has_fiona': has_fiona,
                'has_paula': has_paula,
                'has_tidal': has_tidal,
                'has_harbinger': has_harbinger,
                'has_this_fire': has_this_fire,
                'total_grades': len(grades_found),
                'unique_grades': unique_grades
            }
            
            if any([has_fiona, has_paula, has_tidal, has_harbinger, has_this_fire]):
                print(f'  *** EXCELLENT - Found target content in {db_name}! ***')
            
            print(f'  Saved as: {db_filename}')
            
        else:
            print(f'  ✗ Failed to access {db_name}: {response.status_code}')
            
        print()
        time.sleep(2)  # Be respectful to the server
        
    except Exception as e:
        print(f'  ✗ Error accessing {db_name}: {str(e)}')
        print()

print('=== STEP 3: PARSE GRADES DATABASES FOR TARGET ALBUMS ===')
print()

# Find the databases that contain our target artists
successful_databases = [db for db, info in grade_results.items() if info.get('has_fiona') or info.get('has_paula')]

print(f'Databases containing target artists: {len(successful_databases)}')
for db_name in successful_databases:
    print(f'  - {db_name}: {grade_results[db_name]["filename"]}')

found_reviews = []

# Parse each successful database for specific album reviews
for db_name in successful_databases:
    db_info = grade_results[db_name]
    db_filename = db_info['filename']
    db_path = os.path.join(workspace_dir, db_filename)
    
    print(f'\nParsing {db_name} for album reviews...')
    
    with open(db_path, 'r', encoding='utf-8') as f:
        db_content = f.read()
    
    # Parse HTML to extract structured review data
    soup = BeautifulSoup(db_content, 'html.parser')
    
    # Look for text containing our target albums
    for album in target_albums:
        artist = album['artist']
        title = album['title']
        year = album['year']
        
        print(f'  Searching for: {artist} - "{title}" ({year})')
        
        # Search for mentions of this album
        album_mentions = []
        
        # Method 1: Search in all text for artist and album combinations
        text_content = soup.get_text()
        lines = text_content.split('\n')
        
        for line_idx, line in enumerate(lines):
            line_lower = line.lower().strip()
            artist_lower = artist.lower()
            title_lower = title.lower()
            
            # Look for lines containing both artist and album title
            if artist_lower in line_lower and title_lower in line_lower:
                # Get context around this line
                context_start = max(0, line_idx - 2)
                context_end = min(len(lines), line_idx + 3)
                context_lines = lines[context_start:context_end]
                context = ' '.join(context_lines).strip()
                
                # Look for letter grades in the context
                grade_pattern = r'\b([A-E][+-]?)\b'
                grades_in_context = re.findall(grade_pattern, context)
                
                album_mentions.append({
                    'line_number': line_idx,
                    'line_content': line.strip(),
                    'context': context[:500],  # First 500 chars of context
                    'grades_found': grades_in_context
                })
                
                print(f'    ✓ Found mention on line {line_idx}')
                print(f'      Line: {line.strip()[:100]}...')
                print(f'      Grades in context: {grades_in_context}')
        
        # Method 2: Search for artist name alone and check surrounding content
        if not album_mentions:
            for line_idx, line in enumerate(lines):
                line_lower = line.lower().strip()
                artist_lower = artist.lower()
                
                if artist_lower in line_lower and len(line.strip()) > 10:
                    # Get extended context to look for album titles
                    context_start = max(0, line_idx - 3)
                    context_end = min(len(lines), line_idx + 5)
                    extended_context = ' '.join(lines[context_start:context_end]).lower()
                    
                    # Check if any album by this artist is mentioned in extended context
                    artist_albums = [a['title'].lower() for a in target_albums if a['artist'].lower() == artist_lower]
                    mentioned_albums = [album_title for album_title in artist_albums if album_title in extended_context]
                    
                    if mentioned_albums:
                        context_text = ' '.join(lines[context_start:context_end]).strip()
                        grade_pattern = r'\b([A-E][+-]?)\b'
                        grades_in_context = re.findall(grade_pattern, context_text)
                        
                        album_mentions.append({
                            'line_number': line_idx,
                            'line_content': line.strip(),
                            'context': context_text[:500],
                            'mentioned_albums': mentioned_albums,
                            'grades_found': grades_in_context
                        })
                        
                        print(f'    ✓ Found artist mention with albums on line {line_idx}')
                        print(f'      Albums mentioned: {mentioned_albums}')
                        print(f'      Grades in context: {grades_in_context}')
        
        if album_mentions:
            found_reviews.append({
                'artist': artist,
                'album_title': title,
                'album_year': year,
                'database': db_name,
                'mentions': album_mentions
            })
        else:
            print(f'    ✗ No mentions found for {artist} - "{title}"')

print(f'\n=== STEP 4: COMPILE CHRISTGAU REVIEW RESULTS ===')
print()

print(f'Total albums with found reviews/mentions: {len(found_reviews)}')

if found_reviews:
    print('\n=== DETAILED REVIEW FINDINGS ===')
    print()
    
    for review in found_reviews:
        print(f'Artist: {review["artist"]}')
        print(f'Album: "{review["album_title"]}" ({review["album_year"]})')
        print(f'Database: {review["database"]}')
        print(f'Mentions found: {len(review["mentions"])}')
        
        for mention_idx, mention in enumerate(review['mentions'], 1):
            print(f'\n  Mention {mention_idx}:')
            print(f'    Line {mention["line_number"]}: {mention["line_content"][:150]}...')
            
            if mention.get('grades_found'):
                print(f'    *** LETTER GRADES FOUND: {mention["grades_found"]} ***')
            
            if mention.get('mentioned_albums'):
                print(f'    Related albums mentioned: {mention["mentioned_albums"]}')
            
            print(f'    Context: {mention["context"][:200]}...')
        
        print('-' * 60)

# Create comprehensive results summary
christgau_results_summary = {
    'research_objective': 'Find Robert Christgau reviews and letter grades for pre-1999 Fiona Apple and Paula Cole albums',
    'search_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'databases_accessed': list(christgau_grade_urls.keys()),
    'successful_databases': successful_databases,
    'target_albums_total': len(target_albums),
    'albums_with_found_reviews': len(found_reviews),
    'grade_databases_info': grade_results,
    'detailed_findings': found_reviews,
    'key_albums_status': {
        'tidal_found': any('tidal' in r['album_title'].lower() for r in found_reviews),
        'harbinger_found': any('harbinger' in r['album_title'].lower() for r in found_reviews),
        'this_fire_found': any('this fire' in r['album_title'].lower() for r in found_reviews)
    },
    'summary_by_artist': {
        'fiona_apple': [r for r in found_reviews if 'fiona apple' in r['artist'].lower()],
        'paula_cole': [r for r in found_reviews if 'paula cole' in r['artist'].lower()]
    }
}

# Save comprehensive results
results_filename = 'christgau_reviews_comprehensive_results.json'
results_path = os.path.join(workspace_dir, results_filename)

with open(results_path, 'w', encoding='utf-8') as f:
    json.dump(christgau_results_summary, f, indent=2, ensure_ascii=False)

print(f'\n=== COMPREHENSIVE RESULTS SUMMARY ===')
print()
print(f'Comprehensive results saved: {results_filename}')
print(f'Albums researched: {len(target_albums)}')
print(f'Reviews/mentions found: {len(found_reviews)}')
print(f'Databases successfully accessed: {len(successful_databases)}')

# Show key findings for PLAN-specified albums
key_findings = christgau_results_summary['key_albums_status']
print(f'\nKey albums from PLAN:')
print(f'  - Tidal found: {key_findings["tidal_found"]}')
print(f'  - Harbinger found: {key_findings["harbinger_found"]}')
print(f'  - This Fire found: {key_findings["this_fire_found"]}')

fiona_count = len(christgau_results_summary['summary_by_artist']['fiona_apple'])
paula_count = len(christgau_results_summary['summary_by_artist']['paula_cole'])

print(f'\nArtist summary:')
print(f'  - Fiona Apple albums with reviews: {fiona_count}')
print(f'  - Paula Cole albums with reviews: {paula_count}')

print('\n=== PHASE 7 COMPLETE ===')
print('Successfully accessed Christgau grade databases and extracted review information')
print('Ready for final analysis of letter grades and review compilation')
```