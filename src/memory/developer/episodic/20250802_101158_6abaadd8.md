### Development Step 11: Compile U.S. Presidents’ Birthplaces and Geographic Coordinates in JSON File

**Description**: Collect a complete list of all United States presidents with their official birth city names and state names, then obtain the geographic coordinates (longitude and latitude) for each birth city using authoritative sources such as official presidential biographies or Wikipedia infoboxes. Save the results in a structured format (e.g., CSV or JSON) at workspace/presidential_birthplaces.json.

**Use Cases**:
- Interactive educational platforms mapping U.S. presidents’ birthplaces as part of an e-learning American history module, allowing students to click on each president’s hometown and view biographical details
- Travel and tourism apps generating customized road-trip itineraries that include visits to presidential birth sites with GPS coordinates and local attraction recommendations
- Political science research projects analyzing the geographic distribution of presidential birthplaces and correlating regional origins with voting patterns in historical elections
- Genealogy and ancestry services integrating presidents’ birthplace coordinates to help users compare their own family origins with those of past U.S. leaders
- Data journalism pieces creating interactive maps and visualizations of presidential birth cities to illustrate demographic trends in U.S. leadership over time
- Mobile augmented-reality tour guides that trigger audio and video content when visitors approach actual birth sites of U.S. presidents
- Local heritage organizations planning “Presidents’ Birthplace Trail” events, using precise latitude/longitude data to mark stops and provide historical context on site signage

```
import os
import re
import time
import json
import requests
from bs4 import BeautifulSoup, NavigableString
from geopy.geocoders import Nominatim

# Ensure workspace directory exists
workspace = 'workspace'
os.makedirs(workspace, exist_ok=True)

# 1. Fetch or load the cached presidents list page
list_html_path = os.path.join(workspace, 'presidents_list.html')
if os.path.exists(list_html_path):
    print(f"Loading cached HTML from {list_html_path}")
    with open(list_html_path, 'r', encoding='utf-8') as f:
        list_html = f.read()
else:
    list_url = 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States'
    print(f"Fetching presidents list: {list_url}")
    resp = requests.get(list_url)
    resp.raise_for_status()
    list_html = resp.text
    with open(list_html_path, 'w', encoding='utf-8') as f:
        f.write(list_html)
    print(f"Saved HTML to {list_html_path}")

# 2. Parse the main table of presidents
soup = BeautifulSoup(list_html, 'html.parser')
table = soup.find('table', class_='wikitable')
rows = table.find_all('tr')[1:]
print(f"Found {len(rows)} presidents in table")

# 3. Collect each president's name and page URL
presidents = []
for row in rows:
    cells = row.find_all('td')
    if len(cells) < 2:
        continue
    link = cells[1].find('a', href=True)
    if not link:
        continue
    name = link.get_text(strip=True)
    url = 'https://en.wikipedia.org' + link['href']
    presidents.append({'name': name, 'url': url})
print(f"Collected {len(presidents)} president pages to process")

# 4. Initialize geocoder
geolocator = Nominatim(user_agent='presidential_birth_locator')
results = []

# 5. Process each president
for idx, pres in enumerate(presidents, start=1):
    name = pres['name']
    url = pres['url']
    print(f"\n[{idx}/{len(presidents)}] {name}\nFetching: {url}")
    resp = requests.get(url)
    resp.raise_for_status()
    page = BeautifulSoup(resp.text, 'html.parser')
    time.sleep(1)

    # 6. Try to get birthplace from <span class='birthplace'> first
    birth_place = ''
    span_bp = page.select_one('span.birthplace')
    if span_bp and span_bp.get_text(strip=True):
        birth_place = span_bp.get_text(strip=True)
        print(f"  Found span.birthplace: '{birth_place}'")
    else:
        # 7. Fallback: split the 'Born' infobox cell on <br> to isolate the place
        infobox = page.find('table', class_=lambda c: c and 'infobox' in c)
        if infobox:
            born_tr = infobox.find(lambda tag: tag.name == 'tr' and tag.th and tag.th.get_text(strip=True).startswith('Born'))
            if born_tr:
                td = born_tr.find('td')
                if td:
                    td_html = str(td)
                    parts = re.split(r'<br\s*/?>', td_html, flags=re.IGNORECASE)
                    if len(parts) >= 2:
                        # take the second part after the first <br>
                        place_html = parts[1]
                        # remove any <small>...</small>
                        place_html = re.sub(r'<small[^>]*>.*?</small>', '', place_html, flags=re.DOTALL|re.IGNORECASE)
                        # extract text
                        birth_place = BeautifulSoup(place_html, 'html.parser').get_text(strip=True)
                        print(f"  Fallback place extract: '{birth_place}'")
    if not birth_place:
        print(f"  Warning: could not extract birthplace for {name}")

    # 8. Clean the extracted birthplace
    #   - remove parentheticals
    #   - remove citation brackets
    clean = re.sub(r'\([^)]*\)', '', birth_place)
    clean = re.sub(r'\[.*?\]', '', clean)
    clean = clean.strip()

    # 9. Split into tokens and drop date-like tokens
    tokens = [t.strip() for t in clean.split(',') if t.strip()]
    # drop leading tokens that contain digits (dates)
    while tokens and re.search(r'\d', tokens[0]):
        tokens.pop(0)
    # drop trailing unwanted tokens
    unwanted = re.compile(r'^(British America|United States|U\.?S\.?A?\.?|USA)$', re.I)
    while tokens and unwanted.match(tokens[-1]):
        tokens.pop()
    birth_clean = ', '.join(tokens)
    print(f"  Cleaned birthplace: '{birth_clean}'")

    # 10. Derive city and state
    city = tokens[0] if len(tokens) >= 1 else ''
    state = tokens[1] if len(tokens) >= 2 else ''
    print(f"  Parsed city='{city}', state='{state}'")

    # 11. Geocode: try the full string then fallback to city/state
    latitude = longitude = None
    if birth_clean and city and state:
        query_full = f"{birth_clean}, USA"
        print(f"  Geocoding full: '{query_full}'")
        try:
            loc = geolocator.geocode(query_full, timeout=10)
            time.sleep(1)
            if loc:
                latitude, longitude = loc.latitude, loc.longitude
                print(f"   -> Got coords: ({latitude}, {longitude})")
            else:
                query_cs = f"{city}, {state}, USA"
                print(f"  Fallback geocoding: '{query_cs}'")
                loc2 = geolocator.geocode(query_cs, timeout=10)
                time.sleep(1)
                if loc2:
                    latitude, longitude = loc2.latitude, loc2.longitude
                    print(f"   -> Fallback coords: ({latitude}, {longitude})")
        except Exception as e:
            print(f"   -> Geocoding error: {e}")

    # 12. Record the result
    entry = {
        'name': name,
        'birth_city': city,
        'birth_state': state,
        'latitude': latitude,
        'longitude': longitude
    }
    print(f"  Recorded: {entry}")
    results.append(entry)

# 13. Save all results to JSON
out_path = os.path.join(workspace, 'presidential_birthplaces.json')
with open(out_path, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2)
print(f"\nFinished: saved {len(results)} records to {out_path}")

```