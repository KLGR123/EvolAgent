### Development Step 17: Collect U.S. Presidents’ birth cities and states with geographic coordinates, save as JSON.

**Description**: Collect a complete list of all United States presidents with their official birth city names and state names, then obtain the geographic coordinates (longitude and latitude) for each birth city using authoritative sources such as official presidential biographies or Wikipedia infoboxes. Save the results in a structured format (e.g., CSV or JSON) at workspace/presidential_birthplaces.json.

**Use Cases**:
- Interactive museum exhibit development for a history museum mapping each U.S. president’s birth city on a touch-screen map to engage visitors with geographic context
- Political science research on regional patterns in presidential origins, enabling statistical correlation between birthplaces and voting demographics
- Educational platform integration to auto-generate classroom worksheets and quizzes about presidents’ birth cities with embedded map coordinates
- Heritage tourism itinerary planning for a travel agency offering “Birthplace of Presidents” guided tours across multiple states
- Mobile trivia game development that uses geolocation to offer location-based presidential birthplace challenges when users travel
- Journalism and news websites creating interactive graphics and timelines that pinpoint presidents’ birth locations to accompany feature stories
- Genealogy software enhancement to cross-reference presidential family trees with birth city data for ancestry research tools
- Civic engagement app to organize local “Presidential Birthplace Day” events, sending push notifications to users near historic birth towns

```
import os
import re
import time
import json
import requests
import bs4
from geopy.geocoders import Nominatim

# Ensure workspace directory exists
workspace = 'workspace'
os.makedirs(workspace, exist_ok=True)

# 1) Load or fetch the Wikipedia page of U.S. presidents list
list_path = os.path.join(workspace, 'presidents_list.html')
if os.path.exists(list_path):
    print(f"Loading cached presidents list from {list_path}")
    with open(list_path, 'r', encoding='utf-8') as f:
        list_html = f.read()
else:
    list_url = 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States'
    print(f"Fetching presidents list from {list_url}")
    resp = requests.get(list_url, timeout=10)
    resp.raise_for_status()
    list_html = resp.text
    with open(list_path, 'w', encoding='utf-8') as f:
        f.write(list_html)
    print(f"Saved presidents list to {list_path}")

# 2) Parse the main wikitable of presidents
list_soup = bs4.BeautifulSoup(list_html, 'html.parser')
table = list_soup.find('table', class_='wikitable')
rows = table.find_all('tr')[1:]
print(f"Found {len(rows)} rows in presidents table")

# 3) Build list of president name + individual page URL
presidents = []
for row in rows:
    cols = row.find_all('td')
    if len(cols) < 2:
        continue
    link = cols[1].find('a', href=True)
    if not link:
        continue
    name = link.get_text(strip=True)
    url = 'https://en.wikipedia.org' + link['href']
    presidents.append({'name': name, 'url': url})
print(f"Collected {len(presidents)} presidents to process")

# 4) Helper to extract raw birthplace string
unwanted_trailing = re.compile(r'^(British America|United States|U\.?S\.?A?\.?|USA)$', re.I)

def extract_birthplace(page_soup):
    # Try <span class="birthplace">
    span_bp = page_soup.select_one('span.birthplace')
    if span_bp and span_bp.get_text(strip=True):
        return span_bp.get_text(strip=True)
    # Fallback: infobox 'Born' row
    infobox = page_soup.find('table', class_=lambda c: c and 'infobox' in c)
    if infobox:
        born_th = infobox.find('th', string=re.compile(r'Born'))
        if born_th:
            tr = born_th.parent
            td = tr.find('td')
            if td:
                parts = re.split(r'<br\s*/?>', str(td), flags=re.IGNORECASE)
                if len(parts) >= 2:
                    place_html = parts[1]
                    # strip <small> tags
                    place_html = re.sub(r'<small[^>]*>.*?</small>', '', place_html, flags=re.DOTALL|re.IGNORECASE)
                    text = bs4.BeautifulSoup(place_html, 'html.parser').get_text(separator=' ', strip=True)
                    return text
    return ''

# 5) Initialize geocoder and results list
geo = Nominatim(user_agent='presidential_birth_locator')
results = []

# 6) Iterate each president to extract and geocode birthplace
for idx, pres in enumerate(presidents, start=1):
    name = pres['name']
    url = pres['url']
    print(f"\n[{idx}/{len(presidents)}] {name} - Fetching: {url}")
    try:
        r = requests.get(url, timeout=10)
        r.raise_for_status()
        p_soup = bs4.BeautifulSoup(r.text, 'html.parser')
    except Exception as e:
        print(f"  -> Error fetching {name}: {e}")
        results.append({'name': name, 'birth_city': None, 'birth_state': None, 'latitude': None, 'longitude': None})
        continue
    time.sleep(1)

    raw = extract_birthplace(p_soup)
    print(f"  Raw birthplace: '{raw}'")
    # Clean raw birthplace
    clean = re.sub(r'\([^)]*\)', '', raw)     # remove parentheses
    clean = re.sub(r'\[.*?\]', '', clean).strip()  # remove citations
    tokens = [t.strip() for t in clean.split(',') if t.strip()]
    # drop leading date tokens
    while tokens and re.search(r'\d', tokens[0]):
        tokens.pop(0)
    # drop trailing country tokens
    while tokens and unwanted_trailing.match(tokens[-1]):
        tokens.pop()
    birth_clean = ', '.join(tokens)
    print(f"  Tokens: {tokens}")
    print(f"  Cleaned birthplace: '{birth_clean}'")

    city = tokens[0] if len(tokens) >= 1 else None
    state = tokens[1] if len(tokens) >= 2 else None
    print(f"  Parsed city='{city}', state='{state}'")

    lat = lon = None
    if city and state:
        for query in [f"{city}, {state}, USA", f"{birth_clean}, USA"]:
            print(f"  Geocoding '{query}'...")
            try:
                loc = geo.geocode(query, timeout=10)
            except Exception as ge_er:
                print(f"   -> Geocode error: {ge_er}")
                loc = None
            time.sleep(1)
            if loc:
                lat, lon = loc.latitude, loc.longitude
                print(f"   -> Coordinates: ({lat}, {lon})")
                break
    else:
        print(f"  Insufficient data to geocode for {name}")

    entry = {'name': name, 'birth_city': city, 'birth_state': state, 'latitude': lat, 'longitude': lon}
    results.append(entry)
    print(f"  Recorded: {entry}")

# 7) Save the results to JSON
out_file = os.path.join(workspace, 'presidential_birthplaces.json')
with open(out_file, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2)
print(f"\nFinished: saved {len(results)} records to {out_file}")

```