### Development Step 9: Extract and Alphabetize Chemicals EC 1.11.1.7;3.1.3.1 from 2016 Wiley Sweet Potato Virus Paper

**Description**: Access the identified 2016 Wiley paper 'Effects of Sweet Potato Feathery Mottle Virus and Sweet Potato Chlorotic Stunt Virus' and extract the specific chemicals with EC numbers 1.11.1.7 and 3.1.3.1 used in the virus testing methods. Identify the chemical names corresponding to these EC numbers, alphabetize them, and format the EC numbers in the required semicolon-separated order.

**Use Cases**:
- Agricultural biotech team automating extraction of peroxidase (EC 1.11.1.7) and alkaline phosphatase (EC 3.1.3.1) reagent details from 2016 sweet potato virus studies to optimize field trial protocols
- Pharmaceutical R&D group curating enzyme assay protocols and EC number mappings from Wiley virology papers for antiviral drug development documentation
- Regulatory compliance unit generating standardized EC-to-chemical mappings of enzyme reagents used in plant pathogen testing to support audit and safety submissions
- Bioinformatics department automating literature mining of virus–enzyme interactions to integrate peroxidase and alkaline phosphatase data into a research knowledge graph
- Laboratory operations manager extracting EC numbers and enzyme names from JSON search results to compile a reagent procurement list for virology experiments
- Grant proposal writer summarizing specific peroxidase and alkaline phosphatase assays referenced in key sweet potato virus publications to strengthen funding applications
- Data analytics team building an interactive dashboard of virus detection methods by parsing EC numbers and chemical names from search result files for internal reporting

```
import os
import json
from datetime import datetime

# First, let's locate and properly inspect the search results file
print("Locating search results files...")
print("="*80)

# Check multiple possible locations for the search results file
search_file_candidates = [
    'workspace/sweet_potato_virus_paper_search_20250806_185041.json',
    'workspace_2a649bb1-795f-4a01-b3be-9a01868dae73/sweet_potato_virus_paper_search_20250806_185041.json'
]

search_data = None
used_file_path = None

for file_path in search_file_candidates:
    if os.path.exists(file_path):
        print(f"Found search results file: {file_path}")
        used_file_path = file_path
        break

if not used_file_path:
    print("No search results file found. Checking workspace contents...")
    if os.path.exists('workspace'):
        workspace_files = os.listdir('workspace')
        print(f"Workspace files: {workspace_files}")
        # Look for any virus-related search files
        for file in workspace_files:
            if 'virus' in file.lower() or 'sweet_potato' in file.lower():
                used_file_path = f'workspace/{file}'
                print(f"Using alternative file: {used_file_path}")
                break
    
if not used_file_path:
    print("ERROR: No search results file found.")
else:
    # Load and inspect the file structure first
    print(f"\nInspecting file structure: {used_file_path}")
    print("-"*60)
    
    with open(used_file_path, 'r', encoding='utf-8') as f:
        search_data = json.load(f)
    
    print("File structure overview:")
    for key, value in search_data.items():
        if isinstance(value, list):
            print(f"  {key}: list with {len(value)} items")
            if len(value) > 0 and isinstance(value[0], dict):
                print(f"    Sample item keys: {list(value[0].keys())}")
        elif isinstance(value, dict):
            print(f"  {key}: dict with keys {list(value.keys())}")
        else:
            print(f"  {key}: {value}")
    
    # Now analyze the search results with proper variable handling
    print("\n" + "="*80)
    print("EXTRACTING PAPER CANDIDATES AND EC NUMBER INFORMATION")
    print("="*80)
    
    target_paper = search_data.get('target_paper', 'Unknown')
    target_ec_numbers = search_data.get('target_ec_numbers', [])
    search_results = search_data.get('search_results', [])
    
    print(f"Target Paper: {target_paper}")
    print(f"Target EC Numbers: {target_ec_numbers}")
    print(f"Search Result Sets: {len(search_results)}")
    
    # Initialize result containers
    paper_candidates = []
    ec_chemical_sources = []
    
    # Process each search query result set
    for query_idx, query_result in enumerate(search_results, 1):
        query_text = query_result.get('query', 'Unknown query')
        results_list = query_result.get('results', [])
        
        print(f"\nProcessing Query {query_idx}: {query_text}")
        print(f"Results in this query: {len(results_list)}")
        print("-"*50)
        
        # Analyze each search result
        for result_idx, result in enumerate(results_list[:10], 1):  # Top 10 results per query
            title = result.get('title', 'No title')
            link = result.get('link', 'No URL')
            snippet = result.get('snippet', 'No snippet')
            
            print(f"  {result_idx}. {title[:70]}...")
            
            # Create text for analysis (fixing the scoping issue)
            title_text = title.lower()
            snippet_text = snippet.lower()
            link_text = link.lower()
            
            # Calculate relevance score for target paper identification
            relevance_score = 0
            matching_terms = []
            
            # Check for paper-specific indicators
            if 'sweet potato feathery mottle virus' in title_text or 'sweet potato feathery mottle virus' in snippet_text:
                relevance_score += 10
                matching_terms.append('SPFMV')
            
            if 'sweet potato chlorotic stunt virus' in title_text or 'sweet potato chlorotic stunt virus' in snippet_text:
                relevance_score += 10
                matching_terms.append('SPCSV')
            
            if '2016' in title_text or '2016' in snippet_text:
                relevance_score += 5
                matching_terms.append('2016')
            
            if 'wiley' in link_text or 'onlinelibrary.wiley.com' in link_text:
                relevance_score += 5
                matching_terms.append('Wiley')
            
            if 'effects' in title_text:
                relevance_score += 3
                matching_terms.append('Effects')
            
            # Check for EC numbers and enzyme information
            ec_found = []
            if '1.11.1.7' in snippet_text:
                relevance_score += 8
                ec_found.append('1.11.1.7')
            
            if '3.1.3.1' in snippet_text:
                relevance_score += 8
                ec_found.append('3.1.3.1')
            
            enzyme_terms = []
            if 'peroxidase' in snippet_text:
                enzyme_terms.append('peroxidase')
            if 'alkaline phosphatase' in snippet_text:
                enzyme_terms.append('alkaline phosphatase')
            if 'enzyme' in snippet_text:
                enzyme_terms.append('enzyme')
            
            if enzyme_terms:
                relevance_score += 4
                matching_terms.extend(enzyme_terms)
            
            # Display analysis for this result
            if matching_terms:
                print(f"      Score: {relevance_score}, Terms: {', '.join(matching_terms)}")
            
            if ec_found:
                print(f"      🧪 EC Numbers Found: {', '.join(ec_found)}")
            
            # Store high-relevance paper candidates
            if relevance_score >= 15:
                is_wiley_direct = 'onlinelibrary.wiley.com' in link_text
                paper_candidates.append({
                    'title': title,
                    'link': link,
                    'snippet': snippet,
                    'relevance_score': relevance_score,
                    'matching_terms': matching_terms,
                    'ec_numbers_found': ec_found,
                    'is_wiley_direct': is_wiley_direct,
                    'query_source': query_text
                })
                print(f"      ⭐ HIGH RELEVANCE - Added to candidates")
            
            # Store sources that mention EC numbers with chemical information
            if ec_found or enzyme_terms:
                ec_chemical_sources.append({
                    'title': title,
                    'link': link,
                    'snippet': snippet,
                    'ec_numbers_mentioned': ec_found,
                    'enzyme_terms_found': enzyme_terms,
                    'query_source': query_text
                })
                print(f"      🔬 EC/Chemical info - Added to sources")
    
    # Sort paper candidates by relevance score
    paper_candidates.sort(key=lambda x: x['relevance_score'], reverse=True)
    
    print("\n" + "="*80)
    print("ANALYSIS RESULTS AND CHEMICAL IDENTIFICATION")
    print("="*80)
    
    print(f"\n📚 PAPER CANDIDATES IDENTIFIED: {len(paper_candidates)}")
    
    if paper_candidates:
        print("\nTop paper candidates:")
        for i, candidate in enumerate(paper_candidates[:3], 1):
            print(f"\n{i}. RELEVANCE SCORE: {candidate['relevance_score']}")
            print(f"   Title: {candidate['title']}")
            print(f"   URL: {candidate['link']}")
            print(f"   Wiley Direct: {'✅ YES' if candidate['is_wiley_direct'] else '❌ NO'}")
            print(f"   Terms: {', '.join(candidate['matching_terms'])}")
            if candidate['ec_numbers_found']:
                print(f"   EC Numbers: {', '.join(candidate['ec_numbers_found'])}")
            
            # Check if this is the target paper
            if (candidate['relevance_score'] >= 25 and 
                candidate['is_wiley_direct'] and 
                'effects' in candidate['title'].lower()):
                print(f"   🎯 THIS IS THE TARGET PAPER!")
    
    print(f"\n🧪 EC NUMBER CHEMICAL SOURCES: {len(ec_chemical_sources)}")
    
    # Analyze chemical information from EC sources
    chemical_mapping = {}
    
    if ec_chemical_sources:
        print("\nEC number and chemical information found:")
        for i, source in enumerate(ec_chemical_sources, 1):
            print(f"\n{i}. {source['title'][:60]}...")
            print(f"   URL: {source['link']}")
            
            if source['ec_numbers_mentioned']:
                print(f"   EC Numbers: {', '.join(source['ec_numbers_mentioned'])}")
            
            if source['enzyme_terms_found']:
                print(f"   Enzymes: {', '.join(source['enzyme_terms_found'])}")
            
            snippet_lower = source['snippet'].lower()
            print(f"   Snippet: {source['snippet'][:150]}...")
            
            # Extract chemical name associations
            if 'alkaline phosphatase' in snippet_lower:
                chemical_mapping['3.1.3.1'] = 'Alkaline phosphatase'
                print(f"   💡 IDENTIFIED: Alkaline phosphatase (likely EC 3.1.3.1)")
            
            if 'peroxidase' in snippet_lower:
                chemical_mapping['1.11.1.7'] = 'Peroxidase'
                print(f"   💡 IDENTIFIED: Peroxidase (likely EC 1.11.1.7)")
    
    # Based on standard EC number classifications, provide the chemical identification
    print(f"\n" + "="*80)
    print("FINAL CHEMICAL IDENTIFICATION FOR EC NUMBERS")
    print("="*80)
    
    # EC 1.11.1.7 is peroxidase, EC 3.1.3.1 is alkaline phosphatase (standard biochemistry)
    ec_chemicals = {
        '1.11.1.7': 'Peroxidase',
        '3.1.3.1': 'Alkaline phosphatase'
    }
    
    print(f"\nEC Number to Chemical Mapping:")
    for ec_number in target_ec_numbers:
        chemical_name = ec_chemicals.get(ec_number, 'Unknown')
        print(f"  EC {ec_number} = {chemical_name}")
    
    # Alphabetize the chemical names
    chemical_names = [ec_chemicals.get(ec, 'Unknown') for ec in target_ec_numbers]
    chemical_names_sorted = sorted(chemical_names)
    
    print(f"\n📝 ALPHABETIZED CHEMICAL NAMES: {', '.join(chemical_names_sorted)}")
    
    # Format EC numbers in the order corresponding to alphabetized chemicals
    # Alkaline phosphatase (3.1.3.1) comes before Peroxidase (1.11.1.7) alphabetically
    ec_numbers_ordered = ['3.1.3.1', '1.11.1.7']  # Corresponding to alphabetical order
    
    print(f"📝 EC NUMBERS IN CORRESPONDING ORDER: {';'.join(ec_numbers_ordered)}")
    
    # Save final results
    final_results = {
        'analysis_timestamp': datetime.now().isoformat(),
        'target_paper_identified': paper_candidates[0] if paper_candidates else None,
        'ec_number_chemicals': ec_chemicals,
        'alphabetized_chemicals': chemical_names_sorted,
        'ec_numbers_ordered': ec_numbers_ordered,
        'final_answer': {
            'chemicals_alphabetical': ', '.join(chemical_names_sorted),
            'ec_numbers_semicolon_format': ';'.join(ec_numbers_ordered)
        },
        'paper_candidates': paper_candidates,
        'ec_sources': ec_chemical_sources
    }
    
    results_file = 'workspace/final_ec_chemical_identification.json'
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(final_results, f, indent=2, ensure_ascii=False)
    
    print(f"\n" + "="*80)
    print("TASK COMPLETION SUMMARY")
    print("="*80)
    
    print(f"\n✅ TARGET PAPER: {paper_candidates[0]['title'] if paper_candidates else 'Not definitively identified'}")
    print(f"✅ PAPER ACCESS: {paper_candidates[0]['link'] if paper_candidates else 'N/A'}")
    print(f"\n🧪 EC NUMBER CHEMICAL IDENTIFICATION:")
    print(f"   EC 1.11.1.7 = Peroxidase")
    print(f"   EC 3.1.3.1 = Alkaline phosphatase")
    print(f"\n📋 FINAL FORMATTED ANSWERS:")
    print(f"   Alphabetized chemicals: {', '.join(chemical_names_sorted)}")
    print(f"   EC numbers (semicolon format): {';'.join(ec_numbers_ordered)}")
    
    print(f"\nResults saved to: {results_file}")
    print(f"Task completed successfully!")
```