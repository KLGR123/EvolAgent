### Development Step 8: Locate and Transcribe Teal’c’s Response to “Isn’t That Hot?” in SG-1 YouTube Clip

**Description**: Access and analyze the YouTube video at https://www.youtube.com/watch?v=1htKBjuUWec to locate the specific dialogue where someone asks 'Isn't that hot?' and identify Teal'c's exact response. Extract the audio/video content, transcribe the relevant dialogue section, and document Teal'c's reply to this question.

**Use Cases**:
- Automated quality assurance for call centers by transcribing customer support calls, locating when a customer says “cancel my subscription,” and extracting the agent’s exact response for compliance review
- Digital archiving of corporate training videos, searching for the phrase “safety hazard” in noisy plant footage and documenting the instructor’s follow-up instructions for audit trails
- Film post-production localization workflows that identify and time-stamp a character’s catchphrase (e.g., “bring me the code”) in raw footage and export the translated dialogue script for subtitling
- E-learning content indexing by detecting when an instructor asks “any questions?” in recorded lectures and automatically generating navigation bookmarks around the ensuing student Q&A segment
- Legal deposition analysis where court reporters transcribe lengthy audio, search for the question “do you recall?” and extract the deponent’s precise answer for exhibit preparation
- Manufacturing process monitoring that captures machine alarms (e.g., “overheat warning”) from workshop audio, transcribes the alert, and logs the technician’s acknowledgment response for incident tracking
- Wildlife research audio analysis in the field, identifying when a rare bird call (“tu-weet”) occurs in background recordings and extracting the surrounding researcher commentary for ecological studies
- Podcast production automation that scans recorded episodes for explicit sponsor cue phrases (e.g., “today’s episode is brought to you by”) and isolates the host’s tailored ad read for editing and insertion

```
import os
import json
from pydub import AudioSegment
import speech_recognition as sr
from pydub.effects import normalize, compress_dynamic_range

print("=== ALTERNATIVE APPROACHES FOR TEAL'C AUDIO TRANSCRIPTION ===")
print("Previous attempt failed with Google Speech Recognition")
print("Trying enhanced audio preprocessing and alternative methods...\n")

# First, let's check what files we have in workspace
print("=== CHECKING WORKSPACE FILES ===")
workspace_files = []
for file in os.listdir("workspace"):
    full_path = os.path.join("workspace", file)
    if os.path.isfile(full_path):
        file_size = os.path.getsize(full_path)
        workspace_files.append((file, full_path, file_size))
        size_mb = file_size / (1024 * 1024)
        print(f"  - {file} ({size_mb:.2f} MB)")

# Look for the video file and any existing audio files
video_file = None
audio_file = None

for file_name, full_path, size in workspace_files:
    if file_name.endswith('.mp4'):
        video_file = full_path
        print(f"*** Found video file: {file_name} ***")
    elif file_name.endswith('.wav') and 'tealc' in file_name.lower():
        audio_file = full_path
        print(f"*** Found existing audio file: {file_name} ***")

if not video_file:
    print("\n*** ERROR: No video file found ***")
else:
    print(f"\n=== ENHANCED AUDIO PROCESSING APPROACH ===")
    
    try:
        # Load the video file
        print("Loading video file with pydub...")
        video = AudioSegment.from_file(video_file)
        duration_seconds = len(video) / 1000
        print(f"Video duration: {duration_seconds:.1f} seconds")
        
        # Apply multiple audio enhancement techniques
        print("\n=== APPLYING AUDIO ENHANCEMENTS ===")
        
        # 1. Normalize audio levels
        print("1. Normalizing audio levels...")
        enhanced_audio = normalize(video)
        
        # 2. Apply dynamic range compression to make quiet sounds louder
        print("2. Applying dynamic range compression...")
        enhanced_audio = compress_dynamic_range(enhanced_audio)
        
        # 3. Increase volume if needed
        print("3. Boosting volume...")
        enhanced_audio = enhanced_audio + 6  # Increase by 6dB
        
        # 4. Convert to mono and optimal sample rate for speech recognition
        print("4. Converting to mono and optimal sample rate...")
        enhanced_audio = enhanced_audio.set_channels(1).set_frame_rate(16000)
        
        # Save enhanced audio
        enhanced_audio_file = "workspace/tealc_enhanced_audio.wav"
        enhanced_audio.export(enhanced_audio_file, format="wav")
        enhanced_size = os.path.getsize(enhanced_audio_file)
        print(f"Enhanced audio saved: {enhanced_audio_file} ({enhanced_size} bytes)")
        
        print("\n=== ATTEMPTING TRANSCRIPTION WITH ENHANCED AUDIO ===")
        
        # Initialize speech recognizer with adjusted settings
        recognizer = sr.Recognizer()
        
        # Adjust recognizer sensitivity
        recognizer.energy_threshold = 300  # Lower threshold for quiet audio
        recognizer.dynamic_energy_threshold = True
        recognizer.pause_threshold = 0.8  # Shorter pause threshold
        
        print("Speech recognizer initialized with enhanced settings")
        
        # Try transcription with enhanced audio
        with sr.AudioFile(enhanced_audio_file) as source:
            print("Loading enhanced audio file...")
            
            # Adjust for ambient noise with longer duration
            recognizer.adjust_for_ambient_noise(source, duration=1.0)
            print("Adjusted for ambient noise (extended duration)")
            
            # Record the audio data
            audio_data = recognizer.record(source)
            print("Audio data recorded for transcription")
            
            # Try multiple transcription attempts with different settings
            transcription_attempts = [
                {'language': 'en-US', 'show_all': False},
                {'language': 'en-US', 'show_all': True},
                {'language': 'en', 'show_all': False}
            ]
            
            transcription_success = False
            final_transcription = ""
            
            for attempt_num, settings in enumerate(transcription_attempts, 1):
                try:
                    print(f"\nTranscription attempt {attempt_num} with settings: {settings}")
                    
                    if settings['show_all']:
                        # Get all possible transcriptions with confidence scores
                        result = recognizer.recognize_google(audio_data, 
                                                            language=settings['language'], 
                                                            show_all=True)
                        if result:
                            print(f"Multiple transcription results found: {len(result.get('alternative', []))}")
                            if 'alternative' in result and result['alternative']:
                                best_result = result['alternative'][0]
                                final_transcription = best_result.get('transcript', '')
                                confidence = best_result.get('confidence', 0)
                                print(f"Best transcription (confidence: {confidence:.2f}): '{final_transcription}'")
                                transcription_success = True
                                break
                    else:
                        # Get single best transcription
                        final_transcription = recognizer.recognize_google(audio_data, 
                                                                        language=settings['language'])
                        print(f"Transcription successful: '{final_transcription}'")
                        transcription_success = True
                        break
                        
                except sr.UnknownValueError:
                    print(f"Attempt {attempt_num} failed: Could not understand audio")
                    continue
                except sr.RequestError as e:
                    print(f"Attempt {attempt_num} failed: Service error - {e}")
                    continue
            
            if transcription_success and final_transcription.strip():
                print(f"\n*** TRANSCRIPTION SUCCESSFUL ***")
                print(f"Final transcription: '{final_transcription}'")
                
                # Save the successful transcription
                transcription_file = "workspace/tealc_successful_transcription.txt"
                with open(transcription_file, 'w', encoding='utf-8') as f:
                    f.write("TEAL'C COFFEE SCENE - SUCCESSFUL TRANSCRIPTION\n")
                    f.write("=" * 50 + "\n\n")
                    f.write(f"Source: {os.path.basename(video_file)}\n")
                    f.write(f"Duration: {duration_seconds:.1f} seconds\n")
                    f.write(f"Enhancement applied: Yes\n")
                    f.write(f"Transcription: {final_transcription}\n\n")
                
                print(f"Transcription saved to: {transcription_file}")
                
                # Now analyze for the specific dialogue
                print(f"\n=== ANALYZING FOR 'ISN'T THAT HOT?' DIALOGUE ===")
                
                transcription_lower = final_transcription.lower()
                
                # Search for hot-related patterns
                hot_patterns = [
                    "isn't that hot",
                    "isnt that hot", 
                    "is that hot",
                    "isn't it hot",
                    "that hot",
                    "too hot",
                    "very hot",
                    "hot"
                ]
                
                found_patterns = []
                for pattern in hot_patterns:
                    if pattern in transcription_lower:
                        found_patterns.append(pattern)
                        print(f"*** FOUND PATTERN: '{pattern}' ***")
                
                # Look for Teal'c's characteristic responses
                tealc_patterns = [
                    "indeed",
                    "it is",
                    "extremely",
                    "most",
                    "negative",
                    "affirmative"
                ]
                
                tealc_found = []
                for pattern in tealc_patterns:
                    if pattern in transcription_lower:
                        tealc_found.append(pattern)
                        print(f"Found Teal'c response pattern: '{pattern}'")
                
                # Create final analysis
                final_analysis = {
                    'video_file': os.path.basename(video_file),
                    'duration_seconds': duration_seconds,
                    'transcription_method': 'Enhanced audio processing + Google Speech Recognition',
                    'full_transcription': final_transcription,
                    'hot_patterns_found': found_patterns,
                    'tealc_patterns_found': tealc_found,
                    'analysis_complete': True
                }
                
                # Save detailed analysis
                with open('workspace/tealc_final_analysis.json', 'w', encoding='utf-8') as f:
                    json.dump(final_analysis, f, indent=2)
                
                # Create the final answer file
                with open('workspace/tealc_response_answer.txt', 'w', encoding='utf-8') as f:
                    f.write("TEAL'C'S RESPONSE TO 'ISN'T THAT HOT?'\n")
                    f.write("=" * 50 + "\n\n")
                    f.write(f"Scene: Teal'c trying coffee for the first time\n")
                    f.write(f"Video: {os.path.basename(video_file)}\n")
                    f.write(f"Duration: {duration_seconds:.1f} seconds\n\n")
                    f.write(f"COMPLETE TRANSCRIPTION:\n")
                    f.write(f"'{final_transcription}'\n\n")
                    
                    if found_patterns:
                        f.write(f"Hot-related dialogue found: {', '.join(found_patterns)}\n")
                    if tealc_found:
                        f.write(f"Teal'c response patterns: {', '.join(tealc_found)}\n")
                    
                    f.write(f"\nTEAL'C'S EXACT RESPONSE:\n")
                    f.write(f"Based on the transcription, Teal'c's dialogue in this scene is:\n")
                    f.write(f"'{final_transcription}'\n")
                
                print(f"\n*** ANALYSIS COMPLETE ***")
                print(f"Teal'c's response has been identified and saved to workspace files.")
                print(f"Final transcription: '{final_transcription}'")
                
            else:
                print(f"\n*** ALL TRANSCRIPTION ATTEMPTS FAILED ***")
                print("The audio content may be:")
                print("- Music or sound effects without clear speech")
                print("- Very low quality or heavily distorted")
                print("- In a language not recognized by the service")
                print("- Containing only background noise")
                
                # Save failure analysis
                with open('workspace/transcription_analysis_failed.txt', 'w') as f:
                    f.write("TRANSCRIPTION ANALYSIS - ALL METHODS FAILED\n")
                    f.write("=" * 50 + "\n\n")
                    f.write(f"Video: {os.path.basename(video_file)}\n")
                    f.write(f"Duration: {duration_seconds:.1f} seconds\n")
                    f.write("Methods attempted:\n")
                    f.write("1. Standard Google Speech Recognition\n")
                    f.write("2. Enhanced audio preprocessing\n")
                    f.write("3. Multiple language settings\n")
                    f.write("4. Confidence-based transcription\n\n")
                    f.write("Conclusion: Audio may not contain clear speech dialogue\n")
                
                print(f"Failure analysis saved to: workspace/transcription_analysis_failed.txt")
        
    except Exception as e:
        print(f"\n*** ERROR DURING ENHANCED PROCESSING ***")
        print(f"Error: {str(e)}")
        import traceback
        print(f"Full error details: {traceback.format_exc()}")

print("\n*** ENHANCED TEAL'C DIALOGUE ANALYSIS COMPLETE ***")
```