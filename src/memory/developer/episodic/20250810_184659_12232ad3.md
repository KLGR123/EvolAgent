### Development Step 1: Identify ‚ÄòSacred Desire‚Äô Protagonist: Ex-Soviet Paratrooper Co-Founder Fleeing 1992 Crackdown

**Description**: Conduct a comprehensive web search to identify the book 'Sacred Desire' and its protagonist, focusing on finding information about a former Soviet paratrooper who co-founded an organization and fled due to a 1992 crackdown. Search for keywords including 'Sacred Desire book protagonist Soviet paratrooper', 'Sacred Desire novel former Soviet paratrooper co-founder', '1992 crackdown organization Soviet paratrooper fled', and 'Sacred Desire character co-founded organization 1992'. Extract details about the protagonist's identity, the organization they co-founded, and the circumstances of the 1992 crackdown.

**Use Cases**:
- Investigative journalism research into defector narratives, using comprehensive multi-backend searches to verify details about Soviet paratroopers who fled after the 1992 crackdown
- Academic literary analysis for a university thesis, validating the historical accuracy of a novel‚Äôs protagonist and their co-founded organization
- Library catalog enrichment and metadata curation, discovering obscure or self-published titles like ‚ÄúSacred Desire‚Äù and extracting protagonist information for archival records
- Intelligence and security studies profiling former Soviet military personnel, mapping their organizational ties and flight circumstances after 1992 crackdowns
- Content marketing and promotional strategy for a publishing house, identifying unique selling points and character backstories to pitch the novel to specialized audiences
- Cultural heritage documentation projects, tracing diaspora organizations established by Soviet veterans and detailing their founders‚Äô post-1992 journeys
- Automated competitive analysis for online book retailers, aggregating search results to spot emerging titles and correlate protagonist themes with customer interests
- QA testing of search-aggregation platforms, using complex queries to evaluate relevance scoring, backend consistency, and result prioritization for specialized literature searches

```
from ddgs import DDGS
import json
import os
import time
from datetime import datetime

# Ensure workspace directory exists
os.makedirs('workspace', exist_ok=True)

print('=== COMPREHENSIVE SEARCH FOR "SACRED DESIRE" BOOK AND PROTAGONIST ===')
print('=' * 80)
print('TARGET: Book "Sacred Desire" with protagonist who is:')
print('‚Ä¢ Former Soviet paratrooper')
print('‚Ä¢ Co-founded an organization')
print('‚Ä¢ Fled due to 1992 crackdown')
print('\nSEARCH STRATEGY: Multi-query approach using DuckDuckGo with various keyword combinations')
print('=' * 80)

# Define comprehensive search queries
search_queries = [
    '"Sacred Desire" book protagonist Soviet paratrooper',
    '"Sacred Desire" novel former Soviet paratrooper co-founder',
    'Sacred Desire book Soviet paratrooper organization 1992',
    '"Sacred Desire" character co-founded organization 1992 crackdown',
    'Sacred Desire novel paratrooper fled 1992',
    '"Sacred Desire" book Soviet military organization founder',
    'Sacred Desire protagonist paratrooper organization crackdown',
    '"Sacred Desire" Soviet veteran co-founder 1992',
    'Sacred Desire book former paratrooper fled organization',
    'Sacred Desire novel Soviet military co-founded 1992'
]

# Initialize results storage
all_search_results = {
    'search_timestamp': datetime.now().isoformat(),
    'total_queries': len(search_queries),
    'queries_executed': [],
    'all_results': [],
    'relevant_findings': [],
    'book_candidates': [],
    'protagonist_details': [],
    'search_summary': {}
}

print(f'Executing {len(search_queries)} different search queries...')
print('\n' + '=' * 80)

# Execute searches with detailed analysis
for query_num, query in enumerate(search_queries, 1):
    print(f'\nüîç SEARCH {query_num}/{len(search_queries)}: {query}')
    print('-' * 60)
    
    try:
        # Initialize DuckDuckGo searcher
        searcher = DDGS(timeout=15)
        
        # Perform search with multiple backends
        results = searcher.text(
            query, 
            max_results=15, 
            page=1, 
            backend=["google", "duckduckgo", "bing", "yahoo", "brave"], 
            safesearch="off", 
            region="en-us"
        )
        
        if results == []:
            print(f'‚ùå No results found for query: "{query}"')
            all_search_results['queries_executed'].append({
                'query_number': query_num,
                'query_text': query,
                'status': 'no_results',
                'results_count': 0
            })
        else:
            print(f'‚úÖ Found {len(results)} results for query: "{query}"')
            
            # Analyze each result for relevance
            query_relevant_results = []
            
            for result_num, result in enumerate(results, 1):
                title = result.get('title', 'No title')
                body = result.get('body', 'No description')
                href = result.get('href', 'No URL')
                
                print(f'\n  Result {result_num}:')
                print(f'  Title: {title}')
                print(f'  URL: {href}')
                print(f'  Description: {body[:200]}...')
                
                # Calculate relevance score
                combined_text = f'{title.lower()} {body.lower()}'
                relevance_score = 0
                matched_terms = []
                
                # Key terms and their weights
                key_terms = {
                    'sacred desire': 5,
                    'soviet': 3,
                    'paratrooper': 4,
                    'co-founded': 3,
                    'organization': 2,
                    '1992': 3,
                    'crackdown': 3,
                    'fled': 2,
                    'protagonist': 2,
                    'character': 1,
                    'book': 2,
                    'novel': 2
                }
                
                for term, weight in key_terms.items():
                    if term in combined_text:
                        relevance_score += weight
                        matched_terms.append(term)
                
                print(f'  Relevance Score: {relevance_score}')
                print(f'  Matched Terms: {matched_terms}')
                
                # Store result with analysis
                result_data = {
                    'query_number': query_num,
                    'query_text': query,
                    'result_number': result_num,
                    'title': title,
                    'url': href,
                    'description': body,
                    'relevance_score': relevance_score,
                    'matched_terms': matched_terms
                }
                
                all_search_results['all_results'].append(result_data)
                
                # Identify highly relevant results
                if relevance_score >= 8:  # High relevance threshold
                    query_relevant_results.append(result_data)
                    all_search_results['relevant_findings'].append(result_data)
                    print(f'  ‚≠ê HIGH RELEVANCE - Added to priority findings')
                
                # Identify potential book matches
                if 'sacred desire' in combined_text and relevance_score >= 5:
                    all_search_results['book_candidates'].append(result_data)
                    print(f'  üìö BOOK CANDIDATE - Potential "Sacred Desire" match')
                
                # Identify protagonist details
                if any(term in combined_text for term in ['soviet', 'paratrooper']) and relevance_score >= 6:
                    all_search_results['protagonist_details'].append(result_data)
                    print(f'  üë§ PROTAGONIST DETAIL - Contains character information')
                
                print('  ' + '-' * 40)
            
            all_search_results['queries_executed'].append({
                'query_number': query_num,
                'query_text': query,
                'status': 'success',
                'results_count': len(results),
                'relevant_results': len(query_relevant_results)
            })
            
            print(f'\nüìä Query {query_num} Summary:')
            print(f'   ‚Ä¢ Total results: {len(results)}')
            print(f'   ‚Ä¢ Highly relevant: {len(query_relevant_results)}')
            
    except Exception as e:
        print(f'‚ùå Error executing search {query_num}: {str(e)}')
        all_search_results['queries_executed'].append({
            'query_number': query_num,
            'query_text': query,
            'status': 'error',
            'error_message': str(e),
            'results_count': 0
        })
    
    # Rate limiting between searches
    if query_num < len(search_queries):
        print(f'\n‚è≥ Waiting 3 seconds before next search...')
        time.sleep(3)

# Comprehensive analysis of all results
print('\n' + '=' * 80)
print('üìã COMPREHENSIVE SEARCH ANALYSIS')
print('=' * 80)

total_results = len(all_search_results['all_results'])
high_relevance_count = len(all_search_results['relevant_findings'])
book_candidates_count = len(all_search_results['book_candidates'])
protagonist_details_count = len(all_search_results['protagonist_details'])

print(f'\nüìä SEARCH STATISTICS:')
print(f'   ‚Ä¢ Total queries executed: {len(all_search_results["queries_executed"])}')
print(f'   ‚Ä¢ Total results collected: {total_results}')
print(f'   ‚Ä¢ High relevance results: {high_relevance_count}')
print(f'   ‚Ä¢ Book candidates found: {book_candidates_count}')
print(f'   ‚Ä¢ Protagonist details found: {protagonist_details_count}')

# Analyze most promising findings
if all_search_results['relevant_findings']:
    print(f'\nüéØ TOP HIGH-RELEVANCE FINDINGS:')
    print('-' * 50)
    
    # Sort by relevance score
    sorted_findings = sorted(all_search_results['relevant_findings'], key=lambda x: x['relevance_score'], reverse=True)
    
    for i, finding in enumerate(sorted_findings[:5], 1):
        print(f'\n{i}. SCORE: {finding["relevance_score"]}')
        print(f'   Title: {finding["title"]}')
        print(f'   URL: {finding["url"]}')
        print(f'   Description: {finding["description"][:300]}...')
        print(f'   Matched Terms: {finding["matched_terms"]}')
        print(f'   Query: {finding["query_text"]}')
        print('   ' + '-' * 60)
else:
    print('\n‚ùå No high-relevance findings identified')

# Analyze book candidates
if all_search_results['book_candidates']:
    print(f'\nüìö BOOK CANDIDATES ANALYSIS:')
    print('-' * 40)
    
    for i, candidate in enumerate(all_search_results['book_candidates'], 1):
        print(f'\n{i}. Book Candidate:')
        print(f'   Title: {candidate["title"]}')
        print(f'   URL: {candidate["url"]}')
        print(f'   Description: {candidate["description"][:250]}...')
        print(f'   Relevance Score: {candidate["relevance_score"]}')
        print(f'   Key Terms: {candidate["matched_terms"]}')
else:
    print('\nüìö No specific "Sacred Desire" book candidates found')

# Analyze protagonist information
if all_search_results['protagonist_details']:
    print(f'\nüë§ PROTAGONIST INFORMATION:')
    print('-' * 35)
    
    for i, detail in enumerate(all_search_results['protagonist_details'], 1):
        print(f'\n{i}. Protagonist Detail:')
        print(f'   Title: {detail["title"]}')
        print(f'   Description: {detail["description"][:200]}...')
        print(f'   Relevance Score: {detail["relevance_score"]}')
        print(f'   Character Terms: {detail["matched_terms"]}')
else:
    print('\nüë§ No specific protagonist details found')

# Generate search summary
all_search_results['search_summary'] = {
    'total_queries': len(search_queries),
    'successful_queries': len([q for q in all_search_results['queries_executed'] if q['status'] == 'success']),
    'failed_queries': len([q for q in all_search_results['queries_executed'] if q['status'] in ['error', 'no_results']]),
    'total_results': total_results,
    'high_relevance_results': high_relevance_count,
    'book_candidates': book_candidates_count,
    'protagonist_details': protagonist_details_count,
    'most_successful_query': max(all_search_results['queries_executed'], key=lambda x: x.get('results_count', 0)) if all_search_results['queries_executed'] else None
}

# Save comprehensive results to workspace
results_filename = 'sacred_desire_comprehensive_search_results.json'
results_filepath = os.path.join('workspace', results_filename)

with open(results_filepath, 'w', encoding='utf-8') as f:
    json.dump(all_search_results, f, indent=2, ensure_ascii=False)

print(f'\nüíæ COMPREHENSIVE RESULTS SAVED TO: {results_filepath}')

# Final conclusions and recommendations
print('\n' + '=' * 80)
print('üéØ SEARCH CONCLUSIONS AND RECOMMENDATIONS')
print('=' * 80)

if high_relevance_count > 0:
    print('\n‚úÖ POSITIVE FINDINGS:')
    print(f'   ‚Ä¢ Found {high_relevance_count} highly relevant results')
    print(f'   ‚Ä¢ Identified {book_candidates_count} potential book matches')
    print(f'   ‚Ä¢ Collected {protagonist_details_count} protagonist-related details')
    print('\nüìã RECOMMENDED NEXT STEPS:')
    print('   1. Review high-relevance findings for "Sacred Desire" book details')
    print('   2. Follow up on book candidate URLs for more information')
    print('   3. Investigate protagonist details for Soviet paratrooper connections')
    print('   4. Search for 1992 crackdown context in relevant results')
else:
    print('\n‚ö†Ô∏è  LIMITED FINDINGS:')
    print('   ‚Ä¢ No high-relevance results found with current search terms')
    print('   ‚Ä¢ "Sacred Desire" may be an obscure or fictional work')
    print('   ‚Ä¢ Search terms may need refinement')
    print('\nüìã ALTERNATIVE APPROACHES:')
    print('   1. Search for variations of the title ("Sacred Desires", etc.)')
    print('   2. Focus on Soviet paratrooper organizations from 1992')
    print('   3. Search for 1992 crackdowns on military/veteran organizations')
    print('   4. Look for book databases or literary catalogs')

print('\n5. Review all collected results for additional context clues')
print('6. Consider searching academic databases for literary analysis')
print('7. Check if "Sacred Desire" might be translated from another language')

print(f'\nüìä FINAL STATISTICS:')
print(f'   ‚Ä¢ Search queries: {all_search_results["search_summary"]["total_queries"]}')
print(f'   ‚Ä¢ Successful searches: {all_search_results["search_summary"]["successful_queries"]}')
print(f'   ‚Ä¢ Total results: {all_search_results["search_summary"]["total_results"]}')
print(f'   ‚Ä¢ High-relevance findings: {all_search_results["search_summary"]["high_relevance_results"]}')

if all_search_results['search_summary']['most_successful_query']:
    best_query = all_search_results['search_summary']['most_successful_query']
    print(f'   ‚Ä¢ Most productive query: "{best_query["query_text"]}" ({best_query["results_count"]} results)')

print('\n=== COMPREHENSIVE SEARCH FOR "SACRED DESIRE" COMPLETE ===')
```