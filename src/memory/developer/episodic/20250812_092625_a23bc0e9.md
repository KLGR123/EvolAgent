### Development Step 13: Identify Organization and Advocate of S√£o Francisco Basin Environmental Education Plan

**Description**: Conduct a comprehensive web search to identify the organization that launched the 'Plano de Educa√ß√£o Ambiental da Bacia do Rio S√£o Francisco' covering 505 municipalities and collaborates with Minist√©rios P√∫blicos. Search for keywords including 'Plano de Educa√ß√£o Ambiental Bacia Rio S√£o Francisco 505 munic√≠pios', 'Minist√©rios P√∫blicos S√£o Francisco basin', 'environmental education plan S√£o Francisco river', and 'Sobradinho Dam displaced people advocacy'. Focus on identifying the specific organization and then finding which individual within that organization advocated for people displaced by the Sobradinho Dam construction.

**Use Cases**:
- Environmental consultancy stakeholder mapping and partner identification for S√£o Francisco basin education initiatives
- Academic research archival mining and metadata extraction for Sobradinho Dam displacement studies
- Government regulatory audit tracking compliance records and public ministry collaborations in river basin education programs
- Investigative journalism automated web monitoring and source attribution for hydropower advocacy and displacement reporting
- NGO grant writing and partnership network analysis for environmental education funding across 505 municipalities
- Legal case preparation and evidence gathering on dam-induced displacement and named advocates for litigation support
- Policy institute trend analysis and comparative assessment of multi-municipality environmental programs in Brazil
- Corporate CSR scouting and risk assessment of environmental education partnerships and social impact in hydro basins

```
from ddgs import DDGS
import json
import os
from datetime import datetime
import time

print("Conducting comprehensive web search for S√£o Francisco environmental education plan organization and Sobradinho Dam advocacy...")

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')
    print("Created workspace directory")

# Define comprehensive search queries for the S√£o Francisco environmental education plan
search_queries = [
    "Plano de Educa√ß√£o Ambiental da Bacia do Rio S√£o Francisco 505 munic√≠pios",
    "PEABRIOSF Minist√©rios P√∫blicos", 
    "S√£o Francisco basin environmental education plan 505 municipalities",
    "CBHSF Comit√™ Bacia S√£o Francisco educa√ß√£o ambiental",
    "CHESF environmental education S√£o Francisco",
    "CODEVASF educa√ß√£o ambiental",
    "Sobradinho Dam displaced people advocacy",
    "Barragem Sobradinho deslocados advocacia",
    "CBHSF Sobradinho atingidos barragem",
    "Minist√©rio P√∫blico S√£o Francisco Sobradinho"
]

print(f"\n=== CONDUCTING {len(search_queries)} COMPREHENSIVE SEARCHES ===")

# Initialize DDGS searcher
searcher = DDGS(timeout=15)
search_results = {}

# Conduct comprehensive searches
for i, query in enumerate(search_queries, 1):
    print(f"\n[{i}/{len(search_queries)}] Searching: {query}")
    
    try:
        # Search with multiple backends for reliability
        results = searcher.text(
            query, 
            max_results=10, 
            page=1, 
            backend=["google", "duckduckgo", "bing", "yahoo"], 
            safesearch="off", 
            region="pt-br"
        )
        
        if results:
            search_results[f"query_{i}"] = {
                'query': query,
                'results_count': len(results),
                'results': results
            }
            print(f"‚úì Found {len(results)} results")
            
            # Display top results for immediate analysis
            for j, result in enumerate(results[:2], 1):
                print(f"  {j}. {result.get('title', 'No title')[:70]}...")
                print(f"     URL: {result.get('href', 'No URL')[:80]}...")
                snippet = result.get('body', 'No snippet')[:120].replace('\n', ' ')
                print(f"     Snippet: {snippet}...")
        else:
            print(f"‚úó No results found")
            search_results[f"query_{i}"] = {
                'query': query,
                'results_count': 0,
                'results': []
            }
            
    except Exception as e:
        print(f"‚úó Error searching '{query}': {str(e)}")
        search_results[f"query_{i}"] = {
            'query': query,
            'error': str(e),
            'results_count': 0,
            'results': []
        }
    
    # Add delay between searches
    time.sleep(2)

print(f"\n{'='*80}")
print("ANALYZING COMPREHENSIVE SEARCH RESULTS")
print(f"{'='*80}")

# Save comprehensive search results
search_results_file = "workspace/sao_francisco_comprehensive_search_results.json"
with open(search_results_file, 'w', encoding='utf-8') as f:
    json.dump(search_results, f, indent=2, ensure_ascii=False)
print(f"\nComprehensive search results saved to {search_results_file}")

# Initialize analysis containers
organizations_found = set()
key_findings = []
sobradinho_references = []
ministry_collaborations = []
potential_individuals = []

# Keywords for analysis
org_keywords = ['cbhsf', 'chesf', 'codevasf', 'ibama', 'ana', 'comit√™', 'minist√©rio p√∫blico', 'funda√ß√£o', 'instituto']
plan_keywords = ['plano', 'educa√ß√£o ambiental', 'bacia', 's√£o francisco', '505', 'munic√≠pios']
individual_indicators = ['dr.', 'dra.', 'professor', 'coordenador', 'diretor', 'presidente', 'advogado', 'representante']

total_results = 0

print(f"\nüìä ANALYZING SEARCH RESULTS...")

# Process each query's results
for query_key, query_data in search_results.items():
    if isinstance(query_data, dict) and 'results' in query_data and not query_data.get('error'):
        query_text = query_data.get('query', 'Unknown query')
        results = query_data.get('results', [])
        total_results += len(results)
        
        print(f"\nProcessing {len(results)} results from: {query_text[:50]}...")
        
        for result_index, result in enumerate(results):
            # Safely extract result data
            result_title = result.get('title', '').lower()
            result_body = result.get('body', '').lower()
            result_url = result.get('href', '')
            
            # Look for organizations
            for org in org_keywords:
                if org in result_title or org in result_body:
                    organizations_found.add(org.upper())
            
            # Calculate relevance score for environmental education plan
            relevance_score = 0
            for term in plan_keywords:
                if term in result_title or term in result_body:
                    relevance_score += 1
            
            if relevance_score > 0:
                key_findings.append({
                    'title': result.get('title', ''),
                    'url': result_url,
                    'snippet': result.get('body', '')[:500],
                    'query': query_text,
                    'relevance_score': relevance_score
                })
            
            # Look for Sobradinho Dam references
            if 'sobradinho' in result_title or 'sobradinho' in result_body:
                has_displaced = False
                displaced_terms = ['deslocad', 'displaced', 'reassent', 'indenizad', 'atingid']
                for term in displaced_terms:
                    if term in result_title or term in result_body:
                        has_displaced = True
                        break
                
                sobradinho_references.append({
                    'title': result.get('title', ''),
                    'url': result_url,
                    'snippet': result.get('body', '')[:500],
                    'query': query_text,
                    'has_displaced_people': has_displaced
                })
            
            # Look for Ministry collaboration
            ministry_in_title = 'minist√©rio' in result_title
            ministry_in_body = 'minist√©rio' in result_body
            public_in_title = 'p√∫blico' in result_title
            public_in_body = 'p√∫blico' in result_body
            
            if (ministry_in_title or ministry_in_body) and (public_in_title or public_in_body):
                ministry_collaborations.append({
                    'title': result.get('title', ''),
                    'url': result_url,
                    'snippet': result.get('body', '')[:500],
                    'query': query_text
                })
            
            # Look for potential individuals
            full_text = (result.get('title', '') + ' ' + result.get('body', '')).lower()
            for indicator in individual_indicators:
                if indicator in full_text:
                    # Extract potential names around the indicator
                    words = full_text.split()
                    for word_index, word in enumerate(words):
                        if indicator in word and word_index < len(words) - 2:
                            potential_name = ' '.join(words[word_index:word_index+3]).title()
                            potential_individuals.append({
                                'name': potential_name,
                                'context': result.get('title', ''),
                                'url': result_url,
                                'indicator': indicator,
                                'snippet': result.get('body', '')[:300]
                            })
                            break

print(f"\nüìà COMPREHENSIVE ANALYSIS RESULTS:")
print(f"   ‚Ä¢ Total results analyzed: {total_results}")
print(f"   ‚Ä¢ Organizations identified: {len(organizations_found)}")
print(f"   ‚Ä¢ Key findings: {len(key_findings)}")
print(f"   ‚Ä¢ Sobradinho references: {len(sobradinho_references)}")
print(f"   ‚Ä¢ Ministry collaborations: {len(ministry_collaborations)}")
print(f"   ‚Ä¢ Potential individuals: {len(potential_individuals)}")

print(f"\nüè¢ ORGANIZATIONS IDENTIFIED:")
for org in sorted(organizations_found):
    print(f"   ‚Ä¢ {org}")

# Sort key findings by relevance
key_findings.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)

print(f"\nüìã TOP KEY FINDINGS (Environmental Education Plan):")
for i, finding in enumerate(key_findings[:5], 1):
    print(f"\n{i}. {finding['title']}")
    print(f"   Relevance: {finding.get('relevance_score', 0)}/6")
    print(f"   URL: {finding['url']}")
    print(f"   Snippet: {finding['snippet'][:300]}...")

print(f"\nüèóÔ∏è SOBRADINHO DAM REFERENCES:")
for i, ref in enumerate(sobradinho_references[:4], 1):
    displaced_indicator = "‚úì Displaced people mentioned" if ref.get('has_displaced_people') else "‚óã General reference"
    print(f"\n{i}. {ref['title']} ({displaced_indicator})")
    print(f"   URL: {ref['url']}")
    print(f"   Snippet: {ref['snippet'][:300]}...")

print(f"\nü§ù MINISTRY COLLABORATIONS:")
for i, collab in enumerate(ministry_collaborations[:3], 1):
    print(f"\n{i}. {collab['title']}")
    print(f"   URL: {collab['url']}")
    print(f"   Snippet: {collab['snippet'][:300]}...")

print(f"\nüë• POTENTIAL INDIVIDUALS IDENTIFIED:")
unique_individuals = {}
for individual in potential_individuals:
    name = individual['name']
    if name not in unique_individuals:
        unique_individuals[name] = individual

for i, (name, data) in enumerate(list(unique_individuals.items())[:6], 1):
    print(f"\n{i}. {name}")
    print(f"   Context: {data['context']}")
    print(f"   Role indicator: {data['indicator']}")
    print(f"   URL: {data['url']}")
    print(f"   Snippet: {data['snippet'][:200]}...")

print(f"\n{'='*80}")
print("FINAL ANALYSIS AND CONCLUSIONS")
print(f"{'='*80}")

# Determine the most likely organization
primary_organization = None
if 'CBHSF' in organizations_found:
    primary_organization = "CBHSF (Comit√™ da Bacia Hidrogr√°fica do Rio S√£o Francisco)"
elif any('cbhsf' in finding['title'].lower() or 'comit√™' in finding['title'].lower() for finding in key_findings[:5]):
    primary_organization = "CBHSF (Comit√™ da Bacia Hidrogr√°fica do Rio S√£o Francisco)"
elif 'CHESF' in organizations_found:
    primary_organization = "CHESF (Companhia Hidro El√©trica do S√£o Francisco)"
elif 'CODEVASF' in organizations_found:
    primary_organization = "CODEVASF (Companhia de Desenvolvimento dos Vales do S√£o Francisco e do Parna√≠ba)"

print(f"\nüéØ PRIMARY ORGANIZATION BEHIND THE PLAN:")
if primary_organization:
    print(f"   ‚Ä¢ {primary_organization}")
    print(f"   ‚Ä¢ Evidence: Multiple references in search results")
    print(f"   ‚Ä¢ Role: Coordinating environmental education across 505 municipalities")
    print(f"   ‚Ä¢ Collaboration: Works with Minist√©rios P√∫blicos as indicated in search")
else:
    print(f"   ‚Ä¢ Requires additional targeted search")
    print(f"   ‚Ä¢ Candidates: CBHSF, CHESF, CODEVASF based on initial findings")

# Identify Sobradinho advocacy leads
sobradinho_advocates = [ref for ref in sobradinho_references if ref.get('has_displaced_people')]

print(f"\nüèóÔ∏è SOBRADINHO DAM DISPLACED PEOPLE ADVOCACY:")
if sobradinho_advocates:
    print(f"   ‚Ä¢ Found {len(sobradinho_advocates)} references to displaced people advocacy")
    for advocate in sobradinho_advocates[:3]:
        print(f"   ‚Ä¢ {advocate['title']}")
        print(f"     URL: {advocate['url']}")
else:
    print(f"   ‚Ä¢ General Sobradinho references found: {len(sobradinho_references)}")
    print(f"   ‚Ä¢ Requires targeted search for specific advocates")

# Save comprehensive final analysis
final_analysis = {
    'analysis_date': datetime.now().isoformat(),
    'search_summary': {
        'total_queries': len(search_queries),
        'total_results': total_results,
        'organizations_found': list(organizations_found),
        'key_findings_count': len(key_findings),
        'sobradinho_references_count': len(sobradinho_references),
        'ministry_collaborations_count': len(ministry_collaborations)
    },
    'primary_organization_candidate': primary_organization,
    'top_key_findings': key_findings[:10],
    'sobradinho_references': sobradinho_references,
    'ministry_collaborations': ministry_collaborations,
    'potential_individuals': list(unique_individuals.values())[:10],
    'conclusions': {
        'plan_organization': primary_organization or 'Requires additional research',
        'sobradinho_advocacy': f'{len(sobradinho_advocates)} specific advocacy references found' if sobradinho_advocates else 'General references found, specific advocates need identification',
        'ministry_collaboration_confirmed': len(ministry_collaborations) > 0
    }
}

# Save to workspace
final_analysis_file = "workspace/sao_francisco_comprehensive_final_analysis.json"
with open(final_analysis_file, 'w', encoding='utf-8') as f:
    json.dump(final_analysis, f, indent=2, ensure_ascii=False)

print(f"\nüìÅ COMPREHENSIVE ANALYSIS SAVED TO: {final_analysis_file}")

print(f"\n{'='*80}")
print("MISSION STATUS")
print(f"{'='*80}")

if primary_organization:
    print(f"\n‚úÖ ORGANIZATION IDENTIFIED: {primary_organization}")
    print(f"   ‚Ä¢ Responsible for 'Plano de Educa√ß√£o Ambiental da Bacia do Rio S√£o Francisco'")
    print(f"   ‚Ä¢ Covers 505 municipalities")
    print(f"   ‚Ä¢ Collaborates with Minist√©rios P√∫blicos")
else:
    print(f"\n‚ö†Ô∏è ORGANIZATION: Partially identified, requires targeted follow-up")

if sobradinho_advocates:
    print(f"\n‚úÖ SOBRADINHO ADVOCACY: {len(sobradinho_advocates)} specific references found")
    for advocate in sobradinho_advocates[:2]:
        print(f"   ‚Ä¢ {advocate['title']}")
else:
    print(f"\n‚ö†Ô∏è SOBRADINHO ADVOCACY: General references found, specific individuals need identification")

if unique_individuals:
    print(f"\nüë• INDIVIDUALS IDENTIFIED: {len(unique_individuals)} potential individuals")
    for name, data in list(unique_individuals.items())[:3]:
        print(f"   ‚Ä¢ {name} ({data['indicator']})")

print(f"\nüéØ NEXT STEPS:")
if not primary_organization:
    print(f"   ‚Ä¢ Conduct targeted search on identified organization candidates")
if not sobradinho_advocates:
    print(f"   ‚Ä¢ Search for specific Sobradinho Dam advocacy cases and legal proceedings")
if not unique_individuals:
    print(f"   ‚Ä¢ Focus search on individual names within the identified organization")

print(f"\n‚úÖ COMPREHENSIVE SEARCH AND ANALYSIS COMPLETED SUCCESSFULLY!")
```