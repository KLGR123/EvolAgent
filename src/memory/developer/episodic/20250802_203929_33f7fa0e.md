### Development Step 46: 2011 Bulgarian Census: Tertiary Education Completion Numbers and Percentages by Gender

**Description**: Search for the official 2011 Bulgarian census data from the Bulgarian National Statistical Institute (NSI) or other authoritative government sources that specifically contain the tertiary education completion numbers by gender. Focus on finding the exact counts or percentages of men and women who completed tertiary education according to the 2011 census results.

**Use Cases**:
- Gender equity assessment for Bulgarian Ministry of Education to benchmark male vs. female tertiary graduation rates and guide new policy initiatives
- Academic research project comparing 2011 Bulgarian tertiary completion by gender with other EU member states to study regional gender gaps in higher education
- NGO proposal development requiring exact male and female university graduation figures from the 2011 census for securing EU funding on women’s empowerment programs
- Labor market analysis by a consulting firm using historical gender‐specific tertiary education data to advise Bulgarian employers on talent pipeline planning
- University strategic planning team integrating 2011 gender‐disaggregated graduation rates into enrollment forecasting and scholarship allocation models
- Automated reporting system for the National Statistical Institute to ingest and visualize 2011 census tertiary education by gender in their annual data dashboards
- International development agency impact evaluation leveraging baseline male and female tertiary completion statistics to measure success of past education interventions in Bulgaria
- Data journalism feature creating interactive maps of regional gender disparities in higher education attainment across Bulgaria based on 2011 census statistics

```
import os
import json
from bs4 import BeautifulSoup
import re

workspace_dir = 'workspace'

print("=== EXTRACTING 2011 BULGARIAN CENSUS TERTIARY EDUCATION DATA BY GENDER ===")
print("\nObjective: Extract specific counts/percentages of men and women who completed tertiary education\n")

# First, let's inspect the analysis results to understand what we found
analysis_file = os.path.join(workspace_dir, 'nsi_census_tertiary_education_final_analysis.json')

if os.path.exists(analysis_file):
    print("--- Loading Previous Analysis Results ---")
    with open(analysis_file, 'r', encoding='utf-8') as f:
        analysis_data = json.load(f)
    
    print(f"Analysis timestamp: {analysis_data['analysis_timestamp']}")
    print(f"Files analyzed: {analysis_data['files_analyzed']}")
    print(f"Summary: {analysis_data['summary']}")
    
    # Find the highest priority file
    if analysis_data['analysis_results']:
        top_result = analysis_data['analysis_results'][0]
        print(f"\nHighest priority file: {top_result['filename']}")
        print(f"Relevance score: {top_result['relevance_score']}")
        print(f"Education content matches: {len(top_result['education_content_matches'])}")
        
        if top_result['education_content_matches']:
            print("\nEducation content found:")
            for i, match in enumerate(top_result['education_content_matches'][:5], 1):
                print(f"  {i}. {match[:200]}...")
else:
    print("Analysis file not found. Cannot proceed.")
    exit(1)

# Now let's examine the highest-priority file in detail
highest_priority_file = 'nsi_census_source_4.html'
file_path = os.path.join(workspace_dir, highest_priority_file)

if os.path.exists(file_path):
    print(f"\n--- DETAILED EXAMINATION OF {highest_priority_file} ---")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    print(f"File size: {len(html_content):,} characters")
    
    # Parse with BeautifulSoup
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # Get all text content
    content_text = soup.get_text()
    
    # Look for specific patterns related to tertiary education by gender
    print("\n--- SEARCHING FOR TERTIARY EDUCATION BY GENDER DATA ---")
    
    # Search for patterns that might contain the actual statistics
    tertiary_patterns = [
        r'tertiary education.*?(?:male|female|men|women).*?\d+[,.]?\d*',
        r'(?:male|female|men|women).*?tertiary education.*?\d+[,.]?\d*',
        r'higher education.*?(?:male|female|men|women).*?\d+[,.]?\d*',
        r'(?:male|female|men|women).*?higher education.*?\d+[,.]?\d*',
        r'graduates.*?(?:male|female|men|women).*?\d+[,.]?\d*',
        r'(?:male|female|men|women).*?graduates.*?\d+[,.]?\d*',
        r'bachelor.*?(?:male|female|men|women).*?\d+[,.]?\d*',
        r'(?:male|female|men|women).*?bachelor.*?\d+[,.]?\d*',
        r'university.*?(?:male|female|men|women).*?\d+[,.]?\d*',
        r'(?:male|female|men|women).*?university.*?\d+[,.]?\d*'
    ]
    
    found_statistics = []
    
    for pattern in tertiary_patterns:
        matches = re.findall(pattern, content_text, re.IGNORECASE | re.DOTALL)
        for match in matches:
            # Clean up the match
            clean_match = re.sub(r'\s+', ' ', match.strip())
            if len(clean_match) > 20 and len(clean_match) < 500:  # Reasonable length
                found_statistics.append(clean_match)
    
    if found_statistics:
        print(f"\nFound {len(found_statistics)} potential statistics:")
        for i, stat in enumerate(found_statistics[:10], 1):  # Show first 10
            print(f"  {i}. {stat}")
    else:
        print("\nNo direct statistics found in text patterns.")
    
    # Look for tables that might contain the data
    print("\n--- EXAMINING TABLES FOR TERTIARY EDUCATION DATA ---")
    
    tables = soup.find_all('table')
    print(f"Total tables found: {len(tables)}")
    
    relevant_tables = []
    
    for i, table in enumerate(tables):
        table_text = table.get_text().lower()
        
        # Check if table contains tertiary education and gender information
        has_tertiary = any(term in table_text for term in ['tertiary', 'higher education', 'university', 'bachelor', 'master', 'degree'])
        has_gender = any(term in table_text for term in ['male', 'female', 'men', 'women', 'sex', 'gender'])
        has_numbers = bool(re.search(r'\d+[,.]?\d*', table_text))
        
        if has_tertiary and (has_gender or has_numbers):
            # Extract table structure
            rows = table.find_all('tr')
            table_data = []
            
            for row in rows[:20]:  # Limit to first 20 rows
                cells = row.find_all(['td', 'th'])
                row_data = [cell.get_text().strip() for cell in cells]
                if any(cell for cell in row_data):  # If row has content
                    table_data.append(row_data)
            
            relevant_tables.append({
                'table_index': i,
                'has_tertiary': has_tertiary,
                'has_gender': has_gender,
                'has_numbers': has_numbers,
                'rows_count': len(rows),
                'sample_data': table_data[:10]  # First 10 rows
            })
    
    if relevant_tables:
        print(f"\nFound {len(relevant_tables)} relevant tables:")
        for table_info in relevant_tables:
            print(f"\nTable {table_info['table_index']}:")
            print(f"  Has tertiary: {table_info['has_tertiary']}")
            print(f"  Has gender: {table_info['has_gender']}")
            print(f"  Has numbers: {table_info['has_numbers']}")
            print(f"  Total rows: {table_info['rows_count']}")
            print(f"  Sample data:")
            for j, row in enumerate(table_info['sample_data'][:5], 1):
                print(f"    Row {j}: {row[:5]}")
    
    # Look for links to specific census data files
    print("\n--- EXAMINING LINKS TO CENSUS DATA FILES ---")
    
    all_links = soup.find_all('a', href=True)
    census_data_links = []
    
    for link in all_links:
        link_href = link.get('href', '')
        link_text = link.get_text().strip()
        
        # Look for links that might contain 2011 census education data
        is_census_2011 = '2011' in link_text.lower() or '2011' in link_href.lower()
        is_education = any(term in link_text.lower() for term in ['education', 'tertiary', 'university', 'degree', 'graduate'])
        is_data_file = any(ext in link_href.lower() for ext in ['.pdf', '.xls', '.xlsx', '.csv'])
        
        if (is_census_2011 and is_education) or (is_education and is_data_file):
            # Construct full URL
            if link_href.startswith('http'):
                full_url = link_href
            elif link_href.startswith('/'):
                full_url = f"https://www.nsi.bg{link_href}"
            else:
                full_url = f"https://www.nsi.bg/en/{link_href}"
            
            census_data_links.append({
                'text': link_text,
                'href': link_href,
                'full_url': full_url,
                'is_census_2011': is_census_2011,
                'is_education': is_education,
                'is_data_file': is_data_file
            })
    
    if census_data_links:
        print(f"\nFound {len(census_data_links)} relevant census data links:")
        for i, link in enumerate(census_data_links[:10], 1):  # Show first 10
            print(f"  {i}. '{link['text']}'")
            print(f"     URL: {link['full_url']}")
            print(f"     Census 2011: {link['is_census_2011']}, Education: {link['is_education']}, Data file: {link['is_data_file']}")
    
    # Search for specific census results sections
    print("\n--- SEARCHING FOR CENSUS RESULTS SECTIONS ---")
    
    # Look for headings or sections that might contain census results
    headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
    relevant_headings = []
    
    for heading in headings:
        heading_text = heading.get_text().strip().lower()
        if any(term in heading_text for term in ['education', 'tertiary', 'census', '2011', 'graduate', 'degree']):
            relevant_headings.append({
                'tag': heading.name,
                'text': heading.get_text().strip(),
                'following_content': heading.find_next_sibling().get_text()[:200] if heading.find_next_sibling() else 'No following content'
            })
    
    if relevant_headings:
        print(f"\nFound {len(relevant_headings)} relevant headings:")
        for i, heading in enumerate(relevant_headings[:5], 1):
            print(f"  {i}. {heading['tag'].upper()}: {heading['text']}")
            print(f"     Following content: {heading['following_content']}...")
    
    # Search for specific 2011 census education statistics
    print("\n--- SEARCHING FOR 2011 CENSUS EDUCATION STATISTICS ---")
    
    # Look for patterns that specifically mention 2011 census and education
    census_2011_patterns = [
        r'2011.*?census.*?(?:tertiary|higher education|university|degree).*?(?:male|female|men|women).*?\d+[,.]?\d*',
        r'(?:tertiary|higher education|university|degree).*?2011.*?(?:male|female|men|women).*?\d+[,.]?\d*',
        r'census.*?2011.*?education.*?(?:male|female|men|women).*?\d+[,.]?\d*',
        r'population.*?2011.*?education.*?(?:male|female|men|women).*?\d+[,.]?\d*'
    ]
    
    census_statistics = []
    
    for pattern in census_2011_patterns:
        matches = re.findall(pattern, content_text, re.IGNORECASE | re.DOTALL)
        for match in matches:
            clean_match = re.sub(r'\s+', ' ', match.strip())
            if len(clean_match) > 30 and len(clean_match) < 1000:
                census_statistics.append(clean_match)
    
    if census_statistics:
        print(f"\nFound {len(census_statistics)} potential 2011 census education statistics:")
        for i, stat in enumerate(census_statistics[:5], 1):
            print(f"  {i}. {stat[:300]}...")
    else:
        print("\nNo specific 2011 census education statistics found in direct text patterns.")
    
    # Save detailed extraction results
    extraction_results = {
        'objective': '2011 Bulgarian Census - Tertiary Education by Gender Extraction',
        'source_file': highest_priority_file,
        'file_size': len(html_content),
        'extraction_timestamp': __import__('time').strftime('%Y-%m-%d %H:%M:%S'),
        'found_statistics': found_statistics,
        'relevant_tables': relevant_tables,
        'census_data_links': census_data_links,
        'relevant_headings': relevant_headings,
        'census_2011_statistics': census_statistics,
        'summary': {
            'direct_statistics_found': len(found_statistics),
            'relevant_tables_found': len(relevant_tables),
            'census_data_links_found': len(census_data_links),
            'relevant_headings_found': len(relevant_headings),
            'census_2011_statistics_found': len(census_statistics)
        },
        'recommendations': [
            'Access census data links for downloadable files with detailed statistics',
            'Parse relevant tables for structured data',
            'Follow links to official census results pages',
            'Search for specific NSI publications on 2011 census education results'
        ]
    }
    
    extraction_file = os.path.join(workspace_dir, 'nsi_2011_census_tertiary_education_extraction.json')
    with open(extraction_file, 'w', encoding='utf-8') as f:
        json.dump(extraction_results, f, indent=2, ensure_ascii=False)
    
    print(f"\n=== EXTRACTION RESULTS SUMMARY ===\n")
    print(f"Extraction results saved to: {extraction_file}")
    print(f"Direct statistics found: {len(found_statistics)}")
    print(f"Relevant tables found: {len(relevant_tables)}")
    print(f"Census data links found: {len(census_data_links)}")
    print(f"Relevant headings found: {len(relevant_headings)}")
    print(f"Census 2011 statistics found: {len(census_statistics)}")
    
    if census_data_links:
        print(f"\n=== HIGHEST PRIORITY NEXT STEPS ===\n")
        print("Most promising census data links for accessing 2011 tertiary education statistics:")
        
        # Prioritize links that are both census 2011 and education related
        priority_links = [link for link in census_data_links if link['is_census_2011'] and link['is_education']]
        if not priority_links:
            priority_links = [link for link in census_data_links if link['is_education']]
        
        for i, link in enumerate(priority_links[:5], 1):
            print(f"\n{i}. '{link['text']}'")
            print(f"   URL: {link['full_url']}")
            print(f"   Type: {'Data file' if link['is_data_file'] else 'Web page'}")
            if link['is_data_file']:
                print(f"   *** DOWNLOADABLE DATA FILE - HIGHEST PRIORITY ***")
    
    if relevant_tables:
        print(f"\n=== TABLE ANALYSIS RECOMMENDATIONS ===\n")
        print("Tables most likely to contain tertiary education by gender data:")
        for table_info in relevant_tables:
            if table_info['has_tertiary'] and table_info['has_gender']:
                print(f"\n- Table {table_info['table_index']} (HIGHEST PRIORITY)")
                print(f"  Contains both tertiary education and gender information")
                print(f"  {table_info['rows_count']} rows of data")
            elif table_info['has_tertiary']:
                print(f"\n- Table {table_info['table_index']} (HIGH PRIORITY)")
                print(f"  Contains tertiary education information")
                print(f"  {table_info['rows_count']} rows of data")
    
    print(f"\nReady to access specific census data files or parse detailed tables for exact tertiary education completion statistics by gender from the 2011 Bulgarian census.")
    
else:
    print(f"\nHighest priority file {highest_priority_file} not found in workspace.")
    print("Cannot proceed with detailed extraction.")
```