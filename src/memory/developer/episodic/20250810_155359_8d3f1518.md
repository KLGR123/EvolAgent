### Development Step 4: Surrey Lodge South London: Victorian Origins, Temperance Hall, 1935 Rotating Stage, WWII Damage, Burnley Move

**Description**: Conduct a comprehensive web search to identify Surrey Lodge in South London and trace its historical development during the Victorian era. Focus on finding information about: (1) the original organization that developed Surrey Lodge, (2) its transformation into a temperance hall, (3) the installation of the UK's first rotating stage in 1935, (4) World War II bomb damage, and (5) the company's relocation to Burnley. Use search terms like 'Surrey Lodge South London Victorian era temperance hall', 'first rotating stage UK 1935 temperance hall', 'Surrey Lodge bomb damage World War II Burnley', and 'Victorian temperance organization Surrey Lodge founder'.

**Use Cases**:
- Archival digitization quality control for heritage organizations, automatically scanning downloaded Surrey Lodge HTML pages to verify Victorian-era origins and temperance hall transformations before adding to digital collections
- Museum exhibition content curation pipeline that extracts and cross-checks key events (first UK rotating stage 1935, WWII bomb damage, Burnley relocation) from online archives to ensure exhibit narratives are historically accurate
- Academic research assistant tool for historians, automating web searches and text extraction to gather and validate primary-source details on Surrey Lodge‚Äôs founding organization and its role in the temperance movement
- Urban redevelopment impact assessment workflow that compiles evidence of WWII bomb damage and post-war relocation from multiple HTML sources to inform planning applications and conservation reports
- Genealogical timeline builder for family historians, pulling founder and organizational data about Surrey Lodge from web archives and mapping key changes (temperance hall conversion, stage installation) onto individual family stories
- Tourism app content enrichment service, dynamically fetching and verifying obscure historical facts (e.g., 1935 rotating stage, Burnley move) to generate engaging audio-guide scripts for South London walking tours
- Legal heritage due diligence automation, scanning online documents to confirm past structural damage, original ownership, and relocation history for building listing and conservation planning briefs
- Educational VR asset generator, extracting and validating architectural and historical details of Surrey Lodge‚Äôs Victorian design, temperance hall phase, and wartime events to build accurate immersive learning environments

```
import os
import json
from bs4 import BeautifulSoup
import re
from collections import Counter

print('=== SURREY LODGE ANALYSIS - DEBUGGING VARIABLE SCOPE ISSUE ===')
print('Implementing proper variable scope and debugging HTML content extraction\n')

# Ensure workspace directory exists
os.makedirs('workspace', exist_ok=True)

# Find HTML files
html_files = [f for f in os.listdir('workspace') if f.startswith('surrey_lodge_search_') and f.endswith('.html')]
print(f'Found {len(html_files)} Surrey Lodge HTML files')

if not html_files:
    print('‚ùå No HTML files found')
    exit()

# Initialize results
analysis_results = {
    'timestamp': '2024-12-19',
    'files_analyzed': [],
    'successful_analyses': 0,
    'evidence_found': {},
    'debug_info': []
}

# Define search terms
key_terms = {
    'surrey lodge': 10,
    'south london': 8,
    'temperance': 8,
    'temperance hall': 10,
    'victorian': 6,
    'rotating stage': 10,
    '1935': 8,
    'first rotating stage': 12,
    'bomb damage': 8,
    'world war': 6,
    'wwii': 6,
    'burnley': 8,
    'relocation': 6,
    'theatre': 5,
    'organization': 5,
    'founder': 6
}

print('\n=== PROCESSING FILES WITH DEBUGGING ===') 
print('=' * 60)

# Process each file with proper scope management
for i, filename in enumerate(html_files, 1):
    print(f'\n--- Processing {i}/{len(html_files)}: {filename} ---')
    
    # Initialize file results
    file_result = {
        'filename': filename,
        'status': 'starting',
        'file_size': 0,
        'text_extracted': 0,
        'relevance_score': 0,
        'found_terms': [],
        'historical_indicators': [],
        'debug_notes': []
    }
    
    try:
        # Step 1: Read file
        filepath = os.path.join('workspace', filename)
        print(f'Reading file: {filepath}')
        
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            html_content = f.read()
        
        file_result['file_size'] = len(html_content)
        print(f'File size: {len(html_content):,} characters')
        file_result['debug_notes'].append(f'File read successfully: {len(html_content)} chars')
        
        # Step 2: Parse HTML
        print('Parsing HTML with BeautifulSoup...')
        soup = BeautifulSoup(html_content, 'html.parser')
        file_result['debug_notes'].append('HTML parsed successfully')
        
        # Step 3: Extract text - CRITICAL: Define in proper scope
        print('Extracting text content...')
        raw_text = soup.get_text()
        print(f'Raw text extracted: {len(raw_text)} characters')
        
        # FIXED: Define page_text in the same scope where it will be used
        page_text = raw_text.lower()
        print(f'Converted to lowercase: {len(page_text)} characters')
        
        file_result['text_extracted'] = len(page_text)
        file_result['debug_notes'].append(f'Text extracted and converted: {len(page_text)} chars')
        
        # Debug: Show first 200 characters of extracted text
        print(f'First 200 chars: {page_text[:200]}...')
        
        # Step 4: Analyze terms - page_text is now properly defined
        print('Analyzing terms...')
        found_terms = []
        relevance_score = 0
        
        for term, weight in key_terms.items():
            if term in page_text:  # page_text is defined in this scope
                found_terms.append(term)
                relevance_score += weight
                print(f'  ‚úì Found: {term} (weight: {weight})')
        
        file_result['found_terms'] = found_terms
        file_result['relevance_score'] = relevance_score
        print(f'Total relevance score: {relevance_score}')
        
        # Step 5: Extract historical indicators
        print('Checking historical indicators...')
        historical_indicators = []
        
        if 'surrey lodge' in page_text:
            historical_indicators.append('Surrey Lodge confirmed')
            print('üéØ Surrey Lodge confirmed!')
        
        if 'temperance hall' in page_text:
            historical_indicators.append('Temperance hall found')
            print('üèõÔ∏è Temperance hall found!')
        elif 'temperance' in page_text and 'hall' in page_text:
            historical_indicators.append('Temperance and hall terms found')
            print('üèõÔ∏è Temperance and hall terms found!')
        
        if 'rotating stage' in page_text:
            historical_indicators.append('Rotating stage found')
            print('üé≠ Rotating stage found!')
            
            if '1935' in page_text:
                historical_indicators.append('1935 date confirmed')
                print('üìÖ 1935 date confirmed!')
        
        if any(term in page_text for term in ['bomb damage', 'bombed', 'war damage', 'blitz']):
            historical_indicators.append('WWII damage reference')
            print('üí• WWII damage reference found!')
        
        if 'burnley' in page_text:
            historical_indicators.append('Burnley connection')
            print('üè≠ Burnley connection found!')
        
        file_result['historical_indicators'] = historical_indicators
        file_result['status'] = 'completed'
        analysis_results['successful_analyses'] += 1
        
        print(f'‚úÖ Analysis completed - Score: {relevance_score}, Indicators: {len(historical_indicators)}')
        
    except Exception as e:
        error_msg = str(e)
        print(f'‚ùå Error: {error_msg}')
        file_result['status'] = 'error'
        file_result['error'] = error_msg
        file_result['debug_notes'].append(f'Error occurred: {error_msg}')
    
    # Store results
    analysis_results['files_analyzed'].append(file_result)

print('\n=== ANALYSIS SUMMARY ===') 
print('=' * 50)

successful_files = [f for f in analysis_results['files_analyzed'] if f['status'] == 'completed']
error_files = [f for f in analysis_results['files_analyzed'] if f['status'] == 'error']

print(f'Successfully analyzed: {len(successful_files)} files')
print(f'Errors encountered: {len(error_files)} files')

if successful_files:
    # Sort by relevance
    successful_files.sort(key=lambda x: x['relevance_score'], reverse=True)
    
    print('\nüìä TOP RESULTS BY RELEVANCE:')
    for i, file_data in enumerate(successful_files[:5], 1):
        print(f'\n{i}. {file_data["filename"]}:')
        print(f'   Score: {file_data["relevance_score"]}')
        print(f'   Terms found: {", ".join(file_data["found_terms"][:6])}')
        print(f'   Historical indicators: {", ".join(file_data["historical_indicators"])}')
    
    # Compile all evidence
    all_indicators = []
    for file_data in successful_files:
        all_indicators.extend(file_data['historical_indicators'])
    
    indicator_counts = Counter(all_indicators)
    
    print('\nüìà EVIDENCE FREQUENCY:')
    for indicator, count in indicator_counts.most_common():
        print(f'  ‚Ä¢ {indicator}: {count} files')
    
    # Focus area analysis
    focus_areas = {
        'Surrey Lodge identified': 'Surrey Lodge confirmed' in all_indicators,
        'Temperance hall connection': any('Temperance' in ind for ind in all_indicators),
        'Rotating stage found': 'Rotating stage found' in all_indicators,
        '1935 date confirmed': '1935 date confirmed' in all_indicators,
        'WWII damage reference': 'WWII damage reference' in all_indicators,
        'Burnley connection': 'Burnley connection' in all_indicators
    }
    
    analysis_results['evidence_found'] = focus_areas
    
    print('\nüîç FOCUS AREA RESULTS:')
    for area, found in focus_areas.items():
        status = '‚úÖ' if found else '‚ùå'
        print(f'{status} {area}: {found}')
    
    # Calculate success rate
    confirmed_areas = sum(focus_areas.values())
    success_rate = (confirmed_areas / len(focus_areas)) * 100
    print(f'\nüìà Evidence success rate: {success_rate:.1f}% ({confirmed_areas}/{len(focus_areas)} areas)')
    analysis_results['success_rate'] = success_rate

else:
    print('‚ùå No files successfully analyzed')

if error_files:
    print('\n‚ùå FILES WITH ERRORS:')
    for file_data in error_files:
        print(f'  ‚Ä¢ {file_data["filename"]}: {file_data.get("error", "Unknown error")}')
        if file_data.get('debug_notes'):
            print(f'    Debug: {"; ".join(file_data["debug_notes"])}')

# Save results
results_file = os.path.join('workspace', 'surrey_lodge_debug_analysis.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(analysis_results, f, indent=2, ensure_ascii=False)

print(f'\nüíæ Results saved to: {results_file}')

# Create summary report
summary_content = f'''SURREY LODGE HISTORICAL ANALYSIS - DEBUG VERSION
Generated: {analysis_results["timestamp"]}

PROCESSING RESULTS:
‚Ä¢ Total files: {len(analysis_results["files_analyzed"])}
‚Ä¢ Successfully analyzed: {len(successful_files)}
‚Ä¢ Errors encountered: {len(error_files)}
'''

if analysis_results.get('success_rate'):
    summary_content += f'‚Ä¢ Evidence success rate: {analysis_results["success_rate"]:.1f}%\n'

summary_content += '\nFOCUS AREA FINDINGS:\n'
if analysis_results.get('evidence_found'):
    for area, found in analysis_results['evidence_found'].items():
        status = 'FOUND' if found else 'NOT FOUND'
        summary_content += f'‚Ä¢ {area}: {status}\n'

summary_content += '\nTOP PERFORMING FILES:\n'
for i, file_data in enumerate(successful_files[:3], 1):
    summary_content += f'{i}. {file_data["filename"]} (Score: {file_data["relevance_score"]})\n'
    if file_data['historical_indicators']:
        summary_content += f'   Evidence: {", ".join(file_data["historical_indicators"])}\n'

summary_content += '\nFILES GENERATED:\n'
summary_content += '‚Ä¢ surrey_lodge_debug_analysis.json - Complete analysis data\n'
summary_content += '‚Ä¢ surrey_lodge_debug_summary.txt - This summary report\n'

summary_file = os.path.join('workspace', 'surrey_lodge_debug_summary.txt')
with open(summary_file, 'w', encoding='utf-8') as f:
    f.write(summary_content)

print(f'üìã Summary saved to: {summary_file}')

print('\n' + '=' * 80)
print('SURREY LODGE ANALYSIS - DEBUG VERSION COMPLETE')
print('=' * 80)

if len(successful_files) >= 8:
    print('‚úÖ SUCCESS - Most files analyzed successfully')
elif len(successful_files) >= 5:
    print('‚ö†Ô∏è PARTIAL SUCCESS - Some files analyzed')
else:
    print('‚ùå LIMITED SUCCESS - Few files analyzed')

print('\nüìä FINAL STATISTICS:')
print(f'   ‚Ä¢ Files processed: {len(analysis_results["files_analyzed"])}')
print(f'   ‚Ä¢ Successful analyses: {analysis_results["successful_analyses"]}')
print(f'   ‚Ä¢ Files with errors: {len(error_files)}')

if analysis_results.get('evidence_found'):
    confirmed = [area for area, found in analysis_results['evidence_found'].items() if found]
    if confirmed:
        print('\nüéØ EVIDENCE CONFIRMED:')
        for area in confirmed:
            print(f'   ‚úÖ {area}')

print('\n=== SURREY LODGE DEBUG ANALYSIS COMPLETE ===')
```