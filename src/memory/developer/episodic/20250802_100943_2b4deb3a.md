### Development Step 2: Compile US Presidents’ Birthplaces and Geographic Coordinates into JSON

**Description**: Collect a complete list of all United States presidents with their official birth city names and state names, then obtain the geographic coordinates (longitude and latitude) for each birth city using authoritative sources such as official presidential biographies or Wikipedia infoboxes. Save the results in a structured format (e.g., CSV or JSON) at workspace/presidential_birthplaces.json.

**Use Cases**:
- Interactive map visualization for online civics courses enabling students to explore each president’s birthplace with geospatial context
- Academic research project analyzing regional patterns in presidential birthplaces to study political influence and demographic shifts
- Historical tour itinerary planner for travel agencies designing guided trips to presidential birth cities and nearby heritage sites
- Data journalism dashboard plotting birth city coordinates over time to reveal geographic trends in U.S. political leadership
- Museum exhibit kiosk integration that displays augmented reality overlays of U.S. presidents’ birth homes using geocoded location data
- Mobile trivia app backend leveraging precise birthplace coordinates to generate location-based presidential history challenges
- Political science dataset for demographic analysis of electoral trends based on presidents’ birth cities and regional socioeconomic data

```
import os
import requests
from bs4 import BeautifulSoup

# Ensure workspace directory exists
workspace_dir = 'workspace'
os.makedirs(workspace_dir, exist_ok=True)

# Step 1: Correct URL for list of US presidents
url = 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States'
print(f"Fetching Wikipedia page: {url}")

# Fetch the page content and verify status
response = requests.get(url)
print(f"HTTP response status code: {response.status_code}")
response.raise_for_status()
html_content = response.text

# Save raw HTML for inspection
html_path = os.path.join(workspace_dir, 'presidents_list.html')
with open(html_path, 'w', encoding='utf-8') as f:
    f.write(html_content)
print(f"Saved raw HTML to {html_path}")

# Parse the HTML to inspect table structure
soup = BeautifulSoup(html_content, 'html.parser')
# Find all tables with class 'wikitable'
tables = soup.find_all('table', class_='wikitable')
print(f"Found {len(tables)} tables with class 'wikitable'")

# Inspect first table(s)
inspect_count = min(2, len(tables))
for idx in range(inspect_count):
    table = tables[idx]
    print('=' * 60)
    print(f"Table {idx+1} inspection:")
    # Print header row
    header = table.find('tr')
    if header:
        headers = [th.get_text(strip=True) for th in header.find_all(['th', 'td'])]
        print(f"Header columns ({len(headers)}): {headers}")
    # Count data rows
    rows = table.find_all('tr')[1:]
    print(f"Number of data rows: {len(rows)}")
    # Print first 5 rows content
    print(f"First {min(5, len(rows))} rows:")
    for i, row in enumerate(rows[:5], start=1):
        cells = [cell.get_text(strip=True) for cell in row.find_all(['th','td'])]
        print(f" Row {i}: {cells}")
print("Inspection complete. Use the above structure to plan full parsing of presidents and birthplaces.")
```