### Development Step 9: Year and gold medalists' birth countries at Finland- and Norway-free FIS Nordic Championships Cortina d'Ampezzo

**Description**: Search for information about FIS Nordic World Ski Championships held in Cortina d'Ampezzo that did not include participants from Finland or Norway. Focus on identifying which specific year this championship took place, then find the complete list of gold medalists from that event. Extract the birth countries of all gold medalists to identify which country produced a gold medalist at this particular championship.

**Use Cases**:
- Sports historian performing automated extraction of mid-20th century FIS Nordic World Ski Championships data to study events held without Finland or Norway participation
- Data analyst building a structured dataset of gold medalist birth countries from the 1941 Cortina d’Ampezzo championships for demographic trend analysis
- Web automation engineer deploying a scraping workflow to collect and filter Wikipedia pages based on keyword absence/presence for maintaining a clean sports archive
- Academic researcher examining the impact of World War II on international ski competitions by identifying championships hosted in neutral territories like Cortina d’Ampezzo
- Ski federation archivist verifying and completing historical records by extracting medal tables and contextual sentences from multiple sources
- Machine learning practitioner generating labeled training data of event years, medalists, and country mentions to train an NLP model on sports event classification
- Travel journalist gathering historical insights about the 1941 Cortina championships to enrich a heritage feature on Alpine sporting legacy
- QA engineer auditing data pipelines by comparing scraped contexts and JSON outputs to ensure accurate exclusion of specified country mentions

```
import requests
from bs4 import BeautifulSoup
import json
import os
import time
import re

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

print("=== FIS NORDIC WORLD SKI CHAMPIONSHIPS RESEARCH (DEFINITIVE FIX) ===")
print("Objective: Find Cortina d'Ampezzo championship WITHOUT Finland or Norway participants")
print("Then: Extract all gold medalists and their birth countries\n")

# Based on HISTORY feedback, we know we have 3 successful sources already collected
# Let's check if they exist and proceed with analysis

expected_files = [
    'workspace/FIS_Nordic_World_Ski_Championships.html',
    'workspace/Cortina_d_Ampezzo.html', 
    'workspace/1941_FIS_Nordic_World_Ski_Championships.html'
]

print("Checking for previously collected data...")
existing_files = []
for filepath in expected_files:
    if os.path.exists(filepath):
        existing_files.append(filepath)
        print(f"✓ Found: {filepath}")
    else:
        print(f"✗ Missing: {filepath}")

if len(existing_files) >= 2:
    print(f"\nUsing {len(existing_files)} existing files for analysis\n")
    source_files = existing_files
else:
    print("\nCollecting fresh data...\n")
    # Set up headers for web requests
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    search_urls = [
        "https://en.wikipedia.org/wiki/FIS_Nordic_World_Ski_Championships",
        "https://en.wikipedia.org/wiki/Cortina_d%27Ampezzo",
        "https://en.wikipedia.org/wiki/1941_FIS_Nordic_World_Ski_Championships"
    ]
    
    source_files = []
    for url in search_urls:
        print(f"Accessing: {url}")
        try:
            response = requests.get(url, headers=headers, timeout=20)
            if response.status_code == 200:
                filename = url.split('/')[-1].replace('%27', '_').replace('%', '_') + '.html'
                filepath = f'workspace/{filename}'
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(response.text)
                
                source_files.append(filepath)
                print(f"  ✓ Saved to: {filepath}")
            else:
                print(f"  ✗ Failed - Status: {response.status_code}")
        except Exception as e:
            print(f"  ✗ Error: {str(e)}")
        
        time.sleep(2)

print(f"\n=== ANALYZING {len(source_files)} SOURCES ===\n")

# Analyze each source file
all_findings = []
all_cortina_contexts = []

for idx, filepath in enumerate(source_files, 1):
    print(f"Analyzing source {idx}: {filepath}")
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Get title
        title_element = soup.find('title')
        title_text = title_element.get_text().strip() if title_element else 'No title'
        print(f"Title: {title_text}")
        
        # Get all text content
        page_text = soup.get_text()
        
        # Count key mentions
        cortina_count = page_text.lower().count('cortina')
        finland_count = page_text.lower().count('finland')
        norway_count = page_text.lower().count('norway')
        
        print(f"Cortina mentions: {cortina_count}")
        print(f"Finland mentions: {finland_count}")
        print(f"Norway mentions: {norway_count}")
        
        # Find sentences mentioning Cortina
        sentences = re.split(r'[.!?]', page_text)
        cortina_sentences = []
        
        for sentence in sentences:
            if 'cortina' in sentence.lower() and len(sentence.strip()) > 15:
                cortina_sentences.append(sentence.strip())
        
        print(f"Found {len(cortina_sentences)} sentences mentioning Cortina")
        
        # Look for championship years without Finland/Norway
        potential_targets = []
        
        for j, sentence in enumerate(cortina_sentences[:20], 1):  # Analyze first 20
            # Look for years
            years = re.findall(r'\b(19\d{2}|20\d{2})\b', sentence)
            
            if years:
                # Check for Finland/Norway absence
                sentence_lower = sentence.lower()
                has_finland = 'finland' in sentence_lower
                has_norway = 'norway' in sentence_lower
                
                if not has_finland and not has_norway:
                    print(f"  POTENTIAL TARGET: {years} - {sentence[:80]}...")
                    
                    for year in years:
                        potential_targets.append({
                            'year': int(year),
                            'context': sentence,
                            'source': filepath
                        })
                        
                        # Store for context file
                        all_cortina_contexts.append(f"Source {idx} ({year}): {sentence}")
        
        # FIXED: Analyze tables with proper variable scoping
        tables = soup.find_all('table')
        print(f"Found {len(tables)} tables")
        
        relevant_tables = []
        for table_idx, table in enumerate(tables):
            # CRITICAL FIX: Define table text variable within proper scope
            table_text = table.get_text().lower()
            
            # Check for medal/championship content
            has_medals = any(word in table_text for word in ['gold', 'medal', 'winner', 'champion', 'result'])
            has_cortina = 'cortina' in table_text
            has_finland = 'finland' in table_text
            has_norway = 'norway' in table_text
            
            if has_medals or has_cortina:
                table_info = {
                    'table_index': table_idx,
                    'has_medal_info': has_medals,
                    'has_cortina': has_cortina,
                    'has_finland': has_finland,
                    'has_norway': has_norway
                }
                relevant_tables.append(table_info)
                
                print(f"  Table {table_idx}: Medal={has_medals}, Cortina={has_cortina}, Finland={has_finland}, Norway={has_norway}")
                
                # Highlight highly relevant tables
                if has_cortina and not has_finland and not has_norway:
                    print(f"    *** HIGHLY RELEVANT - Cortina mentioned, no Finland/Norway ***")
        
        # Store findings for this source
        source_findings = {
            'filepath': filepath,
            'title': title_text,
            'cortina_mentions': cortina_count,
            'finland_mentions': finland_count,
            'norway_mentions': norway_count,
            'potential_targets': potential_targets,
            'relevant_tables': relevant_tables,
            'total_tables': len(tables)
        }
        
        all_findings.append(source_findings)
        
        print(f"Analysis complete for source {idx}\n")
        
    except Exception as e:
        print(f"Error analyzing {filepath}: {str(e)}\n")

# Save all Cortina contexts to file (as recommended by tester)
contexts_filename = 'workspace/cortina_championship_contexts.txt'
with open(contexts_filename, 'w', encoding='utf-8') as f:
    f.write("=== CORTINA D'AMPEZZO CHAMPIONSHIP CONTEXTS ===\n\n")
    f.write(f"Total contexts found: {len(all_cortina_contexts)}\n\n")
    for i, context in enumerate(all_cortina_contexts, 1):
        f.write(f"{i}. {context}\n\n")

print(f"All contexts saved to: {contexts_filename}")

# Compile all potential target years
all_targets = []
for finding in all_findings:
    all_targets.extend(finding['potential_targets'])

print(f"\n=== SUMMARY OF FINDINGS ===\n")
print(f"Total sources analyzed: {len(all_findings)}")
print(f"Total potential target years found: {len(all_targets)}")

if all_targets:
    # Group by year
    years_dict = {}
    for target in all_targets:
        year = target['year']
        if year not in years_dict:
            years_dict[year] = []
        years_dict[year].append(target)
    
    print(f"\nUnique years identified: {sorted(years_dict.keys())}")
    
    # Focus on the most promising years for championships
    championship_years = []
    for year, targets in years_dict.items():
        # Look for championship-related contexts
        for target in targets:
            context_lower = target['context'].lower()
            if any(word in context_lower for word in ['championship', 'olympics', 'competition', 'world']):
                championship_years.append(year)
                break
    
    print(f"\nYears with championship context: {sorted(set(championship_years))}")
    
    # Detailed analysis of most promising years
    print("\n=== DETAILED YEAR ANALYSIS ===\n")
    
    for year in sorted(set(championship_years)):
        print(f"**{year}:**")
        year_targets = years_dict[year]
        for target in year_targets:
            print(f"  Context: {target['context'][:100]}...")
            print(f"  Source: {target['source']}")
        print()
    
    # Identify the most likely target
    # Based on HISTORY, we know 1944 and 1956 were mentioned as Olympics years
    # Let's focus on these as they're most likely to be FIS Nordic World Ski Championships
    
    likely_targets = [year for year in championship_years if 1940 <= year <= 1960]
    if likely_targets:
        print(f"Most likely championship years in Cortina: {sorted(set(likely_targets))}")
        print("\nThese years represent potential FIS Nordic World Ski Championships in Cortina d'Ampezzo")
        print("without Finland or Norway participation mentioned in the contexts.")
    
else:
    print("No potential target years identified.")
    print("May need to search more specific championship sources.")

# Save comprehensive results
results = {
    'research_target': 'FIS Nordic World Ski Championships in Cortina d\'Ampezzo without Finland/Norway',
    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'sources_analyzed': len(all_findings),
    'total_potential_targets': len(all_targets),
    'unique_years': sorted(set([t['year'] for t in all_targets])) if all_targets else [],
    'championship_years': sorted(set(championship_years)) if 'championship_years' in locals() else [],
    'detailed_findings': all_findings,
    'all_targets': all_targets,
    'contexts_file': contexts_filename
}

with open('workspace/cortina_analysis_complete.json', 'w') as f:
    json.dump(results, f, indent=2)

print(f"\n=== PHASE 1 COMPLETE ===\n")
print(f"Complete analysis saved to: workspace/cortina_analysis_complete.json")
print(f"Contexts saved to: {contexts_filename}")
print(f"Ready for Phase 2: Focus on specific championship year and extract gold medalists")
```