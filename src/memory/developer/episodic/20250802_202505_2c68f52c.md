### Development Step 15: Search 2011 Bulgarian Census Data on Tertiary Education Completion by Gender

**Description**: Search for the 2011 Bulgarian census data on tertiary education completion by gender. Look for official census results from Bulgaria's National Statistical Institute or other authoritative sources that provide the specific breakdown of men and women who completed tertiary education in 2011.

**Use Cases**:
- Public policy think tank evaluating EU Cohesion funding proposals for Bulgaria’s tertiary education gender gap analysis
- National Statistical Institute’s automated pipeline validating scraped 2011 census tertiary education figures by gender for quality assurance dashboards
- University demography research group compiling historical male vs. female higher education attainment trends in the Balkans for comparative academic studies
- Gender equality NGO monitoring progress in Bulgarian women’s access to tertiary education using scraped census data for advocacy campaigns
- Data journalism team extracting and visualizing province-level gender-disaggregated tertiary education rates from Bulgarian census HTML files for an interactive report
- EdTech analytics platform integrating Bulgarian 2011 census gender-based higher education metrics as part of a global educational insights API for scholarship recommendation engines
- Market research agency incorporating scraped tertiary education completion rates by gender into consumer segmentation models to refine product targeting in Sofia’s tech sector
- Educational policymaker’s office automating the extraction of 2011 census tertiary education statistics by gender to inform regional development grant allocations

```
import os
import json
from bs4 import BeautifulSoup
import re
import time

print("=== BULGARIAN 2011 CENSUS TERTIARY EDUCATION - SIMPLE BULLETPROOF APPROACH ===")
print("Strategy: Minimal code with no variable scoping issues\n")

# Check workspace
workspace_path = 'workspace'
if not os.path.exists(workspace_path):
    print("No workspace directory found")
    exit()

all_files = os.listdir(workspace_path)
html_files = [f for f in all_files if f.endswith('.html')]

print(f"Total files: {len(all_files)}")
print(f"HTML files: {len(html_files)}")

# Show all HTML files with sizes to understand what we have
print("\n=== ALL HTML FILES ===\n")
for i, html_file in enumerate(html_files, 1):
    filepath = os.path.join(workspace_path, html_file)
    file_size = os.path.getsize(filepath)
    print(f"{i:2d}. {html_file}")
    print(f"    Size: {file_size:,} bytes")

# Select the most promising files based on names and sizes
promising_files = []
for filename in html_files:
    filepath = os.path.join(workspace_path, filename)
    file_size = os.path.getsize(filepath)
    
    # Skip very small files
    if file_size < 40000:  # Less than 40KB likely error pages
        continue
    
    # Look for key terms in filename
    if any(term in filename.lower() for term in ['demographics', 'education', 'census', 'nsi']):
        promising_files.append(filename)

print(f"\nPromising files to analyze: {len(promising_files)}")
for pf in promising_files:
    print(f"  - {pf}")

print("\n=== ANALYZING FILES WITH BULLETPROOF APPROACH ===\n")

# Results storage
all_findings = []

# Analyze each promising file with the simplest possible approach
for filename in promising_files[:3]:  # Analyze top 3
    print(f"Analyzing: {filename}")
    
    filepath = os.path.join(workspace_path, filename)
    
    try:
        # Read and parse HTML
        with open(filepath, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        page_title = soup.find('title')
        title_text = page_title.get_text().strip() if page_title else 'No title'
        
        # Get all text - NO VARIABLES, direct usage
        all_text = soup.get_text()
        
        print(f"  Title: {title_text}")
        print(f"  Content length: {len(all_text):,} characters")
        
        # Check relevance using direct string operations
        has_bulgaria = 'bulgaria' in all_text.lower() or 'bulgarian' in all_text.lower()
        has_2011 = '2011' in all_text.lower()
        has_census = 'census' in all_text.lower()
        has_tertiary = 'tertiary' in all_text.lower() or 'higher education' in all_text.lower()
        has_gender = any(term in all_text.lower() for term in ['men', 'women', 'male', 'female'])
        has_education = 'education' in all_text.lower()
        
        relevance = sum([has_bulgaria, has_2011, has_census, has_tertiary, has_gender, has_education])
        
        print(f"  Bulgaria: {has_bulgaria} | 2011: {has_2011} | Census: {has_census}")
        print(f"  Tertiary: {has_tertiary} | Gender: {has_gender} | Education: {has_education}")
        print(f"  Relevance: {relevance}/6")
        
        if relevance >= 3:
            print("  *** EXTRACTING DATA ***")
            
            # Look for sentences with key terms and numbers
            sentences = all_text.split('.')
            good_sentences = []
            
            for sentence in sentences:
                if len(sentence.strip()) < 30:
                    continue
                    
                s_lower = sentence.lower()
                
                # Check for Bulgaria + education + numbers + gender/year
                if (('bulgaria' in s_lower or 'bulgarian' in s_lower) and 
                    ('education' in s_lower or 'tertiary' in s_lower or 'university' in s_lower) and
                    re.search(r'\d+', sentence) and
                    ('2011' in s_lower or 'men' in s_lower or 'women' in s_lower or 'male' in s_lower or 'female' in s_lower)):
                    
                    good_sentences.append(sentence.strip())
            
            print(f"  Good sentences found: {len(good_sentences)}")
            
            # Look for statistical patterns
            stat_patterns = [
                r'tertiary education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'(?:men|women|male|female)[^.]*?tertiary education[^.]*?(\d+[.,]?\d*\s*%?)',
                r'higher education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'2011[^.]*?education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)'
            ]
            
            stat_matches = []
            for pattern in stat_patterns:
                matches = re.finditer(pattern, all_text, re.IGNORECASE)
                for match in matches:
                    context_start = max(0, match.start() - 200)
                    context_end = min(len(all_text), match.end() + 200)
                    context = all_text[context_start:context_end]
                    
                    if 'bulgaria' in context.lower():
                        stat_matches.append({
                            'match': match.group(),
                            'context': context,
                            'file': filename
                        })
            
            print(f"  Statistical matches: {len(stat_matches)}")
            
            # Store findings
            file_findings = {
                'filename': filename,
                'title': title_text,
                'relevance_score': relevance,
                'good_sentences': good_sentences[:5],  # Top 5
                'statistical_matches': stat_matches[:3],  # Top 3
                'indicators': {
                    'bulgaria': has_bulgaria,
                    '2011': has_2011,
                    'census': has_census,
                    'tertiary': has_tertiary,
                    'gender': has_gender,
                    'education': has_education
                }
            }
            
            all_findings.append(file_findings)
            
            # Show key findings
            if good_sentences:
                print(f"  Sample sentence: {good_sentences[0][:200]}...")
            
            if stat_matches:
                print(f"  Sample match: {stat_matches[0]['match']}")
                print(f"  Context: {stat_matches[0]['context'][:150]}...")
        
        else:
            print(f"  Lower relevance - skipping detailed analysis")
        
        print()
        
    except Exception as e:
        print(f"  ERROR: {str(e)}")
        print()

# Save results
print("=== SAVING RESULTS ===\n")

results = {
    'objective': 'Bulgarian 2011 census tertiary education by gender',
    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'html_files_total': len(html_files),
    'promising_files_analyzed': len(promising_files[:3]),
    'files_with_findings': len(all_findings),
    'detailed_findings': all_findings
}

results_file = os.path.join(workspace_path, 'bulgarian_census_bulletproof_analysis.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2, ensure_ascii=False)

print(f"Results saved to: {results_file}")
print(f"Files analyzed: {len(promising_files[:3])}")
print(f"Files with findings: {len(all_findings)}")

# Summary of findings
if all_findings:
    print("\n=== SUMMARY OF FINDINGS ===\n")
    
    total_sentences = sum(len(f['good_sentences']) for f in all_findings)
    total_matches = sum(len(f['statistical_matches']) for f in all_findings)
    
    print(f"Total relevant sentences: {total_sentences}")
    print(f"Total statistical matches: {total_matches}")
    
    print("\nKey findings:")
    for i, finding in enumerate(all_findings, 1):
        print(f"{i}. {finding['filename']} (Relevance: {finding['relevance_score']}/6)")
        print(f"   Title: {finding['title']}")
        print(f"   Sentences: {len(finding['good_sentences'])}, Matches: {len(finding['statistical_matches'])}")
        
        if finding['good_sentences']:
            print(f"   Sample: {finding['good_sentences'][0][:180]}...")
        
        if finding['statistical_matches']:
            print(f"   Stat match: {finding['statistical_matches'][0]['match']}")
        
        print()

else:
    print("\n=== NO FINDINGS ===\n")
    print("No specific tertiary education by gender data found in the analyzed files.")
    print("The data may be in a different format or require more specific sources.")

print("\n=== ANALYSIS COMPLETE ===\n")
print("Bulletproof analysis completed - no variable scoping issues encountered")
```