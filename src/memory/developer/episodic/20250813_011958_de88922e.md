### Development Step 21: Identify Publisher of 1877-78 Four-Volume Edition of Harriet Martineau’s History of England

**Description**: Conduct a targeted verification search specifically for the publisher of Harriet Martineau's 'The History of England During the Thirty Years' Peace: 1816-1846' four-volume edition published in 1877-1878. Search for bibliographic records, library catalogs, antiquarian book listings, and academic references that explicitly identify the publisher of this specific edition. Use search terms including 'Harriet Martineau History England Thirty Years Peace 1877 1878 four volume publisher', 'Martineau 1816-1846 four volumes 1877 publisher', and check sources like WorldCat, British Library catalog, and historical bibliography databases to obtain definitive publisher identification rather than inferential analysis.

**Use Cases**:
- Rare book dealer automating publisher verification for Harriet Martineau’s 1877–1878 four-volume set to ensure accurate listings on AbeBooks and Antiquarian Auctions.
- Special collections librarian integrating targeted WorldCat and British Library catalog searches to update metadata for Martineau’s “History of England” edition in the university archive.
- Digital humanities researcher extracting definitive publisher details for 19th-century peace studies texts to populate a citation database on historical diplomacy.
- Academic reference software developer embedding bibliographic scraping routines that auto-fill publisher fields when scholars import obscure editions like Martineau’s four-volume work.
- Museum exhibit curator compiling an online catalog of Victorian historical publications, using automated searches to confirm the publisher and imprint of each displayed volume.
- Publishing historian conducting a comparative study of mid-19th-century presses, leveraging the script to gather evidence on George Bell & Sons’ output versus rival firms.
- Library systems engineer scheduling nightly checks against external OPACs to flag and correct inferred or missing publisher entries for multi-volume historical works.
- Book conservation specialist documenting provenance chains by extracting publisher and publication data from digital bibliographies for restoration project reports.

```
import os
import requests
from bs4 import BeautifulSoup
import json
import time
from urllib.parse import quote_plus

print('=== TARGETED SEARCH FOR MARTINEAU "HISTORY OF ENGLAND" 1877-1878 PUBLISHER ===')
print('Title: The History of England During the Thirty Years\' Peace: 1816-1846')
print('Author: Harriet Martineau')
print('Edition: Four-volume set')
print('Publication years: 1877-1878')
print('Objective: Identify the specific publisher of this edition')
print('\n' + '='*100 + '\n')

# Ensure workspace directory exists
os.makedirs('workspace', exist_ok=True)

# FIXED: Define ALL variables at the top level before any function definitions
search_base_url = 'https://html.duckduckgo.com/html/'

# Headers for web requests
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1'
}

# Define highly specific search queries for bibliographic verification
bibliographic_queries = [
    '"Harriet Martineau" "History of England During the Thirty Years Peace" 1877 1878 four volume publisher',
    'Martineau "1816-1846" four volumes 1877 publisher bibliographic',
    '"The History of England During the Thirty Years Peace" Martineau 1877 1878 publisher',
    'Harriet Martineau "Thirty Years Peace" 1877 four volume edition publisher',
    'Martineau "History England" 1816-1846 1877-1878 publisher catalog',
    '"History of England During Thirty Years Peace" four volumes 1877 publisher',
    'Harriet Martineau 1877 1878 "History England" publisher bibliographic record',
    'Martineau "Thirty Years Peace" four volume set 1877 publisher',
    '"History England During Thirty Years Peace" Martineau 1877 publisher library',
    'Harriet Martineau 1816-1846 history four volumes 1877 1878 publisher'
]

print('=== STEP 1: CONDUCTING BIBLIOGRAPHIC SEARCHES ===')
print(f'Total targeted queries: {len(bibliographic_queries)}')
print('\nBibliographic search queries:')
for i, query in enumerate(bibliographic_queries, 1):
    print(f'  {i:2d}. {query}')

search_results = {}

# Function to perform targeted bibliographic search
def perform_bibliographic_search(query, search_index):
    """Perform a single bibliographic search and analyze results"""
    print(f'\n--- BIBLIOGRAPHIC SEARCH {search_index}: {query} ---')
    try:
        params = {'q': query}
        response = requests.get(search_base_url, params=params, headers=headers, timeout=30)
        print(f'Status: {response.status_code}')
        
        if response.status_code == 200:
            # Save raw HTML for detailed analysis
            clean_query = query.replace(' ', '_').replace('"', '').replace("'", '')[:50]
            filename = f'martineau_history_search_{search_index:02d}_{clean_query}.html'
            filepath = os.path.join('workspace', filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            print(f'Saved: {filepath}')
            
            # Parse for bibliographic and publisher information
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Look for highly relevant bibliographic results
            bibliographic_findings = []
            for link in soup.find_all('a', href=True):
                href = link.get('href')
                text = link.get_text().strip()
                
                if href and text and len(text) > 20:
                    text_lower = text.lower()
                    relevance_score = 0
                    
                    # High-priority terms for this specific search
                    critical_terms = [
                        ('1877', 5), ('1878', 5),
                        ('martineau', 3), ('harriet martineau', 4),
                        ('history of england', 4), ('thirty years peace', 4),
                        ('1816-1846', 4), ('four volume', 3), ('four volumes', 3),
                        ('publisher', 4), ('published', 3), ('publication', 3),
                        ('bibliographic', 3), ('catalog', 2), ('catalogue', 2),
                        ('library', 2), ('worldcat', 3), ('british library', 4)
                    ]
                    
                    # Known publishers of 19th-century historical works
                    publisher_terms = [
                        ('george bell', 4), ('bell and sons', 4), ('george bell and sons', 5),
                        ('macmillan', 3), ('longman', 3), ('longmans', 3),
                        ('john murray', 4), ('chapman and hall', 4),
                        ('smith elder', 3), ('blackwood', 3),
                        ('cambridge university press', 4), ('oxford university press', 4),
                        ('kegan paul', 3), ('trench', 3), ('trubner', 3)
                    ]
                    
                    # Calculate relevance score
                    for term, score in critical_terms + publisher_terms:
                        if term in text_lower:
                            relevance_score += score
                    
                    # Bonus for bibliographic domains
                    if href:
                        href_lower = href.lower()
                        if any(domain in href_lower for domain in ['worldcat.org', 'bl.uk', 'loc.gov', 'catalog', 'opac']):
                            relevance_score += 5
                        elif any(domain in href_lower for domain in ['amazon.com', 'abebooks.com', 'biblio.com', 'vialibri.net']):
                            relevance_score += 3
                    
                    # Only include highly relevant bibliographic results
                    if relevance_score >= 8:  # Higher threshold for precision
                        bibliographic_findings.append({
                            'url': href,
                            'text': text[:400],  # Extended text for better analysis
                            'relevance_score': relevance_score,
                            'has_1877': '1877' in text_lower,
                            'has_1878': '1878' in text_lower,
                            'has_four_volume': any(term in text_lower for term in ['four volume', 'four volumes', '4 volume', '4 volumes']),
                            'has_publisher_info': any(term in text_lower for term in ['publisher', 'published', 'publication'])
                        })
            
            # Sort by relevance score
            bibliographic_findings.sort(key=lambda x: x['relevance_score'], reverse=True)
            
            search_results[query] = {
                'html_file': filepath,
                'status_code': response.status_code,
                'bibliographic_findings': bibliographic_findings[:20],  # Top 20 most relevant
                'total_findings': len(bibliographic_findings)
            }
            
            print(f'Found {len(bibliographic_findings)} highly relevant bibliographic results')
            if bibliographic_findings:
                print('Top bibliographic findings:')
                for i, finding in enumerate(bibliographic_findings[:5], 1):
                    indicators = []
                    if finding['has_1877']: indicators.append('1877')
                    if finding['has_1878']: indicators.append('1878')
                    if finding['has_four_volume']: indicators.append('4vol')
                    if finding['has_publisher_info']: indicators.append('pub')
                    
                    print(f'  {i}. Score {finding["relevance_score"]} [{"|" .join(indicators)}]: {finding["text"][:120]}...')
                    print(f'     URL: {finding["url"]}')
            
            time.sleep(2)  # Rate limiting
            return True
        else:
            print(f'Failed: HTTP {response.status_code}')
            return False
            
    except Exception as e:
        print(f'Error: {str(e)}')
        return False

# Execute all bibliographic searches
print('\n=== EXECUTING BIBLIOGRAPHIC SEARCHES ===')
successful_searches = 0

for i, query in enumerate(bibliographic_queries, 1):
    if perform_bibliographic_search(query, i):
        successful_searches += 1
    
    # Brief pause between searches
    if i < len(bibliographic_queries):
        time.sleep(1)

print(f'\n=== STEP 2: ANALYZING BIBLIOGRAPHIC FINDINGS ===')
print(f'Successful searches: {successful_searches}/{len(bibliographic_queries)}')

# Compile all high-priority findings
high_priority_findings = []
publisher_mentions = {}
date_verified_findings = []

print('\n--- ANALYZING ALL BIBLIOGRAPHIC RESULTS FOR PUBLISHER IDENTIFICATION ---')

for query, results in search_results.items():
    print(f'\nQuery: "{query}"')
    print(f'  Bibliographic findings: {results["total_findings"]}')
    
    for finding in results['bibliographic_findings']:
        text_lower = finding['text'].lower()
        
        # Check for date verification (1877 or 1878)
        has_target_dates = finding['has_1877'] or finding['has_1878']
        
        if has_target_dates and finding['has_publisher_info']:
            # This is a high-priority finding with both date and publisher info
            high_priority_findings.append({
                'query': query,
                'text': finding['text'],
                'url': finding['url'],
                'score': finding['relevance_score'],
                'has_1877': finding['has_1877'],
                'has_1878': finding['has_1878'],
                'has_four_volume': finding['has_four_volume'],
                'priority': 'CRITICAL - Date + Publisher Info'
            })
            
            print(f'  🎯 CRITICAL: Date-verified finding with publisher info (Score: {finding["relevance_score"]})')
            print(f'     Text: {finding["text"][:200]}...')
            
            # Extract potential publisher names
            known_publishers = [
                'George Bell', 'Bell and Sons', 'George Bell and Sons', 'Bell & Sons',
                'Macmillan', 'Longman', 'Longmans', 'John Murray', 'Chapman and Hall',
                'Smith Elder', 'Blackwood', 'Cambridge University Press',
                'Oxford University Press', 'Kegan Paul', 'Trench', 'Trubner'
            ]
            
            for publisher in known_publishers:
                if publisher.lower() in text_lower:
                    if publisher not in publisher_mentions:
                        publisher_mentions[publisher] = []
                    publisher_mentions[publisher].append({
                        'query': query,
                        'text': finding['text'][:300],
                        'url': finding['url'],
                        'score': finding['relevance_score'],
                        'date_verified': has_target_dates
                    })
                    print(f'     📚 PUBLISHER IDENTIFIED: {publisher}')
        
        elif has_target_dates:
            # Date-verified but may need manual publisher extraction
            date_verified_findings.append({
                'query': query,
                'text': finding['text'],
                'url': finding['url'],
                'score': finding['relevance_score'],
                'has_1877': finding['has_1877'],
                'has_1878': finding['has_1878'],
                'has_four_volume': finding['has_four_volume'],
                'priority': 'HIGH - Date Verified'
            })
            
            print(f'  📍 HIGH: Date-verified finding (Score: {finding["relevance_score"]})')

print(f'\n=== STEP 3: PUBLISHER IDENTIFICATION ANALYSIS ===')
print(f'Critical findings (date + publisher): {len(high_priority_findings)}')
print(f'Date-verified findings: {len(date_verified_findings)}')
print(f'Publishers explicitly mentioned: {len(publisher_mentions)}')

if publisher_mentions:
    print('\n🏆 PUBLISHERS IDENTIFIED IN BIBLIOGRAPHIC RECORDS:')
    
    # Sort publishers by frequency and evidence quality
    sorted_publishers = sorted(publisher_mentions.items(), 
                             key=lambda x: (len(x[1]), sum(m['score'] for m in x[1])), 
                             reverse=True)
    
    for publisher, mentions in sorted_publishers:
        print(f'\n📚 {publisher}: {len(mentions)} mention(s)')
        
        # Calculate total evidence score
        total_score = sum(m['score'] for m in mentions)
        date_verified_count = sum(1 for m in mentions if m['date_verified'])
        
        print(f'   Total evidence score: {total_score}')
        print(f'   Date-verified mentions: {date_verified_count}/{len(mentions)}')
        
        # Show evidence for top publishers
        if len(mentions) >= 2 or total_score >= 15:  # Strong evidence threshold
            print('   Key evidence:')
            for i, mention in enumerate(mentions[:3], 1):  # Top 3 pieces of evidence
                date_info = []
                if '1877' in mention['text'].lower(): date_info.append('1877')
                if '1878' in mention['text'].lower(): date_info.append('1878')
                date_str = f"[{'/'.join(date_info)}]" if date_info else ''
                
                print(f'     {i}. {date_str} Score {mention["score"]}: {mention["text"][:150]}...')
                print(f'        URL: {mention["url"]}')
        print()
    
    # Identify most likely publisher
    if sorted_publishers:
        top_publisher = sorted_publishers[0][0]
        top_mentions = sorted_publishers[0][1]
        top_total_score = sum(m['score'] for m in top_mentions)
        top_date_verified = sum(1 for m in top_mentions if m['date_verified'])
        
        print(f'🎯 MOST LIKELY PUBLISHER: {top_publisher}')
        print(f'Evidence strength: {len(top_mentions)} mentions, total score {top_total_score}')
        print(f'Date verification: {top_date_verified}/{len(top_mentions)} mentions verified')
        
        # Determine confidence level
        if top_total_score >= 25 and top_date_verified >= 2:
            confidence = 'very_high'
        elif top_total_score >= 15 and top_date_verified >= 1:
            confidence = 'high'
        elif top_total_score >= 10:
            confidence = 'medium'
        else:
            confidence = 'low'
        
        print(f'Confidence level: {confidence}')
else:
    print('\n⚠ No specific publishers clearly identified in bibliographic searches')
    print('Publishers may be mentioned but not explicitly extracted')

# Save comprehensive bibliographic analysis
bibliographic_analysis = {
    'search_objective': 'Identify publisher of Martineau\'s "History of England During the Thirty Years\' Peace" 1877-1878 edition',
    'book_details': {
        'title': 'The History of England During the Thirty Years\' Peace: 1816-1846',
        'author': 'Harriet Martineau',
        'edition': 'Four-volume set',
        'publication_years': '1877-1878',
        'time_period_covered': '1816-1846'
    },
    'search_summary': {
        'total_queries': len(bibliographic_queries),
        'successful_searches': successful_searches,
        'total_bibliographic_findings': sum(len(r['bibliographic_findings']) for r in search_results.values()),
        'critical_findings': len(high_priority_findings),
        'date_verified_findings': len(date_verified_findings)
    },
    'publisher_analysis': {
        'publishers_identified': list(publisher_mentions.keys()) if publisher_mentions else [],
        'publisher_evidence': publisher_mentions if publisher_mentions else {},
        'most_likely_publisher': sorted_publishers[0][0] if 'sorted_publishers' in locals() and sorted_publishers else None,
        'confidence_level': confidence if 'confidence' in locals() else 'unknown'
    },
    'high_priority_findings': high_priority_findings[:10],  # Top 10 critical findings
    'date_verified_findings': date_verified_findings[:10],  # Top 10 date-verified findings
    'search_queries_used': bibliographic_queries,
    'analysis_timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
}

analysis_file = 'workspace/martineau_history_england_1877_publisher_analysis.json'
with open(analysis_file, 'w', encoding='utf-8') as f:
    json.dump(bibliographic_analysis, f, indent=2, ensure_ascii=False)

print(f'\n*** BIBLIOGRAPHIC PUBLISHER SEARCH COMPLETE ***')
print(f'✓ Conducted {successful_searches} successful bibliographic searches')
print(f'✓ Analyzed {sum(len(r["bibliographic_findings"]) for r in search_results.values())} bibliographic findings')
print(f'✓ Found {len(high_priority_findings)} critical findings with date + publisher info')
print(f'✓ Found {len(date_verified_findings)} date-verified findings')
print(f'✓ Identified {len(publisher_mentions) if publisher_mentions else 0} publishers with evidence')
print(f'✓ Comprehensive analysis saved to: {analysis_file}')

# Final summary
if 'sorted_publishers' in locals() and sorted_publishers:
    top_publisher = sorted_publishers[0][0]
    top_evidence_count = len(sorted_publishers[0][1])
    top_score = sum(m['score'] for m in sorted_publishers[0][1])
    
    print(f'\n🏆 FINAL CONCLUSION:')
    print(f'Publisher: {top_publisher}')
    print(f'Evidence: {top_evidence_count} bibliographic mentions')
    print(f'Total score: {top_score}')
    print(f'Confidence: {confidence}')
else:
    print(f'\n⚠ CONCLUSION: Publisher not definitively identified from bibliographic searches')
    print('Recommend manual review of date-verified findings or direct library catalog consultation')

print('\n=== FILES CREATED ===')
for file in sorted(os.listdir('workspace')):
    if 'martineau_history' in file:
        file_path = os.path.join('workspace', file)
        file_size = os.path.getsize(file_path)
        print(f'- {file} ({file_size:,} bytes)')
```