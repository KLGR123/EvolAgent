### Development Step 3: Generate JSON of US Presidents’ Birth Cities, States, and Geographic Coordinates

**Description**: Collect a complete list of all United States presidents with their official birth city names and state names, then obtain the geographic coordinates (longitude and latitude) for each birth city using authoritative sources such as official presidential biographies or Wikipedia infoboxes. Save the results in a structured format (e.g., CSV or JSON) at workspace/presidential_birthplaces.json.

**Use Cases**:
- Interactive museum exhibits and educational apps that display a clickable U.S. map of presidential birthplaces with biographical pop-ups for history students
- Political science research dashboards visualizing geographic clusters of presidential origins alongside voting patterns in midterm and presidential elections
- Heritage tourism route planners in travel agencies generating optimized “Presidents’ Birthplace Trail” road-trip itineraries across multiple states
- Data journalism projects mapping presidents’ hometowns against demographic shifts to illustrate regional political trends over time
- State tourism boards automating location-based marketing collateral highlighting famous sites, including birthplace markers and visitor information
- Academic geography assignments where students use real coordinates to perform spatial analysis on birthplace distributions and regional policy outcomes
- Educational mobile games that challenge players to match presidential names to birth cities using GPS-enabled quizzes and reward systems
- Genealogy and family-history platforms integrating presidential birthplace data to help users explore potential ancestral connections and migration patterns

```
import os
import re
import time
import json
import requests
from bs4 import BeautifulSoup
from geopy.geocoders import Nominatim

# -- Helper functions --
def parse_coordinate_component(comp_str):
    """
    Parse a single coordinate component in either DMS (e.g., "38°53′23″N")
    or decimal format (e.g., "38.8977°N") into a float.
    """
    comp_str = comp_str.strip()
    # Decimal format: "38.8977°N"
    m = re.match(r"([0-9]+\.?[0-9]*)°\s*([NSWE])", comp_str)
    if m:
        val = float(m.group(1))
        dir_ = m.group(2)
        if dir_ in ('S', 'W'):
            val = -val
        return val
    # DMS format: "38°53′23″N"
    m = re.match(r"(\d+)°(\d+)′(\d+)″([NSWE])", comp_str)
    if m:
        deg = float(m.group(1))
        minu = float(m.group(2))
        sec = float(m.group(3))
        dir_ = m.group(4)
        val = deg + minu/60.0 + sec/3600.0
        if dir_ in ('S', 'W'):
            val = -val
        return val
    raise ValueError(f"Could not parse coordinate component: '{comp_str}'")

# Ensure workspace directory exists
workspace = 'workspace'
os.makedirs(workspace, exist_ok=True)

# 1. Load or fetch the list of presidents
list_html_path = os.path.join(workspace, 'presidents_list.html')
if os.path.exists(list_html_path):
    print(f"Loading saved list HTML from {list_html_path}")
    with open(list_html_path, 'r', encoding='utf-8') as f:
        list_html = f.read()
else:
    list_url = 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States'
    print(f"Fetching presidents list from {list_url}")
    resp = requests.get(list_url)
    resp.raise_for_status()
    list_html = resp.text
    with open(list_html_path, 'w', encoding='utf-8') as f:
        f.write(list_html)
    print(f"Saved list HTML to {list_html_path}")

# Parse the presidents table
soup_list = BeautifulSoup(list_html, 'html.parser')
table = soup_list.find('table', class_='wikitable')
rows = table.find_all('tr')[1:]
print(f"Found {len(rows)} president rows in the table (including living and deceased)")

# Build list of (name, page_url)
presidents = []
for i, row in enumerate(rows, start=1):
    tds = row.find_all('td')
    if len(tds) < 2:
        continue
    name_cell = tds[1]
    link = name_cell.find('a', href=True)
    if not link:
        continue
    name = link.get_text(strip=True)
    href = link['href']
    page_url = 'https://en.wikipedia.org' + href
    presidents.append({'name': name, 'page_url': page_url})
print(f"Collected {len(presidents)} president page links to process")

# Prepare geolocator (for fallback geocoding)
geolocator = Nominatim(user_agent='presidential_birth_locator')

results = []

# Process each president
for idx, pres in enumerate(presidents, start=1):
    name = pres['name']
    url = pres['page_url']
    print(f"\n[{idx}/{len(presidents)}] Processing: {name}\n  URL: {url}")
    # Fetch individual page
    page_resp = requests.get(url)
    page_resp.raise_for_status()
    page_soup = BeautifulSoup(page_resp.text, 'html.parser')
    time.sleep(1)  # polite pause

    # 2. Try to get coords directly from page (geo-dec or geo)
    coord_tag = page_soup.find('span', class_='geo-dec') or page_soup.find('span', class_='geo')
    latitude = longitude = None
    if coord_tag:
        coords_text = coord_tag.get_text(strip=True)
        parts = coords_text.split()  # e.g. ['38.8977°N', '77.0365°W'] or DMS
        try:
            latitude = parse_coordinate_component(parts[0])
            longitude = parse_coordinate_component(parts[1])
            print(f"  Found coords in page: lat={latitude}, lon={longitude}")
        except Exception as e:
            print(f"  Warning: failed to parse coords '{coords_text}': {e}")
            latitude = longitude = None

    # 3. Locate "Born" row in infobox
    birth_place = None
    infobox = page_soup.find('table', class_=lambda c: c and 'infobox' in c)
    if infobox:
        for tr in infobox.find_all('tr'):
            th = tr.find('th')
            if th and th.get_text(strip=True).startswith('Born'):
                td = tr.find('td')
                if td:
                    # Split on first <br> by using get_text with separator
                    txt = td.get_text(separator='|', strip=True)
                    parts = txt.split('|', 1)
                    if len(parts) > 1:
                        birth_place = parts[1]
                    else:
                        # fallback: full text minus date
                        birth_place = txt
                break
    if birth_place:
        print(f"  Birth place string: {birth_place}")
    else:
        print("  Warning: could not locate birth place in infobox")

    # 4. If no coords from page, geocode birth_place
    if (latitude is None or longitude is None) and birth_place:
        print(f"  Geocoding '{birth_place}'...")
        try:
            loc = geolocator.geocode(birth_place, timeout=10)
            time.sleep(1)  # respect Nominatim usage policy
            if loc:
                latitude = loc.latitude
                longitude = loc.longitude
                print(f"    Geocoded to: lat={latitude}, lon={longitude}")
            else:
                print("    Geocoding returned None")
        except Exception as e:
            print(f"    Error during geocoding: {e}")

    # 5. Split birth_place into city/state
    city = state = None
    if birth_place:
        tokens = [t.strip() for t in birth_place.split(',')]
        if len(tokens) >= 1:
            city = tokens[0]
        if len(tokens) >= 2:
            state = tokens[1]

    # 6. Append to results
    entry = {
        'name': name,
        'birth_city': city,
        'birth_state': state,
        'latitude': latitude,
        'longitude': longitude
    }
    results.append(entry)
    print(f"  Recorded: {entry}")

# 7. Save final results to JSON
out_path = os.path.join(workspace, 'presidential_birthplaces.json')
with open(out_path, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2)
print(f"\nAll done: saved {len(results)} records to {out_path}")
```