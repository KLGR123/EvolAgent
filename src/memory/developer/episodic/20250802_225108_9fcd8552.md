### Development Step 5: Find oldest closed numpy.polynomial Regression issue and its label-addition time

**Description**: Search GitHub for numpy.polynomial issues to identify all closed issues that have the 'Regression' label. Focus on finding the oldest closed issue with this label and determine when the 'Regression' label was added to that specific issue. Use GitHub's issue search functionality with filters for repository 'numpy/numpy', path 'polynomial', status 'closed', and label 'Regression'. Extract the issue creation date, closure date, and label addition timestamp for the oldest matching issue.

**Use Cases**:
- Academic research teams auditing the history of polynomial-related regressions in NumPy to validate the stability of scientific computation methods before citing them in a journal publication
- Software quality assurance engineers automating the extraction of “Regression” label addition timestamps for polynomial modules to measure and improve bug-fix turnaround times in each release cycle
- Data science teams monitoring changes and regressions in NumPy’s polynomial functions to ensure consistency and reproducibility of machine learning model fitting pipelines
- DevOps engineers integrating this GitHub search script into CI/CD workflows to automatically flag new closed regression issues in the polynomial path and prevent regressions from reaching production
- Product managers generating dashboards on closed regression issues for NumPy’s polynomial subpackage to inform road-mapping decisions and resource allocation for maintenance work
- Open-source project maintainers analyzing label-addition timelines on polynomial regression issues to benchmark community response times and prioritize high-impact bug fixes
- Compliance officers in finance or healthcare auditing the lifecycle of critical regression bugs in numerical libraries for regulatory reporting and software validation documentation
- Software educators creating case studies on real-world issue management by tracing the oldest closed regression issues in NumPy’s polynomial module and illustrating best practices in bug triage

```
import requests
import json
from datetime import datetime
import os
import time

print("=== FIXED GITHUB SEARCH FOR NUMPY POLYNOMIAL REGRESSION ISSUES ===")
print("Objective: Fix variable bug and properly extract polynomial regression issues")
print("Focus: Find issues with 'regression' keyword and polynomial content\n")

# Find workspace directory
workspace_dirs = [d for d in os.listdir('.') if d.startswith('workspace')]
workspace_dir = workspace_dirs[0] if workspace_dirs else 'workspace'
os.makedirs(workspace_dir, exist_ok=True)

# GitHub API configuration
base_url = "https://api.github.com"
repo = "numpy/numpy"

headers = {
    'Accept': 'application/vnd.github.v3+json',
    'User-Agent': 'Python-GitHub-Search'
}

print(f"Using workspace directory: {workspace_dir}")
print(f"Repository: {repo}\n")

# Focus on the most promising search strategy from HISTORY
# Search for closed issues with 'regression' keyword and polynomial content
search_query = f"repo:{repo} is:issue is:closed regression polynomial"

print(f"=== TARGETED SEARCH: REGRESSION + POLYNOMIAL ISSUES ===")
print(f"Query: {search_query}")
print(f"Objective: Find oldest closed issue with regression and polynomial content\n")

search_url = f"{base_url}/search/issues"
params = {
    'q': search_query,
    'sort': 'created',  # Sort by creation date
    'order': 'asc',     # Ascending order (oldest first)
    'per_page': 100     # Get more results per page
}

print("Making GitHub API request...")
response = requests.get(search_url, headers=headers, params=params)

print(f"Response status: {response.status_code}")
if response.status_code != 200:
    print(f"Error response: {response.text}")
    exit()

search_results = response.json()
total_count = search_results['total_count']
items = search_results['items']

print(f"Total issues found: {total_count}")
print(f"Issues retrieved in this page: {len(items)}\n")

if not items:
    print("No issues found with the search criteria.")
    exit()

print("=== ANALYZING REGRESSION + POLYNOMIAL ISSUES ===")
print("Filtering and analyzing issues for polynomial relevance...\n")

# Process each issue with proper variable definitions
polynomial_regression_issues = []
polynomial_keywords = ['polynomial', 'poly', 'chebyshev', 'legendre', 'hermite', 'laguerre']

for i, issue in enumerate(items, 1):
    # Fix the bug: Define variables before using them
    title = issue['title'] or ''
    body = issue['body'] or ''
    title_lower = title.lower()
    body_lower = body.lower()
    
    # Check if issue is polynomial-related
    is_polynomial_related = any(keyword in title_lower or keyword in body_lower for keyword in polynomial_keywords)
    
    # Check if issue mentions regression
    has_regression = 'regression' in title_lower or 'regression' in body_lower
    
    print(f"{i}. Issue #{issue['number']}: {title[:80]}...")
    print(f"   Created: {issue['created_at']}")
    print(f"   Closed: {issue['closed_at']}")
    print(f"   State: {issue['state']}")
    print(f"   Labels: {[label['name'] for label in issue['labels']]}")
    print(f"   Polynomial-related: {is_polynomial_related}")
    print(f"   Has regression keyword: {has_regression}")
    print(f"   URL: {issue['html_url']}")
    
    # Store relevant issues
    if is_polynomial_related or has_regression:
        issue_data = {
            'number': issue['number'],
            'title': title,
            'created_at': issue['created_at'],
            'closed_at': issue['closed_at'],
            'state': issue['state'],
            'labels': [label['name'] for label in issue['labels']],
            'html_url': issue['html_url'],
            'api_url': issue['url'],
            'is_polynomial_related': is_polynomial_related,
            'has_regression': has_regression,
            'body_preview': body[:500] if body else ''
        }
        polynomial_regression_issues.append(issue_data)
    
    print()

print(f"=== SUMMARY OF RELEVANT ISSUES ===")
print(f"Total issues analyzed: {len(items)}")
print(f"Polynomial/regression relevant issues: {len(polynomial_regression_issues)}\n")

# Sort by creation date to find the oldest
polynomial_regression_issues.sort(key=lambda x: x['created_at'])

if polynomial_regression_issues:
    print("=== OLDEST RELEVANT ISSUES (sorted by creation date) ===")
    for i, issue in enumerate(polynomial_regression_issues[:5], 1):  # Show top 5 oldest
        print(f"{i}. Issue #{issue['number']}: {issue['title'][:60]}...")
        print(f"   Created: {issue['created_at']}")
        print(f"   Closed: {issue['closed_at']}")
        print(f"   Labels: {issue['labels']}")
        print(f"   Polynomial: {issue['is_polynomial_related']}, Regression: {issue['has_regression']}")
        print(f"   URL: {issue['html_url']}")
        print()
    
    # Identify the oldest issue for detailed timeline analysis
    oldest_issue = polynomial_regression_issues[0]
    print(f"=== OLDEST RELEVANT ISSUE IDENTIFIED ===")
    print(f"Issue #{oldest_issue['number']}: {oldest_issue['title']}")
    print(f"Created: {oldest_issue['created_at']}")
    print(f"Closed: {oldest_issue['closed_at']}")
    print(f"Current labels: {oldest_issue['labels']}")
    print(f"API URL: {oldest_issue['api_url']}")
    print(f"\nNext step: Get detailed timeline for this issue to check label addition history")

# Save comprehensive results
results_data = {
    'search_timestamp': datetime.now().isoformat(),
    'search_query': search_query,
    'repository': repo,
    'total_issues_found': total_count,
    'issues_analyzed': len(items),
    'relevant_issues_count': len(polynomial_regression_issues),
    'oldest_issue': oldest_issue if polynomial_regression_issues else None,
    'all_relevant_issues': polynomial_regression_issues,
    'next_action': 'Get detailed timeline for oldest issue to find label addition timestamp'
}

with open(f'{workspace_dir}/polynomial_regression_issues_analysis.json', 'w') as f:
    json.dump(results_data, f, indent=2)

print(f"\nDetailed analysis saved to: {workspace_dir}/polynomial_regression_issues_analysis.json")
print("Ready for next step: Timeline analysis of the oldest relevant issue")
```