### Development Step 8: Compile Land Area Data for Washington’s 39 County Seat Cities

**Description**: Research and extract the land area data for all 39 Washington state county seats that were identified in the previous step. Use authoritative sources such as the U.S. Census Bureau, official city websites, or government geographic databases to obtain the land area measurements for each county seat city. Focus on finding the official land area figures in square miles or square kilometers for accurate comparison.

**Use Cases**:
- Urban planning and infrastructure assessment for Washington counties: automatically gather land area metrics to compare spatial footprints and prioritize transportation or utility projects across county seats.
- Real estate market analysis and site selection: integrate city land area data into property valuation models to identify underdeveloped county seats with growth potential.
- Emergency services resource allocation: extract and map land area figures to optimize ambulance and fire station coverage planning in each Washington county seat.
- Environmental impact modeling for regional conservation: feed precise city area measurements into habitat encroachment and green space analysis tools for sustainable development studies.
- Logistics and last-mile delivery route optimization: use county seat land areas to estimate delivery zone sizes and allocate delivery fleets efficiently across urban and rural jurisdictions.
- Tourism and economic development dashboards: compile land area statistics to create interactive maps highlighting the largest and smallest county seats for targeted marketing campaigns.
- Academic geographic research and teaching aids: automate the extraction of official land area figures to support student projects and publications on urbanization patterns in Washington state.

```
import os
import json
import requests
from bs4 import BeautifulSoup
import time
import re

print("=== WASHINGTON STATE COUNTY SEATS LAND AREA RESEARCH ===\n")
print("Objective: Extract land area data for all 39 Washington state county seats")
print("Sources: Wikipedia (containing U.S. Census Bureau data)\n")

# Load the county seats data from the JSON file
print("=== LOADING COUNTY SEATS DATA ===\n")

with open('workspace/wa_county_seats.json', 'r') as f:
    county_seats_data = json.load(f)

print(f"Loaded data for {len(county_seats_data)} county seats")
print("\nCounty seats to research:")
for i, seat in enumerate(county_seats_data[:10], 1):  # Show first 10 for brevity
    print(f"  {i:2d}. {seat['county_seat']} ({seat['county']})")
print(f"  ... and {len(county_seats_data)-10} more")

# Initialize data structure for land area research
land_area_results = []

# Headers for web requests
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Connection': 'keep-alive'
}

print("\n=== BEGINNING SYSTEMATIC LAND AREA RESEARCH ===\n")
print("Strategy: Extract land area data from Wikipedia city pages")
print("Wikipedia contains official U.S. Census Bureau land area figures\n")

# Research land area for each county seat
for i, seat_data in enumerate(county_seats_data, 1):
    county_seat = seat_data['county_seat']
    county = seat_data['county']
    
    print(f"[{i:2d}/39] {county_seat}, Washington...", end=" ")
    
    # Construct Wikipedia URL for the city
    city_name_formatted = county_seat.replace(' ', '_')
    wikipedia_url = f"https://en.wikipedia.org/wiki/{city_name_formatted},_Washington"
    
    try:
        # Make request to Wikipedia page
        response = requests.get(wikipedia_url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            # Parse the HTML content
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Look for land area information in the infobox
            land_area_found = None
            area_unit = None
            extraction_method = None
            
            # Method 1: Look for infobox with area information
            infobox = soup.find('table', class_='infobox')
            if infobox:
                rows = infobox.find_all('tr')
                for row in rows:
                    # Look for area-related headers
                    header_cell = row.find('th')
                    if header_cell:
                        header_text = header_cell.get_text().lower().strip()
                        if 'area' in header_text and ('land' in header_text or 'total' in header_text):
                            # Get the corresponding data cell
                            data_cells = row.find_all('td')
                            if data_cells:
                                area_text = data_cells[0].get_text().strip()
                                
                                # Parse area value - look for numbers followed by units
                                area_patterns = [
                                    r'([0-9,]+\.?[0-9]*)\s*sq\s*mi',
                                    r'([0-9,]+\.?[0-9]*)\s*square\s*miles?',
                                    r'([0-9,]+\.?[0-9]*)\s*km²',
                                    r'([0-9,]+\.?[0-9]*)\s*square\s*kilometers?'
                                ]
                                
                                for pattern in area_patterns:
                                    match = re.search(pattern, area_text, re.IGNORECASE)
                                    if match:
                                        land_area_found = match.group(1).replace(',', '')
                                        if 'sq mi' in area_text.lower() or 'square mile' in area_text.lower():
                                            area_unit = 'sq_miles'
                                        elif 'km' in area_text.lower():
                                            area_unit = 'sq_kilometers'
                                        extraction_method = 'infobox_area_row'
                                        break
                                
                                if land_area_found:
                                    break
            
            # Method 2: Look for area in any table cell
            if not land_area_found:
                all_cells = soup.find_all(['td', 'th'])
                for cell in all_cells:
                    cell_text = cell.get_text().strip()
                    # Look for area patterns in any cell
                    area_match = re.search(r'([0-9,]+\.?[0-9]*)\s*(sq\s*mi|square\s*miles?)', cell_text, re.IGNORECASE)
                    if area_match:
                        land_area_found = area_match.group(1).replace(',', '')
                        area_unit = 'sq_miles'
                        extraction_method = 'table_cell_scan'
                        break
            
            # Method 3: Look in page text for area mentions
            if not land_area_found:
                page_text = soup.get_text()
                text_patterns = [
                    r'total area[^0-9]*([0-9,]+\.?[0-9]*)\s*(square miles|sq\s*mi)',
                    r'land area[^0-9]*([0-9,]+\.?[0-9]*)\s*(square miles|sq\s*mi)',
                    r'([0-9,]+\.?[0-9]*)\s*(square miles|sq\s*mi)[^0-9]*total',
                    r'area[^0-9]*([0-9,]+\.?[0-9]*)\s*(square miles|sq\s*mi)'
                ]
                
                for pattern in text_patterns:
                    match = re.search(pattern, page_text, re.IGNORECASE)
                    if match:
                        land_area_found = match.group(1).replace(',', '')
                        area_unit = 'sq_miles'
                        extraction_method = 'page_text_scan'
                        break
            
            # Store the results
            result = {
                'county': county,
                'county_seat': county_seat,
                'fips_code': seat_data['fips_code'],
                'land_area': float(land_area_found) if land_area_found else None,
                'area_unit': area_unit,
                'wikipedia_url': wikipedia_url,
                'data_source': 'Wikipedia (U.S. Census Bureau)',
                'extraction_method': extraction_method,
                'extraction_success': land_area_found is not None,
                'http_status': response.status_code
            }
            
            if land_area_found:
                unit_display = area_unit.replace('_', ' ') if area_unit else 'unknown unit'
                print(f"✓ {land_area_found} {unit_display}")
            else:
                print("✗ No area data found")
                
        else:
            print(f"✗ HTTP {response.status_code}")
            result = {
                'county': county,
                'county_seat': county_seat,
                'fips_code': seat_data['fips_code'],
                'land_area': None,
                'area_unit': None,
                'wikipedia_url': wikipedia_url,
                'data_source': 'Wikipedia (U.S. Census Bureau)',
                'extraction_method': None,
                'extraction_success': False,
                'http_status': response.status_code
            }
            
    except requests.RequestException as e:
        print(f"✗ Request error: {str(e)[:50]}...")
        result = {
            'county': county,
            'county_seat': county_seat,
            'fips_code': seat_data['fips_code'],
            'land_area': None,
            'area_unit': None,
            'wikipedia_url': wikipedia_url,
            'data_source': 'Wikipedia (U.S. Census Bureau)',
            'extraction_method': None,
            'extraction_success': False,
            'error': str(e)
        }
    
    except Exception as e:
        print(f"✗ Processing error: {str(e)[:50]}...")
        result = {
            'county': county,
            'county_seat': county_seat,
            'fips_code': seat_data['fips_code'],
            'land_area': None,
            'area_unit': None,
            'wikipedia_url': wikipedia_url,
            'data_source': 'Wikipedia (U.S. Census Bureau)',
            'extraction_method': None,
            'extraction_success': False,
            'error': str(e)
        }
    
    land_area_results.append(result)
    
    # Rate limiting - be respectful to Wikipedia
    time.sleep(0.5)
    
    # Progress update every 10 cities
    if i % 10 == 0:
        successful = len([r for r in land_area_results if r['extraction_success']])
        print(f"\n  Progress: {i}/39 cities processed, {successful} successful extractions\n")

# Final results analysis
print("\n=== LAND AREA RESEARCH RESULTS ===\n")

successful_extractions = [r for r in land_area_results if r['extraction_success']]
failed_extractions = [r for r in land_area_results if not r['extraction_success']]

print(f"Total cities researched: {len(land_area_results)}")
print(f"Successful extractions: {len(successful_extractions)}")
print(f"Failed extractions: {len(failed_extractions)}")
print(f"Success rate: {len(successful_extractions)/len(land_area_results)*100:.1f}%")

# Display successful results sorted by area
if successful_extractions:
    print(f"\nLand area data successfully extracted:")
    sorted_results = sorted(successful_extractions, key=lambda x: x['land_area'])
    
    for result in sorted_results:
        area_display = f"{result['land_area']:.2f} sq miles"
        print(f"  {result['county_seat']:<15} {area_display:>12} ({result['county']})")

# Show failed extractions for follow-up
if failed_extractions:
    print(f"\nFailed extractions (need alternative research):")
    for result in failed_extractions:
        error_info = result.get('error', result.get('http_status', 'Unknown error'))
        print(f"  {result['county_seat']:<15} ({result['county']}) - {error_info}")

# Save comprehensive results
results_data = {
    'research_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'research_objective': 'Washington state county seats land area data',
    'total_cities': len(land_area_results),
    'successful_extractions': len(successful_extractions),
    'failed_extractions': len(failed_extractions),
    'success_rate_percent': round(len(successful_extractions)/len(land_area_results)*100, 1),
    'data_source': 'Wikipedia (contains U.S. Census Bureau data)',
    'extraction_methods': ['infobox_area_row', 'table_cell_scan', 'page_text_scan'],
    'area_unit': 'square_miles',
    'results': land_area_results,
    'summary_statistics': {
        'smallest_area': min([r['land_area'] for r in successful_extractions]) if successful_extractions else None,
        'largest_area': max([r['land_area'] for r in successful_extractions]) if successful_extractions else None,
        'average_area': sum([r['land_area'] for r in successful_extractions])/len(successful_extractions) if successful_extractions else None
    }
}

with open('workspace/wa_county_seats_land_area_complete.json', 'w') as f:
    json.dump(results_data, f, indent=2)

print(f"\n✓ Complete land area research results saved to: workspace/wa_county_seats_land_area_complete.json")

if successful_extractions:
    stats = results_data['summary_statistics']
    print(f"\n=== SUMMARY STATISTICS ===\n")
    print(f"Smallest county seat by area: {stats['smallest_area']:.2f} sq miles")
    print(f"Largest county seat by area: {stats['largest_area']:.2f} sq miles")
    print(f"Average county seat area: {stats['average_area']:.2f} sq miles")

print(f"\n=== RESEARCH COMPLETE ===\n")
print(f"Land area data extracted for {len(successful_extractions)} out of 39 Washington state county seats")
print(f"Data source: Wikipedia (containing official U.S. Census Bureau figures)")
```