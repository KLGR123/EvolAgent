### Development Step 6: Axis Labels from a Three-Axis Figure in a June 2022 arXiv AI Regulation Paper

**Description**: Search arXiv.org for AI regulation papers originally submitted in June 2022. Focus on identifying papers that discuss artificial intelligence regulation, policy, governance, or related topics. Look for papers with submission dates in June 2022 and examine their content to find one containing a figure with three axes where each axis has label words at both ends. Extract the specific words used as axis labels in this figure.

**Use Cases**:
- Academic literature review automation for policy researchers investigating trends in AI governance frameworks
- Regulatory compliance teams extracting visual models from AI policy papers to inform organizational risk assessments
- Government agencies mapping conceptual frameworks from June 2022 arXiv submissions to guide national AI regulation strategies
- Data scientists building knowledge graphs from figure axis labels in AI governance papers for semantic analysis
- Legal analysts identifying multidimensional models in AI regulation literature to support case law development
- Think tanks benchmarking international AI policy approaches by analyzing three-axis diagrams in scholarly articles
- Corporate strategy teams monitoring academic advances in AI governance to inform internal policy updates
- University instructors sourcing illustrative figures for teaching AI ethics and regulation using automated PDF analysis

```
import os
import json
import requests
from langchain_community.document_loaders import PyPDFLoader
import re
from datetime import datetime

print('=== EXPANDED ANALYSIS OF REMAINING AI REGULATION PAPERS ===') 
print('Objective: Find figure with three axes using broader search patterns')
print('Strategy: Analyze remaining 2 papers with enhanced figure detection\n')

# Ensure workspace exists
workspace = 'workspace'
os.makedirs(workspace, exist_ok=True)

# Load the assessment to get remaining papers
assessment_file = os.path.join(workspace, 'figure_search_assessment.json')

if os.path.exists(assessment_file):
    print('Loading figure search assessment...')
    with open(assessment_file, 'r', encoding='utf-8') as f:
        assessment_data = json.load(f)
    
    remaining_papers = assessment_data.get('remaining_papers', [])
    print(f'Found {len(remaining_papers)} remaining papers to analyze\n')
    
    analysis_results = []
    
    for i, paper in enumerate(remaining_papers, 1):
        title = paper.get('title', 'No title')
        arxiv_id = paper.get('arxiv_id', 'No ID')
        pdf_url = paper.get('pdf_url', 'No URL')
        relevance_score = paper.get('relevance_score', 0)
        
        print(f'=== ANALYZING REMAINING PAPER {i}/{len(remaining_papers)} ===') 
        print(f'Title: {title}')
        print(f'arXiv ID: {arxiv_id}')
        print(f'Relevance Score: {relevance_score}')
        print(f'PDF URL: {pdf_url}\n')
        
        # Download the PDF
        pdf_filename = f'{arxiv_id.replace(".", "_")}.pdf'
        pdf_path = os.path.join(workspace, pdf_filename)
        
        try:
            print(f'Downloading PDF: {pdf_filename}')
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(pdf_url, headers=headers, stream=True, timeout=60)
            response.raise_for_status()
            
            with open(pdf_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            file_size = os.path.getsize(pdf_path)
            print(f'✓ PDF downloaded successfully: {file_size:,} bytes')
            
            # Load and analyze PDF content
            print('Loading PDF content with LangChain...')
            loader = PyPDFLoader(pdf_path)
            pages = loader.load_and_split()
            
            print(f'✓ PDF loaded: {len(pages)} pages')
            
            # Combine all pages for comprehensive search
            full_content = '\n'.join([page.page_content for page in pages])
            
            print(f'Total content length: {len(full_content):,} characters')
            
            # EXPANDED SEARCH PATTERNS - Much broader approach
            print('\n--- EXPANDED FIGURE/DIAGRAM SEARCH ---')
            
            # Enhanced patterns for figures, diagrams, charts, visualizations
            expanded_figure_patterns = [
                # Traditional figure patterns
                r'Figure\s+(\d+)[^.]*?([^.]*?(?:axis|axes|dimension)[^.]*?)',
                r'Fig\.?\s+(\d+)[^.]*?([^.]*?(?:axis|axes|dimension)[^.]*?)',
                
                # Diagram and chart patterns
                r'(diagram[^.]*?(?:three|3)[^.]*?(?:axis|axes|dimension)[^.]*?)',
                r'(chart[^.]*?(?:three|3)[^.]*?(?:axis|axes|dimension)[^.]*?)',
                r'(visualization[^.]*?(?:three|3)[^.]*?(?:axis|axes|dimension)[^.]*?)',
                r'(framework[^.]*?(?:three|3)[^.]*?(?:axis|axes|dimension)[^.]*?)',
                
                # Three-dimensional patterns
                r'([^.]*?(?:three|3)[^.]*?(?:dimensional|dimension)[^.]*?)',
                r'([^.]*?(?:three|3)[^.]*?(?:axis|axes)[^.]*?)',
                r'([^.]*?(?:x-axis|y-axis|z-axis)[^.]*?)',
                
                # Model or framework descriptions
                r'([^.]*?model[^.]*?(?:three|3)[^.]*?(?:axis|axes|dimension)[^.]*?)',
                r'([^.]*?framework[^.]*?(?:axis|axes|dimension)[^.]*?)',
                
                # Caption patterns
                r'([^.]*?caption[^.]*?(?:axis|axes|dimension)[^.]*?)',
                r'([^.]*?shows[^.]*?(?:three|3)[^.]*?(?:axis|axes|dimension)[^.]*?)',
                r'([^.]*?depicts[^.]*?(?:three|3)[^.]*?(?:axis|axes|dimension)[^.]*?)',
                
                # Coordinate system patterns
                r'([^.]*?coordinate[^.]*?(?:three|3)[^.]*?(?:axis|axes)[^.]*?)',
                r'([^.]*?space[^.]*?(?:three|3)[^.]*?(?:dimensional|dimension)[^.]*?)',
            ]
            
            figure_matches = []
            
            for pattern in expanded_figure_patterns:
                matches = re.findall(pattern, full_content, re.IGNORECASE | re.DOTALL)
                if matches:
                    print(f'Pattern found {len(matches)} matches: "{pattern[:40]}..."')
                    figure_matches.extend(matches)
            
            # Search for any mention of "three" with various terms
            print('\n--- SEARCHING FOR "THREE" CONTEXTS ---')
            
            three_patterns = [
                r'([^.]*?three[^.]*?(?:axis|axes|dimension|component|factor|element|aspect)[^.]*?)',
                r'([^.]*?(?:axis|axes|dimension|component|factor|element|aspect)[^.]*?three[^.]*?)',
                r'([^.]*?3[^.]*?(?:axis|axes|dimension|component|factor|element|aspect)[^.]*?)',
                r'([^.]*?(?:axis|axes|dimension|component|factor|element|aspect)[^.]*?3[^.]*?)',
            ]
            
            three_matches = []
            
            for pattern in three_patterns:
                matches = re.findall(pattern, full_content, re.IGNORECASE | re.DOTALL)
                if matches:
                    print(f'"Three" pattern found {len(matches)} matches')
                    three_matches.extend(matches[:5])  # Limit to first 5 per pattern
            
            # Search for axis label patterns - more comprehensive
            print('\n--- SEARCHING FOR AXIS LABEL PATTERNS ---')
            
            axis_label_patterns = [
                # Direct axis labeling
                r'([^.]*?(?:x-axis|y-axis|z-axis)[^.]*?(?:label|labeled|labelled)[^.]*?)',
                r'([^.]*?(?:label|labeled|labelled)[^.]*?(?:x-axis|y-axis|z-axis)[^.]*?)',
                
                # Axis endpoints
                r'([^.]*?axis[^.]*?(?:from|to|between)[^.]*?(?:low|high|left|right|top|bottom)[^.]*?)',
                r'([^.]*?(?:low|high|left|right|top|bottom)[^.]*?axis[^.]*?)',
                
                # Range descriptions
                r'([^.]*?(?:ranging|ranges|range)[^.]*?(?:from|to)[^.]*?(?:low|high|minimum|maximum)[^.]*?)',
                r'([^.]*?(?:spectrum|scale|continuum)[^.]*?(?:from|to)[^.]*?)',
                
                # Dimensional analysis
                r'([^.]*?dimension[^.]*?(?:from|to|between)[^.]*?)',
                r'([^.]*?(?:horizontal|vertical|depth)[^.]*?axis[^.]*?)',
            ]
            
            axis_label_matches = []
            
            for pattern in axis_label_patterns:
                matches = re.findall(pattern, full_content, re.IGNORECASE | re.DOTALL)
                if matches:
                    print(f'Axis label pattern found {len(matches)} matches')
                    axis_label_matches.extend(matches[:3])  # Limit to first 3 per pattern
            
            # Search for specific academic figure terminology
            print('\n--- SEARCHING FOR ACADEMIC FIGURE TERMINOLOGY ---')
            
            academic_patterns = [
                r'([^.]*?(?:conceptual|theoretical)[^.]*?(?:framework|model)[^.]*?(?:three|3)[^.]*?)',
                r'([^.]*?(?:three|3)[^.]*?(?:conceptual|theoretical)[^.]*?(?:framework|model)[^.]*?)',
                r'([^.]*?matrix[^.]*?(?:three|3)[^.]*?(?:dimension|axis)[^.]*?)',
                r'([^.]*?(?:three|3)[^.]*?matrix[^.]*?(?:dimension|axis)[^.]*?)',
                r'([^.]*?typology[^.]*?(?:three|3)[^.]*?(?:dimension|axis)[^.]*?)',
                r'([^.]*?(?:three|3)[^.]*?typology[^.]*?(?:dimension|axis)[^.]*?)',
            ]
            
            academic_matches = []
            
            for pattern in academic_patterns:
                matches = re.findall(pattern, full_content, re.IGNORECASE | re.DOTALL)
                if matches:
                    print(f'Academic pattern found {len(matches)} matches')
                    academic_matches.extend(matches[:3])
            
            # Save analysis results
            paper_analysis = {
                'paper_info': {
                    'title': title,
                    'arxiv_id': arxiv_id,
                    'pdf_url': pdf_url,
                    'relevance_score': relevance_score,
                    'pdf_path': pdf_path,
                    'file_size': file_size,
                    'page_count': len(pages)
                },
                'expanded_figure_matches': figure_matches,
                'three_context_matches': three_matches,
                'axis_label_matches': axis_label_matches,
                'academic_framework_matches': academic_matches,
                'analysis_timestamp': datetime.now().isoformat()
            }
            
            analysis_results.append(paper_analysis)
            
            # Display key findings for this paper
            print(f'\n=== EXPANDED ANALYSIS SUMMARY FOR PAPER {i} ===')
            print(f'Expanded figure matches: {len(figure_matches)}')
            print(f'"Three" context matches: {len(three_matches)}')
            print(f'Axis label matches: {len(axis_label_matches)}')
            print(f'Academic framework matches: {len(academic_matches)}')
            
            # Show the most promising matches
            all_matches = figure_matches + three_matches + axis_label_matches + academic_matches
            
            if all_matches:
                print('\n*** MOST PROMISING MATCHES ***')
                for j, match in enumerate(all_matches[:5], 1):
                    match_text = str(match) if isinstance(match, str) else ' '.join(str(m) for m in match if m)
                    # Clean up the match text
                    clean_match = match_text.replace('\n', ' ').strip()[:200]
                    print(f'  {j}. {clean_match}...')
                    
                    # Check if this match contains potential axis labels
                    if any(term in clean_match.lower() for term in ['low', 'high', 'left', 'right', 'top', 'bottom', 'minimum', 'maximum']):
                        print(f'     *** CONTAINS POTENTIAL AXIS LABELS ***')
            
            print(f'\n{"="*60}\n')
            
        except Exception as e:
            print(f'❌ Error analyzing paper {i}: {str(e)}')
            error_analysis = {
                'paper_info': {
                    'title': title,
                    'arxiv_id': arxiv_id,
                    'error': str(e)
                },
                'analysis_timestamp': datetime.now().isoformat()
            }
            analysis_results.append(error_analysis)
            continue
    
    # Save comprehensive expanded analysis results
    expanded_results_file = os.path.join(workspace, 'expanded_pdf_analysis_results.json')
    with open(expanded_results_file, 'w', encoding='utf-8') as f:
        json.dump({
            'analysis_date': datetime.now().isoformat(),
            'objective': 'Find figure with three axes containing label words at both ends - EXPANDED SEARCH',
            'papers_analyzed': len(analysis_results),
            'search_strategy': 'Broader patterns including diagram, chart, visualization, framework, academic terminology',
            'analysis_results': analysis_results
        }, f, indent=2, ensure_ascii=False)
    
    print(f'=== EXPANDED ANALYSIS COMPLETE ===')
    print(f'✓ Analyzed {len(analysis_results)} remaining papers with expanded search patterns')
    print(f'✓ Results saved to: {expanded_results_file}')
    
    # Summary of findings across all remaining papers
    total_expanded_matches = sum(len(result.get('expanded_figure_matches', [])) for result in analysis_results if 'expanded_figure_matches' in result)
    total_three_matches = sum(len(result.get('three_context_matches', [])) for result in analysis_results if 'three_context_matches' in result)
    total_axis_label_matches = sum(len(result.get('axis_label_matches', [])) for result in analysis_results if 'axis_label_matches' in result)
    total_academic_matches = sum(len(result.get('academic_framework_matches', [])) for result in analysis_results if 'academic_framework_matches' in result)
    
    print(f'\n=== OVERALL EXPANDED FINDINGS SUMMARY ===')
    print(f'Total expanded figure matches: {total_expanded_matches}')
    print(f'Total "three" context matches: {total_three_matches}')
    print(f'Total axis label matches: {total_axis_label_matches}')
    print(f'Total academic framework matches: {total_academic_matches}')
    
    grand_total = total_expanded_matches + total_three_matches + total_axis_label_matches + total_academic_matches
    
    if grand_total > 0:
        print(f'\n✓ Found {grand_total} total matches using expanded search patterns!')
        print('✓ Ready for detailed examination of specific matches')
        print('✓ Next step: Analyze matches for three-axis figures with specific label words')
    else:
        print('\n⚠ Still no matches found even with expanded search patterns')
        print('May need to consider that the target figure is not in these specific papers')
        print('Or the figure description uses very different terminology')
    
else:
    print(f'❌ Assessment file not found: {assessment_file}')
    print('Need to run the assessment phase first')

print('\n*** EXPANDED PDF ANALYSIS PHASE COMPLETE ***')
```