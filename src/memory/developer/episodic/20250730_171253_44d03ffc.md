### Development Step 13: Bachelor’s Degree Institutions of U.S. Homeland Security Secretaries Before April 2019

**Description**: Search for the complete list of United States Secretaries of Homeland Security who served prior to April 2019 (excluding acting secretaries) and identify their educational backgrounds, specifically focusing on where each secretary obtained their bachelor's degree.

**Use Cases**:
- Government policy research: comparing DHS secretaries’ undergraduate alma maters with major homeland security policy shifts to identify potential educational influences on decision-making
- Journalistic profiling automation: extracting and compiling Secretaries’ bachelor’s degree information for news articles on cabinet composition and leadership backgrounds
- Academic study of leadership trends: statistical analysis of homeland security secretaries’ undergraduate institutions against departmental performance metrics
- Political consulting briefings: generating quick-reference briefs on each secretary’s educational background for debate prep and advisor recommendations
- HR compliance audits: automating verification of past Secretaries’ bachelor’s degree credentials for internal government audits and record-keeping
- Data journalism dashboards: building interactive timelines that visualize each secretary’s term alongside their undergraduate institution for public engagement pieces
- University data science curriculum: demonstrating real-world web scraping and data extraction techniques by fetching and parsing cabinet member education details
- Non-profit diversity analysis: mapping the educational diversity of homeland security leadership to support advocacy for broader academic representation in government roles

```
import requests
import os
import re
import json
from bs4 import BeautifulSoup
import time

# Define workspace directory
workspace_dir = 'workspace'
os.makedirs(workspace_dir, exist_ok=True)

print("Starting search for US Secretaries of Homeland Security and their education...")

# Function to perform web requests with exponential backoff
def fetch_with_backoff(url, max_retries=5):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    for attempt in range(max_retries):
        try:
            print(f"Attempt {attempt + 1} to fetch URL: {url}")
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            return response
        except requests.exceptions.RequestException as e:
            wait_time = 2 ** attempt
            if attempt < max_retries - 1:
                print(f"Error: {e}. Retrying in {wait_time} seconds...")
                time.sleep(wait_time)
            else:
                print(f"Failed after {max_retries} attempts: {e}")
                return None

# Fetch list of US Secretaries of Homeland Security from Wikipedia
print("Fetching list of Secretaries from Wikipedia...")
wiki_url = "https://en.wikipedia.org/wiki/United_States_Secretary_of_Homeland_Security"
wiki_response = fetch_with_backoff(wiki_url)

if not wiki_response:
    print("Failed to fetch Wikipedia page. Exiting.")
    exit(1)

# Parse the Wikipedia page to extract secretaries and their tenures
wiki_soup = BeautifulSoup(wiki_response.content, 'html.parser')

# Find the table with secretaries
secretaries_table = None
for table in wiki_soup.find_all('table', class_='wikitable'):
    # Look for a table that has headers containing "No.", "Portrait", "Name", etc.
    headers = [th.get_text().strip() for th in table.find_all('th')]
    if "No." in headers and "Name" in headers and "Term of office" in headers:
        secretaries_table = table
        break

if not secretaries_table:
    print("Could not find the secretaries table on the Wikipedia page. Exiting.")
    exit(1)

# Extract secretaries' information
secretaries = []
for row in secretaries_table.find_all('tr')[1:]:  # Skip the header row
    cells = row.find_all(['th', 'td'])
    if len(cells) >= 3:  # Make sure there are enough cells
        # Extract name
        name_cell = cells[2]  # Assuming name is in the third column
        name_text = name_cell.get_text().strip()
        
        # Skip if it contains "Acting"
        if "Acting" in name_text:
            continue
            
        name = re.sub(r'\[.*?\]', '', name_text).strip()  # Remove reference tags
        
        # Extract term of office
        term_cell = cells[3] if len(cells) > 3 else None  # Assuming term is in the fourth column
        term_text = term_cell.get_text().strip() if term_cell else ""
        
        # Extract end date to check if before April 2019
        end_date_match = re.search(r'(\w+ \d+, \d{4})\s*[–—-]\s*(\w+ \d+, \d{4}|Incumbent|present)', term_text, re.IGNORECASE)
        
        if end_date_match:
            end_date = end_date_match.group(2)
            # If the secretary's term ended after April 2019 or is still serving, we'll include them
            # because we want secretaries who served prior to April 2019 (including those still in office then)
            if "Incumbent" in end_date or "present" in end_date.lower():
                # Check start date to see if they were in office before April 2019
                start_date = end_date_match.group(1)
                start_year_match = re.search(r'\d{4}', start_date)
                if start_year_match and int(start_year_match.group(0)) < 2019:
                    # Started before 2019, so they served before April 2019
                    pass
                elif start_year_match and int(start_year_match.group(0)) == 2019:
                    # Started in 2019, check month
                    start_month_match = re.search(r'(January|February|March|April|May|June|July|August|September|October|November|December)', start_date)
                    if start_month_match and start_month_match.group(1) in ["January", "February", "March", "April"]:
                        # Started in Jan-Apr 2019
                        pass
                    else:
                        # Started after April 2019
                        continue
            else:
                # Not incumbent, check if their term ended before April 2019
                end_year_match = re.search(r'\d{4}', end_date)
                if end_year_match:
                    end_year = int(end_year_match.group(0))
                    if end_year > 2019:
                        # Ended after 2019
                        pass
                    elif end_year < 2019:
                        # Ended before 2019
                        pass
                    else:  # end_year == 2019
                        # Ended in 2019, check month
                        end_month_match = re.search(r'(January|February|March|April|May|June|July|August|September|October|November|December)', end_date)
                        if end_month_match:
                            end_month = end_month_match.group(1)
                            months = ["January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December"]
                            if months.index(end_month) >= 4:  # May or later
                                # Ended after April 2019
                                pass
                        
        # Get Wikipedia link for more details
        wiki_link = None
        for a in name_cell.find_all('a'):
            if a.has_attr('href') and '/wiki/' in a['href']:
                wiki_link = "https://en.wikipedia.org" + a['href']
                break
                
        secretaries.append({
            'name': name,
            'term': term_text,
            'wiki_link': wiki_link
        })

print(f"Found {len(secretaries)} Secretaries of Homeland Security who served before April 2019 (excluding acting secretaries)")

# Function to extract educational background from a secretary's Wikipedia page
def get_education_background(wiki_link):
    print(f"Fetching education details from: {wiki_link}")
    response = fetch_with_backoff(wiki_link)
    if not response:
        return "Education information not available"
    
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # Look for education information in the infobox
    infobox = soup.find('table', class_='infobox')
    if infobox:
        education = None
        for row in infobox.find_all('tr'):
            header = row.find('th')
            if header and ('Education' in header.get_text() or 'Alma mater' in header.get_text()):
                education = row.find('td').get_text().strip()
                return education
    
    # If not found in infobox, look in the content
    content = soup.find('div', class_='mw-parser-output')
    if content:
        paragraphs = content.find_all('p')
        education_keywords = ['graduate', 'graduated', 'degree', 'university', 'college', 'B.A.', 'B.S.', 'bachelor', 'education']
        
        for paragraph in paragraphs:
            text = paragraph.get_text().lower()
            if any(keyword in text for keyword in education_keywords):
                return paragraph.get_text().strip()
    
    return "Education information not found"

# Enhance secretaries data with education information
print("\nRetrieving educational background for each Secretary...")
for secretary in secretaries:
    if secretary['wiki_link']:
        education = get_education_background(secretary['wiki_link'])
        secretary['education'] = education
        # Extract bachelor's degree information if possible
        bachelor_match = re.search(r'(bachelor[\w\s]*|B\.?A\.?|B\.?S\.?)[\s\w]*(?:from|at)\s+([\w\s&,\.]+)', education, re.IGNORECASE)
        if bachelor_match:
            secretary['bachelors_degree'] = bachelor_match.group(2).strip()
        else:
            # Try a more generic search for university names
            university_match = re.search(r'(University|College)\s+of\s+[\w\s&,\.]+|[\w\s&,\.]+\s+(University|College)', education)
            if university_match:
                secretary['bachelors_degree'] = university_match.group(0).strip()
            else:
                secretary['bachelors_degree'] = "Not specifically identified"
    else:
        secretary['education'] = "Wikipedia link not available"
        secretary['bachelors_degree'] = "Unknown"

# Save the results
results_file = os.path.join(workspace_dir, 'homeland_security_secretaries.json')
with open(results_file, 'w') as f:
    json.dump(secretaries, f, indent=4)

print(f"\nResults saved to {results_file}")

# Print a summary of the findings
print("\nSummary of US Secretaries of Homeland Security who served prior to April 2019:")
print("-" * 80)
for secretary in secretaries:
    print(f"Name: {secretary['name']}")
    print(f"Term: {secretary['term']}")
    print(f"Bachelor's Degree: {secretary.get('bachelors_degree', 'Unknown')}")
    print("-" * 80)

```