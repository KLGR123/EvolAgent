### Development Step 1: Parse Excel to Identify Steam Locomotives in North American Railroad Museum and Calculate Total Wheels

**Description**: Parse and analyze the attached Excel file data/gaia/2023/validation/54612da3-fd56-4941-80f4-5eb82330de25.xlsx to extract locomotive data from the North American railroad museum collection. Identify all steam locomotives in the collection by examining locomotive types, wheel configurations, or other identifying characteristics, then calculate the total number of wheels for all steam locomotives listed.

**Use Cases**:
- Museum collection inventory automation for the North American Railroad Museum, extracting steam locomotive types and calculating total wheel counts to streamline maintenance schedules
- Historical research data extraction for mechanical engineering theses, analyzing wheel configurations of 19th-century steam engines from archival Excel records
- Digital exhibit content generation for a virtual railway tour app, transforming locomotive specifications and wheel arrangements into interactive user interfaces
- Restoration project planning for heritage railway societies, using aggregated wheel counts and configuration data to estimate material needs and labor costs
- Grant proposal preparation and KPI reporting for museum curators, leveraging steam locomotive prevalence and wheel-count metrics to support funding requests
- University data science coursework on real-world Excel parsing, teaching students to identify steam locomotives and compute total wheels using openpyxl and pandas
- Archival metadata ingestion for library and museum catalogs, automating extraction of locomotive builder, class, and wheel configuration details into digital repositories
- Performance benchmarking of Python Excel-processing workflows in industrial heritage analysis, comparing data-only loads and regex searches on locomotive collections

```
import os
import pandas as pd
from openpyxl import load_workbook
import json

# The path to the Excel file to be analyzed
xlsx_path = "data/gaia/2023/validation/54612da3-fd56-4941-80f4-5eb82330de25.xlsx"

print("=== NORTH AMERICAN RAILROAD MUSEUM - LOCOMOTIVE DATA ANALYSIS ===\n")
print(f"Analyzing file: {xlsx_path}")

# Check if file exists
if not os.path.exists(xlsx_path):
    print(f"Error: Excel file '{xlsx_path}' does not exist.")
    exit()

print(f"File exists: {xlsx_path}")
file_size = os.path.getsize(xlsx_path)
print(f"File size: {file_size} bytes")

# Load workbook with openpyxl to examine structure and formatting
print("\nLoading workbook with openpyxl to examine structure...")
wb = load_workbook(xlsx_path, data_only=True)  # Use data_only=True to get calculated values

print(f"Number of worksheets: {len(wb.worksheets)}")
print(f"Worksheet names: {[sheet.title for sheet in wb.worksheets]}")

# Examine each worksheet
for sheet_idx, sheet in enumerate(wb.worksheets):
    print(f"\n=== ANALYZING WORKSHEET: {sheet.title} ===\n")
    
    max_row = sheet.max_row
    max_col = sheet.max_column
    print(f"Sheet dimensions: {max_row} rows x {max_col} columns")
    
    # Get the range of actual data
    min_row = sheet.min_row
    min_col = sheet.min_column
    print(f"Data range: rows {min_row}-{max_row}, columns {min_col}-{max_col}")
    
    print("\n=== FIRST 15 ROWS PREVIEW ===\n")
    # Display first 15 rows to understand structure
    for row in range(min_row, min(max_row + 1, min_row + 15)):
        row_data = []
        for col in range(min_col, max_col + 1):
            cell = sheet.cell(row=row, column=col)
            cell_value = cell.value if cell.value is not None else ""
            row_data.append(str(cell_value))
        print(f"Row {row}: {row_data}")
    
    print("\n=== COLUMN HEADERS ANALYSIS ===\n")
    # Examine the first row as potential headers
    headers = []
    for col in range(min_col, max_col + 1):
        cell = sheet.cell(row=min_row, column=col)
        header_value = cell.value if cell.value is not None else f"Col_{col}"
        headers.append(str(header_value))
        print(f"Column {col}: '{header_value}'")
    
    print(f"\nIdentified headers: {headers}")
    
    # Look for locomotive-related keywords in headers and data
    print("\n=== SEARCHING FOR LOCOMOTIVE-RELATED DATA ===\n")
    locomotive_keywords = ['locomotive', 'engine', 'steam', 'diesel', 'electric', 'number', 'id', 'type', 'wheel', 'configuration', 'class', 'model', 'road', 'builder']
    
    found_keywords = []
    for header in headers:
        header_lower = header.lower()
        for keyword in locomotive_keywords:
            if keyword in header_lower:
                found_keywords.append({
                    'header': header,
                    'keyword': keyword,
                    'column_index': headers.index(header)
                })
                print(f"Found keyword '{keyword}' in header: '{header}'")
    
    print(f"\nTotal locomotive-related keywords found in headers: {len(found_keywords)}")
    
    # Sample some data rows to understand content
    print("\n=== DATA SAMPLE (Rows 2-10) ===\n")
    for row in range(min_row + 1, min(max_row + 1, min_row + 10)):
        if row <= max_row:
            print(f"Row {row}:")
            for col_idx, col in enumerate(range(min_col, max_col + 1)):
                cell = sheet.cell(row=row, column=col)
                cell_value = cell.value if cell.value is not None else ""
                header = headers[col_idx] if col_idx < len(headers) else f"Col_{col}"
                print(f"  {header}: '{cell_value}' (type: {type(cell_value)})")
    
    # Search for steam locomotive indicators
    print("\n=== SEARCHING FOR STEAM LOCOMOTIVE INDICATORS ===\n")
    steam_indicators = ['steam', 'wheel', 'configuration', 'class']
    steam_found = []
    
    for row in range(min_row, min(max_row + 1, min_row + 20)):
        for col in range(min_col, max_col + 1):
            cell = sheet.cell(row=row, column=col)
            if cell.value and isinstance(cell.value, str):
                cell_text = cell.value.lower()
                for indicator in steam_indicators:
                    if indicator in cell_text:
                        steam_found.append({
                            'row': row,
                            'col': col,
                            'value': cell.value,
                            'header': headers[col - min_col] if (col - min_col) < len(headers) else f"Col_{col}",
                            'indicator': indicator
                        })
                        print(f"Found '{indicator}' at ({row}, {col}): '{cell.value}'")
    
    print(f"\nTotal steam locomotive indicators found: {len(steam_found)}")

# Also load with pandas for easier data manipulation
print("\n" + "="*60)
print("PANDAS DATAFRAME ANALYSIS")
print("="*60)

try:
    # Try to read the Excel file with pandas
    df_dict = pd.read_excel(xlsx_path, sheet_name=None)  # Read all sheets
    
    print(f"\nPandas successfully loaded {len(df_dict)} sheet(s)")
    
    for sheet_name, sheet_df in df_dict.items():
        print(f"\n=== PANDAS ANALYSIS: {sheet_name} ===\n")
        print(f"DataFrame shape: {sheet_df.shape}")
        print(f"Column names: {list(sheet_df.columns)}")
        print(f"Data types:\n{sheet_df.dtypes}")
        
        print("\nFirst 10 rows:")
        print(sheet_df.head(10).to_string())
        
        print("\nBasic statistics for numeric columns:")
        numeric_cols = sheet_df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            print(sheet_df[numeric_cols].describe())
        else:
            print("No numeric columns found")
        
        print("\nMissing values:")
        print(sheet_df.isnull().sum())
        
        # Look for locomotive-specific columns
        print("\n=== LOCOMOTIVE-SPECIFIC COLUMN IDENTIFICATION ===\n")
        column_names = [col.lower() for col in sheet_df.columns]
        
        potential_id_cols = [col for col in sheet_df.columns if any(keyword in col.lower() for keyword in ['number', 'id', 'locomotive', 'engine', 'road'])]
        potential_type_cols = [col for col in sheet_df.columns if any(keyword in col.lower() for keyword in ['type', 'class', 'model', 'steam', 'diesel', 'wheel', 'configuration'])]
        potential_builder_cols = [col for col in sheet_df.columns if any(keyword in col.lower() for keyword in ['builder', 'manufacturer', 'built', 'date'])]
        
        print(f"Potential locomotive ID columns: {potential_id_cols}")
        print(f"Potential locomotive type columns: {potential_type_cols}")
        print(f"Potential builder columns: {potential_builder_cols}")
        
        # Search for steam locomotives in the dataframe
        print("\n=== SEARCHING FOR STEAM LOCOMOTIVES IN DATA ===\n")
        steam_locomotive_matches = []
        
        for col in sheet_df.columns:
            if sheet_df[col].dtype == 'object':  # String columns
                # Search for steam indicators
                steam_mask = sheet_df[col].astype(str).str.contains('steam', case=False, na=False)
                # Search for wheel configuration patterns (like 0-4-0, 2-6-2, etc.)
                wheel_config_mask = sheet_df[col].astype(str).str.contains(r'\d+-\d+-\d+', case=False, na=False, regex=True)
                
                combined_mask = steam_mask | wheel_config_mask
                
                if combined_mask.any():
                    matches = sheet_df[combined_mask]
                    print(f"Found potential steam locomotive matches in column '{col}':")
                    for idx, row in matches.iterrows():
                        print(f"  Row {idx}: {row[col]}")
                        steam_locomotive_matches.append({
                            'row_index': idx,
                            'column': col,
                            'value': row[col],
                            'full_row': row.to_dict()
                        })
        
        print(f"\nTotal potential steam locomotive matches found: {len(steam_locomotive_matches)}")
        
except Exception as e:
    print(f"Error reading with pandas: {e}")
    print("Will proceed with openpyxl analysis only")

# Save initial analysis
analysis_data = {
    'file_path': xlsx_path,
    'file_size': file_size,
    'worksheets': [sheet.title for sheet in wb.worksheets],
    'analysis_timestamp': pd.Timestamp.now().isoformat()
}

with open('workspace/locomotive_museum_analysis_initial.json', 'w') as f:
    json.dump(analysis_data, f, indent=2)

print(f"\nInitial analysis saved to: workspace/locomotive_museum_analysis_initial.json")
print("Next step: Extract steam locomotive data and calculate total wheel count")
```