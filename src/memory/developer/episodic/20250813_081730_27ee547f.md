### Development Step 5: Abel Hugo’s Napoleonic Service, Spanish Campaign Map Authorship, Madrid’s Hospital de Saint Louis, Reign Timeline

**Description**: Research Abel Hugo, Victor Hugo's brother, focusing on his military service during the Napoleonic Wars and his time in Madrid. Search for information about his authorship of works containing maps of Napoleon's camps in Spain, his connection to the Hospital de Saint Louis in Madrid (converted to military hospital in 1809), and identify during which ruler's reign these events occurred. Look for biographical details about Abel Hugo's military career, his publications, and the specific timeframe when he was in Madrid with Victor Hugo.

**Use Cases**:
- Automated extraction of Abel Hugo’s Napoleonic War service details to support a military history journal’s article on French officers in the Peninsular War
- Integration of Abel Hugo’s 1809 Madrid hospital connections into a museum exhibit’s digital timeline for interactive visitor storytelling
- Creation of a GIS-ready dataset of Napoleon’s camp locations in Spain by parsing Abel Hugo’s map publications for a historical mapping platform
- Populating an academic bibliography generator with Abel Hugo’s authored works for graduate researchers in French Romantic literature
- Building a web-based biographical profile of Abel Hugo for an educational portal on Victor Hugo’s family and their roles during the Napoleonic era
- Curating content for a virtual museum display by linking Abel Hugo’s publications and keywords (e.g., “madrid,” “military hospital”) with multimedia assets
- Enriching a digital library’s knowledge graph with Abel Hugo’s military career and publication metadata for enhanced search and cross-referencing
- Supporting genealogical researchers by extracting and cross-verifying Abel Hugo’s life events (e.g., Madrid stay under Joseph Bonaparte) from multilingual Wikipedia sources

```
import requests
import json
import os
from datetime import datetime
from bs4 import BeautifulSoup
import time

print("Final Abel Hugo research with simplified Wikipedia parsing...")

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

# Initialize results storage
all_results = []
search_errors = []

print("\n=== SIMPLIFIED WIKIPEDIA SEARCH FOR ABEL HUGO ===")

# Wikipedia URLs to search
wikipedia_urls = [
    "https://en.wikipedia.org/wiki/Abel_Hugo",
    "https://fr.wikipedia.org/wiki/Abel_Hugo",  # French Wikipedia often has more details
    "https://en.wikipedia.org/wiki/Victor_Hugo",
    "https://en.wikipedia.org/wiki/Napoleonic_Wars",
    "https://en.wikipedia.org/wiki/Peninsular_War",
    "https://en.wikipedia.org/wiki/Madrid"
]

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

for url in wikipedia_urls:
    try:
        print(f"\nFetching: {url}")
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Extract title
        title_elem = soup.find('h1', class_='firstHeading')
        title = title_elem.get_text(strip=True) if title_elem else 'Unknown Title'
        print(f"Page title: {title}")
        
        # Extract main content - SIMPLIFIED APPROACH
        content_div = soup.find('div', {'id': 'mw-content-text'})
        if content_div:
            # Simply remove scripts and styles - no complex class checking
            for unwanted in content_div.find_all(['script', 'style']):
                unwanted.decompose()
            
            # Remove common navigation elements by tag and simple class checks
            for nav in content_div.find_all('div'):
                nav_class = nav.get('class')
                if nav_class and isinstance(nav_class, list):
                    nav_class_joined = ' '.join(nav_class)
                    if 'navbox' in nav_class_joined or 'infobox' in nav_class_joined:
                        nav.decompose()
            
            content = content_div.get_text(separator=' ', strip=True)
            print(f"Content length: {len(content)} characters")
            
            # Target keywords for Abel Hugo research
            target_keywords = [
                'abel hugo', 'victor hugo', 'napoleonic wars', 'madrid', 'spain', 
                'military service', 'military hospital', 'hospital',
                'napoleon', 'camps', 'maps', 'publications', 'author', 'brother',
                '1809', 'peninsular war', 'french army', 'officer', 'career',
                'joseph bonaparte', 'ferdinand vii', 'saint louis', 'saint-louis'
            ]
            
            # Find matching keywords
            content_lower = content.lower()
            found_keywords = []
            for keyword in target_keywords:
                if keyword in content_lower:
                    found_keywords.append(keyword)
            
            print(f"Keywords found: {', '.join(found_keywords)}")
            
            if found_keywords:
                result = {
                    'title': title,
                    'url': url,
                    'content': content[:5000],  # First 5000 characters
                    'keywords_found': found_keywords,
                    'source': 'Wikipedia',
                    'relevance_score': len(found_keywords)
                }
                all_results.append(result)
                print(f"Added relevant result with {len(found_keywords)} keyword matches")
                
                # Special handling for Abel Hugo content
                if 'abel hugo' in content_lower:
                    print("\n*** ABEL HUGO BIOGRAPHICAL CONTENT FOUND ***")
                    # Extract key information about Abel Hugo
                    content_sentences = content.split('.')
                    abel_info = []
                    
                    for sentence in content_sentences:
                        sentence_clean = sentence.strip()
                        sentence_lower = sentence_clean.lower()
                        
                        # Look for sentences mentioning Abel Hugo
                        if ('abel hugo' in sentence_lower or 
                            ('abel' in sentence_lower and 'hugo' in sentence_lower)) and len(sentence_clean) > 20:
                            abel_info.append(sentence_clean)
                    
                    print(f"Found {len(abel_info)} informative sentences about Abel Hugo:")
                    for i, info in enumerate(abel_info[:6], 1):
                        print(f"  {i}. {info[:300]}...")
                    
                    # Look for specific details
                    military_mentions = []
                    madrid_mentions = []
                    publication_mentions = []
                    
                    for info in abel_info:
                        info_lower = info.lower()
                        if any(term in info_lower for term in ['military', 'army', 'officer', 'service', 'war']):
                            military_mentions.append(info)
                        if 'madrid' in info_lower:
                            madrid_mentions.append(info)
                        if any(term in info_lower for term in ['author', 'wrote', 'published', 'work', 'book']):
                            publication_mentions.append(info)
                    
                    if military_mentions:
                        print(f"\n  Military references: {len(military_mentions)}")
                        for mil in military_mentions[:2]:
                            print(f"    - {mil[:200]}...")
                    
                    if madrid_mentions:
                        print(f"\n  Madrid references: {len(madrid_mentions)}")
                        for mad in madrid_mentions[:2]:
                            print(f"    - {mad[:200]}...")
                    
                    if publication_mentions:
                        print(f"\n  Publication references: {len(publication_mentions)}")
                        for pub in publication_mentions[:2]:
                            print(f"    - {pub[:200]}...")
            
        time.sleep(2)  # Be respectful to Wikipedia
        
    except Exception as e:
        error_msg = f"Error fetching {url}: {str(e)}"
        print(error_msg)
        search_errors.append(error_msg)

# Load existing Google Books results if available
print(f"\n=== LOADING PREVIOUS GOOGLE BOOKS RESULTS ===")
existing_files = ['abel_hugo_final_research.json', 'abel_hugo_complete_research.json']
existing_google_books = []

for filename in existing_files:
    filepath = f'workspace/{filename}'
    if os.path.exists(filepath):
        print(f"Loading existing results from: {filepath}")
        try:
            with open(filepath, 'r') as f:
                existing_data = json.load(f)
            
            existing_results = existing_data.get('all_results', [])
            google_books = [r for r in existing_results if r.get('source') == 'Google Books']
            existing_google_books.extend(google_books)
            print(f"Found {len(google_books)} Google Books results")
            
        except Exception as e:
            print(f"Error loading {filepath}: {str(e)}")

# Remove duplicates from Google Books results
seen_titles = set()
unique_google_books = []
for book in existing_google_books:
    title = book.get('title', '')
    if title not in seen_titles:
        seen_titles.add(title)
        unique_google_books.append(book)

print(f"Unique Google Books results: {len(unique_google_books)}")

# Combine all results
all_results.extend(unique_google_books)
all_results.sort(key=lambda x: x['relevance_score'], reverse=True)

print(f"\n=== COMPREHENSIVE ABEL HUGO ANALYSIS ===")
print(f"Total results: {len(all_results)}")
print(f"Wikipedia results: {len([r for r in all_results if r['source'] == 'Wikipedia'])}")
print(f"Google Books results: {len([r for r in all_results if r['source'] == 'Google Books'])}")

# Analyze all results for Abel Hugo information
abel_hugo_findings = {
    'military_service': [],
    'madrid_time': [],
    'napoleon_maps': [],
    'hospital_connections': [],
    'publications': [],
    'timeframe_1809': [],
    'ruler_context': [],
    'family_relations': [],
    'biographical_summary': []
}

for result in all_results:
    # Get content for analysis
    if 'content' in result:
        text = result['content'].lower()
        original_text = result['content']
    elif 'description' in result:
        text = result['description'].lower()
        original_text = result['description']
    else:
        text = result.get('title', '').lower()
        original_text = result.get('title', '')
    
    # Analyze for Abel Hugo relevance
    if 'abel hugo' in text or ('abel' in text and 'hugo' in text and 'victor' in text):
        print(f"\nAnalyzing: {result['title']}")
        
        # Military service
        if any(term in text for term in ['military', 'army', 'officer', 'service', 'soldier', 'war', 'campaign']):
            abel_hugo_findings['military_service'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'content': original_text[:1000],
                'keywords': result['keywords_found']
            })
            print("  ✓ Military service info")
        
        # Madrid connections
        if 'madrid' in text:
            abel_hugo_findings['madrid_time'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'content': original_text[:1000],
                'keywords': result['keywords_found']
            })
            print("  ✓ Madrid connection")
        
        # Napoleon maps/camps
        if 'napoleon' in text and ('maps' in text or 'camps' in text):
            abel_hugo_findings['napoleon_maps'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'content': original_text[:1000],
                'keywords': result['keywords_found']
            })
            print("  ✓ Napoleon maps/camps")
        
        # Hospital connections
        if 'hospital' in text:
            abel_hugo_findings['hospital_connections'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'content': original_text[:1000],
                'keywords': result['keywords_found']
            })
            print("  ✓ Hospital connection")
        
        # Publications
        if any(term in text for term in ['author', 'wrote', 'published', 'publication', 'work', 'book']):
            abel_hugo_findings['publications'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'content': original_text[:1000],
                'keywords': result['keywords_found']
            })
            print("  ✓ Publications")
        
        # 1809 timeframe
        if '1809' in text:
            abel_hugo_findings['timeframe_1809'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'content': original_text[:1000],
                'keywords': result['keywords_found']
            })
            print("  ✓ 1809 timeframe")
        
        # Ruler context
        if any(ruler in text for ruler in ['joseph bonaparte', 'napoleon', 'ferdinand']):
            abel_hugo_findings['ruler_context'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'content': original_text[:1000],
                'keywords': result['keywords_found']
            })
            print("  ✓ Ruler context")
        
        # Family relations
        if 'victor hugo' in text and 'brother' in text:
            abel_hugo_findings['family_relations'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'content': original_text[:1000],
                'keywords': result['keywords_found']
            })
            print("  ✓ Family relations")
        
        # Add to biographical summary
        abel_hugo_findings['biographical_summary'].append({
            'source': result['title'],
            'url': result.get('url', ''),
            'content': original_text[:1200],
            'keywords': result['keywords_found'],
            'relevance_score': result['relevance_score']
        })

# Save final comprehensive research
final_research = {
    'research_date': datetime.now().isoformat(),
    'research_focus': 'Abel Hugo - Victor Hugo\'s brother: military service during Napoleonic Wars, Madrid connections, Napoleon camp maps, Hospital de Saint Louis, publications, ruler context',
    'search_summary': {
        'total_results': len(all_results),
        'wikipedia_results': len([r for r in all_results if r['source'] == 'Wikipedia']),
        'google_books_results': len([r for r in all_results if r['source'] == 'Google Books']),
        'search_errors': len(search_errors)
    },
    'all_results': all_results,
    'abel_hugo_findings': abel_hugo_findings,
    'search_errors': search_errors
}

output_file = 'workspace/abel_hugo_final_comprehensive_research.json'
with open(output_file, 'w') as f:
    json.dump(final_research, f, indent=2)

print(f"\n{'='*80}")
print("ABEL HUGO RESEARCH FINAL SUMMARY")
print(f"{'='*80}")
print(f"Complete research saved to: {output_file}")
print(f"Total results analyzed: {len(all_results)}")
print(f"Wikipedia pages successfully processed: {len([r for r in all_results if r['source'] == 'Wikipedia'])}")
print(f"Google Books results included: {len([r for r in all_results if r['source'] == 'Google Books'])}")

# Display key findings
print(f"\n=== ABEL HUGO KEY RESEARCH FINDINGS ===")
for category, findings in abel_hugo_findings.items():
    if findings and category != 'biographical_summary':
        print(f"\n{category.replace('_', ' ').title()}: {len(findings)} sources found")
        # Show best source for this category
        best_source = max(findings, key=lambda x: len(x.get('keywords', [])))
        print(f"  Primary source: {best_source['source']}")
        print(f"  Keywords: {', '.join(best_source.get('keywords', []))}")
        print(f"  Content sample: {best_source['content'][:250]}...")

# Display top overall sources
print(f"\n=== TOP SOURCES FOR ABEL HUGO RESEARCH ===")
for i, result in enumerate(all_results[:6], 1):
    print(f"\n{i}. {result['title']} (Score: {result['relevance_score']})")
    print(f"   Source: {result['source']}")
    if 'authors' in result:
        print(f"   Authors: {', '.join(result['authors'])}")
    print(f"   Keywords: {', '.join(result['keywords_found'])}")
    
    if 'content' in result:
        print(f"   Preview: {result['content'][:200]}...")
    elif 'description' in result:
        print(f"   Description: {result['description'][:200]}...")

print(f"\n=== SEARCH ERRORS ===")
if search_errors:
    print(f"Encountered {len(search_errors)} errors:")
    for error in search_errors:
        print(f"  - {error}")
else:
    print("No search errors - all sources processed successfully!")

print(f"\nAbel Hugo research completed! Check {output_file} for complete findings.")
```