### Development Step 4: Download ‘A Dark Trace’ Open Access PDF, Extract Chapter 2 to Identify Endopsychic Myths Author

**Description**: Access and download the full text of 'A Dark Trace: Sigmund Freud on the Sense of Guilt' by H. Westerink from Project MUSE using DOI 10.1353/book.24372. Since the book was confirmed to be open access, retrieve the complete text and save it to workspace/dark_trace_freud_book.pdf or appropriate format. Focus on locating and extracting Chapter 2 content to identify the author who influenced Freud's belief in 'endopsychic myths'. If the full book is not directly downloadable, extract Chapter 2 specifically or access the book's table of contents to determine the exact chapter title and content structure.

**Use Cases**:
- Academic psychoanalytic researchers automating extraction of Chapter 2 from “A Dark Trace” to systematically review Freud’s conceptualization of endopsychic myths across primary sources
- Digital humanities scholars building a searchable corpus of philosophical influences on Freudian guilt by scraping open-access chapters via DOI-based access scripts
- University librarians ingesting open-access book PDFs and parsing Chapter 2 metadata to streamline cataloging and improve digital library discoverability
- NLP engineers curating a domain-specific text dataset by extracting passages on Freud’s influences from Chapter 2 for machine-learning models analyzing psychoanalytic discourse
- Graduate students generating annotated excerpts of Jungian and Nietzschean references in Chapter 2 to support literature reviews in their theses on psychoanalytic genealogy
- E-learning content developers embedding targeted psychoanalytic chapter content into online course modules by automating retrieval of specific chapters from Project MUSE
- Open-access compliance officers validating and archiving Chapter 2 downloads to ensure licensing adherence and long-term preservation in institutional repositories
- Legal historians retrieving and analyzing Chapter 2 discussions of guilt theories to trace historical legal concepts in interdisciplinary law research

```
import os
import json
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import time

print('=== INVESTIGATING PROJECT MUSE BOOK ACCESS FOR CHAPTER 2 ===')
print('Objective: Access Chapter 2 "Dark Traces" (pages 37-56) to find author who influenced Freud\'s "endopsychic myths"\n')

# First, inspect the saved Project MUSE book page analysis
book_analysis_file = 'workspace/project_muse_book_page.json'

if os.path.exists(book_analysis_file):
    print('=== INSPECTING PROJECT MUSE BOOK PAGE ANALYSIS ===')
    with open(book_analysis_file, 'r', encoding='utf-8') as f:
        book_data = json.load(f)
    
    print(f'Book analysis keys: {list(book_data.keys())}')
    
    for key, value in book_data.items():
        if isinstance(value, (str, bool, int)):
            print(f'{key}: {value}')
        elif isinstance(value, list):
            print(f'{key}: List with {len(value)} items')
            if len(value) > 0:
                print(f'  Sample: {value[0]}')
        elif isinstance(value, dict):
            print(f'{key}: Dictionary with keys {list(value.keys())}')
    
    print(f'\nKey findings:')
    print(f'Book URL: {book_data.get("url", "Unknown")}')
    print(f'Title: {book_data.get("title", "Unknown")}')
    print(f'Book title: {book_data.get("book_title", "Unknown")}')
    print(f'Chapter 2 found: {book_data.get("chapter_2_found", False)}')
    print(f'Open access: {book_data.get("is_open_access", False)}')
    print(f'Access links: {len(book_data.get("access_links", []))}')
    print(f'Preview links: {len(book_data.get("preview_links", []))}')
else:
    print(f'Book analysis file not found: {book_analysis_file}')

print('\n=== TRYING CHAPTER-SPECIFIC ACCESS METHODS ===')

# Since we know it's Chapter 2 on pages 37-56, try different URL patterns
base_url = 'https://muse.jhu.edu/book/24372'
book_id = '24372'

# Possible chapter access URLs
chapter_urls = [
    f'https://muse.jhu.edu/book/{book_id}/chapter/2',
    f'https://muse.jhu.edu/chapter/{book_id}/2',
    f'https://muse.jhu.edu/book/{book_id}/ch/2',
    f'https://muse.jhu.edu/book/{book_id}/read/chapter/2',
    f'https://muse.jhu.edu/book/{book_id}/view/chapter/2',
    f'{base_url}/chapter/2',
    f'{base_url}/ch/2',
    f'{base_url}/read/2',
    f'{base_url}/view/2'
]

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Referer': base_url
}

successful_chapter_urls = []

print('Trying chapter-specific URL patterns:')
for i, chapter_url in enumerate(chapter_urls, 1):
    print(f'\n{i}. Testing: {chapter_url}')
    try:
        response = requests.get(chapter_url, headers=headers, timeout=20)
        print(f'   Status: {response.status_code}')
        
        if response.status_code == 200:
            print(f'   *** SUCCESS - Chapter URL accessible ***')
            print(f'   Final URL: {response.url}')
            print(f'   Content length: {len(response.content):,} bytes')
            
            successful_chapter_urls.append({
                'original_url': chapter_url,
                'final_url': response.url,
                'content_length': len(response.content),
                'response': response
            })
        elif response.status_code == 302 or response.status_code == 301:
            print(f'   Redirect to: {response.headers.get("Location", "Unknown")}')
    except Exception as e:
        print(f'   Error: {str(e)}')

if successful_chapter_urls:
    print(f'\n=== ANALYZING SUCCESSFUL CHAPTER ACCESS ===')
    
    # Use the first successful URL
    chapter_access = successful_chapter_urls[0]
    chapter_response = chapter_access['response']
    
    print(f'Analyzing content from: {chapter_access["final_url"]}')
    
    soup = BeautifulSoup(chapter_response.content, 'html.parser')
    
    # Get page title
    page_title = soup.find('title')
    if page_title:
        print(f'Page title: {page_title.get_text().strip()}')
    
    # Look for chapter content
    chapter_content_selectors = [
        'div.chapter-content',
        'div.content',
        'div.main-content',
        'div.text-content',
        'article',
        'main',
        'div[id*="chapter"]',
        'div[class*="chapter"]'
    ]
    
    chapter_content = None
    for selector in chapter_content_selectors:
        content_elem = soup.select_one(selector)
        if content_elem:
            chapter_content = content_elem
            print(f'Chapter content found with selector: {selector}')
            break
    
    if not chapter_content:
        # Fall back to main content area
        chapter_content = soup.find('body')
        print('Using full body content as fallback')
    
    if chapter_content:
        # Extract text content
        chapter_text = chapter_content.get_text()
        
        print(f'\nChapter content length: {len(chapter_text):,} characters')
        print(f'First 500 characters: {chapter_text[:500]}...')
        
        # Search for key terms related to "endopsychic myths"
        search_terms = [
            'endopsychic myth',
            'endopsychic',
            'myth',
            'mythology',
            'carl jung',
            'jung',
            'nietzsche',
            'schopenhauer',
            'kant',
            'philosophy',
            'influence',
            'influenced'
        ]
        
        print(f'\n=== SEARCHING FOR ENDOPSYCHIC MYTHS REFERENCES ===')
        
        found_terms = {}
        for term in search_terms:
            count = chapter_text.lower().count(term.lower())
            if count > 0:
                found_terms[term] = count
                print(f'Found "{term}": {count} occurrences')
        
        if found_terms:
            print(f'\n=== EXTRACTING RELEVANT PASSAGES ===')
            
            # Focus on "endopsychic" if found
            if any('endopsychic' in term.lower() for term in found_terms.keys()):
                print('Extracting passages about "endopsychic":')  
                
                text_lower = chapter_text.lower()
                endopsychic_positions = []
                start = 0
                while True:
                    pos = text_lower.find('endopsychic', start)
                    if pos == -1:
                        break
                    endopsychic_positions.append(pos)
                    start = pos + 1
                
                for i, pos in enumerate(endopsychic_positions, 1):
                    context_start = max(0, pos - 300)
                    context_end = min(len(chapter_text), pos + 400)
                    context = chapter_text[context_start:context_end]
                    
                    print(f'\nEndopsychic passage {i}:')
                    print(f'Position: {pos}')
                    print(f'Context: ...{context}...')
                    print('-' * 80)
            
            # Also look for author names that might be the influence
            author_names = ['jung', 'nietzsche', 'schopenhauer', 'kant', 'hegel', 'darwin']
            for author in author_names:
                if author in found_terms:
                    print(f'\nExtracting passages mentioning "{author}":')
                    
                    text_lower = chapter_text.lower()
                    author_positions = []
                    start = 0
                    while True:
                        pos = text_lower.find(author, start)
                        if pos == -1:
                            break
                        author_positions.append(pos)
                        start = pos + 1
                    
                    # Show first few occurrences
                    for i, pos in enumerate(author_positions[:3], 1):
                        context_start = max(0, pos - 200)
                        context_end = min(len(chapter_text), pos + 300)
                        context = chapter_text[context_start:context_end]
                        
                        print(f'\n{author.title()} mention {i}:')
                        print(f'Context: ...{context}...')
                        print('-' * 60)
        
        # Save the chapter content for further analysis
        chapter_data = {
            'source_url': chapter_access['final_url'],
            'chapter_title': 'Chapter 2: Dark Traces',
            'content_length': len(chapter_text),
            'full_text': chapter_text,
            'search_terms_found': found_terms,
            'extraction_timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        chapter_file = 'workspace/chapter_2_dark_traces_content.json'
        with open(chapter_file, 'w', encoding='utf-8') as f:
            json.dump(chapter_data, f, indent=2, ensure_ascii=False)
        
        print(f'\n*** CHAPTER 2 CONTENT SUCCESSFULLY EXTRACTED ***')
        print(f'Saved to: {chapter_file}')
        print(f'Content length: {len(chapter_text):,} characters')
        print(f'Search terms found: {len(found_terms)} out of {len(search_terms)}')

else:
    print('\n=== NO DIRECT CHAPTER ACCESS FOUND ===')
    print('Trying alternative access methods...')
    
    # Try accessing the main book page again and look for reading interfaces
    print('\n=== RE-EXAMINING MAIN BOOK PAGE FOR READING OPTIONS ===')
    
    try:
        main_response = requests.get(base_url, headers=headers, timeout=30)
        if main_response.status_code == 200:
            main_soup = BeautifulSoup(main_response.content, 'html.parser')
            
            # Look for "Read Online", "View", or similar buttons
            read_selectors = [
                'a:contains("Read")',
                'a:contains("View")',
                'a:contains("Online")',
                'button:contains("Read")',
                '.read-button',
                '.view-button',
                '.online-access',
                '[data-action="read"]'
            ]
            
            read_links = []
            for selector in read_selectors:
                try:
                    elements = main_soup.select(selector)
                    for elem in elements:
                        href = elem.get('href') or elem.get('data-href')
                        if href:
                            if href.startswith('/'):
                                href = urljoin(base_url, href)
                            read_links.append({
                                'url': href,
                                'text': elem.get_text().strip(),
                                'selector': selector
                            })
                except:
                    pass
            
            print(f'Found {len(read_links)} potential reading links:')
            for i, link in enumerate(read_links, 1):
                print(f'{i}. {link["text"]} -> {link["url"]}')
            
            if read_links:
                print('\nTrying first reading link...')
                try:
                    read_response = requests.get(read_links[0]['url'], headers=headers, timeout=30)
                    print(f'Reading interface status: {read_response.status_code}')
                    print(f'Final URL: {read_response.url}')
                except Exception as read_error:
                    print(f'Error accessing reading interface: {str(read_error)}')
    
    except Exception as main_error:
        print(f'Error re-examining main page: {str(main_error)}')

print('\n=== CHAPTER 2 ACCESS ATTEMPT COMPLETE ===')
print('Summary:')
print('- Tested multiple chapter-specific URL patterns')
print('- Attempted to extract Chapter 2 "Dark Traces" content')
print('- Searched for "endopsychic myths" references and author influences')
print('- Saved any accessible content for analysis')
print('\nObjective: Identify the author who influenced Freud\'s belief in "endopsychic myths"')
print('Status: Analysis of extracted content should reveal the answer')
```