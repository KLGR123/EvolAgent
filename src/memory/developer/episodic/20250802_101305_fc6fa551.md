### Development Step 15: Compile US Presidents’ Birth Cities, States, Coordinates into JSON/CSV at workspace/presidential_birthplaces.json

**Description**: Collect a complete list of all United States presidents with their official birth city names and state names, then obtain the geographic coordinates (longitude and latitude) for each birth city using authoritative sources such as official presidential biographies or Wikipedia infoboxes. Save the results in a structured format (e.g., CSV or JSON) at workspace/presidential_birthplaces.json.

**Use Cases**:
- Interactive museum kiosk mapping Presidential birthplaces with on-screen biographies and multimedia content for visitors
- K-12 educational geography app that lets students locate each President’s birth city on an interactive US map and learn state history
- Tour operator itinerary planner for a “Presidential Heritage Trail” that geocodes birth locations into day-by-day travel routes and logistics
- Data journalism visualization overlaying Presidential birthplace distribution onto electoral college maps for an online news feature
- Historical GIS analysis toolkit for academic researchers studying geographic patterns in early US leadership origins and domestic migration
- Local government heritage program integrating Presidential birthplace coordinates into public walking tours and roadside historical markers
- Travel blog automation that uses geocoded birth data to generate location-based historical content and GPS-guided itinerary suggestions

```
import os
import re
import time
import json
import requests
from bs4 import BeautifulSoup
from geopy.geocoders import Nominatim

# Ensure workspace directory exists
workspace = 'workspace'
os.makedirs(workspace, exist_ok=True)

# 1) Load or fetch the Wikipedia page listing all U.S. presidents
list_path = os.path.join(workspace, 'presidents_list.html')
if os.path.exists(list_path):
    print(f"Loading cached list from {list_path}")
    with open(list_path, 'r', encoding='utf-8') as f:
        list_html = f.read()
else:
    url = 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States'
    print(f"Fetching presidents list from {url}")
    resp = requests.get(url, timeout=10)
    resp.raise_for_status()
    list_html = resp.text
    with open(list_path, 'w', encoding='utf-8') as f:
        f.write(list_html)
    print(f"Saved presidents list to {list_path}")

# 2) Parse the main wikitable of presidents
soup = BeautifulSoup(list_html, 'html.parser')
table = soup.find('table', class_='wikitable')
rows = table.find_all('tr')[1:]
print(f"Found {len(rows)} rows in the presidents table")

# 3) Build list of (name, page_url)
presidents = []
for row in rows:
    cols = row.find_all('td')
    if len(cols) < 2:
        continue
    link = cols[1].find('a', href=True)
    if not link:
        continue
    name = link.get_text(strip=True)
    page_url = 'https://en.wikipedia.org' + link['href']
    presidents.append({'name': name, 'url': page_url})
print(f"Collected {len(presidents)} presidents to process")

# 4) Helper: extract a raw birthplace string from a president's page soup
def extract_birthplace(soup):
    # First try span.birthplace
    span_bp = soup.select_one('span.birthplace')
    if span_bp and span_bp.get_text(strip=True):
        return span_bp.get_text(strip=True)
    # Fallback: infobox Born row
    infobox = soup.find('table', class_=lambda c: c and 'infobox' in c)
    if infobox:
        th = infobox.find('th', string=re.compile('Born'))
        if th:
            tr = th.parent
            td = tr.find('td')
            if td:
                parts = re.split(r'<br\s*/?>', str(td), flags=re.IGNORECASE)
                if len(parts) >= 2:
                    place_html = parts[1]
                    # strip any <small> tags
                    place_html = re.sub(r'<small[^>]*>.*?</small>', '', place_html,
                                        flags=re.DOTALL|re.IGNORECASE)
                    text = BeautifulSoup(place_html, 'html.parser').get_text(separator=' ', strip=True)
                    return text
    return ''

# 5) Initialize geocoder and results list
g = Nominatim(user_agent='presidential_birth_locator')
results = []

# 6) Iterate over each president and gather birthplace & coordinates
for idx, pres in enumerate(presidents, start=1):
    name = pres['name']
    url = pres['url']
    print(f"\n[{idx}/{len(presidents)}] {name}\nFetching: {url}")
    # Fetch page
    try:
        r = requests.get(url, timeout=10)
        r.raise_for_status()
        p_soup = BeautifulSoup(r.text, 'html.parser')
    except Exception as e:
        print(f"  -> Error fetching {name}: {e}")
        results.append({'name': name, 'birth_city': None, 'birth_state': None,
                        'latitude': None, 'longitude': None})
        continue
    time.sleep(1)

    # Extract and clean birthplace
    raw = extract_birthplace(p_soup)
    print(f"  Raw birthplace: '{raw}'")
    # remove parentheses and citations
    cleaned = re.sub(r'\([^)]*\)', '', raw)
    cleaned = re.sub(r'\[.*?\]', '', cleaned).strip()
    # split tokens by comma
    tokens = [t.strip() for t in cleaned.split(',') if t.strip()]
    # drop tokens with digits (dates)
    while tokens and re.search(r'\d', tokens[0]):
        tokens.pop(0)
    # drop trailing country tokens\ n    unwanted = re.compile(r'^(British America|United States|U\.?S\.?A?\.?|USA)$', re.I)
    while tokens and unwanted.match(tokens[-1]):
        tokens.pop()
    birth_clean = ', '.join(tokens)
    print(f"  Tokens: {tokens}")
    print(f"  Cleaned birthplace: '{birth_clean}'")

    # derive city and state
    city = tokens[0] if len(tokens) >= 1 else None
    state = tokens[1] if len(tokens) >= 2 else None
    print(f"  Parsed city='{city}', state='{state}'")

    # geocode
    lat = lon = None
    if city and state:
        for q in [f"{city}, {state}, USA", f"{birth_clean}, USA"]:
            print(f"  Geocoding '{q}'...")
            try:
                loc = g.geocode(q, timeout=10)
            except Exception as ge:
                print(f"   -> geocode error: {ge}")
                loc = None
            time.sleep(1)
            if loc:
                lat, lon = loc.latitude, loc.longitude
                print(f"   -> Got coords: ({lat}, {lon})")
                break
    else:
        print(f"  Insufficient info to geocode for {name}")

    entry = {'name': name, 'birth_city': city, 'birth_state': state,
             'latitude': lat, 'longitude': lon}
    print(f"  Recorded: {entry}")
    results.append(entry)

# 7) Save all results to JSON
out_file = os.path.join(workspace, 'presidential_birthplaces.json')
with open(out_file, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2)
print(f"\nFinished: saved {len(results)} records to {out_file}")
```