### Development Step 26: Search and Download ‘Can Hiccup Supply Enough Fish to Maintain a Dragon’s Diet?’ PDF

**Description**: Conduct a web search for the University of Leicester paper titled "Can Hiccup Supply Enough Fish to Maintain a Dragon’s Diet?" and download the full PDF of that paper into workspace/dragon_diet_fish_bag.pdf.

**Use Cases**:
- Academic researcher automates retrieval of PDF versions of domain-specific journal articles (e.g., collecting marine biology papers on dragon feeding strategies) into a local workspace for offline literature review
- Corporate compliance team scans Bing search results for newly published regulatory guideline PDFs (e.g., environmental impact reports) and extracts context snippets to flag relevant policy changes
- Patent analyst gathers patent specification PDFs from public search engines to streamline prior-art investigations, saving raw HTML and link contexts for downstream review
- Financial analyst harvests quarterly and annual report PDFs from company investor-relations sites via automated search queries, then extracts text snippets for rapid trend analysis
- Legal department captures court decision and statute PDFs from online databases, archiving search result HTML and snippet contexts to build an internal e-discovery repository
- Marketing research group aggregates competitor whitepapers and product brochures in PDF form, logging occurrences and snippet previews to identify new market offerings
- Data engineer sources technical standards and specification PDFs from ISO or IEEE web portals by automated search, preserving HTML contexts and snippet files for integration into validation pipelines
- Healthcare informatics team downloads clinical guideline and trial protocol PDFs through targeted search queries, extracting snippet previews to prioritize documents for patient-care policy development

```
import os
import sys
import re
import requests

# Module‐level HTTP headers for all requests
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                  'AppleWebKit/537.36 (KHTML, like Gecko) '
                  'Chrome/91.0.4472.124 Safari/537.36',
    'Accept-Language': 'en-US,en;q=0.9',
    'Accept': 'text/html'
}

# Step 1: Ensure workspace directory exists
workspace = 'workspace'
if not os.path.isdir(workspace):
    print(f"ERROR: Workspace directory '{workspace}' does not exist.")
    sys.exit(1)
print(f"[INFO] Using workspace: {workspace}\n")

# Step 2: Construct the Bing search query
title = "Can Hiccup Supply Enough Fish to Maintain a Dragon's Diet?"
query = f'"{title}" filetype:pdf'
print(f"[SEARCH] Bing query: {query}\n")

# Step 3: Perform the HTTP GET to Bing and capture HTML
search_url = 'https://www.bing.com/search'
try:
    response = requests.get(search_url,
                            params={'q': query},
                            headers=HEADERS,
                            timeout=30)
    response.raise_for_status()
    html = response.text
    print(f"[SEARCH] Retrieved {len(html)} characters of HTML from Bing.\n")
except Exception as e:
    print(f"ERROR: Failed to fetch Bing search results: {e}")
    sys.exit(1)

# Step 4: Save the raw HTML for offline analysis
html_path = os.path.join(workspace, 'bing_search.html')
with open(html_path, 'w', encoding='utf-8') as f:
    f.write(html)
print(f"[SAVE] Full Bing HTML saved to: {html_path}\n")

# Step 5: Locate every occurrence of 'pdf' in the HTML
positions = [m.start() for m in re.finditer(r'pdf', html, flags=re.IGNORECASE)]
print(f"[PARSE] Found {len(positions)} occurrences of 'pdf' in the HTML.\n")

# Step 6: Extract up to the first 20 context snippets around each occurrence
snippets = []
for pos in positions[:20]:
    start = max(0, pos - 80)
    end = min(len(html), pos + 80)
    context = html[start:end].replace('\n', ' ')
    snippets.append((pos, context))

# Step 7: Write those snippets to a file for detailed review
snip_path = os.path.join(workspace, 'pdf_snippets.txt')
with open(snip_path, 'w', encoding='utf-8') as f:
    for idx, (pos, ctx) in enumerate(snippets, 1):
        f.write(f"Occurrence {idx} at index {pos}:\n")
        f.write(ctx + "\n" + '-'*80 + "\n")
print(f"[SAVE] First {len(snippets)} context snippets saved to: {snip_path}\n")

# Step 8: Print the first 5 snippets to console for quick inspection
for i, (pos, ctx) in enumerate(snippets[:5], 1):
    print(f"[SNIPPET {i}] Index {pos}: {ctx}\n")

print("[COMPLETE] HTML dump and PDF-context snippets are ready for inspection.")
```