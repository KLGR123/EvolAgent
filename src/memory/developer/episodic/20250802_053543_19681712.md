### Development Step 9: Search and Download 'Can Hiccup Supply Enough Fish to Maintain a Dragon’s Diet?' PDF

**Description**: Conduct a web search for the University of Leicester paper titled "Can Hiccup Supply Enough Fish to Maintain a Dragon’s Diet?" and download the full PDF of that paper into workspace/dragon_diet_fish_bag.pdf.

**Use Cases**:
- Automated retrieval of quarterly 10-K and 10-Q PDF filings from sec.gov for building up-to-date financial models in investment banking
- Scheduled download of the latest ISO standard PDFs from iso.org to ensure manufacturing quality processes remain compliant
- Bulk acquisition of peer-reviewed articles in PDF format from institute domains (e.g., site:ieee.org) for training a machine-learning literature review tool
- Periodic scraping of government tender documents (site:gov.uk) to gather upcoming procurement PDFs for bid-management platforms
- Automated collection of safety data sheets (MSDS) in PDF form from chemical supplier sites to update laboratory compliance systems
- Real-time fetching of competitor product spec-sheet PDFs from electronics manufacturer domains to feed a dynamic pricing intelligence dashboard
- Routine extraction of policy white papers from think-tank websites for policy–impact analysis and briefing preparation
- Scheduled download of academic conference proceedings in PDF from university repositories to populate a citation database for researchers

```
import os
import requests

# Step 1: Ensure workspace directory exists
workspace = 'workspace'
os.makedirs(workspace, exist_ok=True)
print(f"[INFO] Workspace directory: {workspace}")

# Step 2: Define paper title and site-specific search query
title = "Can Hiccup Supply Enough Fish to Maintain a Dragon’s Diet?"
query = f'site:le.ac.uk "{title}" filetype:pdf'
print(f"[INFO] Search query for site-specific PDF: {query}\n")

# Common headers for HTTP requests
headers = {'User-Agent': 'Mozilla/5.0'}

# Step 3: Fetch DuckDuckGo HTML for site:le.ac.uk search
print("[INFO] Fetching DuckDuckGo search results restricted to le.ac.uk...")
ddg_url = 'https://duckduckgo.com/html/'
ddg_resp = requests.get(ddg_url, params={'q': query}, headers=headers, timeout=30)
ddg_resp.raise_for_status()
path_ddg = os.path.join(workspace, 'site_le_duckduckgo_search.html')
with open(path_ddg, 'w', encoding='utf-8') as f:
    f.write(ddg_resp.text)
print(f"[DONE] Saved DuckDuckGo HTML to: {path_ddg}\n")

# Step 4: Fetch Bing HTML for site:le.ac.uk search
print("[INFO] Fetching Bing search results restricted to le.ac.uk...")
bing_url = 'https://www.bing.com/search'
bing_resp = requests.get(bing_url, params={'q': query}, headers=headers, timeout=30)
bing_resp.raise_for_status()
path_bing = os.path.join(workspace, 'site_le_bing_search.html')
with open(path_bing, 'w', encoding='utf-8') as f:
    f.write(bing_resp.text)
print(f"[DONE] Saved Bing HTML to: {path_bing}\n")

# Step 5: Next steps for parsing
print("[INFO] ===== INTERMEDIATE OUTPUTS READY =====")
print(f"- Inspect {path_ddg} to identify how PDF links or redirect parameters are structured in DuckDuckGo results.")
print(f"- Inspect {path_bing} to examine the HTML structure of Bing results and locate .pdf link patterns on le.ac.uk.")
print("After inspection, implement parsing logic to extract the actual PDF URL and perform the download to workspace/dragon_diet_fish_bag.pdf.")
```