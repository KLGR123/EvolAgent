### Development Step 25: Search and Download PDF: Can Hiccup Supply Enough Fish to Maintain a Dragon’s Diet?

**Description**: Conduct a web search for the University of Leicester paper titled "Can Hiccup Supply Enough Fish to Maintain a Dragon’s Diet?" and download the full PDF of that paper into workspace/dragon_diet_fish_bag.pdf.

**Use Cases**:
- Automated retrieval of clinical trial PDFs from public health databases to aggregate data for a meta-analysis on cardiovascular drug efficacy
- Bulk download of patent application PDFs from government search portals to support intellectual property attorneys in novelty and infringement assessments
- Corporate compliance team’s automated scraping of regulatory guideline PDFs from multiple government websites to maintain up-to-date policy libraries
- Market research analysts’ extraction of competitor whitepaper and product specification PDFs from vendor sites for comparative feature benchmarking
- University library integration that searches academic repositories for newly published thesis PDFs to update catalog entries and support digital archiving
- Data journalism workflow that automates fetching central bank report PDFs to extract key economic indicators for real-time news dashboards
- Environmental consultancy process to bulk download environmental impact assessment PDFs from government registries for geospatial analysis in project planning
- Software localization pipeline that searches and retrieves vendor user manual PDFs to feed into translation management systems

```
import os
import sys
import re
import requests

# Module-level headers for HTTP requests\ nHEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                  'AppleWebKit/537.36 (KHTML, like Gecko) '
                  'Chrome/91.0.4472.124 Safari/537.36',
    'Accept-Language': 'en-US,en;q=0.9',
    'Accept': 'text/html'
}

# Ensure workspace directory exists
workspace = 'workspace'
if not os.path.isdir(workspace):
    print(f"ERROR: Workspace directory '{workspace}' does not exist.")
    sys.exit(1)
print(f"[INFO] Using workspace: {workspace}\n")

# Construct the search query for the target paper
query = '"Can Hiccup Supply Enough Fish to Maintain a Dragon\'s Diet?" filetype:pdf'
print(f"[SEARCH] Bing query: {query}\n")

# Perform Bing search
search_url = 'https://www.bing.com/search'
try:
    response = requests.get(search_url, params={'q': query}, headers=HEADERS, timeout=30)
    response.raise_for_status()
    html = response.text
    print(f"[SEARCH] Retrieved {len(html)} characters of HTML from Bing.\n")
except Exception as e:
    print(f"ERROR: Failed to fetch Bing search results: {e}")
    sys.exit(1)

# Save full HTML for offline inspection
html_path = os.path.join(workspace, 'bing_search.html')
with open(html_path, 'w', encoding='utf-8') as f:
    f.write(html)
print(f"[SAVE] Full Bing HTML saved to: {html_path}\n")

# Find all occurrences of 'pdf' in the HTML and record their positions
pdf_positions = [m.start() for m in re.finditer(r'pdf', html, flags=re.IGNORECASE)]
print(f"[PARSE] Found {len(pdf_positions)} occurrences of 'pdf' in the HTML.\n")

# Extract context snippets around each occurrence (up to first 20)
snippets = []
for pos in pdf_positions[:20]:
    start = max(0, pos - 80)
    end = min(len(html), pos + 80)
    context = html[start:end].replace('\n', ' ')
    snippets.append((pos, context))

# Save snippets to a file
snip_path = os.path.join(workspace, 'pdf_snippets.txt')
with open(snip_path, 'w', encoding='utf-8') as f:
    for i, (pos, ctx) in enumerate(snippets, 1):
        f.write(f"Occurrence {i} at index {pos}:\n")
        f.write(ctx + "\n" + '-'*80 + "\n")
print(f"[SAVE] First {len(snippets)} context snippets saved to: {snip_path}\n")

# Print the first 5 snippets to console for immediate inspection
for i, (pos, ctx) in enumerate(snippets[:5], 1):
    print(f"[SNIPPET {i}] Index {pos}: {ctx}\n")

print("[COMPLETE] HTML dump and PDF-context snippets are ready for inspection.")
```