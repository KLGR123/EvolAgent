### Development Step 16: Compile Complete List of US Presidents’ Birthplaces with Cities, States, and Coordinates into JSON

**Description**: Collect a complete list of all United States presidents with their official birth city names and state names, then obtain the geographic coordinates (longitude and latitude) for each birth city using authoritative sources such as official presidential biographies or Wikipedia infoboxes. Save the results in a structured format (e.g., CSV or JSON) at workspace/presidential_birthplaces.json.

**Use Cases**:
- Interactive educational platform mapping each U.S. president’s birth city and state to teach geography and presidential history through an animated timeline
- Political science research dashboard analyzing regional birth patterns of presidents to study shifts in electoral influence and demographic trends
- Museum kiosk application that visualizes presidential birthplaces on a touch-screen map, enriching visitor experiences with biographical pop-ups and travel recommendations
- Themed travel itinerary generator for tour operators, using geo-coordinates to plan road trips that visit presidential birth cities and related historical landmarks
- News media interactive feature overlaying presidents’ birth locations with county-level voting data to illustrate geographic correlations in election coverage
- Genealogy research tool integrating presidential birthplace data with ancestry records to explore family migration and roots of American leaders
- Mobile history app that sends push notifications and historical anecdotes when users approach a former president’s birthplace during city walks
- Data journalism project combining presidential birth coordinates with socio-economic indicators to visualize and report on regional leadership trends over U.S. history

```
import os
import re
import time
import json
import requests
from bs4 import BeautifulSoup
from geopy.geocoders import Nominatim

# Ensure workspace directory exists
workspace = 'workspace'
os.makedirs(workspace, exist_ok=True)

# 1. Load or fetch the Wikipedia page listing all U.S. presidents
list_path = os.path.join(workspace, 'presidents_list.html')
if os.path.exists(list_path):
    print(f"Loading cached presidents list from {list_path}")
    with open(list_path, 'r', encoding='utf-8') as f:
        list_html = f.read()
else:
    list_url = 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States'
    print(f"Fetching presidents list from {list_url}")
    resp = requests.get(list_url, timeout=10)
    resp.raise_for_status()
    list_html = resp.text
    with open(list_path, 'w', encoding='utf-8') as f:
        f.write(list_html)
    print(f"Saved presidents list to {list_path}")

# 2. Parse the main wikitable of presidents
soup = BeautifulSoup(list_html, 'html.parser')
table = soup.find('table', class_='wikitable')
rows = table.find_all('tr')[1:]
print(f"Found {len(rows)} rows in the presidents table")

# 3. Build list of (name, page_url)
presidents = []
for row in rows:
    cols = row.find_all('td')
    if len(cols) < 2:
        continue
    link = cols[1].find('a', href=True)
    if not link:
        continue
    name = link.get_text(strip=True)
    page_url = 'https://en.wikipedia.org' + link['href']
    presidents.append({'name': name, 'url': page_url})
print(f"Collected {len(presidents)} presidents to process")

# 4. Helper: extract a raw birthplace string from a president's page soup
unwanted_trailing = re.compile(r'^(British America|United States|U\.?S\.?A?\.?|USA)$', re.I)

def extract_birthplace(page_soup):
    # Try <span class="birthplace">
    span_bp = page_soup.select_one('span.birthplace')
    if span_bp and span_bp.get_text(strip=True):
        return span_bp.get_text(strip=True)
    # Fallback: infobox 'Born' row
    infobox = page_soup.find('table', class_=lambda c: c and 'infobox' in c)
    if infobox:
        born_th = infobox.find('th', string=re.compile('Born'))
        if born_th:
            tr = born_th.parent
            td = tr.find('td')
            if td:
                parts = re.split(r'<br\s*/?>', str(td), flags=re.IGNORECASE)
                if len(parts) >= 2:
                    place_html = parts[1]
                    place_html = re.sub(r'<small[^>]*>.*?</small>', '', place_html,
                                        flags=re.DOTALL|re.IGNORECASE)
                    text = BeautifulSoup(place_html, 'html.parser').get_text(separator=' ', strip=True)
                    return text
    return ''

# 5. Initialize geocoder and results list
g = Nominatim(user_agent='presidential_birth_locator')
results = []

# 6. Iterate over each president and collect birthplace & coordinates
for idx, pres in enumerate(presidents, start=1):
    name = pres['name']
    url = pres['url']
    print(f"\n[{idx}/{len(presidents)}] {name}\nFetching: {url}")
    try:
        r = requests.get(url, timeout=10)
        r.raise_for_status()
        page_soup = BeautifulSoup(r.text, 'html.parser')
    except Exception as e:
        print(f"  -> Error fetching {name}: {e}")
        results.append({'name': name, 'birth_city': None, 'birth_state': None,
                        'latitude': None, 'longitude': None})
        continue
    time.sleep(1)

    # Extract and clean raw birthplace
    raw = extract_birthplace(page_soup)
    print(f"  Raw birthplace: '{raw}'")
    cleaned = re.sub(r'\([^)]*\)', '', raw)  # remove parentheses
    cleaned = re.sub(r'\[.*?\]', '', cleaned).strip()  # remove citations

    # Split into tokens and clean tokens
    tokens = [t.strip() for t in cleaned.split(',') if t.strip()]
    while tokens and re.search(r'\d', tokens[0]):  # drop date tokens
        tokens.pop(0)
    while tokens and unwanted_trailing.match(tokens[-1]):  # drop country tokens
        tokens.pop()
    birth_clean = ', '.join(tokens)
    print(f"  Tokens: {tokens}")
    print(f"  Cleaned birthplace: '{birth_clean}'")

    # Derive city and state
    city = tokens[0] if len(tokens) >= 1 else None
    state = tokens[1] if len(tokens) >= 2 else None
    print(f"  Parsed city='{city}', state='{state}'")

    # Geocode
    lat = lon = None
    if city and state:
        for query in [f"{city}, {state}, USA", f"{birth_clean}, USA"]:
            print(f"  Geocoding '{query}'...")
            try:
                loc = g.geocode(query, timeout=10)
            except Exception as ge:
                print(f"   -> Geocode error: {ge}")
                loc = None
            time.sleep(1)
            if loc:
                lat, lon = loc.latitude, loc.longitude
                print(f"   -> Got coords: ({lat}, {lon})")
                break
    else:
        print(f"  Insufficient info to geocode for {name}")

    entry = {'name': name, 'birth_city': city, 'birth_state': state,
             'latitude': lat, 'longitude': lon}
    print(f"  Recorded: {entry}")
    results.append(entry)

# 7. Save results to JSON
out_file = os.path.join(workspace, 'presidential_birthplaces.json')
with open(out_file, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2)
print(f"\nFinished: saved {len(results)} records to {out_file}")
```