### Development Step 12: Download PDF of University of Leicester’s "Can Hiccup Supply Enough Fish to Maintain Dragon Diet?"

**Description**: Conduct a web search for the University of Leicester paper titled "Can Hiccup Supply Enough Fish to Maintain a Dragon’s Diet?" and download the full PDF of that paper into workspace/dragon_diet_fish_bag.pdf.

**Use Cases**:
- Automated regulatory compliance retrieval for a utilities company: download the latest environmental impact assessment PDF from the state regulator’s domain each month and store it in a shared workspace for audit teams
- Academic research archiving: automatically fetch and save faculty publications’ PDFs from the university repository to maintain a local backup for library preservation
- Legal case aggregation: pull court opinion PDFs from a specific jurisdiction’s website to build a searchable offline database for paralegals and attorneys
- Financial analysis pipeline: retrieve quarterly earnings report PDFs directly from corporate investor-relations domains to feed into a valuation and forecasting model
- Engineering parts catalog automation: download up-to-date technical specification PDFs for mechanical components from suppliers’ websites to populate a component database
- Environmental data integration: automatically fetch climate monitoring report PDFs from a government meteorological service domain for input into simulation workflows
- Product competitive intelligence: collect competitor product datasheet PDFs from rival domains to update internal comparison matrices and inform product strategy
- Marketing collateral consolidation: pull event brochure and whitepaper PDFs from conference and partner domains into a central repository for campaign planning and collateral distribution

```
import os
import sys
import re
import requests
from urllib.parse import urlparse

# Step 1: Ensure workspace directory exists
workspace = 'workspace'
os.makedirs(workspace, exist_ok=True)
print(f"[INFO] Using workspace: {workspace}\n")

# Step 2: Paths to previously saved search result HTML files
ddg_html = os.path.join(workspace, 'site_le_duckduckgo_search.html')
bing_html = os.path.join(workspace, 'site_le_bing_search.html')

# Step 3: Verify that HTML files exist
for path in (ddg_html, bing_html):
    if not os.path.exists(path):
        print(f"ERROR: Missing required file: {path}")
        print("Run the site-specific search step first to save HTML files.")
        sys.exit(1)
print(f"[INFO] Found HTML files:\n - {ddg_html}\n - {bing_html}\n")

# Step 4: Load HTML content
ddg_content = open(ddg_html, 'r', encoding='utf-8').read()
bing_content = open(bing_html, 'r', encoding='utf-8').read()

# Step 5: Extract all PDF URLs by regex
pattern = re.compile(r'https?://[^"\' >]+\.pdf(?:\?[^"\' >]*)?', re.IGNORECASE)
ddg_urls = pattern.findall(ddg_content)
bing_urls = pattern.findall(bing_content)
all_candidates = list(dict.fromkeys(ddg_urls + bing_urls))  # dedupe preserving order
print(f"[INFO] Total raw PDF URLs found: {len(all_candidates)}")
for i, url in enumerate(all_candidates, 1):
    print(f"  {i}. {url}")

# Step 6: Filter to University of Leicester domain
leicester_candidates = [url for url in all_candidates
                        if 'le.ac.uk' in urlparse(url).netloc.lower()]
print(f"\n[INFO] PDF URLs on 'le.ac.uk' domain: {len(leicester_candidates)}")
for i, url in enumerate(leicester_candidates, 1):
    print(f"  {i}. {url}")

# Step 7: Allow manual override via environment variable
env_override = os.getenv('DRAGON_PDF_URL')
if env_override:
    pdf_link = env_override
    print(f"[INFO] Override URL from DRAGON_PDF_URL: {pdf_link}\n")
elif leicester_candidates:
    pdf_link = leicester_candidates[0]
    print(f"[INFO] Selected PDF link from 'le.ac.uk': {pdf_link}\n")
else:
    print("ERROR: No PDF links found on 'le.ac.uk'.")
    print("Please inspect the HTML files or set DRAGON_PDF_URL to the correct PDF URL.")
    sys.exit(1)

# Step 8: Download the selected PDF to workspace
pdf_path = os.path.join(workspace, 'dragon_diet_fish_bag.pdf')
print(f"[DOWNLOAD] Fetching PDF from: {pdf_link}\n         Saving to: {pdf_path}\n")
headers = {'User-Agent': 'Mozilla/5.0', 'Accept': 'application/pdf'}
total_bytes = 0
try:
    with requests.get(pdf_link, headers=headers, stream=True, timeout=60) as r:
        r.raise_for_status()
        with open(pdf_path, 'wb') as f:
            for chunk in r.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    total_bytes += len(chunk)
except Exception as e:
    print(f"ERROR: Failed to download PDF: {e}")
    sys.exit(1)

# Step 9: Final report
print(f"[DONE] Download complete: {total_bytes} bytes ({total_bytes/1024/1024:.2f} MB)")
if total_bytes < 10_000:
    print("WARNING: File size < 10 KB; the PDF may be incomplete or incorrect.")
else:
    print(f"SUCCESS: PDF saved at {pdf_path}")
```