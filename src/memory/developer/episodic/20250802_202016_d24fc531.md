### Development Step 8: 2011 Bulgarian Census Tertiary Education Completion by Gender

**Description**: Search for the 2011 Bulgarian census data on tertiary education completion by gender. Look for official census results from Bulgaria's National Statistical Institute or other authoritative sources that provide the specific breakdown of men and women who completed tertiary education in 2011.

**Use Cases**:
- Government ministry drafting gender equity legislation using detailed 2011 Bulgarian tertiary education attainment stats by gender
- University research center analyzing historical gender distribution in Bulgarian higher education for longitudinal academic participation studies
- International development NGO measuring the impact of women’s scholarship programs on tertiary enrollment across Bulgarian regions
- Tech company workforce planning team evaluating the availability of male and female university graduates to shape regional hiring strategies in Bulgaria
- Regional education board identifying districts with low male university completion rates to target vocational and upskilling initiatives
- Market intelligence firm profiling Bulgaria’s skilled labor market based on 2011 tertiary degree attainment by gender for investment advisory reports
- Data journalism project visualizing gender disparities in Bulgarian higher education using census-extracted statistics for public awareness articles

```
import os
import json
from bs4 import BeautifulSoup
import re
import time

# First, let's inspect what files are actually in the workspace
print("=== ANALYZING SAVED BULGARIAN CENSUS DATA FILES ===")
print("Objective: Extract tertiary education completion by gender from 2011 Bulgarian census")
print("Strategy: Analyze all saved HTML files with proper variable handling\n")

if os.path.exists('workspace'):
    files = os.listdir('workspace')
    html_files = [f for f in files if f.endswith('.html')]
    print(f"HTML files available for analysis: {len(html_files)}")
    
    # Show the most promising files based on names - FIXED variable name
    priority_files = []
    for file in html_files:  # Using 'file' to match the loop variable
        if any(term in file.lower() for term in ['education', 'demographics', 'census', 'nsi', 'eurostat']):
            priority_files.append(file)
    
    print(f"Priority files (education/census related): {len(priority_files)}")
    for pf in priority_files[:10]:  # Show top 10
        print(f"  {pf}")
else:
    print("No workspace directory found")
    exit()

print("\n=== DETAILED ANALYSIS OF SAVED CONTENT ===\n")

analysis_results = []
specific_findings = []

for i, html_file in enumerate(html_files, 1):
    print(f"Analyzing {i}/{len(html_files)}: {html_file}")
    
    filepath = f'workspace/{html_file}'
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        # Parse HTML content
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Get page title
        title_element = soup.find('title')
        page_title = title_element.get_text().strip() if title_element else 'No title found'
        
        # Get all text content and create lowercase version for analysis - FIXED immediately
        full_text = soup.get_text()
        text_for_analysis = full_text.lower()  # Create lowercase version immediately after full_text
        
        print(f"  Title: {page_title}")
        print(f"  Content length: {len(full_text)} characters")
        
        # Skip very small files (likely error pages)
        if len(full_text) < 1000:
            print(f"  Skipping - content too small (likely error page)")
            print()
            continue
        
        # Check relevance for Bulgarian census and education
        has_bulgaria = 'bulgaria' in text_for_analysis or 'bulgarian' in text_for_analysis
        has_2011 = '2011' in text_for_analysis
        has_census = 'census' in text_for_analysis
        has_tertiary = any(term in text_for_analysis for term in ['tertiary', 'higher education', 'university degree', 'tertiary education'])
        has_gender = any(term in text_for_analysis for term in ['men', 'women', 'male', 'female', 'gender', 'sex'])
        has_education = 'education' in text_for_analysis
        
        relevance_score = sum([has_bulgaria, has_2011, has_census, has_tertiary, has_gender, has_education])
        
        print(f"  Bulgaria: {has_bulgaria} | 2011: {has_2011} | Census: {has_census}")
        print(f"  Tertiary ed: {has_tertiary} | Gender: {has_gender} | Education: {has_education}")
        print(f"  Relevance score: {relevance_score}/6")
        
        if relevance_score >= 3:  # Analyze high-relevance sources
            print(f"  *** HIGH RELEVANCE - EXTRACTING DATA ***")
            
            # Search for specific education statistics with gender breakdown
            education_sentences = []
            sentences = full_text.split('.')
            
            for sentence in sentences:
                sentence_clean = sentence.strip()
                sentence_lower = sentence_clean.lower()
                
                if len(sentence_clean) > 30:  # Skip very short sentences
                    # Look for sentences with Bulgaria + education + numbers/percentages + gender
                    has_bulgaria_ref = 'bulgaria' in sentence_lower
                    has_education_ref = any(term in sentence_lower for term in 
                                          ['tertiary', 'education', 'university', 'higher', 'degree', 'graduate', 'completed'])
                    has_numbers = bool(re.search(r'\d+[.,]?\d*\s*%?', sentence_lower))
                    has_gender_ref = any(term in sentence_lower for term in ['men', 'women', 'male', 'female'])
                    has_year_ref = '2011' in sentence_lower
                    
                    if has_bulgaria_ref and has_education_ref and has_numbers and (has_gender_ref or has_year_ref):
                        education_sentences.append(sentence_clean)
            
            print(f"  Education sentences with data: {len(education_sentences)}")
            
            # Look for tables with statistical data
            tables = soup.find_all('table')
            relevant_tables = []
            
            for table_idx, table in enumerate(tables):
                table_text = table.get_text().lower()
                
                # Check if table contains education and gender data
                if (any(term in table_text for term in ['education', 'tertiary', 'university', 'degree']) and
                    any(term in table_text for term in ['men', 'women', 'male', 'female', 'gender'])):
                    
                    # Extract table headers
                    headers = [th.get_text().strip() for th in table.find_all('th')]
                    
                    # Get all rows of data
                    rows = table.find_all('tr')
                    table_data = []
                    
                    for row in rows:
                        cells = [td.get_text().strip() for td in row.find_all(['td', 'th'])]
                        if cells and any(cell for cell in cells if cell.strip()):  # Skip empty rows
                            table_data.append(cells)
                    
                    relevant_tables.append({
                        'index': table_idx,
                        'headers': headers,
                        'data': table_data[:10],  # First 10 rows
                        'total_rows': len(rows)
                    })
            
            print(f"  Relevant tables found: {len(relevant_tables)}")
            
            # Search for specific numerical patterns related to tertiary education by gender
            education_stats = []
            
            # Enhanced patterns to capture tertiary education statistics by gender
            stat_patterns = [
                r'tertiary education.*?(\d+[.,]?\d*\s*%?).*?(?:men|women|male|female)',
                r'(?:men|women|male|female).*?tertiary education.*?(\d+[.,]?\d*\s*%?)',
                r'university.*?(?:men|women|male|female).*?(\d+[.,]?\d*\s*%?)',
                r'(?:men|women|male|female).*?university.*?(\d+[.,]?\d*\s*%?)',
                r'higher education.*?(?:men|women|male|female).*?(\d+[.,]?\d*\s*%?)',
                r'(?:men|women|male|female).*?higher education.*?(\d+[.,]?\d*\s*%?)',
                r'completed.*?tertiary.*?(\d+[.,]?\d*\s*%?)',
                r'degree.*?(?:men|women|male|female).*?(\d+[.,]?\d*\s*%?)',
                r'2011.*?education.*?(?:men|women|male|female).*?(\d+[.,]?\d*\s*%?)'
            ]
            
            for pattern in stat_patterns:
                matches = re.finditer(pattern, full_text, re.IGNORECASE | re.DOTALL)
                for match in matches:
                    # Get extended context around the match
                    start = max(0, match.start() - 300)
                    end = min(len(full_text), match.end() + 300)
                    context = full_text[start:end].strip()
                    
                    # Check if context mentions Bulgaria and is relevant
                    context_lower = context.lower()
                    if 'bulgaria' in context_lower or 'bulgarian' in context_lower:
                        education_stats.append({
                            'pattern': pattern,
                            'match': match.group(),
                            'context': context,
                            'source_file': html_file
                        })
            
            print(f"  Education statistics found: {len(education_stats)}")
            
            # Look for specific census data patterns
            census_patterns = [
                r'2011.*?census.*?tertiary.*?(\d+[.,]?\d*)',
                r'census.*?2011.*?education.*?(\d+[.,]?\d*)',
                r'population.*?tertiary.*?education.*?(\d+[.,]?\d*)',
                r'completed.*?tertiary.*?2011.*?(\d+[.,]?\d*)'
            ]
            
            for pattern in census_patterns:
                matches = re.finditer(pattern, full_text, re.IGNORECASE | re.DOTALL)
                for match in matches:
                    start = max(0, match.start() - 200)
                    end = min(len(full_text), match.end() + 200)
                    context = full_text[start:end].strip()
                    
                    if 'bulgaria' in context.lower():
                        specific_findings.append({
                            'type': 'census_data',
                            'pattern': pattern,
                            'match': match.group(),
                            'context': context,
                            'source_file': html_file
                        })
            
            # Show key findings from this source
            if education_sentences:
                print(f"  Key sentence: {education_sentences[0][:200]}...")
            
            if education_stats:
                print(f"  Key statistic: {education_stats[0]['match']}")
                print(f"  Context: {education_stats[0]['context'][:150]}...")
            
            if relevant_tables and relevant_tables[0]['headers']:
                print(f"  Table headers: {relevant_tables[0]['headers'][:5]}")
            
            # Store comprehensive analysis for this source
            analysis_results.append({
                'filename': html_file,
                'title': page_title,
                'relevance_score': relevance_score,
                'content_length': len(full_text),
                'education_sentences': education_sentences[:5],  # Top 5
                'education_statistics': education_stats[:3],     # Top 3
                'relevant_tables': relevant_tables[:2],          # Top 2
                'has_bulgaria': has_bulgaria,
                'has_2011': has_2011,
                'has_census': has_census,
                'has_tertiary': has_tertiary,
                'has_gender': has_gender
            })
            
            # Add all education stats to specific findings
            for stat in education_stats:
                specific_findings.append({
                    'type': 'education_statistic',
                    'pattern': stat['pattern'],
                    'match': stat['match'],
                    'context': stat['context'],
                    'source_file': html_file
                })
        
        print()
        
    except Exception as e:
        print(f"  ✗ Error analyzing {html_file}: {str(e)}")
        print()

# Save comprehensive analysis results
print("=== COMPILATION OF FINDINGS ===\n")

final_results = {
    'search_objective': 'Bulgarian 2011 census tertiary education completion by gender',
    'analysis_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'files_analyzed': len(html_files),
    'relevant_sources': len(analysis_results),
    'specific_findings_count': len(specific_findings),
    'analysis_results': analysis_results,
    'specific_findings': specific_findings
}

with open('workspace/bulgarian_tertiary_education_final_analysis.json', 'w', encoding='utf-8') as f:
    json.dump(final_results, f, indent=2, ensure_ascii=False)

print(f"Final analysis saved to: workspace/bulgarian_tertiary_education_final_analysis.json")
print(f"Files analyzed: {len(html_files)}")
print(f"Relevant sources: {len(analysis_results)}")
print(f"Specific findings: {len(specific_findings)}")

# Display summary of key findings
if analysis_results:
    print("\n=== SUMMARY OF RELEVANT SOURCES ===\n")
    
    # Sort by relevance score
    analysis_results.sort(key=lambda x: x['relevance_score'], reverse=True)
    
    for i, result in enumerate(analysis_results, 1):
        print(f"{i}. {result['title']} (Score: {result['relevance_score']}/6)")
        print(f"   File: {result['filename']}")
        print(f"   Content: {result['content_length']} chars")
        
        if result['education_sentences']:
            print(f"   Finding: {result['education_sentences'][0][:150]}...")
        
        if result['education_statistics']:
            print(f"   Statistic: {result['education_statistics'][0]['match']}")
        
        print()

if specific_findings:
    print("=== SPECIFIC TERTIARY EDUCATION FINDINGS ===\n")
    
    for i, finding in enumerate(specific_findings[:10], 1):  # Show top 10
        print(f"{i}. Type: {finding['type']}")
        print(f"   Match: {finding['match']}")
        print(f"   Source: {finding['source_file']}")
        print(f"   Context: {finding['context'][:200]}...")
        print()

print("=== ANALYSIS COMPLETE ===\n")
print("Bulgarian 2011 census tertiary education data by gender has been systematically extracted")
print("All findings saved to workspace for detailed review and verification")
```