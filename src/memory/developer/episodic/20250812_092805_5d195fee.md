### Development Step 18: Find S√£o Francisco Basin Environmental Education Plan Organizer and Sobradinho Dam Displacement Advocate

**Description**: Conduct a comprehensive web search to identify the organization that launched the 'Plano de Educa√ß√£o Ambiental da Bacia do Rio S√£o Francisco' covering 505 municipalities and collaborates with Minist√©rios P√∫blicos. Search for keywords including 'Plano de Educa√ß√£o Ambiental Bacia Rio S√£o Francisco 505 munic√≠pios', 'Minist√©rios P√∫blicos S√£o Francisco basin', 'environmental education plan S√£o Francisco river', and 'Sobradinho Dam displaced people advocacy'. Focus on identifying the specific organization and then finding which individual within that organization advocated for people displaced by the Sobradinho Dam construction.

**Use Cases**:
- Investigative journalism for fact-checking CBHSF individuals advocating for Sobradinho Dam displaced communities
- Legal compliance automation for government watchdogs monitoring environmental justice actions across the S√£o Francisco basin
- NGO operational planning to map CBHSF and Minist√©rio P√∫blico collaborations across 505 municipalities for targeted outreach
- Academic research synthesis of JSON search outputs to extract role-based networks in participatory water governance case studies
- Environmental consultancy due diligence to verify online claims on plan coverage and institutional partnerships before client advisories
- Data-driven stakeholder engagement to generate targeted contact lists of basin committee coordinators and technical specialists for consultations
- Policy performance monitoring through automated scans of web search data to track advocacy efforts and update annual environmental education reports
- Geopolitical risk assessment within ESG frameworks by detecting emerging advocacy figures linked to Sobradinho Dam hydropower projects

```
import json
import os
from datetime import datetime

print("Loading and analyzing existing targeted search results to identify CBHSF individuals who advocated for Sobradinho Dam displaced people...")

# First, let's check what files exist in workspace to understand our data
print("\n=== WORKSPACE FILE INSPECTION ===")
workspace_files = []
for root, dirs, files in os.walk('.'):
    for file in files:
        if 'cbhsf' in file.lower() or 'sobradinho' in file.lower() or 'sao_francisco' in file.lower():
            full_path = os.path.join(root, file)
            workspace_files.append(full_path)
            print(f"Found relevant file: {full_path}")

if not workspace_files:
    print("No existing CBHSF/Sobradinho files found, will analyze available data")

# Look for the most recent targeted search results file
targeted_search_file = None
for file_path in workspace_files:
    if 'targeted_search' in file_path and file_path.endswith('.json'):
        targeted_search_file = file_path
        break

if not targeted_search_file:
    # Check in workspace directory specifically
    workspace_dir = 'workspace'
    if os.path.exists(workspace_dir):
        for file in os.listdir(workspace_dir):
            if 'targeted_search' in file and file.endswith('.json'):
                targeted_search_file = os.path.join(workspace_dir, file)
                break

if targeted_search_file and os.path.exists(targeted_search_file):
    print(f"\n=== LOADING TARGETED SEARCH RESULTS ===")
    print(f"File: {targeted_search_file}")
    
    # First inspect the file structure
    try:
        with open(targeted_search_file, 'r', encoding='utf-8') as f:
            search_data = json.load(f)
        
        print(f"\nüìä FILE STRUCTURE INSPECTION:")
        print(f"   ‚Ä¢ Top-level keys: {list(search_data.keys())[:10]}")
        print(f"   ‚Ä¢ Total queries: {len(search_data)}")
        
        # Inspect a sample query structure
        sample_key = list(search_data.keys())[0]
        sample_data = search_data[sample_key]
        print(f"\nüìã SAMPLE QUERY STRUCTURE ({sample_key}):")
        for key, value in sample_data.items():
            if isinstance(value, list):
                print(f"   ‚Ä¢ {key}: list with {len(value)} items")
                if len(value) > 0 and isinstance(value[0], dict):
                    sample_result_keys = list(value[0].keys())
                    print(f"     Sample result keys: {sample_result_keys}")
            else:
                print(f"   ‚Ä¢ {key}: {type(value).__name__} - {str(value)[:100]}...")
        
    except Exception as e:
        print(f"Error loading file: {str(e)}")
        search_data = None
else:
    print(f"\nNo targeted search results file found. Available files: {workspace_files}")
    search_data = None

if search_data:
    print(f"\n{='*80}")
    print("ANALYZING SEARCH RESULTS FOR CBHSF INDIVIDUALS")
    print(f"{='*80}")
    
    # Initialize analysis containers
    cbhsf_individuals = []
    sobradinho_advocates = []
    key_connections = []
    potential_names = set()
    
    # Enhanced keywords for analysis
    individual_role_keywords = [
        'presidente', 'diretor', 'coordenador', 'secret√°rio', 'advogado', 
        'representante', 'membro', 'conselheiro', 't√©cnico', 'especialista',
        'executivo', 'gerente', 'supervisor'
    ]
    
    sobradinho_terms = [
        'sobradinho', 'deslocad', 'reassent', 'indenizad', 'atingid', 
        'compensa√ß', 'remo√ß', 'transferi', 'realoca√ß', 'barragem'
    ]
    
    advocacy_terms = [
        'advogad', 'represent', 'defens', 'luta', 'direito', 'justi√ßa', 
        'reivindica√ß', 'movimento', 'a√ß√£o', 'processo', 'apoio'
    ]
    
    total_results_processed = 0
    queries_with_results = 0
    
    # Process each query's results
    for query_key, query_data in search_data.items():
        if isinstance(query_data, dict) and 'results' in query_data:
            query_text = query_data.get('query', 'Unknown query')
            results = query_data.get('results', [])
            
            if results:  # Only process queries with results
                queries_with_results += 1
                total_results_processed += len(results)
                
                print(f"\nProcessing {len(results)} results from: {query_text[:60]}...")
                
                for result in results:
                    if isinstance(result, dict):
                        # Safely extract result data
                        title = result.get('title', '').lower()
                        body = result.get('body', '').lower()
                        url = result.get('href', '')
                        
                        # Combine text for analysis
                        combined_text = (title + ' ' + body).lower()
                        
                        # Check for CBHSF mentions
                        cbhsf_mentioned = any(term in combined_text for term in [
                            'cbhsf', 'comit√™', 'bacia hidrogr√°fica', 's√£o francisco'
                        ])
                        
                        # Check for individual roles
                        individual_roles_found = [role for role in individual_role_keywords if role in combined_text]
                        
                        # Check for Sobradinho terms
                        sobradinho_terms_found = [term for term in sobradinho_terms if term in combined_text]
                        
                        # Check for advocacy terms
                        advocacy_terms_found = [term for term in advocacy_terms if term in combined_text]
                        
                        # Identify CBHSF individuals
                        if cbhsf_mentioned and individual_roles_found:
                            cbhsf_individuals.append({
                                'title': result.get('title', ''),
                                'url': url,
                                'snippet': result.get('body', '')[:400],
                                'roles_found': individual_roles_found,
                                'query': query_text,
                                'relevance_score': len(individual_roles_found)
                            })
                        
                        # Identify Sobradinho advocates
                        if sobradinho_terms_found and advocacy_terms_found:
                            sobradinho_advocates.append({
                                'title': result.get('title', ''),
                                'url': url,
                                'snippet': result.get('body', '')[:400],
                                'sobradinho_terms': sobradinho_terms_found,
                                'advocacy_terms': advocacy_terms_found,
                                'cbhsf_connection': cbhsf_mentioned,
                                'individual_indicators': individual_roles_found,
                                'query': query_text
                            })
                        
                        # Identify key connections (CBHSF + Sobradinho + Individual)
                        if cbhsf_mentioned and sobradinho_terms_found and individual_roles_found:
                            key_connections.append({
                                'title': result.get('title', ''),
                                'url': url,
                                'snippet': result.get('body', '')[:400],
                                'cbhsf_terms': ['cbhsf' if 'cbhsf' in combined_text else 'comit√™'],
                                'sobradinho_terms': sobradinho_terms_found,
                                'individual_roles': individual_roles_found,
                                'advocacy_terms': advocacy_terms_found,
                                'query': query_text,
                                'relevance': 'Very High - Contains all key elements'
                            })
    
    print(f"\nüìà ANALYSIS RESULTS:")
    print(f"   ‚Ä¢ Queries processed: {queries_with_results}")
    print(f"   ‚Ä¢ Total results analyzed: {total_results_processed}")
    print(f"   ‚Ä¢ CBHSF individuals found: {len(cbhsf_individuals)}")
    print(f"   ‚Ä¢ Sobradinho advocates found: {len(sobradinho_advocates)}")
    print(f"   ‚Ä¢ Key connections found: {len(key_connections)}")
    
    # Display findings
    print(f"\n{='*80}")
    print("DETAILED FINDINGS")
    print(f"{='*80}")
    
    if cbhsf_individuals:
        print(f"\nüë• CBHSF INDIVIDUALS IDENTIFIED ({len(cbhsf_individuals)}):")
        for i, individual in enumerate(cbhsf_individuals[:5], 1):
            print(f"\n{i}. {individual['title']}")
            print(f"   Roles mentioned: {', '.join(individual['roles_found'])}")
            print(f"   URL: {individual['url'][:70]}...")
            print(f"   Snippet: {individual['snippet'][:200]}...")
            print(f"   From query: {individual['query'][:50]}...")
    else:
        print(f"\nüë• CBHSF INDIVIDUALS: None specifically identified")
    
    if sobradinho_advocates:
        print(f"\nüèóÔ∏è SOBRADINHO ADVOCATES IDENTIFIED ({len(sobradinho_advocates)}):")
        for i, advocate in enumerate(sobradinho_advocates[:5], 1):
            print(f"\n{i}. {advocate['title']}")
            print(f"   Sobradinho terms: {', '.join(advocate['sobradinho_terms'])}")
            print(f"   Advocacy terms: {', '.join(advocate['advocacy_terms'])}")
            print(f"   CBHSF connection: {'Yes' if advocate['cbhsf_connection'] else 'No'}")
            if advocate['individual_indicators']:
                print(f"   Individual roles: {', '.join(advocate['individual_indicators'])}")
            print(f"   URL: {advocate['url'][:70]}...")
            print(f"   Snippet: {advocate['snippet'][:200]}...")
    else:
        print(f"\nüèóÔ∏è SOBRADINHO ADVOCATES: None specifically identified")
    
    if key_connections:
        print(f"\nüéØ KEY CONNECTIONS (CBHSF + Sobradinho + Individual) ({len(key_connections)}):")
        for i, connection in enumerate(key_connections[:3], 1):
            print(f"\n{i}. {connection['title']}")
            print(f"   Relevance: {connection['relevance']}")
            print(f"   CBHSF terms: {', '.join(connection['cbhsf_terms'])}")
            print(f"   Sobradinho terms: {', '.join(connection['sobradinho_terms'])}")
            print(f"   Individual roles: {', '.join(connection['individual_roles'])}")
            print(f"   Advocacy terms: {', '.join(connection['advocacy_terms'])}")
            print(f"   URL: {connection['url'][:70]}...")
            print(f"   Snippet: {connection['snippet'][:200]}...")
    else:
        print(f"\nüéØ KEY CONNECTIONS: None identified")
    
    # Compile comprehensive analysis
    comprehensive_analysis = {
        'analysis_date': datetime.now().isoformat(),
        'organization_confirmed': 'CBHSF (Comit√™ da Bacia Hidrogr√°fica do Rio S√£o Francisco)',
        'environmental_plan': 'Plano de Educa√ß√£o Ambiental da Bacia do Rio S√£o Francisco',
        'municipalities_covered': 505,
        'ministry_collaboration': 'Confirmed - Works with Minist√©rios P√∫blicos',
        'analysis_summary': {
            'queries_processed': queries_with_results,
            'total_results_analyzed': total_results_processed,
            'cbhsf_individuals_found': len(cbhsf_individuals),
            'sobradinho_advocates_found': len(sobradinho_advocates),
            'key_connections_found': len(key_connections)
        },
        'cbhsf_individuals': cbhsf_individuals[:10],
        'sobradinho_advocates': sobradinho_advocates[:10],
        'key_connections': key_connections[:5],
        'methodology': {
            'individual_role_keywords': individual_role_keywords,
            'sobradinho_terms': sobradinho_terms,
            'advocacy_terms': advocacy_terms
        }
    }
    
    # Save comprehensive analysis
    analysis_file = "workspace/cbhsf_individual_analysis_final.json"
    with open(analysis_file, 'w', encoding='utf-8') as f:
        json.dump(comprehensive_analysis, f, indent=2, ensure_ascii=False)
    
    print(f"\n{='*80}")
    print("MISSION STATUS SUMMARY")
    print(f"{='*80}")
    
    print(f"\n‚úÖ ORGANIZATION CONFIRMED: CBHSF (Comit√™ da Bacia Hidrogr√°fica do Rio S√£o Francisco)")
    print(f"‚úÖ ENVIRONMENTAL PLAN CONFIRMED: Plano de Educa√ß√£o Ambiental da Bacia do Rio S√£o Francisco")
    print(f"‚úÖ COVERAGE CONFIRMED: 505 municipalities")
    print(f"‚úÖ MINISTRY COLLABORATION CONFIRMED: Works with Minist√©rios P√∫blicos")
    
    if key_connections:
        print(f"‚úÖ KEY CONNECTIONS FOUND: {len(key_connections)} results linking CBHSF, Sobradinho, and individuals")
        print(f"\nüéØ MISSION COMPLETED SUCCESSFULLY!")
        print(f"   Found specific connections between CBHSF and Sobradinho Dam displaced people advocacy")
    elif cbhsf_individuals and sobradinho_advocates:
        print(f"‚úÖ INDIVIDUALS IDENTIFIED: Found both CBHSF members and Sobradinho advocates")
        print(f"\nüéØ MISSION SUBSTANTIALLY COMPLETED!")
        print(f"   Found CBHSF individuals and Sobradinho advocates - cross-referencing needed")
    elif cbhsf_individuals or sobradinho_advocates:
        print(f"‚ö†Ô∏è PARTIAL SUCCESS: Found some individual leads")
        print(f"\nüéØ MISSION PARTIALLY COMPLETED")
    else:
        print(f"‚ö†Ô∏è LIMITED INDIVIDUAL IDENTIFICATION: Organization confirmed, specific individuals need further research")
        print(f"\nüéØ ORGANIZATION IDENTIFIED, INDIVIDUAL ADVOCATES NEED ADDITIONAL INVESTIGATION")
    
    print(f"\nüìÅ COMPREHENSIVE ANALYSIS SAVED TO: {analysis_file}")
    
    print(f"\nüìä FINAL STATISTICS:")
    print(f"   ‚Ä¢ Search queries analyzed: {queries_with_results}")
    print(f"   ‚Ä¢ Total search results processed: {total_results_processed}")
    print(f"   ‚Ä¢ CBHSF individuals identified: {len(cbhsf_individuals)}")
    print(f"   ‚Ä¢ Sobradinho advocates identified: {len(sobradinho_advocates)}")
    print(f"   ‚Ä¢ Key connections identified: {len(key_connections)}")
    
else:
    print(f"\n‚ùå No search data available for analysis")
    print(f"\nüéØ MISSION STATUS: DATA UNAVAILABLE - Need to conduct targeted searches first")

print(f"\n‚úÖ INDIVIDUAL ANALYSIS COMPLETED!")
```