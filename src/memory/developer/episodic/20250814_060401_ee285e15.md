### Development Step 3: Title:  
Identify OpenCV Version and Contributors for Initial Mask-RCNN Model Support Implementation

**Description**: Research OpenCV version history and release notes to identify when Mask-RCNN model support was first added to the library. Focus on finding the specific OpenCV version that introduced Mask-RCNN functionality, then examine the contributors, commit history, and development team for that particular release. Extract the names of all contributors who worked on implementing Mask-RCNN support in OpenCV.

**Use Cases**:
- OpenCV library auditing for academic researchers investigating the evolution of deep learning model support, specifically tracking the introduction and contributors of Mask-RCNN functionality for citation or reproducibility purposes
- Corporate compliance review by software engineering managers to verify third-party code provenance and contributor attribution before integrating OpenCV‚Äôs Mask-RCNN features into proprietary computer vision products
- Automated generation of detailed contributor and version history reports for open-source maintainers preparing release notes or grant documentation related to major feature additions in OpenCV
- Security and vulnerability assessment by DevSecOps teams to identify all individuals involved in the Mask-RCNN implementation, supporting risk analysis and supply chain transparency in critical AI deployments
- Technical due diligence for technology consultants evaluating which OpenCV version to adopt in large-scale image segmentation pipelines, ensuring Mask-RCNN support and understanding the maturity of the implementation
- Educational curriculum development by instructors creating case studies on open-source collaboration, using the Mask-RCNN integration in OpenCV to illustrate real-world software engineering processes and contributor roles

```
import requests
import json
from datetime import datetime
import os
import time

print("=== DETAILED OPENCV MASK-RCNN CONTRIBUTOR ANALYSIS ===\n")
print("Objective: Extract all contributors from PR #12243 and correlate with OpenCV versions")
print("Focus: Get detailed pull request info, commit details, and version correlation\n")

# Find workspace directory
workspace_dirs = [d for d in os.listdir('.') if d.startswith('workspace')]
workspace_dir = workspace_dirs[0] if workspace_dirs else 'workspace'
os.makedirs(workspace_dir, exist_ok=True)

# GitHub API configuration
base_url = "https://api.github.com"
repo = "opencv/opencv"
pr_number = 12243
commit_sha = "472b71eceff52681222834545d85c36c7227f977"

headers = {
    'Accept': 'application/vnd.github.v3+json',
    'User-Agent': 'Python-OpenCV-Contributor-Analysis'
}

print(f"Repository: {repo}")
print(f"Target PR: #{pr_number}")
print(f"Primary commit SHA: {commit_sha}")
print(f"Workspace: {workspace_dir}\n")

# Step 1: Get detailed pull request information
print("=== STEP 1: ANALYZING PULL REQUEST #12243 ===\n")

pr_url = f"{base_url}/repos/{repo}/pulls/{pr_number}"
print(f"PR API URL: {pr_url}")

try:
    pr_response = requests.get(pr_url, headers=headers)
    
    if pr_response.status_code == 200:
        pr_data = pr_response.json()
        
        print("‚úÖ Pull Request Details Retrieved Successfully")
        print(f"Title: {pr_data['title']}")
        print(f"Number: #{pr_data['number']}")
        print(f"State: {pr_data['state']}")
        print(f"Created: {pr_data['created_at']}")
        print(f"Merged: {pr_data.get('merged_at', 'Not merged')}")
        print(f"Author: {pr_data['user']['login']} ({pr_data['user']['name'] or 'N/A'})")
        print(f"Base branch: {pr_data['base']['ref']}")
        print(f"Head branch: {pr_data['head']['ref']}")
        print(f"Commits: {pr_data['commits']}")
        print(f"Additions: {pr_data['additions']}")
        print(f"Deletions: {pr_data['deletions']}")
        print(f"Changed files: {pr_data['changed_files']}")
        
        # Extract assignees and reviewers
        assignees = [assignee['login'] for assignee in pr_data.get('assignees', [])]
        print(f"Assignees: {assignees if assignees else 'None'}")
        
        # Get merger information
        merged_by = pr_data.get('merged_by')
        if merged_by:
            print(f"Merged by: {merged_by['login']} ({merged_by.get('name', 'N/A')})")
        
    else:
        print(f"‚ùå Error fetching PR: {pr_response.status_code}")
        print(f"Error details: {pr_response.text[:200]}...")
        pr_data = None
        
except Exception as e:
    print(f"‚ùå Exception fetching PR: {str(e)}")
    pr_data = None

time.sleep(1)

# Step 2: Get all commits in the pull request
print("\n=== STEP 2: ANALYZING ALL COMMITS IN PR #12243 ===\n")

if pr_data:
    pr_commits_url = f"{base_url}/repos/{repo}/pulls/{pr_number}/commits"
    print(f"PR Commits URL: {pr_commits_url}")
    
    try:
        commits_response = requests.get(pr_commits_url, headers=headers)
        
        if commits_response.status_code == 200:
            pr_commits = commits_response.json()
            print(f"‚úÖ Found {len(pr_commits)} commits in PR #{pr_number}")
            
            all_contributors = set()
            commit_details = []
            
            for i, commit in enumerate(pr_commits, 1):
                commit_info = commit['commit']
                author_name = commit_info['author']['name']
                author_email = commit_info['author']['email']
                committer_name = commit_info['committer']['name']
                committer_email = commit_info['committer']['email']
                
                print(f"{i}. Commit: {commit['sha'][:12]}...")
                print(f"   Message: {commit_info['message'][:80]}...")
                print(f"   Date: {commit_info['author']['date']}")
                print(f"   Author: {author_name} <{author_email}>")
                print(f"   Committer: {committer_name} <{committer_email}>")
                
                # Add to contributors set
                all_contributors.add(f"{author_name} <{author_email}>")
                if author_name != committer_name:
                    all_contributors.add(f"{committer_name} <{committer_email}>")
                
                # Store detailed info
                commit_details.append({
                    'sha': commit['sha'],
                    'message': commit_info['message'],
                    'date': commit_info['author']['date'],
                    'author_name': author_name,
                    'author_email': author_email,
                    'committer_name': committer_name,
                    'committer_email': committer_email,
                    'url': commit['html_url']
                })
                print()
            
            print(f"=== ALL CONTRIBUTORS IN PR #{pr_number} ===\n")
            for i, contributor in enumerate(sorted(all_contributors), 1):
                print(f"{i}. {contributor}")
                
        else:
            print(f"‚ùå Error fetching PR commits: {commits_response.status_code}")
            pr_commits = []
            all_contributors = set()
            commit_details = []
            
    except Exception as e:
        print(f"‚ùå Exception fetching PR commits: {str(e)}")
        pr_commits = []
        all_contributors = set()
        commit_details = []
else:
    pr_commits = []
    all_contributors = set()
    commit_details = []

time.sleep(1)

# Step 3: Get pull request reviews and reviewers
print("\n=== STEP 3: ANALYZING PR REVIEWS AND REVIEWERS ===\n")

if pr_data:
    reviews_url = f"{base_url}/repos/{repo}/pulls/{pr_number}/reviews"
    print(f"Reviews URL: {reviews_url}")
    
    try:
        reviews_response = requests.get(reviews_url, headers=headers)
        
        if reviews_response.status_code == 200:
            reviews = reviews_response.json()
            print(f"‚úÖ Found {len(reviews)} reviews for PR #{pr_number}")
            
            reviewers = set()
            
            for i, review in enumerate(reviews, 1):
                reviewer = review['user']['login']
                reviewer_name = review['user'].get('name', 'N/A')
                review_state = review['state']
                submitted_at = review['submitted_at']
                
                print(f"{i}. Reviewer: {reviewer} ({reviewer_name})")
                print(f"   State: {review_state}")
                print(f"   Submitted: {submitted_at}")
                print(f"   Body: {(review.get('body') or 'No comment')[:100]}...")
                print()
                
                reviewers.add(f"{reviewer} ({reviewer_name})")
            
            print(f"=== ALL REVIEWERS FOR PR #{pr_number} ===\n")
            for i, reviewer in enumerate(sorted(reviewers), 1):
                print(f"{i}. {reviewer}")
                
        else:
            print(f"‚ùå Error fetching reviews: {reviews_response.status_code}")
            reviews = []
            reviewers = set()
            
    except Exception as e:
        print(f"‚ùå Exception fetching reviews: {str(e)}")
        reviews = []
        reviewers = set()
else:
    reviews = []
    reviewers = set()

time.sleep(1)

# Step 4: Correlate with OpenCV versions
print("\n=== STEP 4: CORRELATING WITH OPENCV VERSIONS ===\n")

# Load previous release data
try:
    with open(f'{workspace_dir}/opencv_maskrcnn_research.json', 'r') as f:
        previous_data = json.load(f)
except:
    previous_data = {}

# Get more detailed release information around August 2018
releases_url = f"{base_url}/repos/{repo}/releases"
params = {'per_page': 100}

try:
    releases_response = requests.get(releases_url, headers=headers, params=params)
    
    if releases_response.status_code == 200:
        releases = releases_response.json()
        print(f"‚úÖ Retrieved {len(releases)} OpenCV releases")
        
        # Find releases around August 2018
        target_date = datetime.fromisoformat('2018-08-24T14:47:32+03:00')
        
        print("\n=== RELEASES AROUND MASK-RCNN INTRODUCTION (Aug 2018) ===\n")
        
        relevant_releases = []
        for release in releases:
            release_date = datetime.fromisoformat(release['published_at'].replace('Z', '+00:00'))
            
            # Find releases within 6 months of the commit
            days_diff = abs((release_date - target_date).days)
            if days_diff <= 180:  # 6 months
                relevant_releases.append({
                    'tag': release['tag_name'],
                    'name': release['name'],
                    'published_at': release['published_at'],
                    'days_from_commit': days_diff,
                    'before_commit': release_date < target_date
                })
        
        # Sort by proximity to commit date
        relevant_releases.sort(key=lambda x: x['days_from_commit'])
        
        print(f"Found {len(relevant_releases)} releases within 6 months of Mask-RCNN commit:")
        for i, release in enumerate(relevant_releases[:10], 1):
            status = "BEFORE" if release['before_commit'] else "AFTER"
            print(f"{i}. {release['tag']} - {release['name']}")
            print(f"   Published: {release['published_at']}")
            print(f"   {status} commit by {release['days_from_commit']} days")
            print()
        
        # Identify the version that likely included Mask-RCNN
        if relevant_releases:
            after_releases = [r for r in relevant_releases if not r['before_commit']]
            if after_releases:
                likely_version = after_releases[0]
                print(f"üéØ LIKELY VERSION WITH MASK-RCNN: {likely_version['tag']}")
                print(f"   Published: {likely_version['published_at']}")
                print(f"   {likely_version['days_from_commit']} days after the commit")
            
    else:
        print(f"‚ùå Error fetching releases: {releases_response.status_code}")
        releases = []
        relevant_releases = []
        
except Exception as e:
    print(f"‚ùå Exception fetching releases: {str(e)}")
    releases = []
    relevant_releases = []

# Step 5: Compile comprehensive results
print("\n=== COMPREHENSIVE MASK-RCNN IMPLEMENTATION ANALYSIS ===\n")

analysis_results = {
    'analysis_timestamp': datetime.now().isoformat(),
    'repository': repo,
    'mask_rcnn_introduction': {
        'primary_commit_sha': commit_sha,
        'commit_date': '2018-08-24T14:47:32+03:00',
        'pull_request_number': pr_number,
        'pull_request_url': f'https://github.com/{repo}/pull/{pr_number}'
    },
    'pull_request_details': pr_data if pr_data else {},
    'all_commits_in_pr': commit_details,
    'contributors': {
        'commit_contributors': sorted(list(all_contributors)),
        'reviewers': sorted(list(reviewers)) if 'reviewers' in locals() else [],
        'pr_author': pr_data['user']['login'] if pr_data else None,
        'merged_by': pr_data.get('merged_by', {}).get('login') if pr_data else None
    },
    'version_correlation': {
        'commit_date': '2018-08-24T14:47:32+03:00',
        'relevant_releases': relevant_releases if 'relevant_releases' in locals() else [],
        'likely_first_version_with_maskrcnn': likely_version['tag'] if 'likely_version' in locals() else 'TBD'
    },
    'implementation_stats': {
        'commits_in_pr': len(pr_commits) if pr_commits else 0,
        'files_changed': pr_data.get('changed_files') if pr_data else 0,
        'lines_added': pr_data.get('additions') if pr_data else 0,
        'lines_deleted': pr_data.get('deletions') if pr_data else 0,
        'reviews_count': len(reviews) if 'reviews' in locals() else 0
    }
}

# Save comprehensive analysis
output_file = f'{workspace_dir}/opencv_maskrcnn_contributors_analysis.json'
with open(output_file, 'w') as f:
    json.dump(analysis_results, f, indent=2)

print(f"‚úÖ Comprehensive analysis saved to: {output_file}")

# Final summary
print("\n=== FINAL SUMMARY: OPENCV MASK-RCNN IMPLEMENTATION ===\n")
print(f"üéØ First introduced: August 24, 2018")
print(f"üéØ Pull Request: #{pr_number}")
print(f"üéØ Primary commit: {commit_sha}")

if pr_data:
    print(f"üéØ PR Author: {pr_data['user']['login']} ({pr_data['user'].get('name', 'N/A')})")
    if pr_data.get('merged_by'):
        print(f"üéØ Merged by: {pr_data['merged_by']['login']} ({pr_data['merged_by'].get('name', 'N/A')})")

if all_contributors:
    print(f"\nüë• ALL CONTRIBUTORS TO MASK-RCNN IMPLEMENTATION:")
    for i, contributor in enumerate(sorted(all_contributors), 1):
        print(f"  {i}. {contributor}")

if 'reviewers' in locals() and reviewers:
    print(f"\nüëÄ REVIEWERS:")
    for i, reviewer in enumerate(sorted(reviewers), 1):
        print(f"  {i}. {reviewer}")

if 'likely_version' in locals():
    print(f"\nüì¶ LIKELY FIRST VERSION WITH MASK-RCNN: {likely_version['tag']}")
    print(f"   Published: {likely_version['published_at']}")

print(f"\nüìä Implementation Scale:")
if pr_data:
    print(f"   - {pr_data.get('commits', 0)} commits")
    print(f"   - {pr_data.get('changed_files', 0)} files changed")
    print(f"   - {pr_data.get('additions', 0)} lines added")
    print(f"   - {pr_data.get('deletions', 0)} lines deleted")

print("\n‚úÖ MASK-RCNN CONTRIBUTOR ANALYSIS COMPLETE")
```