### Development Step 13: Compile U.S. Presidents’ Birth Cities and Coordinates into presidential_birthplaces.json

**Description**: Collect a complete list of all United States presidents with their official birth city names and state names, then obtain the geographic coordinates (longitude and latitude) for each birth city using authoritative sources such as official presidential biographies or Wikipedia infoboxes. Save the results in a structured format (e.g., CSV or JSON) at workspace/presidential_birthplaces.json.

**Use Cases**:
- Interactive educational web map for high school history classes, allowing students to explore U.S. presidents by birthplace with geospatial visualization.
- Historical research and spatial analysis for political science studies examining regional birth origin patterns of U.S. presidents over time.
- Heritage tourism itinerary planner presenting a “Presidential Birthplaces Trail,” using precise coordinates to guide visitors to birth sites and museums.
- Automated data pipeline feeding a civic engagement platform, mapping congressional districts relative to presidential birth cities for targeted outreach programs.
- Interactive quiz and trivia mobile app that generates location-based questions (e.g., “Which president was born near these coordinates?”) using the JSON dataset.
- News media interactive infographic tool that visualizes presidential birthplaces on election anniversaries to enhance storytelling with accurate geolocation.
- GIS integration for a university digital humanities project, combining presidential birthplace coordinates with demographic layers to analyze historical migration trends.
- Genealogical research platform enhancing family tree profiles by linking presidential ancestors to exact birth locations and enriching narratives with map context.

```
import os
import re
import time
import json
import requests
from bs4 import BeautifulSoup, NavigableString
from geopy.geocoders import Nominatim

# Ensure workspace directory exists
workspace = 'workspace'
os.makedirs(workspace, exist_ok=True)

# 1. Load or fetch the main list of presidents
list_html_path = os.path.join(workspace, 'presidents_list.html')
if os.path.exists(list_html_path):
    print(f"Loading cached HTML from {list_html_path}")
    with open(list_html_path, 'r', encoding='utf-8') as f:
        list_html = f.read()
else:
    list_url = 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States'
    print(f"Fetching presidents list: {list_url}")
    resp = requests.get(list_url, timeout=10)
    resp.raise_for_status()
    list_html = resp.text
    with open(list_html_path, 'w', encoding='utf-8') as f:
        f.write(list_html)
    print(f"Saved HTML to {list_html_path}")

# 2. Parse the table of presidents
soup = BeautifulSoup(list_html, 'html.parser')
table = soup.find('table', class_='wikitable')
rows = table.find_all('tr')[1:]
print(f"Found {len(rows)} presidents in table")

# 3. Build list of president names and URLs
presidents = []
for row in rows:
    cols = row.find_all('td')
    if len(cols) < 2:
        continue
    link = cols[1].find('a', href=True)
    if not link:
        continue
    name = link.get_text(strip=True)
    url = 'https://en.wikipedia.org' + link['href']
    presidents.append({'name': name, 'url': url})
print(f"Collected {len(presidents)} president entries to process")

# 4. Initialize geolocator
geolocator = Nominatim(user_agent='presidential_birth_locator')
results = []

# Patterns
unwanted_trailing = re.compile(r'^(British America|United States|U\.?S\.?A?\.?|USA)$', re.I)

def extract_birthplace(soup):
    """Extract raw birthplace string from president page soup"""
    # Try span.birthplace
    span_bp = soup.select_one('span.birthplace')
    if span_bp and span_bp.get_text(strip=True):
        return span_bp.get_text(strip=True)
    # Fallback: infobox Born row
    infobox = soup.find('table', class_=lambda c: c and 'infobox' in c)
    if infobox:
        born_tr = infobox.find(lambda tag: tag.name=='tr' and tag.th and tag.th.get_text(strip=True).startswith('Born'))
        if born_tr:
            td = born_tr.find('td')
            if td:
                # Split HTML on <br> to separate date from place
                parts = re.split(r'<br\s*/?>', str(td), flags=re.IGNORECASE)
                if len(parts) >= 2:
                    place_html = parts[1]
                    place_html = re.sub(r'<small[^>]*>.*?</small>', '', place_html, flags=re.DOTALL|re.IGNORECASE)
                    place_text = BeautifulSoup(place_html, 'html.parser').get_text(separator=' ', strip=True)
                    return place_text
    return ''

# 5. Process each president
for idx, pres in enumerate(presidents, start=1):
    name = pres['name']
    url = pres['url']
    print(f"\n[{idx}/{len(presidents)}] {name}\nFetching page: {url}")
    # Fetch page safely
    try:
        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
        page_soup = BeautifulSoup(resp.text, 'html.parser')
    except Exception as e:
        print(f"  -> Error fetching {name}: {e}")
        results.append({'name': name, 'birth_city': None, 'birth_state': None, 'latitude': None, 'longitude': None})
        continue
    time.sleep(1)

    # Extract birthplace
    raw_place = extract_birthplace(page_soup)
    if raw_place:
        print(f"  Extracted raw birthplace: '{raw_place}'")
    else:
        print(f"  Warning: no birthplace found for {name}")

    # Clean up raw_place
    clean = re.sub(r'\([^)]*\)', '', raw_place)
    clean = re.sub(r'\[.*?\]', '', clean)
    clean = clean.strip()

    # Tokenize by comma
    tokens = [tok.strip() for tok in clean.split(',') if tok.strip()]
    # Drop leading date tokens
    while tokens and re.search(r'\d', tokens[0]):
        tokens.pop(0)
    # Drop trailing unwanted
    while tokens and unwanted_trailing.match(tokens[-1]):
        tokens.pop()
    birth_clean = ', '.join(tokens)
    print(f"  Cleaned birthplace tokens: {tokens}")
    print(f"  Cleaned birthplace string: '{birth_clean}'")

    # Derive city and state
    city = tokens[0] if len(tokens) >= 1 else None
    state = tokens[1] if len(tokens) >= 2 else None
    print(f"  Parsed city='{city}', state='{state}'")

    # Geocode
    latitude = longitude = None
    if city and state:
        for query in [f"{city}, {state}, USA", f"{birth_clean}, USA"]:
            print(f"  Geocoding: '{query}'")
            try:
                loc = geolocator.geocode(query, timeout=10)
                time.sleep(1)
                if loc:
                    latitude, longitude = loc.latitude, loc.longitude
                    print(f"   -> Got coords: ({latitude}, {longitude})")
                    break
            except Exception as ge:
                print(f"   -> Geocoding error for '{query}': {ge}")
    else:
        print(f"  Insufficient data to geocode for {name}")

    # Record result
    entry = {'name': name, 'birth_city': city, 'birth_state': state,
             'latitude': latitude, 'longitude': longitude}
    print(f"  Recorded: {entry}")
    results.append(entry)

# 6. Save results
out_path = os.path.join(workspace, 'presidential_birthplaces.json')
with open(out_path, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2)
print(f"\nFinished: saved {len(results)} records to {out_path}")
```