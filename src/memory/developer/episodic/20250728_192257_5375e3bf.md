### Development Step 2: 1977 Yankees Walk Totals and At-Bat Statistics: Identify Highest Walker

**Description**: Search for comprehensive 1977 New York Yankees regular season statistics focusing on individual player walk totals. Target these information sources: (1) Official MLB statistics databases or archives, (2) Baseball-Reference.com historical data for 1977 Yankees roster, (3) Sports statistics websites with detailed seasonal breakdowns, (4) Historical baseball records covering individual player performance metrics. Extract complete batting statistics including walks (BB) and at-bats (AB) for all Yankees players during the 1977 regular season. Identify the player with the highest walk total and record their corresponding at-bat count for verification.

**Use Cases**:
- Automated sports analytics workflow for a baseball research lab that extracts 1977 Yankees walk and at-bat data from official MLB archives to feed into sabermetric models.
- Fantasy baseball platform ingestion pipeline that scrapes Baseball-Reference to import historical walk totals and at-bat counts for recreating retro league drafts and player valuation.
- Sports journalism verification tool that pulls archived Yankees batting tables to fact-check player on-base performance in feature stories on the 1977 World Series season.
- Academic statistical study on plate discipline trends using extracted walk and at-bat figures for the 1977 New York Yankees roster to support peer-reviewed publications.
- Interactive museum exhibit dashboard that automatically loads player BB and AB stats from 1977 to power visual timelines and fan-driven exploration of Yankees history.
- Sports betting analytics system incorporating historical walk-to-at-bat ratios from the 1977 season to refine predictive models for modern game odds.
- Digital memorabilia marketplace integration that auto-populates player performance metadata (walks and at-bats) from trusted archives to enhance trading card listings.
- Enterprise data pipeline for a sports data provider that standardizes extracted BB and AB columns from multiple sources into a cloud warehouse for client reporting APIs.

```
import json
import os
from bs4 import BeautifulSoup
import re

# First, let's inspect the structure of the saved analysis file to understand what data we have
analysis_file = 'workspace/baseball_reference_analysis.json'

print("=== ANALYZING SAVED BASEBALL-REFERENCE DATA ===")
print("Step 1: Inspecting the structure of saved analysis file...")

if os.path.exists(analysis_file):
    with open(analysis_file, 'r') as f:
        analysis_data = json.load(f)
    
    print(f"\nAnalysis file keys: {list(analysis_data.keys())}")
    print(f"Source: {analysis_data.get('source', 'Unknown')}")
    print(f"URL: {analysis_data.get('url', 'Unknown')}")
    print(f"Access successful: {analysis_data.get('access_successful', False)}")
    print(f"Total tables found: {analysis_data.get('total_tables_found', 0)}")
    print(f"Batting tables identified: {analysis_data.get('batting_tables_identified', 0)}")
    
    # Examine the batting data analysis structure
    if 'batting_data_analysis' in analysis_data:
        batting_data = analysis_data['batting_data_analysis']
        print(f"\nFound {len(batting_data)} batting data tables to analyze")
        
        # Inspect each batting table
        for i, table_data in enumerate(batting_data):
            print(f"\n--- Table {table_data.get('table_index', i+1)} Analysis ---")
            headers = table_data.get('headers', [])
            print(f"Headers ({len(headers)}): {headers}")
            print(f"Row count: {table_data.get('row_count', 0)}")
            
            # Look for BB (walks) and AB (at-bats) columns
            bb_index = None
            ab_index = None
            player_index = None
            
            for j, header in enumerate(headers):
                header_clean = header.strip().upper()
                if header_clean == 'BB' or 'WALK' in header_clean:
                    bb_index = j
                    print(f"*** Found BB (walks) column at index {j}: '{header}' ***")
                elif header_clean == 'AB' or 'AT BAT' in header_clean or header_clean == 'AT-BAT':
                    ab_index = j
                    print(f"*** Found AB (at-bats) column at index {j}: '{header}' ***")
                elif 'PLAYER' in header_clean or 'NAME' in header_clean or header_clean == 'NAME':
                    player_index = j
                    print(f"*** Found player name column at index {j}: '{header}' ***")
            
            # Examine sample rows
            sample_rows = table_data.get('sample_rows', [])
            print(f"\nSample rows ({len(sample_rows)}):")
            for k, row in enumerate(sample_rows):
                print(f"  Row {k+1}: {row}")
                
                # If we found BB and AB columns, highlight those values
                if bb_index is not None and len(row) > bb_index:
                    print(f"    BB value at index {bb_index}: '{row[bb_index]}'")
                if ab_index is not None and len(row) > ab_index:
                    print(f"    AB value at index {ab_index}: '{row[ab_index]}'")
                if player_index is not None and len(row) > player_index:
                    print(f"    Player name at index {player_index}: '{row[player_index]}'")
            
            # Store column indices for later use
            table_data['bb_column_index'] = bb_index
            table_data['ab_column_index'] = ab_index
            table_data['player_column_index'] = player_index
            
            # Determine if this table is suitable for extraction
            if bb_index is not None and ab_index is not None and player_index is not None:
                print(f"\n*** TABLE {table_data.get('table_index', i+1)} IS SUITABLE FOR EXTRACTION ***")
                print(f"Has all required columns: Player({player_index}), BB({bb_index}), AB({ab_index})")
                table_data['suitable_for_extraction'] = True
            else:
                print(f"\n--- Table {table_data.get('table_index', i+1)} missing required columns ---")
                missing = []
                if bb_index is None: missing.append('BB')
                if ab_index is None: missing.append('AB')
                if player_index is None: missing.append('Player')
                print(f"Missing: {', '.join(missing)}")
                table_data['suitable_for_extraction'] = False
    
    # Save updated analysis with column indices
    with open('workspace/baseball_reference_analysis_updated.json', 'w') as f:
        json.dump(analysis_data, f, indent=2)
    
    print(f"\n=== ANALYSIS COMPLETE ===")
    print("Updated analysis saved to workspace/baseball_reference_analysis_updated.json")
    
else:
    print(f"Error: Analysis file not found at {analysis_file}")
    print("Available files in workspace:")
    if os.path.exists('workspace'):
        for file in os.listdir('workspace'):
            print(f"  - {file}")
    else:
        print("  - workspace directory not found")

print("\n" + "="*60)
print("NEXT STEP: Parse the actual HTML file to extract complete player statistics")
print("Will focus on tables identified as suitable for extraction")
```