### Development Step 8: Identify ‘Little Monsters’ Comic Illustrator and Their Writer Collaborations

**Description**: Search for information about the comic book 'Little Monsters' to identify its illustrator/artist. Focus on finding the artist who illustrated this comic and any information about their collaborations with writers. Look for official publication details, creator credits, and any collaborative relationships mentioned in connection with this work.

**Use Cases**:
- Automating the retrieval of artist and writer credits for an indie comic historian building a comprehensive database of obscure horror graphic novels
- Enabling intellectual property lawyers to gather attribution evidence when verifying creator rights and licensing details for niche comic titles
- Powering a comic magazine’s editorial team to automatically compile illustrator bios and collaboration histories for feature articles on emerging artists
- Helping a specialized bookstore enrich its online catalog with accurate artist credits and publication data for independently published comics
- Assisting library cataloguers in augmenting graphic novel metadata with verified artist and writer information for better discovery in academic collections
- Supporting comic convention organizers in confirming guest speaker credentials by identifying illustrators of lesser-known series for panel line-ups
- Equipping market analysts at a publishing house to track illustrator mention frequencies across multiple comic databases and spot trending artists
- Streamlining fan-community wikis by automatically scraping and updating collaborative credits for “Little Monsters” enthusiasts maintaining character and creator pages

```
import os
import requests
from bs4 import BeautifulSoup
import json
import time
from urllib.parse import quote
import re
from collections import Counter

# Create workspace directory if it doesn't exist
os.makedirs('workspace', exist_ok=True)

print("=== ALTERNATIVE SEARCH APPROACH FOR 'LITTLE MONSTERS' COMIC ARTIST ===")
print("Using DuckDuckGo and comic-specific databases")
print("Previous Google searches failed due to anti-bot measures")
print("=" * 75)

# Initialize search results storage
search_results = {
    'alternative_searches': [],
    'artist_candidates': [],
    'publication_info': [],
    'search_sources': [],
    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
}

print("\nSTEP 1: Trying DuckDuckGo search (fewer anti-bot measures)")
print("-" * 60)

# DuckDuckGo search queries
ddg_queries = [
    '"Little Monsters" comic book artist creator',
    'Little Monsters graphic novel illustrator',
    'Little Monsters comic series writer artist team',
    'Little Monsters horror comic creator credits'
]

for i, query in enumerate(ddg_queries, 1):
    print(f"\nDuckDuckGo Search {i}: {query}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Connection': 'keep-alive'
    }
    
    # DuckDuckGo search URL
    ddg_url = f"https://duckduckgo.com/html/?q={quote(query)}"
    
    try:
        print(f"Requesting: {ddg_url}")
        response = requests.get(ddg_url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
        
        # Get clean text content
        text_content = soup.get_text()
        
        print(f"  ✓ DuckDuckGo response received ({len(text_content)} chars)")
        
        # Look for DuckDuckGo search results
        # DuckDuckGo uses different selectors than Google
        result_selectors = ['.result', '.web-result', '.result__body', '.result__title']
        results = []
        
        for selector in result_selectors:
            found_results = soup.select(selector)
            if found_results:
                results = found_results[:8]  # First 8 results
                print(f"  Found {len(results)} results using selector: {selector}")
                break
        
        # Extract information from search results
        search_snippets = []
        for result in results:
            # Try to find title and description
            title_elem = result.find(['h2', 'h3', 'a'])
            desc_elem = result.find(['p', 'span', 'div'], string=lambda text: text and len(text) > 15)
            
            title = title_elem.get_text() if title_elem else ''
            description = desc_elem.get_text() if desc_elem else ''
            
            # Combine title and description for analysis
            combined_text = f"{title} {description}".lower()
            
            # Look for creator-related keywords
            creator_keywords = ['artist', 'illustrator', 'creator', 'writer', 'by ', 'created by', 'art by', 'illustrated by']
            
            if any(keyword in combined_text for keyword in creator_keywords) and 'little monsters' in combined_text:
                search_snippets.append({
                    'title': title[:150],
                    'description': description[:300],
                    'source': 'DuckDuckGo',
                    'relevance_score': sum(1 for kw in creator_keywords if kw in combined_text)
                })
                
                print(f"    RELEVANT: {title[:80]}...")
                print(f"    Desc: {description[:120]}...")
        
        # Search full text for artist mentions
        artist_mentions = []
        lines = text_content.split('\n')
        
        for line in lines:
            line_lower = line.strip().lower()
            if ('little monsters' in line_lower and 
                any(keyword in line_lower for keyword in ['artist', 'illustrator', 'creator', 'by '])):
                
                clean_line = ' '.join(line.strip().split())
                if len(clean_line) > 20 and len(clean_line) < 200:
                    artist_mentions.append(clean_line)
        
        if artist_mentions:
            print(f"  Found {len(artist_mentions)} potential artist mentions:")
            for mention in artist_mentions[:3]:
                print(f"    - {mention[:100]}...")
        
        # Record search attempt
        search_results['alternative_searches'].append({
            'query': query,
            'source': 'DuckDuckGo',
            'results_found': len(search_snippets),
            'snippets': search_snippets,
            'artist_mentions': artist_mentions[:5]
        })
        
        # Save raw HTML
        filename = f"workspace/duckduckgo_search_{i}.html"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(response.text)
        print(f"  Raw HTML saved to: {filename}")
        
    except Exception as e:
        print(f"  ✗ DuckDuckGo search failed: {e}")
        search_results['alternative_searches'].append({
            'query': query,
            'source': 'DuckDuckGo',
            'status': 'Failed',
            'error': str(e)
        })
    
    time.sleep(3)  # Respectful delay

print("\nSTEP 2: Searching comic-specific databases and sites")
print("-" * 60)

# Try comic-specific sites
comic_sites = [
    {
        'name': 'ComicVine',
        'search_url': 'https://comicvine.gamespot.com/search/?q=Little+Monsters+comic',
        'description': 'Major comic database'
    },
    {
        'name': 'MyComicShop',
        'search_url': 'https://www.mycomicshop.com/search?q=Little+Monsters',
        'description': 'Comic retailer with detailed credits'
    },
    {
        'name': 'League of Comic Geeks',
        'search_url': 'https://leagueofcomicgeeks.com/search/titles?keyword=Little+Monsters',
        'description': 'Comic tracking database'
    }
]

for site in comic_sites:
    print(f"\nSearching {site['name']}: {site['description']}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5'
    }
    
    try:
        print(f"Requesting: {site['search_url']}")
        response = requests.get(site['search_url'], headers=headers, timeout=20)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        text_content = soup.get_text().lower()
        
        print(f"  ✓ {site['name']} response received ({len(text_content)} chars)")
        
        # Look for Little Monsters mentions
        little_monsters_count = text_content.count('little monsters')
        print(f"  'Little Monsters' mentions: {little_monsters_count}")
        
        # Look for creator information
        creator_patterns = [
            r'writer[:\s]*([A-Z][a-z]+\s+[A-Z][a-z]+)',
            r'artist[:\s]*([A-Z][a-z]+\s+[A-Z][a-z]+)',
            r'creator[:\s]*([A-Z][a-z]+\s+[A-Z][a-z]+)',
            r'by\s+([A-Z][a-z]+\s+[A-Z][a-z]+)',
            r'illustrated by\s+([A-Z][a-z]+\s+[A-Z][a-z]+)'
        ]
        
        found_creators = []
        for pattern in creator_patterns:
            matches = re.findall(pattern, response.text)  # Use raw text for better pattern matching
            found_creators.extend(matches)
        
        if found_creators:
            print(f"  Potential creators found: {len(found_creators)}")
            # Remove duplicates and count frequency
            creator_frequency = Counter(found_creators)
            for creator, count in creator_frequency.most_common(5):
                print(f"    {creator}: mentioned {count} time(s)")
                
                search_results['artist_candidates'].append({
                    'name': creator,
                    'source': site['name'],
                    'frequency': count,
                    'confidence': 'Medium' if count > 1 else 'Low'
                })
        
        # Save site content for manual review
        filename = f"workspace/{site['name'].lower().replace(' ', '_')}_search.html"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(response.text)
        print(f"  Content saved to: {filename}")
        
        search_results['search_sources'].append({
            'name': site['name'],
            'url': site['search_url'],
            'status': 'Success',
            'little_monsters_mentions': little_monsters_count,
            'creators_found': len(set(found_creators))
        })
        
    except Exception as e:
        print(f"  ✗ {site['name']} search failed: {e}")
        search_results['search_sources'].append({
            'name': site['name'],
            'url': site['search_url'],
            'status': 'Failed',
            'error': str(e)
        })
    
    time.sleep(4)  # Longer delay for comic sites

print("\nSTEP 3: Analyzing all collected artist information")
print("-" * 60)

# Compile all potential artists from all sources
all_artists = []

# From DuckDuckGo searches
for search in search_results['alternative_searches']:
    if 'artist_mentions' in search:
        for mention in search['artist_mentions']:
            # Extract names using regex patterns
            name_patterns = [
                r'by\s+([A-Z][a-z]+\s+[A-Z][a-z]+)',
                r'artist\s+([A-Z][a-z]+\s+[A-Z][a-z]+)',
                r'creator\s+([A-Z][a-z]+\s+[A-Z][a-z]+)',
                r'illustrated by\s+([A-Z][a-z]+\s+[A-Z][a-z]+)'
            ]
            
            for pattern in name_patterns:
                matches = re.findall(pattern, mention)
                all_artists.extend(matches)

# From comic sites
for candidate in search_results['artist_candidates']:
    all_artists.append(candidate['name'])

print(f"Total artist names collected: {len(all_artists)}")

if all_artists:
    # Count frequency across all sources
    artist_frequency = Counter(all_artists)
    
    print("\nMost frequently mentioned artists:")
    for artist, count in artist_frequency.most_common(10):
        print(f"  {artist}: mentioned {count} time(s)")
        
        # Add to final results with confidence scoring
        confidence = 'High' if count >= 3 else 'Medium' if count >= 2 else 'Low'
        search_results['publication_info'].append({
            'artist_name': artist,
            'total_mentions': count,
            'confidence': confidence,
            'comic_title': 'Little Monsters'
        })
else:
    print("No artist names extracted from alternative searches")

# Save comprehensive results
results_file = 'workspace/little_monsters_alternative_search_results.json'
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(search_results, f, indent=2, ensure_ascii=False)

print(f"\n✓ Alternative search results saved to: {results_file}")

print("\n" + "=" * 75)
print("LITTLE MONSTERS COMIC ARTIST - ALTERNATIVE SEARCH RESULTS")
print("=" * 75)

if search_results['publication_info']:
    print("\n*** POTENTIAL ARTISTS IDENTIFIED ***")
    for info in search_results['publication_info']:
        print(f"Artist: {info['artist_name']}")
        print(f"Mentions: {info['total_mentions']}")
        print(f"Confidence: {info['confidence']}")
        print(f"Comic: {info['comic_title']}")
        print()
else:
    print("\n*** ALTERNATIVE SEARCH SUMMARY ***")
    ddg_searches = len([s for s in search_results['alternative_searches'] if s.get('status') != 'Failed'])
    comic_site_searches = len([s for s in search_results['search_sources'] if s.get('status') == 'Success'])
    
    print(f"DuckDuckGo searches completed: {ddg_searches}")
    print(f"Comic site searches completed: {comic_site_searches}")
    
    if ddg_searches == 0 and comic_site_searches == 0:
        print("\nAll alternative search methods failed.")
        print("This suggests either:")
        print("1. 'Little Monsters' is a very obscure or indie comic")
        print("2. The comic may be known by a different title")
        print("3. Network/access restrictions are preventing searches")
        print("4. The comic may be self-published with limited online presence")
    else:
        print("\nSearches completed but no definitive artist information extracted.")
        print("Manual review of saved HTML files recommended.")

print("\nFiles created for manual inspection:")
for file in os.listdir('workspace'):
    if file.endswith(('.html', '.json')) and ('duckduckgo' in file or 'comic' in file or 'alternative' in file):
        print(f"  - {file}")

print("\nNext steps if no artist found:")
print("1. Manual inspection of saved HTML files")
print("2. Try searching for specific 'Little Monsters' comic series/publishers")
print("3. Search for 'Little Monsters' with different qualifiers (horror, indie, etc.)")
print("4. Consider that multiple comics may share this title")
```