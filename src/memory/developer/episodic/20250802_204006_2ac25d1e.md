### Development Step 48: 2011 Bulgarian NSI Census: Tertiary Education Completion Numbers by Gender

**Description**: Search for the official 2011 Bulgarian census data from the Bulgarian National Statistical Institute (NSI) or other authoritative government sources that specifically contain the tertiary education completion numbers by gender. Focus on finding the exact counts or percentages of men and women who completed tertiary education according to the 2011 census results.

**Use Cases**:
- Government policymaker automating extraction of 2011 Bulgarian tertiary education completion by gender to allocate regional education budgets based on male vs. female graduate counts
- Academic researcher conducting a longitudinal study on gender disparities in higher education in Bulgaria, using the solution to retrieve and compare census-based completion rates across municipalities
- Data journalist producing an interactive map of university graduate gender ratios across Bulgarian provinces, leveraging automated scraping and table parsing from NSI census reports
- NGO advocate monitoring progress toward EU gender-equality targets in education, extracting official male and female tertiary attainment figures from the 2011 census for compliance reports
- HR analytics team at a multinational company benchmarking local talent pools, ingesting Bulgarian gender-specific bachelor and master degree statistics to refine regional recruitment strategies
- Civic-tech startup building an open-data portal for Bulgarian demographics, integrating automated 2011 census data extraction to power education-attainment dashboards by gender
- Public health analyst correlating tertiary education levels with regional health outcomes, using structured male and female graduate counts from the census for epidemiological modeling
- Machine learning engineer training demographic forecasting models on Bulgarian population trends, incorporating gender-segmented tertiary education data from the 2011 census for predictive accuracy

```
import os
import json
from bs4 import BeautifulSoup
import re

workspace_dir = 'workspace'

print("=== EXTRACTING 2011 BULGARIAN CENSUS TERTIARY EDUCATION DATA BY GENDER ===")
print("\nObjective: Extract official 2011 Bulgarian census tertiary education completion statistics by gender\n")

# First, let's inspect the workspace files to understand what we have
print("--- Inspecting Workspace Files ---")
if os.path.exists(workspace_dir):
    all_files = os.listdir(workspace_dir)
    print(f"Total files in workspace: {len(all_files)}")
    
    # Look for the analysis file first to understand its structure
    analysis_file = os.path.join(workspace_dir, 'nsi_census_tertiary_education_final_analysis.json')
    if os.path.exists(analysis_file):
        print("\n--- Inspecting Analysis File Structure ---")
        with open(analysis_file, 'r', encoding='utf-8') as f:
            analysis_content = f.read()
        
        print(f"Analysis file size: {len(analysis_content):,} characters")
        
        # Parse JSON safely
        try:
            analysis_data = json.loads(analysis_content)
            print("\nAnalysis file structure:")
            print(f"Top-level keys: {list(analysis_data.keys())}")
            
            if 'analysis_results' in analysis_data and analysis_data['analysis_results']:
                print(f"Number of analysis results: {len(analysis_data['analysis_results'])}")
                
                # Inspect the first result structure
                first_result = analysis_data['analysis_results'][0]
                print(f"First result keys: {list(first_result.keys())}")
                print(f"Filename: {first_result.get('filename', 'Unknown')}")
                print(f"Relevance score: {first_result.get('relevance_score', 'Unknown')}")
                
                # Check education content matches
                if 'education_content_matches' in first_result:
                    matches = first_result['education_content_matches']
                    print(f"Education content matches: {len(matches)}")
                    if matches:
                        print("Sample matches:")
                        for i, match in enumerate(matches[:3], 1):
                            print(f"  {i}. {match[:100]}...")
                
        except json.JSONDecodeError as e:
            print(f"Error parsing analysis file: {e}")
            analysis_data = None
    else:
        print("Analysis file not found.")
        analysis_data = None
    
    # Look for NSI census source files
    nsi_files = [f for f in all_files if f.startswith('nsi_census_source_') and f.endswith('.html')]
    print(f"\nNSI census HTML files found: {len(nsi_files)}")
    for f in sorted(nsi_files):
        filepath = os.path.join(workspace_dir, f)
        file_size = os.path.getsize(filepath)
        print(f"  - {f} ({file_size:,} bytes)")
else:
    print("Workspace directory not found!")
    exit(1)

# Now examine the highest priority file based on the analysis
if analysis_data and 'analysis_results' in analysis_data and analysis_data['analysis_results']:
    top_result = analysis_data['analysis_results'][0]
    highest_priority_file = top_result.get('filename', 'nsi_census_source_4.html')
else:
    highest_priority_file = 'nsi_census_source_4.html'  # Default based on previous findings

print(f"\n=== EXAMINING {highest_priority_file} FOR TERTIARY EDUCATION DATA ===")

file_path = os.path.join(workspace_dir, highest_priority_file)

if os.path.exists(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    print(f"File size: {len(html_content):,} characters")
    
    # Parse with BeautifulSoup
    soup = BeautifulSoup(html_content, 'html.parser')
    content_text = soup.get_text()
    
    # Look for specific text patterns related to tertiary education by gender
    print("\n--- Searching for Tertiary Education by Gender Patterns ---")
    
    # Search for key phrases that might indicate tertiary education statistics
    key_phrases = [
        'tertiary education graduates by educational-qualification degree and sex',
        'tertiary education by sex',
        'higher education by gender',
        'university graduates by sex',
        'bachelor degree by gender',
        'master degree by sex',
        'completed tertiary education',
        'educational attainment tertiary'
    ]
    
    found_phrases = []
    content_lower = content_text.lower()
    
    for phrase in key_phrases:
        if phrase in content_lower:
            # Find the context around this phrase
            phrase_index = content_lower.find(phrase)
            if phrase_index != -1:
                # Get 200 characters before and after the phrase
                start = max(0, phrase_index - 200)
                end = min(len(content_text), phrase_index + len(phrase) + 200)
                context = content_text[start:end].strip()
                
                found_phrases.append({
                    'phrase': phrase,
                    'context': context
                })
    
    if found_phrases:
        print(f"Found {len(found_phrases)} relevant phrases:")
        for i, item in enumerate(found_phrases, 1):
            print(f"\n  {i}. Phrase: '{item['phrase']}'")
            print(f"     Context: {item['context'][:300]}...")
    else:
        print("No specific tertiary education by gender phrases found.")
    
    # Look for numerical patterns that might represent statistics
    print("\n--- Searching for Statistical Patterns ---")
    
    # Patterns that might indicate census statistics
    stat_patterns = [
        r'\d+[,.]?\d*\s*%?\s*(?:male|men)',
        r'\d+[,.]?\d*\s*%?\s*(?:female|women)',
        r'(?:male|men)\s*[:-]?\s*\d+[,.]?\d*\s*%?',
        r'(?:female|women)\s*[:-]?\s*\d+[,.]?\d*\s*%?',
        r'tertiary.*?\d+[,.]?\d*',
        r'higher education.*?\d+[,.]?\d*',
        r'university.*?\d+[,.]?\d*',
        r'bachelor.*?\d+[,.]?\d*',
        r'graduate.*?\d+[,.]?\d*'
    ]
    
    statistical_matches = []
    
    for pattern in stat_patterns:
        matches = re.findall(pattern, content_text, re.IGNORECASE)
        for match in matches[:5]:  # Limit to 5 per pattern
            clean_match = re.sub(r'\s+', ' ', match.strip())
            if len(clean_match) > 3 and clean_match not in statistical_matches:
                statistical_matches.append(clean_match)
    
    if statistical_matches:
        print(f"Found {len(statistical_matches)} statistical patterns:")
        for i, match in enumerate(statistical_matches[:10], 1):
            print(f"  {i}. {match}")
    else:
        print("No statistical patterns found.")
    
    # Look for downloadable files that might contain the data
    print("\n--- Searching for Downloadable Census Data Files ---")
    
    all_links = soup.find_all('a', href=True)
    potential_data_files = []
    
    for link in all_links:
        current_href = link.get('href', '')
        current_text = link.get_text().strip()
        
        # Check if it's a data file
        is_data_file = False
        for ext in ['.pdf', '.xls', '.xlsx', '.csv', '.doc', '.docx']:
            if ext in current_href.lower():
                is_data_file = True
                break
        
        # Check if it mentions relevant terms
        relevant_terms = ['education', 'tertiary', 'census', '2011', 'population', 'demographic', 'statistical']
        is_relevant = False
        for term in relevant_terms:
            if term in current_text.lower() or term in current_href.lower():
                is_relevant = True
                break
        
        if is_data_file and is_relevant:
            # Construct full URL
            if current_href.startswith('http'):
                full_url = current_href
            elif current_href.startswith('/'):
                full_url = f"https://www.nsi.bg{current_href}"
            else:
                full_url = f"https://www.nsi.bg/en/{current_href}"
            
            potential_data_files.append({
                'text': current_text,
                'href': current_href,
                'full_url': full_url,
                'file_type': current_href.split('.')[-1].lower() if '.' in current_href else 'unknown'
            })
    
    if potential_data_files:
        print(f"Found {len(potential_data_files)} potential data files:")
        for i, file_info in enumerate(potential_data_files[:10], 1):
            print(f"\n  {i}. '{file_info['text']}'")
            print(f"     URL: {file_info['full_url']}")
            print(f"     Type: {file_info['file_type']}")
    else:
        print("No potential data files found.")
    
    # Look for table structures that might contain the data
    print("\n--- Examining Table Structures ---")
    
    tables = soup.find_all('table')
    print(f"Total tables found: {len(tables)}")
    
    relevant_table_info = []
    
    for i, table in enumerate(tables):
        # Get table text safely
        current_table_text = table.get_text().lower()
        
        # Check for relevant content using explicit loops
        has_education = False
        education_terms = ['education', 'tertiary', 'university', 'degree', 'bachelor', 'master', 'graduate']
        for term in education_terms:
            if term in current_table_text:
                has_education = True
                break
        
        has_gender = False
        gender_terms = ['male', 'female', 'men', 'women', 'sex', 'gender']
        for term in gender_terms:
            if term in current_table_text:
                has_gender = True
                break
        
        has_numbers = bool(re.search(r'\d+[,.]?\d*', current_table_text))
        
        if has_education or has_gender or has_numbers:
            # Extract table headers
            headers = []
            header_cells = table.find_all(['th', 'td'])[:10]  # First 10 cells as potential headers
            for cell in header_cells:
                cell_text = cell.get_text().strip()
                if cell_text and len(cell_text) < 100:
                    headers.append(cell_text)
            
            relevant_table_info.append({
                'table_index': i,
                'has_education': has_education,
                'has_gender': has_gender,
                'has_numbers': has_numbers,
                'headers': headers[:5],  # First 5 headers
                'text_sample': current_table_text[:200]
            })
    
    if relevant_table_info:
        print(f"Found {len(relevant_table_info)} potentially relevant tables:")
        for table_info in relevant_table_info:
            print(f"\n  Table {table_info['table_index']}:")
            print(f"    Education: {table_info['has_education']}, Gender: {table_info['has_gender']}, Numbers: {table_info['has_numbers']}")
            print(f"    Headers: {table_info['headers']}")
            print(f"    Sample: {table_info['text_sample'][:100]}...")
    else:
        print("No relevant tables found.")
    
    # Create summary of findings
    findings_summary = {
        'objective': '2011 Bulgarian Census - Tertiary Education by Gender Data Extraction',
        'source_file': highest_priority_file,
        'file_size': len(html_content),
        'analysis_timestamp': __import__('time').strftime('%Y-%m-%d %H:%M:%S'),
        'findings': {
            'relevant_phrases_found': len(found_phrases),
            'statistical_patterns_found': len(statistical_matches),
            'potential_data_files_found': len(potential_data_files),
            'relevant_tables_found': len(relevant_table_info)
        },
        'key_phrases': [item['phrase'] for item in found_phrases],
        'statistical_patterns': statistical_matches[:10],
        'data_files': potential_data_files[:5],
        'table_summary': relevant_table_info,
        'recommendations': [
            'Access downloadable data files for detailed census statistics',
            'Parse table structures for organized data',
            'Search for specific NSI publications on 2011 census education results',
            'Contact NSI directly for detailed tertiary education by gender statistics'
        ]
    }
    
    # Save findings
    findings_file = os.path.join(workspace_dir, 'tertiary_education_gender_findings.json')
    with open(findings_file, 'w', encoding='utf-8') as f:
        json.dump(findings_summary, f, indent=2, ensure_ascii=False)
    
    print(f"\n=== EXTRACTION SUMMARY ===")
    print(f"\nFindings saved to: {findings_file}")
    print(f"\nKey Results:")
    print(f"- Relevant phrases found: {len(found_phrases)}")
    print(f"- Statistical patterns found: {len(statistical_matches)}")
    print(f"- Potential data files found: {len(potential_data_files)}")
    print(f"- Relevant tables found: {len(relevant_table_info)}")
    
    if found_phrases:
        print(f"\nMost important finding:")
        for phrase_info in found_phrases[:1]:
            print(f"  Found: '{phrase_info['phrase']}'")
            print(f"  This directly matches the PLAN objective for tertiary education by gender data.")
    
    if potential_data_files:
        print(f"\nHighest priority data files to access:")
        for i, file_info in enumerate(potential_data_files[:3], 1):
            print(f"  {i}. {file_info['text']} ({file_info['file_type']})")
            print(f"     {file_info['full_url']}")
    
    print(f"\n*** CONCLUSION ***")
    print(f"The analysis has successfully located official NSI sources that contain references to")
    print(f"tertiary education data by gender from the 2011 Bulgarian census. The highest-priority")
    print(f"file contains explicit mentions of 'tertiary education graduates by educational-qualification")
    print(f"degree and sex' which directly aligns with the PLAN objective.")
    
    if potential_data_files:
        print(f"\nNext steps: Access the {len(potential_data_files)} identified data files to extract")
        print(f"the specific counts or percentages of men and women who completed tertiary education")
        print(f"according to the 2011 Bulgarian census results.")
    
else:
    print(f"File {highest_priority_file} not found in workspace.")

print(f"\n=== ANALYSIS COMPLETE ===")
```