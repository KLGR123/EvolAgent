### Development Step 9: Search NSI 2011 Bulgarian Census for Tertiary Education Completion by Gender

**Description**: Search for the 2011 Bulgarian census data on tertiary education completion by gender. Look for official census results from Bulgaria's National Statistical Institute or other authoritative sources that provide the specific breakdown of men and women who completed tertiary education in 2011.

**Use Cases**:
- Automated extraction of gender‐segmented tertiary education data for a government education ministry to monitor regional enrollment trends and allocate scholarship funds efficiently
- Gender equity research at a women’s rights NGO, scraping national census HTML files to quantify male vs. female university completion rates and guide targeted outreach programs
- University admissions office integration, parsing official census pages to forecast incoming student demographics and adjust faculty recruiting and course offerings based on educational attainment distributions
- Data journalism pipeline that automatically scans downloaded census reports for tables on higher–education by gender, generating up‐to‐date infographics for online news features on Bulgaria’s education gap
- Labor market consultancy analysis, merging extracted census statistics on tertiary credentials by gender with employment data to advise corporate clients on talent acquisition strategies
- Academic comparative study in sociology, systematically harvesting 2011 Bulgarian census education breakdowns alongside other EU countries’ data for cross‐national gender disparity publications
- Business intelligence dashboard for an ed-tech firm, automatically pulling and updating NSI census HTML tables to enrich product usage analytics with regional education‐level demographics
- Archival digitization workflow for a national library, programmatically inspecting stored HTML reports to tag and catalog documents containing tertiary education and gender statistics in the metadata index

```
import os
import json
from bs4 import BeautifulSoup
import re
import time

# Let's start fresh and carefully inspect the workspace
print("=== BULGARIAN 2011 CENSUS TERTIARY EDUCATION DATA EXTRACTION ===")
print("Objective: Find tertiary education completion by gender from 2011 Bulgarian census")
print("Strategy: Careful file inspection followed by systematic content analysis\n")

# Step 1: Inspect workspace contents
workspace_path = 'workspace'
if not os.path.exists(workspace_path):
    print("No workspace directory found")
    exit()

all_files = os.listdir(workspace_path)
print(f"Total files in workspace: {len(all_files)}")

# Separate HTML files from other files
html_files = []
other_files = []

for filename in all_files:
    if filename.endswith('.html'):
        html_files.append(filename)
    else:
        other_files.append(filename)

print(f"HTML files: {len(html_files)}")
print(f"Other files: {len(other_files)}")

# Show all HTML files with their sizes
print("\n=== HTML FILES INVENTORY ===\n")
for i, html_file in enumerate(html_files, 1):
    filepath = os.path.join(workspace_path, html_file)
    file_size = os.path.getsize(filepath)
    print(f"{i:2d}. {html_file}")
    print(f"    Size: {file_size:,} bytes")
    
    # Quick relevance check based on filename
    filename_lower = html_file.lower()
    relevance_indicators = []
    if 'bulgaria' in filename_lower:
        relevance_indicators.append('Bulgaria')
    if 'education' in filename_lower:
        relevance_indicators.append('Education')
    if 'demographics' in filename_lower:
        relevance_indicators.append('Demographics')
    if 'census' in filename_lower:
        relevance_indicators.append('Census')
    if 'nsi' in filename_lower:
        relevance_indicators.append('NSI')
    if 'eurostat' in filename_lower:
        relevance_indicators.append('Eurostat')
    
    if relevance_indicators:
        print(f"    Relevance: {', '.join(relevance_indicators)}")
    print()

# Show other files that might contain analysis results
print("=== OTHER FILES ===\n")
for other_file in other_files:
    filepath = os.path.join(workspace_path, other_file)
    file_size = os.path.getsize(filepath)
    print(f"{other_file} - {file_size:,} bytes")

# Step 2: Start with the most promising HTML files
print("\n=== SELECTING PRIORITY FILES FOR ANALYSIS ===\n")

# Identify high-priority files based on names and sizes
priority_files = []
for html_file in html_files:
    filepath = os.path.join(workspace_path, html_file)
    file_size = os.path.getsize(filepath)
    
    # Skip very small files (likely error pages)
    if file_size < 5000:
        continue
    
    filename_lower = html_file.lower()
    priority_score = 0
    
    # Score based on filename relevance
    if 'demographics' in filename_lower:
        priority_score += 3
    if 'education' in filename_lower:
        priority_score += 3
    if 'bulgaria' in filename_lower:
        priority_score += 2
    if 'census' in filename_lower:
        priority_score += 2
    if 'nsi' in filename_lower:
        priority_score += 2
    if 'eurostat' in filename_lower:
        priority_score += 1
    
    if priority_score > 0:
        priority_files.append({
            'filename': html_file,
            'size': file_size,
            'priority_score': priority_score
        })

# Sort by priority score
priority_files.sort(key=lambda x: x['priority_score'], reverse=True)

print(f"Priority files identified: {len(priority_files)}")
for i, pf in enumerate(priority_files, 1):
    print(f"{i}. {pf['filename']} (Score: {pf['priority_score']}, Size: {pf['size']:,} bytes)")

print("\n=== ANALYZING TOP PRIORITY FILES ===\n")

# Step 3: Analyze the top priority files
analysis_results = []
top_files_to_analyze = priority_files[:5]  # Analyze top 5 files

for file_info in top_files_to_analyze:
    filename = file_info['filename']
    print(f"Analyzing: {filename}")
    
    filepath = os.path.join(workspace_path, filename)
    
    try:
        # Read the HTML file
        with open(filepath, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        # Parse with BeautifulSoup
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Get page title
        title_tag = soup.find('title')
        page_title = title_tag.get_text().strip() if title_tag else 'No title'
        
        # Extract all text content
        page_text = soup.get_text()
        page_text_lower = page_text.lower()
        
        print(f"  Title: {page_title}")
        print(f"  Content length: {len(page_text):,} characters")
        
        # Check for key indicators
        has_bulgaria = 'bulgaria' in page_text_lower
        has_2011 = '2011' in page_text_lower
        has_census = 'census' in page_text_lower
        has_tertiary = any(term in page_text_lower for term in ['tertiary', 'tertiary education', 'higher education'])
        has_gender_terms = any(term in page_text_lower for term in ['men', 'women', 'male', 'female', 'gender'])
        has_education = 'education' in page_text_lower
        
        indicators = []
        if has_bulgaria: indicators.append('Bulgaria')
        if has_2011: indicators.append('2011')
        if has_census: indicators.append('Census')
        if has_tertiary: indicators.append('Tertiary')
        if has_gender_terms: indicators.append('Gender')
        if has_education: indicators.append('Education')
        
        print(f"  Key indicators: {', '.join(indicators)}")
        
        # If this looks promising, do deeper analysis
        if len(indicators) >= 4:
            print(f"  *** HIGH RELEVANCE - EXTRACTING DATA ***")
            
            # Look for sentences with numbers and education terms
            sentences = page_text.split('.')
            relevant_sentences = []
            
            for sentence in sentences:
                sentence_clean = sentence.strip()
                if len(sentence_clean) < 50:  # Skip short sentences
                    continue
                
                sentence_lower = sentence_clean.lower()
                
                # Look for sentences with Bulgaria + education + numbers
                if ('bulgaria' in sentence_lower and 
                    any(edu_term in sentence_lower for edu_term in ['education', 'tertiary', 'university', 'degree']) and
                    re.search(r'\d+', sentence_lower)):
                    relevant_sentences.append(sentence_clean)
            
            print(f"  Relevant sentences found: {len(relevant_sentences)}")
            
            # Look for tables
            tables = soup.find_all('table')
            education_tables = []
            
            for table_idx, table in enumerate(tables):
                table_text = table.get_text().lower()
                if (any(term in table_text for term in ['education', 'tertiary', 'university']) and
                    any(term in table_text for term in ['men', 'women', 'male', 'female'])):
                    
                    # Extract table structure
                    headers = [th.get_text().strip() for th in table.find_all('th')]
                    rows = table.find_all('tr')
                    
                    education_tables.append({
                        'index': table_idx,
                        'headers': headers[:10],  # First 10 headers
                        'row_count': len(rows)
                    })
            
            print(f"  Education-related tables: {len(education_tables)}")
            
            # Store results
            analysis_results.append({
                'filename': filename,
                'title': page_title,
                'content_length': len(page_text),
                'indicators': indicators,
                'relevant_sentences': relevant_sentences[:3],  # Top 3
                'education_tables': education_tables[:2],      # Top 2
                'full_analysis': True
            })
            
            # Show sample findings
            if relevant_sentences:
                print(f"  Sample: {relevant_sentences[0][:200]}...")
            if education_tables:
                print(f"  Table headers: {education_tables[0]['headers'][:5]}")
        else:
            # Store basic info for low-relevance files
            analysis_results.append({
                'filename': filename,
                'title': page_title,
                'content_length': len(page_text),
                'indicators': indicators,
                'full_analysis': False
            })
        
        print()
        
    except Exception as e:
        print(f"  Error analyzing {filename}: {str(e)}")
        print()

# Save analysis results
print("=== SAVING ANALYSIS RESULTS ===\n")

final_analysis = {
    'objective': 'Extract Bulgarian 2011 census tertiary education completion by gender',
    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'total_html_files': len(html_files),
    'priority_files_analyzed': len(top_files_to_analyze),
    'files_with_full_analysis': len([r for r in analysis_results if r.get('full_analysis', False)]),
    'analysis_results': analysis_results
}

results_file = os.path.join(workspace_path, 'bulgarian_census_analysis_results.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(final_analysis, f, indent=2, ensure_ascii=False)

print(f"Analysis results saved to: {results_file}")
print(f"Total HTML files: {len(html_files)}")
print(f"Priority files analyzed: {len(top_files_to_analyze)}")
print(f"Files with detailed analysis: {len([r for r in analysis_results if r.get('full_analysis', False)])}")

# Summary of findings
print("\n=== SUMMARY OF FINDINGS ===\n")

high_relevance_files = [r for r in analysis_results if r.get('full_analysis', False)]
if high_relevance_files:
    for i, result in enumerate(high_relevance_files, 1):
        print(f"{i}. {result['title']}")
        print(f"   File: {result['filename']}")
        print(f"   Indicators: {', '.join(result['indicators'])}")
        if result.get('relevant_sentences'):
            print(f"   Key finding: {result['relevant_sentences'][0][:150]}...")
        if result.get('education_tables'):
            print(f"   Tables with education data: {len(result['education_tables'])}")
        print()
else:
    print("No high-relevance files found. May need to expand search criteria.")

print("=== ANALYSIS COMPLETE ===\n")
print("Ready for next phase: detailed extraction of specific tertiary education statistics by gender")
```