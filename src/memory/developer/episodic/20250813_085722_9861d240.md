### Development Step 15: Identify ‚ÄòLittle Monsters‚Äô Comic Book Illustrator and Their Collaborations with Writers

**Description**: Search for information about the comic book 'Little Monsters' to identify its illustrator/artist. Focus on finding the artist who illustrated this comic and any information about their collaborations with writers. Look for official publication details, creator credits, and any collaborative relationships mentioned in connection with this work.

**Use Cases**:
- Cataloging vintage comic book metadata for an online library, automatically extracting illustrator and writer credits from web sources to populate a searchable archive.
- Due diligence for intellectual property lawyers, programmatically verifying artist and writer attributions in obscure comic titles to support licensing negotiations.
- E-commerce product enrichment for comic retailers, scraping official publication details to auto-fill illustrator names and collaboration info in product listings.
- Academic research on comic book collaborations, aggregating data on illustrators and writers across multiple series for network analysis in a media studies study.
- Podcast script preparation for comic culture shows, quickly gathering accurate artist credits and publication histories to craft well-informed episode narratives.
- Festival guest curation for comic conventions, scanning online sources to identify and invite artists who illustrated specific cult-classic comics like ‚ÄúLittle Monsters.‚Äù
- Journalistic fact-checking for entertainment reporters, extracting and validating illustrator names and co-creator relationships to ensure accuracy in articles.
- Digital marketing campaign planning for comic publishers, compiling illustrator portfolios and past collaborations to feature in targeted social media content.

```
import os
from bs4 import BeautifulSoup
import re
import json
import time

print("=== LITTLE MONSTERS COMIC ARTIST SEARCH ===")
print("Searching for information about Little Monsters comic artist/illustrator")
print("=" * 70)

# Create workspace directory if needed
workspace_dir = 'workspace'
if not os.path.exists(workspace_dir):
    os.makedirs(workspace_dir, exist_ok=True)
    print("Created workspace directory")

# First, let's check what files we already have
print(f"\nChecking existing files in {workspace_dir}:")
if os.path.exists(workspace_dir):
    all_files = os.listdir(workspace_dir)
    html_files = [f for f in all_files if f.endswith('.html')]
    json_files = [f for f in all_files if f.endswith('.json')]
    
    print(f"Total files: {len(all_files)}")
    print(f"HTML files: {len(html_files)}")
    print(f"JSON files: {len(json_files)}")
    
    if html_files:
        print(f"\nHTML files available for inspection:")
        for i, file in enumerate(html_files[:10], 1):  # Show first 10
            print(f"  {i:2d}. {file}")
        if len(html_files) > 10:
            print(f"  ... and {len(html_files) - 10} more files")
else:
    print("No existing workspace found")

# Initialize search results
search_results = {
    'comic_title': 'Little Monsters',
    'search_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'files_analyzed': [],
    'artist_candidates': [],
    'search_summary': {}
}

print(f"\n{'='*70}")
print("CONDUCTING FRESH SEARCH FOR LITTLE MONSTERS COMIC ARTIST")
print(f"{'='*70}")

# Let's start with a targeted web search for Little Monsters comic information
import requests
from urllib.parse import quote

# Search queries specifically for Little Monsters comic artist information
search_queries = [
    'Little Monsters comic book artist illustrator creator',
    '"Little Monsters" comic series artist writer',
    'Little Monsters graphic novel illustrator',
    'Little Monsters comic book Gold Key artist',
    'Little Monsters comic creator credits'
]

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Connection': 'keep-alive'
}

for i, query in enumerate(search_queries, 1):
    print(f"\nSearch {i}: {query}")
    print("-" * 50)
    
    try:
        # Use DuckDuckGo search
        search_url = f"https://duckduckgo.com/?q={quote(query)}&t=h_&ia=web"
        print(f"Searching: {search_url}")
        
        response = requests.get(search_url, headers=headers, timeout=15)
        response.raise_for_status()
        
        # Parse the response
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove scripts and styles
        for script in soup(["script", "style"]):
            script.decompose()
        
        # Get text content
        text_content = soup.get_text()
        
        print(f"‚úì Search completed ({len(text_content):,} characters)")
        
        # Save the search results
        filename = f'little_monsters_search_{i}.html'
        filepath = os.path.join(workspace_dir, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(response.text)
        print(f"‚úì Results saved to: {filename}")
        
        # Look for potential artist information in the results
        lines = text_content.split('\n')
        relevant_lines = []
        
        for line in lines:
            line_clean = ' '.join(line.strip().split())
            if (len(line_clean) > 20 and 
                'little monsters' in line_clean.lower() and
                any(keyword in line_clean.lower() for keyword in ['artist', 'creator', 'writer', 'illustrator', 'by'])):
                relevant_lines.append(line_clean)
        
        if relevant_lines:
            print(f"Found {len(relevant_lines)} potentially relevant lines:")
            for j, line in enumerate(relevant_lines[:3], 1):
                print(f"  {j}. {line[:100]}...")
        
        # Search for artist names using patterns
        artist_patterns = [
            r'(?i)(?:artist|art by|illustrated by|artwork by|drawn by)[:\s]+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)',
            r'(?i)(?:writer|written by|story by|script by)[:\s]+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)',
            r'(?i)(?:creator|created by|by)[:\s]+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)',
            r'(?i)little monsters.*?(?:by|artist|writer)[:\s]*([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)'
        ]
        
        found_creators = []
        for pattern in artist_patterns:
            matches = re.findall(pattern, text_content)
            for match in matches:
                if (len(match.strip()) > 2 and len(match.strip()) < 40 and
                    not any(word in match.lower() for word in ['little', 'monsters', 'comic', 'book'])):
                    found_creators.append(match.strip())
        
        if found_creators:
            unique_creators = list(set(found_creators))
            print(f"Potential creators found: {', '.join(unique_creators)}")
            
            for creator in unique_creators:
                search_results['artist_candidates'].append({
                    'name': creator,
                    'source': f'Search {i}',
                    'query': query
                })
        
        search_results['files_analyzed'].append({
            'filename': filename,
            'query': query,
            'relevant_lines': len(relevant_lines),
            'creators_found': len(found_creators)
        })
        
    except Exception as e:
        print(f"‚úó Search {i} failed: {e}")
        search_results['files_analyzed'].append({
            'query': query,
            'status': 'Failed',
            'error': str(e)
        })
    
    time.sleep(2)  # Respectful delay

print(f"\n{'='*70}")
print("ANALYZING SEARCH RESULTS")
print(f"{'='*70}")

# Analyze all collected artist candidates
all_artists = [candidate['name'] for candidate in search_results['artist_candidates']]

if all_artists:
    from collections import Counter
    artist_frequency = Counter(all_artists)
    
    print(f"\nüé® ARTIST CANDIDATES IDENTIFIED:")
    print(f"Total mentions: {len(all_artists)}")
    print(f"Unique artists: {len(artist_frequency)}")
    
    print(f"\nArtist ranking by frequency:")
    for rank, (artist, count) in enumerate(artist_frequency.most_common(), 1):
        sources = [c['source'] for c in search_results['artist_candidates'] if c['name'] == artist]
        print(f"  {rank}. {artist} - {count} mention(s) from {', '.join(set(sources))}")
    
    # Identify top candidate
    if artist_frequency:
        top_artist = artist_frequency.most_common(1)[0]
        print(f"\n*** MOST LIKELY LITTLE MONSTERS ARTIST: {top_artist[0]} ***")
        print(f"*** CONFIDENCE: {top_artist[1]} mention(s) across searches ***")
        
        search_results['search_summary'] = {
            'status': 'SUCCESS',
            'top_artist': top_artist[0],
            'confidence': f'{top_artist[1]} mentions',
            'total_candidates': len(artist_frequency)
        }
else:
    print(f"\n‚ùå NO ARTIST CANDIDATES FOUND")
    print(f"This could indicate:")
    print(f"1. The comic may be very obscure or indie")
    print(f"2. Creator information may not be widely available online")
    print(f"3. There may be multiple comics with this title")
    print(f"4. Search results may not contain the specific information")
    
    search_results['search_summary'] = {
        'status': 'NO_RESULTS',
        'searches_completed': len([f for f in search_results['files_analyzed'] if f.get('status') != 'Failed']),
        'total_searches': len(search_results['files_analyzed'])
    }

# Save comprehensive results
results_file = os.path.join(workspace_dir, 'little_monsters_artist_search_results.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(search_results, f, indent=2, ensure_ascii=False)

print(f"\n‚úì Search results saved to: {results_file}")

# If we have existing files from previous searches, let's also examine those
if html_files:
    print(f"\n{'='*70}")
    print("EXAMINING EXISTING SEARCH FILES")
    print(f"{'='*70}")
    
    # Look at a few key files that might contain comic information
    priority_files_to_check = [
        'comicvine_search.html',
        'mycomicshop_search.html',
        'gold_key_search_1.html',
        'little_monsters_search_1.html'
    ]
    
    for filename in priority_files_to_check:
        filepath = os.path.join(workspace_dir, filename)
        if os.path.exists(filepath):
            print(f"\nExamining: {filename}")
            try:
                with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                soup = BeautifulSoup(content, 'html.parser')
                text = soup.get_text()
                
                # Count key terms
                lm_count = text.lower().count('little monsters')
                artist_count = text.lower().count('artist')
                
                print(f"  'Little Monsters' mentions: {lm_count}")
                print(f"  'Artist' mentions: {artist_count}")
                
                if lm_count > 0:
                    # Look for lines with both Little Monsters and creator terms
                    lines = text.split('\n')
                    for line in lines:
                        if ('little monsters' in line.lower() and 
                            any(term in line.lower() for term in ['artist', 'creator', 'by', 'writer'])):
                            print(f"  Relevant: {line.strip()[:120]}...")
                            break
                            
            except Exception as e:
                print(f"  Error reading {filename}: {e}")

print(f"\n{'='*70}")
print("LITTLE MONSTERS ARTIST SEARCH COMPLETED")
print(f"{'='*70}")

if search_results['search_summary'].get('status') == 'SUCCESS':
    print(f"\n‚úÖ SUCCESS: Found potential artist information")
    print(f"Recommended artist: {search_results['search_summary']['top_artist']}")
    print(f"Confidence: {search_results['search_summary']['confidence']}")
else:
    print(f"\n‚ö†Ô∏è  INCOMPLETE: No definitive artist found")
    print(f"Searches completed: {len(search_results['files_analyzed'])}")
    print(f"Files created for manual review: {len([f for f in search_results['files_analyzed'] if 'filename' in f])}")
    
print(f"\nAll search data saved to workspace/ for further analysis.")
```