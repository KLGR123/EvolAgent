### Development Step 5: Generate JSON of US Presidents’ Birth Cities, States, and Geographic Coordinates

**Description**: Collect a complete list of all United States presidents with their official birth city names and state names, then obtain the geographic coordinates (longitude and latitude) for each birth city using authoritative sources such as official presidential biographies or Wikipedia infoboxes. Save the results in a structured format (e.g., CSV or JSON) at workspace/presidential_birthplaces.json.

**Use Cases**:
- Interactive classroom geography modules for history teachers visualizing US presidents’ birthplaces on an interactive map
- Political science research analyzing spatial distribution of presidential birthplaces to study regional influences on leadership pathways
- Travel and tourism route-planning tools designing presidential heritage tours with optimized itineraries between birth cities
- News media data-driven features embedding geolocated infographics of presidents’ birth locations for anniversary and election coverage
- Mobile educational gaming apps offering location-based trivia on presidential birthplaces using map-based challenges
- Museum exhibit kiosks displaying a geospatial timeline of US presidents’ birth locations for visitor engagement
- Non-profit and civic organizations mapping birthplaces to assess historical representation and state-level political engagement
- GIS and data analysis platforms integrating presidential birthplace coordinates into broader demographic and socioeconomic spatial models

```
import os
import re
import time
import json
import requests
from bs4 import BeautifulSoup, NavigableString, Tag
from geopy.geocoders import Nominatim

# Ensure workspace directory exists
workspace = 'workspace'
os.makedirs(workspace, exist_ok=True)

# Load or fetch the list of presidents page
list_html_path = os.path.join(workspace, 'presidents_list.html')
if os.path.exists(list_html_path):
    print(f"Loading cached HTML from {list_html_path}")
    with open(list_html_path, 'r', encoding='utf-8') as f:
        list_html = f.read()
else:
    url = 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States'
    print(f"Fetching presidents list from {url}")
    resp = requests.get(url)
    resp.raise_for_status()
    list_html = resp.text
    with open(list_html_path, 'w', encoding='utf-8') as f:
        f.write(list_html)
    print(f"Saved HTML to {list_html_path}")

# Parse the presidents table
soup = BeautifulSoup(list_html, 'html.parser')
table = soup.find('table', class_='wikitable')
rows = table.find_all('tr')[1:]
print(f"Found {len(rows)} presidents in table")

# Collect names and URLs
presidents = []
for row in rows:
    cells = row.find_all('td')
    if len(cells) < 2:
        continue
    a = cells[1].find('a', href=True)
    if not a:
        continue
    name = a.get_text(strip=True)
    page_url = 'https://en.wikipedia.org' + a['href']
    presidents.append({'name': name, 'url': page_url})
print(f"Collected {len(presidents)} president pages to fetch")

# Prepare geocoder
geolocator = Nominatim(user_agent='presidential_birth_locator')
results = []

for idx, pres in enumerate(presidents, start=1):
    name = pres['name']
    url = pres['url']
    print(f"\n[{idx}/{len(presidents)}] Processing {name}\n URL: {url}")

    # Fetch individual page
    resp = requests.get(url)
    resp.raise_for_status()
    page = resp.text
    soup_p = BeautifulSoup(page, 'html.parser')
    time.sleep(1)

    # Find Born row in infobox
    infobox = soup_p.find('table', class_=lambda c: c and 'infobox' in c)
    birth_place = ''
    if infobox:
        for tr in infobox.find_all('tr'):
            th = tr.find('th')
            if th and th.get_text(strip=True).startswith('Born'):
                td = tr.find('td')
                if td:
                    # Use contents to isolate location after <br>
                    contents = td.contents
                    # find first <br>
                    br_index = next((i for i, el in enumerate(contents)
                                     if isinstance(el, Tag) and el.name == 'br'), None)
                    if br_index is not None:
                        parts = []
                        # iterate siblings after the <br>
                        for el in contents[br_index + 1:]:
                            # skip unwanted tags
                            if isinstance(el, Tag):
                                if el.name == 'a':
                                    parts.append(el.get_text())
                                else:
                                    # skip sup, span, small, etc.
                                    continue
                            elif isinstance(el, NavigableString):
                                txt = str(el)
                                # ignore comments, parentheses, references
                                if txt.strip() and not txt.strip().startswith('(') and not txt.strip().startswith('['):
                                    parts.append(txt)
                        # join, clean whitespace
                        raw = ''.join(parts).strip()
                        raw = re.sub(r'\s+', ' ', raw)
                        # remove parentheticals
                        raw = re.sub(r'\([^)]*\)', '', raw).strip()
                        # strip trailing commas/spaces
                        raw = raw.rstrip(', ')  
                        birth_place = raw
                break
    print(f"  Raw extracted place: '{birth_place}'")

    # Clean out historical country markers
    # Remove trailing 'British America', 'U.S.', etc.
    birth_clean = re.sub(r',?\s*(British America|British\xa0America|U\.S\.?|U\.S\.A\.?|United States|USA)$', '', birth_place)
    birth_clean = birth_clean.strip()

    # Split into city/state
    city = state = ''
    if birth_clean:
        tokens = [t.strip() for t in birth_clean.split(',') if t.strip()]
        if tokens:
            city = tokens[0]
        if len(tokens) > 1:
            state = tokens[1]
    print(f"  Cleaned city='{city}', state='{state}'")

    # Geocode "City, State, USA"
    lat = lon = None
    if city and state:
        query = f"{city}, {state}, USA"
        print(f"  Geocoding: '{query}'")
        try:
            location = geolocator.geocode(query, timeout=10)
            time.sleep(1)
            if location:
                lat, lon = location.latitude, location.longitude
                print(f"   -> Got coords: ({lat}, {lon})")
            else:
                print("   -> Geocoding returned no result")
        except Exception as e:
            print(f"   -> Geocoding error: {e}")

    entry = {
        'name': name,
        'birth_city': city,
        'birth_state': state,
        'latitude': lat,
        'longitude': lon
    }
    results.append(entry)

# Save to JSON
out_file = os.path.join(workspace, 'presidential_birthplaces.json')
with open(out_file, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2)
print(f"\nSaved {len(results)} records to {out_file}")
```