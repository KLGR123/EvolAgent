### Development Step 3: **Title:**  
Locate and Analyze Footnote 397 in Federico Lauria’s 2014 Dissertation for Bibliographic Reference

**Description**: Search for Federico Lauria's 2014 dissertation to locate and examine footnote 397. Extract the complete bibliographic information and identify the specific work referenced in this footnote. Focus on finding the dissertation title, institution, and accessing the full text or at least the section containing footnote 397 to determine what literary or historical work is being cited.

**Use Cases**:
- Academic research verification for scholars needing to trace and confirm specific citations (such as footnote 397) in dissertations for literature reviews or meta-analyses
- Library and information science staff assisting patrons in locating hard-to-find dissertation references or verifying bibliographic details for interlibrary loan requests
- Automated digital humanities projects aiming to extract, cross-reference, and analyze footnotes and bibliographies across large corpora of academic theses
- University administrative offices conducting audits of doctoral dissertations to ensure citation integrity and completeness before degree conferral
- Legal teams performing due diligence on scholarly works cited in expert testimony, requiring precise identification and retrieval of referenced materials
- Publishers or editors fact-checking academic manuscripts prior to publication, needing to confirm the existence and content of specific footnotes in cited dissertations

```
import os
import requests
from bs4 import BeautifulSoup
import json
from urllib.parse import urljoin, quote
import time
import re

print('=== SAVING COMPREHENSIVE SEARCH LOG AND EXPLORING ALTERNATIVE APPROACHES ===')
print('Target: Federico Lauria 2014 dissertation footnote 397')
print('Status: Dissertation identified, but footnote 397 not yet located')
print('\n' + '='*80 + '\n')

# Ensure workspace directory exists
os.makedirs('workspace', exist_ok=True)

# First, save the comprehensive search log as recommended by tester
print('=== STEP 1: SAVING COMPREHENSIVE SEARCH LOG ===')

search_log_content = '''
COMPREHENSIVE FEDERICO LAURIA DISSERTATION SEARCH LOG
=====================================================

DISSERTATION IDENTIFIED:
Title: "The Logic of the Liver: A Deontic View of the Intentionality of Desire"
Author: Federico Lauria
Year: 2014
Source: PhilPapers (https://philpapers.org/rec/LAUQLO)
Likely Institution: University of Geneva (based on topic and author profile)

SEARCH ATTEMPTS COMPLETED:
1. Google Scholar searches with multiple query variations
2. ProQuest Dissertations & Theses Global search
3. WorldCat dissertation search
4. Direct PhilPapers access (403 error - access restricted)
5. Downloaded and analyzed 422-page PDF from core.ac.uk
6. Alternative searches using full dissertation title

FOOTNOTE 397 SEARCH RESULTS:
- Comprehensive regex pattern search performed
- Enhanced patterns used: footnote 397, note 397, \\b397\\., etc.
- Nearby footnotes found: 395 (page 247), 398 (page 331), 399 (page 300)
- NO FOOTNOTE 397 FOUND in available 422-page document

FILES DOWNLOADED:
- lauria_dissertation_match_3.pdf (1,961,589 bytes, 422 pages)
- Multiple HTML pages from Google Books and Academia.edu
- Search results in JSON format

CONCLUSIONS:
- The dissertation exists and has been partially located
- Footnote 397 may be in a different version/draft
- Access restrictions prevent full dissertation download
- May require institutional access or direct author contact

NEXT STEPS NEEDED:
1. Try institutional repositories (University of Geneva)
2. Search for different versions or drafts
3. Contact author directly
4. Check if footnote numbering varies between versions
'''

log_path = 'workspace/comprehensive_dissertation_search_log.txt'
with open(log_path, 'w', encoding='utf-8') as f:
    f.write(search_log_content)

print(f'✓ Comprehensive search log saved to: {log_path}')

print('\n=== STEP 2: ANALYZING EXISTING FILES FOR CLUES ===')

# Let's examine the existing files more carefully for any clues
if os.path.exists('workspace'):
    print('Examining existing workspace files:')
    for file in os.listdir('workspace'):
        file_path = os.path.join('workspace', file)
        file_size = os.path.getsize(file_path)
        print(f'- {file} ({file_size:,} bytes)')
        
        # If it's a text file, let's check for any mention of footnote numbering
        if file.endswith('.txt') and 'preview' in file:
            print(f'  Examining {file} for footnote patterns...')
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                # Look for footnote patterns in the preview
                footnote_mentions = re.findall(r'footnote\s*\d+|note\s*\d+|\b\d{3}\b', content, re.IGNORECASE)
                if footnote_mentions:
                    print(f'    Found footnote patterns: {footnote_mentions[:10]}')
                    
                # Look for bibliography or reference sections
                if any(word in content.lower() for word in ['bibliography', 'references', 'works cited']):
                    print(f'    ✓ Contains bibliography/reference section')
                    
            except Exception as e:
                print(f'    Error reading {file}: {str(e)}')

print('\n=== STEP 3: CREATIVE ALTERNATIVE APPROACHES ===')

# Headers for requests
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Connection': 'keep-alive'
}

# Approach 1: Search for University of Geneva institutional repository
print('\nApproach 1: University of Geneva Institutional Repository Search')

geneva_queries = [
    'site:unige.ch Federico Lauria dissertation 2014',
    'site:archive-ouverte.unige.ch "Logic of the Liver"',
    'site:unige.ch "deontic view" Lauria',
    'inurl:unige.ch Federico Lauria PhD thesis'
]

for i, query in enumerate(geneva_queries, 1):
    print(f'\nGeneva search {i}: {query}')
    
    # Use Google to search the University of Geneva domain
    google_url = f'https://www.google.com/search?q={quote(query)}'
    print(f'Google search URL: {google_url}')
    
    try:
        time.sleep(2)
        response = requests.get(google_url, headers=headers, timeout=30)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Look for search results
            result_links = soup.find_all('a', href=True)
            geneva_links = []
            
            for link in result_links:
                href = link.get('href')
                if href and 'unige.ch' in href and ('lauria' in href.lower() or 'logic' in href.lower()):
                    geneva_links.append(href)
            
            if geneva_links:
                print(f'  Found {len(geneva_links)} University of Geneva links:')
                for link in geneva_links[:3]:
                    print(f'    - {link}')
            else:
                print('  No specific Geneva links found')
        
        else:
            print(f'  Google search failed: {response.status_code}')
    
    except Exception as e:
        print(f'  Geneva search error: {str(e)}')

# Approach 2: Search ResearchGate for Federico Lauria
print('\n\nApproach 2: ResearchGate Profile and Publications Search')

researchgate_queries = [
    'site:researchgate.net Federico Lauria',
    'site:researchgate.net "Logic of the Liver" Lauria',
    'researchgate.net/profile/Federico-Lauria'
]

for i, query in enumerate(researchgate_queries, 1):
    print(f'\nResearchGate search {i}: {query}')
    
    if 'researchgate.net/profile' in query:
        # Direct profile access
        profile_url = f'https://{query}'
        print(f'Direct profile URL: {profile_url}')
        
        try:
            response = requests.get(profile_url, headers=headers, timeout=30)
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Save the profile page
                profile_path = 'workspace/federico_lauria_researchgate_profile.html'
                with open(profile_path, 'w', encoding='utf-8') as f:
                    f.write(response.text)
                print(f'  ✓ ResearchGate profile saved to: {profile_path}')
                
                # Look for publication links
                pub_links = soup.find_all('a', href=lambda x: x and 'publication' in x)
                if pub_links:
                    print(f'  Found {len(pub_links)} publication links')
                    for link in pub_links[:5]:
                        href = link.get('href')
                        text = link.get_text().strip()
                        if 'liver' in text.lower() or 'desire' in text.lower():
                            print(f'    Relevant: {text} -> {href}')
            else:
                print(f'  Profile access failed: {response.status_code}')
        
        except Exception as e:
            print(f'  Profile access error: {str(e)}')
    
    else:
        # Google search for ResearchGate
        google_url = f'https://www.google.com/search?q={quote(query)}'
        try:
            time.sleep(2)
            response = requests.get(google_url, headers=headers, timeout=30)
            if response.status_code == 200:
                print(f'  ✓ Google search for ResearchGate completed')
            else:
                print(f'  Google search failed: {response.status_code}')
        except Exception as e:
            print(f'  ResearchGate search error: {str(e)}')

# Approach 3: Search Academia.edu
print('\n\nApproach 3: Academia.edu Search')

academia_url = 'https://www.academia.edu/search?q=Federico+Lauria+Logic+of+the+Liver'
print(f'Academia.edu search: {academia_url}')

try:
    response = requests.get(academia_url, headers=headers, timeout=30)
    if response.status_code == 200:
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Save Academia.edu search results
        academia_path = 'workspace/academia_edu_search_results.html'
        with open(academia_path, 'w', encoding='utf-8') as f:
            f.write(response.text)
        print(f'✓ Academia.edu search results saved to: {academia_path}')
        
        # Look for relevant papers
        paper_links = soup.find_all('a', href=lambda x: x and 'papers' in x)
        if paper_links:
            print(f'Found {len(paper_links)} paper links')
            for link in paper_links[:3]:
                text = link.get_text().strip()
                if 'lauria' in text.lower():
                    print(f'  Relevant: {text}')
    else:
        print(f'Academia.edu search failed: {response.status_code}')

except Exception as e:
    print(f'Academia.edu search error: {str(e)}')

# Approach 4: Search for different versions or drafts
print('\n\nApproach 4: Search for Different Versions/Drafts')

version_queries = [
    '"Federico Lauria" "Logic of the Liver" draft',
    '"Federico Lauria" dissertation "work in progress"',
    '"Federico Lauria" thesis "preliminary version"',
    '"Federico Lauria" "deontic view" manuscript',
    'Federico Lauria 2013 2014 2015 dissertation  # Search adjacent years'
]

for i, query in enumerate(version_queries, 1):
    print(f'\nVersion search {i}: {query}')
    
    # Use Google Scholar for academic versions
    scholar_url = f'https://scholar.google.com/scholar?q={quote(query)}'
    
    try:
        time.sleep(2)
        response = requests.get(scholar_url, headers=headers, timeout=30)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            results = soup.find_all('div', class_='gs_r gs_or gs_scl')
            
            print(f'  Found {len(results)} results')
            
            for j, result in enumerate(results[:2], 1):  # Top 2 results
                title_elem = result.find('h3', class_='gs_rt')
                if title_elem:
                    title_link = title_elem.find('a')
                    title = title_link.get_text() if title_link else title_elem.get_text()
                    url = title_link.get('href') if title_link else None
                    
                    print(f'    Result {j}: {title.strip()}')
                    if url and '.pdf' in url.lower():
                        print(f'      PDF URL: {url}')
                        
                        # Try to download if it's a direct PDF
                        try:
                            pdf_response = requests.get(url, headers=headers, timeout=60)
                            if pdf_response.status_code == 200 and 'pdf' in pdf_response.headers.get('content-type', '').lower():
                                pdf_filename = f'lauria_version_search_{i}_{j}.pdf'
                                pdf_path = f'workspace/{pdf_filename}'
                                
                                with open(pdf_path, 'wb') as pdf_file:
                                    pdf_file.write(pdf_response.content)
                                
                                file_size = os.path.getsize(pdf_path)
                                print(f'      ✓ Downloaded: {pdf_path} ({file_size:,} bytes)')
                        except Exception as download_error:
                            print(f'      Download failed: {str(download_error)}')
        
        else:
            print(f'  Scholar search failed: {response.status_code}')
    
    except Exception as e:
        print(f'  Version search error: {str(e)}')

# Approach 5: Look for the specific bibliographic work that might be in footnote 397
print('\n\nApproach 5: Reverse Engineering - Search for Works Likely to be in Footnote 397')

# Based on the dissertation topic (deontic view of desire), footnote 397 might reference:
# - Classic works on desire, emotion, or deontic logic
# - Contemporary philosophy of mind works
# - Works on intentionality

likely_references = [
    '"Federico Lauria" "Anscombe" desire',  # Elizabeth Anscombe - classic on desire
    '"Federico Lauria" "Kenny" action',     # Anthony Kenny - action theory
    '"Federico Lauria" "Searle" intentionality',  # John Searle - intentionality
    '"Federico Lauria" "Dretske" representation',  # Fred Dretske - representation
    '"Federico Lauria" "Millikan" function',      # Ruth Millikan - biological functions
    '"Federico Lauria" "Crane" intentionality'    # Tim Crane - intentionality
]

print('Searching for potential works referenced in footnote 397:')

for i, query in enumerate(likely_references, 1):
    print(f'\nReference search {i}: {query}')
    
    scholar_url = f'https://scholar.google.com/scholar?q={quote(query)}'
    
    try:
        time.sleep(2)
        response = requests.get(scholar_url, headers=headers, timeout=30)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            results = soup.find_all('div', class_='gs_r gs_or gs_scl')
            
            if results:
                print(f'  Found {len(results)} results - potential bibliographic connections')
                
                for j, result in enumerate(results[:1], 1):  # Just first result
                    title_elem = result.find('h3', class_='gs_rt')
                    if title_elem:
                        title = title_elem.get_text().strip()
                        print(f'    {title}')
            else:
                print(f'  No results found')
        
        else:
            print(f'  Search failed: {response.status_code}')
    
    except Exception as e:
        print(f'  Reference search error: {str(e)}')

print('\n=== STEP 4: ANALYZING DOWNLOADED PDFs FOR FOOTNOTE 397 ===')

# Check if we downloaded any new PDFs and analyze them
new_pdfs = []
for file in os.listdir('workspace') if os.path.exists('workspace') else []:
    if file.endswith('.pdf') and 'version_search' in file:
        new_pdfs.append(os.path.join('workspace', file))

if new_pdfs:
    print(f'Found {len(new_pdfs)} new PDFs to analyze:')
    
    for pdf_path in new_pdfs:
        print(f'\nAnalyzing: {pdf_path}')
        file_size = os.path.getsize(pdf_path)
        print(f'File size: {file_size:,} bytes')
        
        try:
            from langchain_community.document_loaders import PyPDFLoader
            
            loader = PyPDFLoader(pdf_path)
            pages = loader.load_and_split()
            print(f'✓ PDF loaded: {len(pages)} pages')
            
            # Search for footnote 397
            footnote_patterns = [
                r'footnote\s*397',
                r'note\s*397',
                r'\b397\.',
                r'\b397\s',
                r'\b397:',
                r'\(397\)',
                r'\[397\]'
            ]
            
            found_397 = False
            for page_num, page in enumerate(pages, 1):
                page_text = page.page_content
                
                for pattern in footnote_patterns:
                    matches = list(re.finditer(pattern, page_text, re.IGNORECASE))
                    
                    if matches:
                        print(f'\n🎯 FOOTNOTE 397 FOUND ON PAGE {page_num}!')
                        
                        for match in matches:
                            context_start = max(0, match.start() - 1000)
                            context_end = min(len(page_text), match.end() + 1500)
                            context = page_text[context_start:context_end]
                            
                            print('\n*** FOOTNOTE 397 CONTEXT ***')
                            print('='*100)
                            print(context)
                            print('='*100)
                            
                            # Save the footnote
                            footnote_file = f'workspace/FOUND_footnote_397_{os.path.basename(pdf_path)}.txt'
                            with open(footnote_file, 'w', encoding='utf-8') as f:
                                f.write(f'FOOTNOTE 397 FOUND!\n')
                                f.write(f'Source: {pdf_path}\n')
                                f.write(f'Page: {page_num}\n')
                                f.write(f'Pattern: {pattern}\n\n')
                                f.write('CONTEXT:\n')
                                f.write(context)
                            
                            print(f'\n✓ Footnote 397 saved to: {footnote_file}')
                            found_397 = True
                            break
                
                if found_397:
                    break
            
            if not found_397:
                print('⚠ Footnote 397 not found in this PDF')
        
        except ImportError:
            print('⚠ PyPDFLoader not available')
        except Exception as pdf_error:
            print(f'❌ PDF analysis error: {str(pdf_error)}')

else:
    print('No new PDFs downloaded to analyze')

print('\n=== FINAL SUMMARY AND RECOMMENDATIONS ===')

# Create a comprehensive status report
status_report = {
    'dissertation_identified': True,
    'title': 'The Logic of the Liver: A Deontic View of the Intentionality of Desire',
    'author': 'Federico Lauria',
    'year': 2014,
    'likely_institution': 'University of Geneva',
    'philpapers_url': 'https://philpapers.org/rec/LAUQLO',
    'footnote_397_found': False,
    'nearby_footnotes_found': [395, 398, 399],
    'pdfs_analyzed': [],
    'search_strategies_attempted': [
        'Google Scholar multiple queries',
        'ProQuest Dissertations',
        'WorldCat',
        'PhilPapers direct access',
        'University of Geneva repository search',
        'ResearchGate profile search',
        'Academia.edu search',
        'Version/draft searches',
        'Reverse engineering bibliographic searches'
    ],
    'access_barriers': [
        'PhilPapers 403 access denied',
        'Institutional access restrictions',
        'Possible incomplete versions available'
    ],
    'next_steps': [
        'Contact University of Geneva library directly',
        'Email Federico Lauria for dissertation access',
        'Try interlibrary loan services',
        'Check if footnote numbering differs between versions',
        'Verify if footnote 397 exists in the complete dissertation'
    ]
}

status_path = 'workspace/footnote_397_search_status.json'
with open(status_path, 'w', encoding='utf-8') as f:
    json.dump(status_report, f, indent=2, ensure_ascii=False)

print(f'✓ Final status report saved to: {status_path}')

print('\n=== WORKSPACE FILES SUMMARY ===')
if os.path.exists('workspace'):
    total_files = 0
    total_size = 0
    
    print('All files in workspace:')
    for file in sorted(os.listdir('workspace')):
        file_path = os.path.join('workspace', file)
        file_size = os.path.getsize(file_path)
        total_files += 1
        total_size += file_size
        
        print(f'- {file} ({file_size:,} bytes)')
    
    print(f'\nTotal: {total_files} files, {total_size:,} bytes ({total_size/1024/1024:.2f} MB)')

print('\n=== CONCLUSION ===')
print('✓ Dissertation successfully identified and located')
print('✓ Multiple search strategies implemented')
print('✓ Comprehensive analysis of available documents performed')
print('✓ Search log and status reports created')
print('\n⚠ FOOTNOTE 397 NOT YET LOCATED')
print('\nPossible explanations:')
print('1. Footnote 397 may only exist in the complete/final version')
print('2. Footnote numbering may differ between drafts')
print('3. The specific page containing footnote 397 may be access-restricted')
print('4. Footnote 397 may be in supplementary materials or appendices')
print('\nRecommended next actions:')
print('1. Contact University of Geneva philosophy department')
print('2. Email Federico Lauria directly (if contact info available)')
print('3. Request full dissertation through academic channels')
print('4. Verify the specific context requiring footnote 397')
```