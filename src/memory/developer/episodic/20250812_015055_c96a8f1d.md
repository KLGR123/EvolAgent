### Development Step 9: Find IFP-Reform Party Federalism and Bill of Rights Agreement, Identify South African Ambassador to France

**Description**: Conduct a comprehensive web search to identify the agreement between a South African political figure and the leader of the Inkatha Freedom Party that led to the formation of the Reform Party and proposed a federal system and bill of rights. Focus on finding information about this specific political agreement, the parties involved, and identify who later served as South African ambassador to France. Search for keywords including 'Inkatha Freedom Party agreement Reform Party', 'South Africa federal system bill of rights agreement', 'South African ambassador France Reform Party', and 'IFP leader political agreement federal system'.

**Use Cases**:
- Investigative journalism workflow for fact‚Äêchecking the Mahlabatini Declaration details and tracing its impact on South African party formation
- Academic research automation to extract and analyze federal system proposals in historical political agreements
- NGO policy monitoring to identify and log human rights clauses in agreements using targeted web searches
- Government archival project for compiling diplomatic career data of envoys, including South African ambassadors to France
- Data integration pipeline for building a political timeline and mapping key figures like Harry Schwarz and Mangosuthu Buthelezi
- Corporate intelligence gathering to assess historical political risks and reform precedents in emerging markets
- Software development for a knowledge‚Äêgraph service that automatically links agreements, participants, and policy proposals from web sources

```
import requests
import json
import os
from datetime import datetime
import time

print("Conducting targeted search for Harry Schwarz diplomatic career and ambassador to France information...")

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

# Based on our analysis, we identified Harry Schwarz as the key figure
# Let's search specifically for his diplomatic career and ambassador role

print("\n=== TARGETED SEARCH FOR HARRY SCHWARZ AMBASSADOR INFORMATION ===")

# URLs to search for Harry Schwarz information
harry_schwarz_urls = [
    "https://en.wikipedia.org/wiki/Harry_Schwarz",
    "https://en.wikipedia.org/wiki/List_of_South_African_ambassadors",
    "https://en.wikipedia.org/wiki/South_Africa%E2%80%93France_relations",
    "https://en.wikipedia.org/wiki/Mahlabatini_Declaration_of_Faith",
    "https://en.wikipedia.org/wiki/United_Party_(South_Africa)"
]

# Keywords specifically for Harry Schwarz and ambassador information
schwarz_keywords = [
    'Harry Schwarz',
    'ambassador',
    'France',
    'diplomatic',
    'embassy',
    'envoy',
    'consul',
    'foreign ministry',
    'diplomatic service',
    'Mahlabatini Declaration',
    'Reform Party',
    'United Party',
    'federal system',
    'bill of rights'
]

# Headers for web requests
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

# Storage for Harry Schwarz search results
schwarz_results = {}
schwarz_analysis = {}

print(f"\nStarting targeted search of {len(harry_schwarz_urls)} URLs for Harry Schwarz information...")

# Conduct targeted web search
for i, url in enumerate(harry_schwarz_urls, 1):
    page_name = url.split('/')[-1].replace('%E2%80%93', '_').replace('%20', '_')
    print(f"\n[{i}/{len(harry_schwarz_urls)}] Fetching: {page_name}")
    print(f"URL: {url}")
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        content = response.text
        
        schwarz_results[page_name] = {
            'url': url,
            'content_length': len(content),
            'content': content[:30000],  # Store first 30000 characters
            'fetch_time': datetime.now().isoformat()
        }
        
        print(f"‚úì Successfully retrieved {len(content):,} characters")
        
        # Analyze content for Harry Schwarz keywords immediately
        content_lower = content.lower()
        found_keywords = []
        relevant_sections = []
        
        print(f"Analyzing content for {len(schwarz_keywords)} Harry Schwarz keywords...")
        
        for keyword in schwarz_keywords:
            if keyword.lower() in content_lower:
                found_keywords.append(keyword)
                
                # Find sections around keyword - get multiple occurrences
                start_pos = 0
                keyword_lower = keyword.lower()
                
                while True:
                    pos = content_lower.find(keyword_lower, start_pos)
                    if pos == -1:
                        break
                    
                    # Extract context around keyword
                    section_start = max(0, pos - 1000)
                    section_end = min(len(content), pos + 1000)
                    section = content[section_start:section_end]
                    
                    relevant_sections.append({
                        'keyword': keyword,
                        'section': section,
                        'position': pos,
                        'occurrence': len([s for s in relevant_sections if s['keyword'] == keyword]) + 1
                    })
                    
                    start_pos = pos + 1
                    
                    # Limit to 5 occurrences per keyword per page
                    if len([s for s in relevant_sections if s['keyword'] == keyword]) >= 5:
                        break
        
        schwarz_analysis[page_name] = {
            'url': url,
            'found_keywords': found_keywords,
            'relevant_sections': relevant_sections,
            'keyword_count': len(found_keywords),
            'section_count': len(relevant_sections)
        }
        
        print(f"‚úì Found {len(found_keywords)} keywords, {len(relevant_sections)} relevant sections")
        if found_keywords:
            print(f"Keywords: {', '.join(found_keywords[:8])}{'...' if len(found_keywords) > 8 else ''}")
        
    except Exception as e:
        print(f"‚úó Error fetching {url}: {str(e)}")
        schwarz_results[page_name] = {
            'url': url,
            'error': str(e),
            'content_length': 0,
            'content': '',
            'fetch_time': datetime.now().isoformat()
        }
        schwarz_analysis[page_name] = {
            'url': url,
            'found_keywords': [],
            'relevant_sections': [],
            'keyword_count': 0,
            'section_count': 0,
            'error': str(e)
        }
    
    # Add delay between requests
    time.sleep(1.5)

print(f"\n{'='*80}")
print("HARRY SCHWARZ TARGETED SEARCH COMPLETED")
print(f"{'='*80}")

# Save Harry Schwarz search results
schwarz_output_file = "workspace/harry_schwarz_search_results.json"
with open(schwarz_output_file, 'w') as f:
    json.dump(schwarz_analysis, f, indent=2)
print(f"\nHarry Schwarz search results saved to {schwarz_output_file}")

# Generate search summary
schwarz_summary = {
    'search_date': datetime.now().isoformat(),
    'urls_searched': len(harry_schwarz_urls),
    'successful_fetches': len([r for r in schwarz_results.values() if 'error' not in r]),
    'failed_fetches': len([r for r in schwarz_results.values() if 'error' in r]),
    'total_keywords_found': sum(r.get('keyword_count', 0) for r in schwarz_analysis.values()),
    'total_sections_found': sum(r.get('section_count', 0) for r in schwarz_analysis.values())
}

print(f"\nHARRY SCHWARZ SEARCH SUMMARY:")
print(f"URLs searched: {schwarz_summary['urls_searched']}")
print(f"Successful fetches: {schwarz_summary['successful_fetches']}")
print(f"Failed fetches: {schwarz_summary['failed_fetches']}")
print(f"Total keywords found: {schwarz_summary['total_keywords_found']}")
print(f"Total relevant sections: {schwarz_summary['total_sections_found']}")

# Display results by page
print(f"\n{'='*80}")
print("HARRY SCHWARZ SEARCH RESULTS BY PAGE")
print(f"{'='*80}")

for page_name, results in schwarz_analysis.items():
    if results.get('keyword_count', 0) > 0:
        print(f"\nüìÑ {page_name}")
        print(f"   URL: {results['url']}")
        print(f"   Keywords found ({results['keyword_count']}): {', '.join(results['found_keywords'])}")
        print(f"   Relevant sections: {results['section_count']}")
    elif 'error' in results:
        print(f"\n‚ùå {page_name} - Error: {results['error']}")
    else:
        print(f"\n‚ö™ {page_name} - No relevant keywords found")

print(f"\n{'='*80}")
print("ANALYZING FOR AMBASSADOR TO FRANCE EVIDENCE")
print(f"{'='*80}")

# Look specifically for ambassador to France evidence
ambassador_evidence = []
mahlabatini_details = []
reform_party_connection = []

for page_name, results in schwarz_analysis.items():
    for section in results.get('relevant_sections', []):
        section_text = section['section'].lower()
        section_content = section['section']
        
        # Look for ambassador + France combinations
        if 'harry schwarz' in section_text and 'ambassador' in section_text and 'france' in section_text:
            ambassador_evidence.append({
                'source': page_name,
                'section': section_content,
                'keyword': section['keyword'],
                'url': results['url']
            })
        
        # Look for Mahlabatini Declaration details
        if 'mahlabatini' in section_text and ('harry schwarz' in section_text or 'buthelezi' in section_text):
            mahlabatini_details.append({
                'source': page_name,
                'section': section_content,
                'keyword': section['keyword'],
                'url': results['url']
            })
        
        # Look for Reform Party connection
        if 'harry schwarz' in section_text and 'reform party' in section_text:
            reform_party_connection.append({
                'source': page_name,
                'section': section_content,
                'keyword': section['keyword'],
                'url': results['url']
            })

# Save comprehensive Harry Schwarz findings
schwarz_findings = {
    'search_date': datetime.now().isoformat(),
    'search_summary': schwarz_summary,
    'ambassador_evidence': ambassador_evidence,
    'mahlabatini_details': mahlabatini_details,
    'reform_party_connection': reform_party_connection,
    'search_keywords': schwarz_keywords,
    'pages_analyzed': list(schwarz_analysis.keys())
}

schwarz_findings_file = "workspace/harry_schwarz_findings.json"
with open(schwarz_findings_file, 'w') as f:
    json.dump(schwarz_findings, f, indent=2)
print(f"\nHarry Schwarz findings saved to {schwarz_findings_file}")

# Display key findings
print(f"\nüá´üá∑ AMBASSADOR TO FRANCE EVIDENCE: {len(ambassador_evidence)}")
for i, evidence in enumerate(ambassador_evidence, 1):
    print(f"\n{i}. From {evidence['source']}:")
    print(f"   {evidence['section'][:600]}...")

print(f"\nüìú MAHLABATINI DECLARATION DETAILS: {len(mahlabatini_details)}")
for i, detail in enumerate(mahlabatini_details[:3], 1):
    print(f"\n{i}. From {detail['source']}:")
    print(f"   {detail['section'][:600]}...")

print(f"\nüèõÔ∏è REFORM PARTY CONNECTION: {len(reform_party_connection)}")
for i, connection in enumerate(reform_party_connection[:3], 1):
    print(f"\n{i}. From {connection['source']}:")
    print(f"   {connection['section'][:600]}...")

print(f"\n{'='*80}")
print("FINAL ANALYSIS AND CONCLUSIONS")
print(f"{'='*80}")

# Compile final answer based on all evidence
final_analysis = {
    'search_date': datetime.now().isoformat(),
    'question': 'Agreement between South African political figure and IFP leader that led to Reform Party formation and proposed federal system and bill of rights, and who served as ambassador to France',
    'identified_agreement': 'Mahlabatini Declaration of Faith (January 4, 1974)',
    'ifp_leader': 'Mangosuthu Buthelezi (Chief Executive Councillor of KwaZulu)',
    'other_political_figure': 'Harry Schwarz (Transvaal leader of United Party)',
    'agreement_details': {
        'proposed_federal_system': True,
        'proposed_bill_of_rights': True,
        'led_to_reform_party': True,
        'date': 'January 4, 1974',
        'location': 'Mahlabatini, KwaZulu'
    },
    'ambassador_to_france': {
        'confirmed': len(ambassador_evidence) > 0,
        'evidence_found': len(ambassador_evidence),
        'candidate': 'Harry Schwarz'
    },
    'confidence_level': {
        'agreement_identification': 'High - Multiple sources confirm Mahlabatini Declaration',
        'participants': 'High - Buthelezi and Schwarz clearly identified',
        'federal_system_bill_of_rights': 'High - Explicitly mentioned in sources',
        'reform_party_connection': 'High - Schwarz founded Reform Party after leaving United Party',
        'ambassador_to_france': 'Low - No direct evidence found in current search' if len(ambassador_evidence) == 0 else 'High - Direct evidence found'
    }
}

final_analysis_file = "workspace/final_analysis.json"
with open(final_analysis_file, 'w') as f:
    json.dump(final_analysis, f, indent=2)

print(f"\nüìã FINAL ANSWER:")
print(f"Agreement: {final_analysis['identified_agreement']}")
print(f"IFP Leader: {final_analysis['ifp_leader']}")
print(f"Other Political Figure: {final_analysis['other_political_figure']}")
print(f"Date: {final_analysis['agreement_details']['date']}")
print(f"Proposed Federal System: {final_analysis['agreement_details']['proposed_federal_system']}")
print(f"Proposed Bill of Rights: {final_analysis['agreement_details']['proposed_bill_of_rights']}")
print(f"Led to Reform Party: {final_analysis['agreement_details']['led_to_reform_party']}")
print(f"Ambassador to France: {'Harry Schwarz' if final_analysis['ambassador_to_france']['confirmed'] else 'Requires additional verification'}")

print(f"\nüìÅ Final analysis saved to {final_analysis_file}")

print(f"\n{'='*80}")
print("COMPREHENSIVE SEARCH AND ANALYSIS COMPLETED SUCCESSFULLY!")
print(f"{'='*80}")
print(f"üìä Total Statistics:")
print(f"   ‚Ä¢ Initial search pages: 10")
print(f"   ‚Ä¢ Harry Schwarz targeted search pages: {len(harry_schwarz_urls)}")
print(f"   ‚Ä¢ Ambassador evidence found: {len(ambassador_evidence)}")
print(f"   ‚Ä¢ Mahlabatini Declaration references: {len(mahlabatini_details)}")
print(f"   ‚Ä¢ Reform Party connections: {len(reform_party_connection)}")
print(f"\nüéØ MISSION STATUS: {'COMPLETED' if len(ambassador_evidence) > 0 else 'PARTIALLY COMPLETED - Agreement identified, ambassador role needs verification'}")
```