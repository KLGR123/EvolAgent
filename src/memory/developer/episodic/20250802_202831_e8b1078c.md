### Development Step 28: Locate 2011 NSI Census Data on Bulgarian Tertiary Education Completion by Gender

**Description**: Search for the official 2011 Bulgarian census data from the Bulgarian National Statistical Institute (NSI) or other authoritative government sources that specifically contain the tertiary education completion numbers by gender. Focus on finding the exact counts or percentages of men and women who completed tertiary education according to the 2011 census results.

**Use Cases**:
- Government policy analysis for allocating tertiary education funding based on 2011 census gender completion rates
- Academic research on regional gender disparities in higher education attainment using official NSI data
- Corporate HR strategic planning to identify talent pools by university graduate gender distribution in Bulgaria
- Nonprofit program design targeting womenâ€™s access to university by analyzing census-derived completion statistics
- Edtech market segmentation and product development informed by gender-specific tertiary education trends
- Data journalism investigations into historical gender gaps in Bulgarian higher education with official census figures
- Municipal infrastructure planning for student services guided by locality-specific university completion rates by gender
- Educational consulting for benchmarking institutional performance using 2011 census tertiary graduation data

```
import os
import json
from bs4 import BeautifulSoup
import re

# First, let's examine what files we have in workspace from previous attempts
workspace_dir = 'workspace'
print("=== EXAMINING WORKSPACE CONTENTS ===\n")

if os.path.exists(workspace_dir):
    files = os.listdir(workspace_dir)
    print(f"Files in workspace: {files}")
    
    # Look for the research summary file
    summary_file = os.path.join(workspace_dir, 'bulgarian_census_research_summary.json')
    if os.path.exists(summary_file):
        print(f"\nFound research summary file. Let's inspect its structure:")
        with open(summary_file, 'r', encoding='utf-8') as f:
            summary_data = json.load(f)
        
        print(f"Summary keys: {list(summary_data.keys())}")
        print(f"Research target: {summary_data.get('research_target', 'N/A')}")
        print(f"Successful sources: {summary_data.get('successful_sources', 0)}")
        print(f"Priority sources: {summary_data.get('priority_sources', 0)}")
        
        if 'sources_data' in summary_data:
            print(f"\nSource data available for {len(summary_data['sources_data'])} sources")
    
    # Look for downloaded HTML files
    html_files = [f for f in files if f.endswith('.html')]
    print(f"\nHTML files found: {html_files}")
    
    # If we have HTML files, let's examine the first one
    if html_files:
        first_html = os.path.join(workspace_dir, html_files[0])
        print(f"\nExamining first HTML file: {html_files[0]}")
        
        with open(first_html, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        print(f"HTML file size: {len(html_content):,} characters")
        
        # Parse with BeautifulSoup to analyze structure
        soup = BeautifulSoup(html_content, 'html.parser')
        title = soup.find('title')
        print(f"Page title: {title.get_text().strip() if title else 'No title'}")
        
        # Look for key elements
        tables = soup.find_all('table')
        print(f"Tables found: {len(tables)}")
        
        links = soup.find_all('a', href=True)
        print(f"Links found: {len(links)}")
        
        # Search for education-related content
        content_text = soup.get_text().lower()
        education_terms = ['education', 'census', '2011', 'tertiary', 'higher education', 'university']
        
        print(f"\nEducation-related terms found:")
        for term in education_terms:
            count = content_text.count(term)
            if count > 0:
                print(f"  '{term}': {count} occurrences")
        
        # Look for specific census or statistical data patterns
        census_patterns = [
            r'census\s+2011',
            r'education.*level',
            r'tertiary.*education',
            r'higher.*education',
            r'university.*degree'
        ]
        
        print(f"\nCensus/Education patterns found:")
        for pattern in census_patterns:
            matches = re.findall(pattern, content_text, re.IGNORECASE)
            if matches:
                print(f"  Pattern '{pattern}': {len(matches)} matches")
                for match in matches[:3]:  # Show first 3 matches
                    print(f"    - {match}")
else:
    print("No workspace directory found. Starting fresh search.")

print("\n=== WORKSPACE ANALYSIS COMPLETE ===\n")
```