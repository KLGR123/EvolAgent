### Development Step 42: Official NSI 2011 Bulgarian Census: Tertiary Education Completion by Gender

**Description**: Search for the official 2011 Bulgarian census data from the Bulgarian National Statistical Institute (NSI) or other authoritative government sources that specifically contain the tertiary education completion numbers by gender. Focus on finding the exact counts or percentages of men and women who completed tertiary education according to the 2011 census results.

**Use Cases**:
- Government education department automates extraction of 2011 Bulgarian census tertiary education by gender to evaluate the impact of national scholarship and training programs on men and women.
- University research office analyzes regional male vs. female university completion rates from the 2011 NSI census to identify underrepresented groups and plan targeted outreach campaigns.
- Non-profit organization focused on women’s empowerment uses automated parsing of NSI census HTML to design gender-specific tertiary education initiatives in Bulgaria’s rural municipalities.
- Market research firm integrates 2011 tertiary education attainment by gender into BI dashboards to advise corporate clients on workforce skills and talent development in Bulgarian regions.
- Data journalism team mines official 2011 Bulgarian census tables to visualize historical gender gaps in higher education and produce an interactive news feature.
- Academic comparative study combines Bulgarian census tertiary education statistics with Eurostat data to benchmark Bulgaria’s progress against EU gender parity objectives.
- Educational policy consultancy builds an ETL pipeline from NSI sources to power an online portal tracking province-level tertiary graduation rates by gender over time.
- Machine learning researcher trains predictive models using 2011 census gender-segmented completion rates to forecast future labor force composition and university enrollment trends in Bulgaria.

```
import os
import json
from bs4 import BeautifulSoup
import re
import time

workspace_dir = 'workspace'

print("=== PARSING NSI CENSUS FILES FOR 2011 BULGARIAN TERTIARY EDUCATION DATA BY GENDER ===")
print("\nObjective: Extract official 2011 Bulgarian census tertiary education completion statistics by gender\n")

# First, inspect workspace files to understand what we have
print("--- Inspecting Workspace Files ---")
if os.path.exists(workspace_dir):
    all_files = os.listdir(workspace_dir)
    print(f"Total files in workspace: {len(all_files)}")
    
    # Look for NSI census source files
    nsi_files = [f for f in all_files if f.startswith('nsi_census_source_') and f.endswith('.html')]
    print(f"\nNSI census HTML files found: {len(nsi_files)}")
    for f in sorted(nsi_files):
        filepath = os.path.join(workspace_dir, f)
        file_size = os.path.getsize(filepath)
        print(f"  - {f} ({file_size:,} bytes)")
else:
    print("Workspace directory not found!")
    exit(1)

if not nsi_files:
    print("No NSI census files found. Cannot proceed with analysis.")
    exit(1)

print(f"\n=== PHASE 1: SYSTEMATIC ANALYSIS OF NSI CENSUS FILES ===\n")

analysis_results = []

for filename in sorted(nsi_files):
    print(f"--- Analyzing: {filename} ---")
    
    filepath = os.path.join(workspace_dir, filename)
    with open(filepath, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    print(f"File size: {len(html_content):,} characters")
    
    # Parse with BeautifulSoup
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # Get page title
    title = soup.find('title')
    page_title = title.get_text().strip() if title else 'No title found'
    print(f"Page title: {page_title}")
    
    # Get all text content for analysis
    content_text = soup.get_text()
    content_lower = content_text.lower()
    
    # Count key terms related to our search
    education_indicators = {
        'tertiary': content_lower.count('tertiary'),
        'higher_education': content_lower.count('higher education'),
        'university': content_lower.count('university'),
        'education': content_lower.count('education'),
        'degree': content_lower.count('degree'),
        'educational_attainment': content_lower.count('educational attainment')
    }
    
    gender_indicators = {
        'male': content_lower.count('male'),
        'female': content_lower.count('female'),
        'men': content_lower.count('men'),
        'women': content_lower.count('women'),
        'gender': content_lower.count('gender'),
        'by_sex': content_lower.count('by sex')
    }
    
    census_indicators = {
        '2011': content_lower.count('2011'),
        'census': content_lower.count('census'),
        'population': content_lower.count('population'),
        'statistics': content_lower.count('statistics')
    }
    
    print(f"Education indicators: {education_indicators}")
    print(f"Gender indicators: {gender_indicators}")
    print(f"Census indicators: {census_indicators}")
    
    # Find all tables
    tables = soup.find_all('table')
    print(f"Tables found: {len(tables)}")
    
    # Analyze tables for relevant content - FIX THE VARIABLE SCOPING
    relevant_tables = []
    for i, table in enumerate(tables):
        # DEFINE table_text BEFORE using it
        table_text = table.get_text().lower()
        
        # Check if table contains education-related content
        has_education = any(term in table_text for term in ['education', 'tertiary', 'university', 'degree', 'higher'])
        has_gender = any(term in table_text for term in ['male', 'female', 'men', 'women', 'gender', 'sex'])
        has_census = '2011' in table_text or 'census' in table_text
        has_numbers = bool(re.search(r'\d+[,.]?\d*\s*%?', table_text))
        
        if has_education and (has_gender or has_census):
            # Extract table headers
            headers = []
            header_cells = table.find_all(['th', 'td'])[:15]  # First 15 cells as potential headers
            for cell in header_cells:
                cell_text = cell.get_text().strip()
                if cell_text and len(cell_text) < 100:  # Reasonable header length
                    headers.append(cell_text)
            
            relevant_tables.append({
                'table_index': i,
                'has_education': has_education,
                'has_gender': has_gender,
                'has_census': has_census,
                'has_numbers': has_numbers,
                'headers': headers[:8],  # First 8 headers
                'table_text_sample': table_text[:400]  # First 400 chars
            })
    
    if relevant_tables:
        print(f"\nRelevant tables found: {len(relevant_tables)}")
        for table_info in relevant_tables:
            print(f"  Table {table_info['table_index']}:")
            print(f"    Education: {table_info['has_education']}, Gender: {table_info['has_gender']}, Census: {table_info['has_census']}, Numbers: {table_info['has_numbers']}")
            print(f"    Headers: {table_info['headers']}")
            print(f"    Sample text: {table_info['table_text_sample'][:200]}...")
    
    # Look for downloadable files - PROPER VARIABLE DEFINITION
    download_links = []
    all_links = soup.find_all('a', href=True)
    print(f"Total links found: {len(all_links)}")
    
    for link in all_links:
        # PROPERLY DEFINE VARIABLES FIRST
        link_href = link.get('href', '')
        link_text = link.get_text().strip()
        
        # Check for data file extensions or relevant content
        is_data_file = any(ext in link_href.lower() for ext in ['.xls', '.xlsx', '.pdf', '.csv', '.doc', '.docx'])
        is_relevant_text = any(term in link_text.lower() for term in ['education', 'census', '2011', 'data', 'table', 'statistics', 'demographic'])
        
        if is_data_file or is_relevant_text:
            # Construct full URL
            if link_href.startswith('http'):
                full_url = link_href
            elif link_href.startswith('/'):
                full_url = f"https://www.nsi.bg{link_href}"
            else:
                full_url = f"https://www.nsi.bg/en/{link_href}"
            
            download_links.append({
                'text': link_text,
                'href': link_href,
                'full_url': full_url,
                'is_data_file': is_data_file,
                'is_relevant_text': is_relevant_text
            })
    
    print(f"Relevant download links found: {len(download_links)}")
    if download_links:
        print("Top download links:")
        for i, link in enumerate(download_links[:8], 1):
            print(f"  {i}. '{link['text']}'")
            print(f"     URL: {link['full_url']}")
            print(f"     Data file: {link['is_data_file']}, Relevant: {link['is_relevant_text']}")
    
    # Search for specific education content patterns
    education_content_matches = []
    
    # Patterns to find tertiary education by gender
    search_patterns = [
        r'tertiary education.*?(?:male|female|men|women|gender|sex)',
        r'higher education.*?(?:male|female|men|women|gender|sex)',
        r'university.*?(?:male|female|men|women|gender|sex)',
        r'(?:male|female|men|women).*?tertiary',
        r'(?:male|female|men|women).*?higher education',
        r'education.*?by.*?(?:gender|sex)',
        r'2011.*?census.*?education',
        r'educational attainment.*?(?:male|female)',
        r'completed.*?tertiary.*?education',
        r'bachelor.*?degree.*?(?:male|female)',
        r'university.*?graduate.*?(?:male|female)',
        r'\d+[,.]?\d*\s*%.*?(?:tertiary|higher education).*?(?:male|female)',
        r'(?:male|female).*?\d+[,.]?\d*\s*%.*?(?:tertiary|higher education)'
    ]
    
    for pattern in search_patterns:
        matches = re.findall(pattern, content_text, re.IGNORECASE | re.DOTALL)
        for match in matches[:3]:  # Limit to 3 matches per pattern
            clean_match = re.sub(r'\s+', ' ', match.strip())[:300]  # Clean and limit length
            if clean_match not in education_content_matches:  # Avoid duplicates
                education_content_matches.append(clean_match)
    
    if education_content_matches:
        print(f"\nEducation content matches found: {len(education_content_matches)}")
        for i, match in enumerate(education_content_matches[:5], 1):
            print(f"  {i}. {match}...")
    
    # Calculate relevance score
    relevance_score = (
        sum(education_indicators.values()) * 3 +
        sum(gender_indicators.values()) * 2 +
        sum(census_indicators.values()) * 2 +
        len(relevant_tables) * 15 +
        len(education_content_matches) * 10 +
        len(download_links) * 5
    )
    
    print(f"\nRelevance score for {filename}: {relevance_score}")
    
    if relevance_score > 100:
        print("*** VERY HIGH PRIORITY - LIKELY CONTAINS TARGET DATA ***")
    elif relevance_score > 50:
        print("** HIGH PRIORITY - GOOD POTENTIAL FOR DATA **")
    elif relevance_score > 20:
        print("* MODERATE PRIORITY *")
    
    # Store analysis results
    analysis_results.append({
        'filename': filename,
        'page_title': page_title,
        'file_size': len(html_content),
        'education_indicators': education_indicators,
        'gender_indicators': gender_indicators,
        'census_indicators': census_indicators,
        'tables_count': len(tables),
        'relevant_tables': relevant_tables,
        'download_links': download_links,
        'education_content_matches': education_content_matches,
        'relevance_score': relevance_score
    })
    
    print("\n" + "="*60 + "\n")

# Sort by relevance score
analysis_results.sort(key=lambda x: x['relevance_score'], reverse=True)

print(f"=== ANALYSIS SUMMARY ===\n")
print(f"Files analyzed: {len(analysis_results)}")

if analysis_results:
    print("\nFiles ranked by relevance to tertiary education by gender:")
    for i, result in enumerate(analysis_results, 1):
        print(f"\n{i}. {result['filename']} (Score: {result['relevance_score']})")
        print(f"   Title: {result['page_title']}")
        print(f"   Size: {result['file_size']:,} characters")
        print(f"   Tables: {result['tables_count']}, Relevant: {len(result['relevant_tables'])}")
        print(f"   Download links: {len(result['download_links'])}")
        print(f"   Education matches: {len(result['education_content_matches'])}")
        
        # Show key indicators for high-scoring files
        if result['relevance_score'] > 50:
            print(f"   Education indicators: {result['education_indicators']}")
            print(f"   Gender indicators: {result['gender_indicators']}")
            print(f"   Census indicators: {result['census_indicators']}")
        
        # Show top download links for high-priority files
        if result['relevance_score'] > 50 and result['download_links']:
            print(f"   Top download links:")
            for j, link in enumerate(result['download_links'][:3], 1):
                print(f"     {j}. '{link['text']}'")
                print(f"        {link['full_url']}")

# Save comprehensive analysis
final_analysis = {
    'objective': '2011 Bulgarian Census - Tertiary Education by Gender Analysis',
    'analysis_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'files_analyzed': len(analysis_results),
    'analysis_results': analysis_results,
    'summary': {
        'very_high_priority': len([r for r in analysis_results if r['relevance_score'] > 100]),
        'high_priority': len([r for r in analysis_results if 50 < r['relevance_score'] <= 100]),
        'moderate_priority': len([r for r in analysis_results if 20 < r['relevance_score'] <= 50]),
        'low_priority': len([r for r in analysis_results if r['relevance_score'] <= 20])
    },
    'next_steps': [
        'Access highest-priority download links for detailed census data',
        'Parse relevant tables for specific tertiary education statistics',
        'Extract male/female tertiary education completion numbers',
        'Verify data is from official 2011 Bulgarian census'
    ]
}

final_analysis_file = os.path.join(workspace_dir, 'nsi_census_tertiary_education_final_analysis.json')
with open(final_analysis_file, 'w', encoding='utf-8') as f:
    json.dump(final_analysis, f, indent=2, ensure_ascii=False)

print(f"\n=== COMPREHENSIVE ANALYSIS COMPLETE ===\n")
print(f"Analysis results saved to: {final_analysis_file}")

if analysis_results:
    top_result = analysis_results[0]
    print(f"\nHighest priority file: {top_result['filename']} (Score: {top_result['relevance_score']})")
    print(f"Title: {top_result['page_title']}")
    print(f"Contains {len(top_result['relevant_tables'])} relevant tables and {len(top_result['download_links'])} download links")
    
    if top_result['education_content_matches']:
        print(f"\nMost promising education content from top file:")
        for i, match in enumerate(top_result['education_content_matches'][:3], 1):
            print(f"  {i}. {match}")
    
    if top_result['download_links']:
        print(f"\nMost promising download links from top file:")
        for i, link in enumerate(top_result['download_links'][:5], 1):
            print(f"  {i}. '{link['text']}'")
            print(f"     {link['full_url']}")
            if link['is_data_file']:
                print(f"     *** DATA FILE - HIGH PRIORITY FOR DOWNLOAD ***")
    
    print(f"\nReady to extract specific tertiary education completion data by gender from the highest-priority sources.")
else:
    print("\nNo analysis results generated. Check file availability and content.")
```