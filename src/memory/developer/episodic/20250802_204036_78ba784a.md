### Development Step 50: Search Official 2011 Bulgarian Census Tertiary Education Completion Data by Gender

**Description**: Search for the official 2011 Bulgarian census data from the Bulgarian National Statistical Institute (NSI) or other authoritative government sources that specifically contain the tertiary education completion numbers by gender. Focus on finding the exact counts or percentages of men and women who completed tertiary education according to the 2011 census results.

**Use Cases**:
- Government education ministry budget planning for higher education programs by automatically extracting 2011 census tertiary graduation counts by gender to inform funding allocations.
- Academic sociological research on regional gender disparities in university attainment, using the automated data extraction to compile comparative studies across Bulgarian provinces.
- NGO gender equality project development, leveraging census-derived male vs. female tertiary completion rates to design targeted empowerment and scholarship initiatives.
- HR and talent acquisition analytics for multinational firms, integrating regional tertiary education statistics by gender to map skilled workforce availability in Bulgaria.
- Data journalism and interactive visualization production, using the extracted NSI census figures to illustrate trends in women’s participation in higher education.
- EdTech platform benchmarking features, embedding gender-segmented tertiary education data into dashboards for schools and policymakers assessing progress over time.
- International development agency policy briefs on gender parity in education, automating the collection of official census statistics to monitor UN Sustainable Development Goal 4 indicators.
- Municipal education authority reporting and scholarship management, generating localized reports on tertiary graduate gender ratios for community outreach and resource planning.

```
import os
import json
from bs4 import BeautifulSoup
import re
import requests
import time

workspace_dir = 'workspace'

print("=== FINAL EXTRACTION: 2011 BULGARIAN CENSUS TERTIARY EDUCATION BY GENDER ===")
print("\nObjective: Extract exact counts/percentages of men and women who completed tertiary education from 2011 Bulgarian census\n")

# First, safely inspect what files we have in workspace
if not os.path.exists(workspace_dir):
    print("Workspace directory not found!")
    exit(1)

all_files = os.listdir(workspace_dir)
print(f"Total files in workspace: {len(all_files)}")

# Look for the key files we need
nsi_files = []
analysis_files = []
census_files = []

for filename in all_files:
    if filename.startswith('nsi_census_source_') and filename.endswith('.html'):
        nsi_files.append(filename)
    elif 'analysis' in filename.lower() and filename.endswith('.json'):
        analysis_files.append(filename)
    elif 'census' in filename.lower() and ('2011' in filename or 'Census2011' in filename):
        census_files.append(filename)

print(f"\nFile inventory:")
print(f"- NSI census HTML files: {len(nsi_files)}")
print(f"- Analysis files: {len(analysis_files)}")
print(f"- Census data files: {len(census_files)}")

for f in nsi_files:
    size = os.path.getsize(os.path.join(workspace_dir, f))
    print(f"  • {f} ({size:,} bytes)")

# Load the analysis file to understand the structure safely
analysis_data = None
if analysis_files:
    analysis_file = os.path.join(workspace_dir, analysis_files[0])
    print(f"\n--- Inspecting Analysis File: {analysis_files[0]} ---")
    
    try:
        with open(analysis_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print(f"File size: {len(content):,} characters")
        
        # Parse JSON safely
        analysis_data = json.loads(content)
        print(f"JSON structure keys: {list(analysis_data.keys())}")
        
        if 'analysis_results' in analysis_data:
            results = analysis_data['analysis_results']
            print(f"Analysis results count: {len(results)}")
            
            if results:
                top_result = results[0]
                print(f"Top result keys: {list(top_result.keys())}")
                print(f"Top result filename: {top_result.get('filename', 'Unknown')}")
                print(f"Relevance score: {top_result.get('relevance_score', 'Unknown')}")
        
    except Exception as e:
        print(f"Error reading analysis file: {e}")
        analysis_data = None

# Now examine the highest priority NSI file directly
target_file = 'nsi_census_source_4.html'  # Based on previous analysis
if target_file not in nsi_files:
    if nsi_files:
        target_file = nsi_files[0]  # Use first available
    else:
        print("No NSI census files found!")
        exit(1)

print(f"\n=== EXAMINING TARGET FILE: {target_file} ===")

file_path = os.path.join(workspace_dir, target_file)
with open(file_path, 'r', encoding='utf-8') as f:
    html_content = f.read()

print(f"File size: {len(html_content):,} characters")

# Parse HTML
soup = BeautifulSoup(html_content, 'html.parser')
full_text = soup.get_text()

print(f"Extracted text length: {len(full_text):,} characters")

# Search for the key phrase we know exists
key_phrase = 'tertiary education graduates by educational-qualification degree and sex'
print(f"\n--- Searching for Key Phrase ---")
print(f"Target phrase: '{key_phrase}'")

if key_phrase.lower() in full_text.lower():
    print("✓ Key phrase found in document!")
    
    # Find the location and extract surrounding context
    text_lower = full_text.lower()
    phrase_index = text_lower.find(key_phrase.lower())
    
    if phrase_index != -1:
        # Extract 500 characters before and after the phrase
        start_pos = max(0, phrase_index - 500)
        end_pos = min(len(full_text), phrase_index + len(key_phrase) + 500)
        context = full_text[start_pos:end_pos]
        
        print(f"\nContext around key phrase:")
        print(f"{'='*60}")
        print(context)
        print(f"{'='*60}")
else:
    print("✗ Key phrase not found")

# Look for any links that might lead to downloadable data
print(f"\n--- Searching for Data Download Links ---")

data_links = []
all_links = soup.find_all('a')
print(f"Total links found: {len(all_links)}")

for link in all_links:
    link_href = link.get('href', '')
    link_text = link.get_text().strip()
    
    # Check if it's a data file
    data_extensions = ['.pdf', '.xls', '.xlsx', '.csv', '.doc']
    is_data_file = any(ext in link_href.lower() for ext in data_extensions)
    
    # Check if it mentions relevant terms
    relevant_terms = ['education', 'tertiary', 'census', '2011', 'population', 'demographic']
    is_relevant = any(term in link_text.lower() or term in link_href.lower() for term in relevant_terms)
    
    if is_data_file and is_relevant:
        # Build full URL
        if link_href.startswith('http'):
            full_url = link_href
        elif link_href.startswith('/'):
            full_url = f"https://www.nsi.bg{link_href}"
        else:
            full_url = f"https://www.nsi.bg/en/{link_href}"
        
        data_links.append({
            'text': link_text,
            'href': link_href,
            'full_url': full_url,
            'extension': link_href.split('.')[-1].lower() if '.' in link_href else 'unknown'
        })

print(f"Found {len(data_links)} potential data files:")
for i, link_info in enumerate(data_links[:10], 1):
    print(f"  {i}. '{link_info['text']}' ({link_info['extension']})")
    print(f"     {link_info['full_url']}")

# Try to access the main 2011 census final report directly
print(f"\n--- Accessing Official 2011 Census Final Report ---")

census_final_url = 'https://www.nsi.bg/census2011/PDOCS2/Census2011final_en.pdf'
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

try:
    print(f"Attempting to download: {census_final_url}")
    response = requests.get(census_final_url, headers=headers, timeout=30)
    
    if response.status_code == 200:
        print(f"✓ Successfully downloaded Census 2011 final report")
        print(f"File size: {len(response.content):,} bytes")
        
        # Save the PDF
        pdf_path = os.path.join(workspace_dir, 'Census2011_Final_Report.pdf')
        with open(pdf_path, 'wb') as f:
            f.write(response.content)
        
        print(f"PDF saved to: {pdf_path}")
        
        # Note: PDF parsing would require additional libraries
        print(f"\n*** IMPORTANT: The official 2011 Census Final Report PDF has been downloaded ***")
        print(f"This PDF likely contains the detailed tertiary education statistics by gender.")
        print(f"The file is {len(response.content):,} bytes and should contain comprehensive census data.")
        
    else:
        print(f"✗ Failed to download PDF - Status: {response.status_code}")
        
except Exception as e:
    print(f"✗ Error downloading PDF: {e}")

# Search for any existing census data we might have downloaded
print(f"\n--- Checking for Existing Census Data Files ---")

if census_files:
    print(f"Found {len(census_files)} existing census files:")
    for census_file in census_files:
        file_path = os.path.join(workspace_dir, census_file)
        file_size = os.path.getsize(file_path)
        print(f"  • {census_file} ({file_size:,} bytes)")
else:
    print("No existing census data files found.")

# Look for specific statistical patterns in the HTML content
print(f"\n--- Searching for Statistical Data Patterns ---")

# Search for numerical patterns that might represent census statistics
statistical_patterns = [
    r'\b\d{1,3}[,.]\d{3}\b',  # Numbers like 123,456 or 123.456
    r'\b\d+[.]\d+%\b',        # Percentages like 45.6%
    r'\b\d+%\b',              # Simple percentages like 45%
    r'\b\d{4,}\b'             # Large numbers (4+ digits)
]

found_numbers = []
for pattern in statistical_patterns:
    matches = re.findall(pattern, full_text)
    found_numbers.extend(matches[:20])  # Limit to prevent overflow

# Remove duplicates while preserving order
unique_numbers = []
for num in found_numbers:
    if num not in unique_numbers:
        unique_numbers.append(num)

print(f"Found {len(unique_numbers)} unique numerical patterns:")
for i, num in enumerate(unique_numbers[:20], 1):
    print(f"  {i}. {num}")

# Search for text sections that mention tertiary education
print(f"\n--- Searching for Tertiary Education Sections ---")

# Split text into sentences and look for relevant ones
sentences = re.split(r'[.!?]+', full_text)
relevant_sentences = []

for sentence in sentences:
    sentence_clean = sentence.strip()
    if len(sentence_clean) > 20:  # Skip very short sentences
        sentence_lower = sentence_clean.lower()
        
        # Check if sentence contains tertiary education terms
        tertiary_terms = ['tertiary', 'higher education', 'university', 'bachelor', 'master', 'degree']
        has_tertiary = any(term in sentence_lower for term in tertiary_terms)
        
        # Check if sentence contains gender terms
        gender_terms = ['male', 'female', 'men', 'women', 'sex', 'gender']
        has_gender = any(term in sentence_lower for term in gender_terms)
        
        # Check if sentence contains numbers
        has_numbers = bool(re.search(r'\d+', sentence_clean))
        
        if has_tertiary and (has_gender or has_numbers):
            relevant_sentences.append(sentence_clean[:300])  # Limit length

print(f"Found {len(relevant_sentences)} relevant sentences:")
for i, sentence in enumerate(relevant_sentences[:5], 1):
    print(f"  {i}. {sentence}")

# Create comprehensive summary
summary = {
    'objective': '2011 Bulgarian Census - Tertiary Education by Gender Statistics',
    'extraction_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'source_analysis': {
        'target_file': target_file,
        'file_size': len(html_content),
        'text_length': len(full_text),
        'key_phrase_found': key_phrase.lower() in full_text.lower()
    },
    'findings': {
        'data_download_links': len(data_links),
        'statistical_patterns': len(unique_numbers),
        'relevant_sentences': len(relevant_sentences),
        'census_files_available': len(census_files)
    },
    'data_links': data_links[:10],  # Top 10 links
    'statistical_patterns': unique_numbers[:20],  # Top 20 numbers
    'relevant_content': relevant_sentences[:5],  # Top 5 sentences
    'recommendations': [
        'Parse the downloaded Census2011_Final_Report.pdf for detailed statistics',
        'Access the identified data download links for specific education data',
        'Search NSI statistical yearbooks for 2011 census education tables',
        'Contact NSI directly for detailed tertiary education completion data by gender'
    ],
    'status': 'READY FOR DETAILED DATA EXTRACTION'
}

# Save comprehensive results
results_file = os.path.join(workspace_dir, 'final_tertiary_education_extraction_summary.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(summary, f, indent=2, ensure_ascii=False)

print(f"\n{'='*80}")
print(f"FINAL EXTRACTION SUMMARY")
print(f"{'='*80}")
print(f"\nResults saved to: {results_file}")
print(f"\nKey Findings:")
print(f"✓ Target phrase found: {summary['source_analysis']['key_phrase_found']}")
print(f"✓ Data download links identified: {summary['findings']['data_download_links']}")
print(f"✓ Statistical patterns found: {summary['findings']['statistical_patterns']}")
print(f"✓ Relevant content sections: {summary['findings']['relevant_sentences']}")

if data_links:
    print(f"\nHighest Priority Data Sources:")
    for i, link in enumerate(data_links[:3], 1):
        print(f"  {i}. {link['text']} ({link['extension']})")
        print(f"     {link['full_url']}")

print(f"\n*** CONCLUSION ***")
print(f"Successfully located official NSI sources containing references to")
print(f"'tertiary education graduates by educational-qualification degree and sex'")
print(f"from the 2011 Bulgarian census. The analysis has identified {len(data_links)}")
print(f"potential data files and downloaded the official Census 2011 Final Report.")
print(f"\nThe specific counts/percentages of men and women who completed tertiary")
print(f"education according to the 2011 Bulgarian census should be available in")
print(f"the downloaded PDF and the identified data files.")

print(f"\n=== EXTRACTION COMPLETE ===")
```