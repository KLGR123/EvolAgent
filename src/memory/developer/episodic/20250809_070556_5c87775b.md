### Development Step 7: Locate 1994 example for 'caminata' in Collins Spanish-English dictionary and identify its source title.

**Description**: Search for the Spanish word 'caminata' in the Collins Spanish-to-English dictionary online to locate the 1994 example sentence. Focus on finding the Collins dictionary entry that contains an example sentence from 1994, then identify the source title of that example sentence and prepare it for Google translation.

**Use Cases**:
- Linguistic research tracing the evolution of example sentences in Spanish-English dictionaries for academic publications
- Automated extraction of historical dictionary examples for digital humanities projects analyzing language change
- Library or archive staff verifying the provenance of example sentences in legacy print dictionaries for cataloging purposes
- Language learning app developers sourcing authentic, dated example sentences to enhance vocabulary teaching modules
- Legal teams investigating copyright or attribution of dictionary content in translation disputes
- Publishers cross-referencing dictionary example citations for inclusion in new bilingual dictionary editions
- University instructors preparing annotated reading materials that require original source attribution for dictionary examples
- Machine translation system trainers collecting dated, context-rich example sentences to improve translation model accuracy

```
import os
import requests
from bs4 import BeautifulSoup
import time

print('=== ALTERNATIVE APPROACH: ARCHIVED COLLINS DICTIONARY FOR CAMINATA 1994 EXAMPLE ===')
print('Using Wayback Machine to find historical Collins dictionary content\n')

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

# The current Collins dictionary pages are showing loading screens or blocking access
# Let's try to find archived versions that might contain the 1994 example

# Target Collins dictionary URL for caminata
target_url = 'https://www.collinsdictionary.com/dictionary/spanish-english/caminata'

print(f'Target URL: {target_url}')
print('Searching for archived versions that might contain 1994 example sentence...')

# Check if the webpage is available in the Wayback Machine
api_url = f'https://archive.org/wayback/available?url={target_url}'
print(f'\nChecking Wayback Machine availability: {api_url}')

try:
    avail_response = requests.get(api_url, timeout=20)
    
    if avail_response.status_code == 200:
        avail_data = avail_response.json()
        print('✓ Wayback Machine API response received')
        
        if 'archived_snapshots' in avail_data and 'closest' in avail_data['archived_snapshots']:
            closest = avail_data['archived_snapshots']['closest']
            
            if closest['available']:
                archive_url = closest['url']
                archive_date = closest['timestamp']
                
                print(f'✓ Found archived version:')
                print(f'  Archive date: {archive_date[:4]}-{archive_date[4:6]}-{archive_date[6:8]}')
                print(f'  Archive URL: {archive_url}')
                
                # Get the archived version
                print('\nAccessing archived Collins dictionary page...')
                
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
                
                archive_response = requests.get(archive_url, headers=headers, timeout=30)
                
                if archive_response.status_code == 200:
                    print('✓ Successfully accessed archived Collins dictionary page')
                    print(f'Content length: {len(archive_response.text):,} characters')
                    
                    # Save archived content
                    archive_filename = f'collins_archived_{archive_date[:8]}.html'
                    archive_filepath = os.path.join('workspace', archive_filename)
                    
                    with open(archive_filepath, 'w', encoding='utf-8') as f:
                        f.write(archive_response.text)
                    
                    print(f'Archived content saved to: {archive_filepath}')
                    
                    # Parse and analyze for 1994 content
                    soup = BeautifulSoup(archive_response.content, 'html.parser')
                    
                    # Remove wayback machine elements
                    for element in soup.find_all(class_=lambda x: x and 'wayback' in x.lower()):
                        element.decompose()
                    
                    page_text = soup.get_text()
                    
                    # Check for 1994 references
                    has_1994 = '1994' in page_text
                    print(f'\nContains "1994": {has_1994}')
                    
                    if has_1994:
                        print('\n*** 1994 CONTENT FOUND IN ARCHIVED VERSION ***')
                        
                        # Find all lines containing 1994
                        lines = page_text.split('\n')
                        lines_with_1994 = []
                        
                        for line_num, line in enumerate(lines, 1):
                            if '1994' in line and line.strip():
                                lines_with_1994.append((line_num, line.strip()))
                        
                        print(f'Found {len(lines_with_1994)} lines containing "1994":')
                        
                        for line_num, line_text in lines_with_1994:
                            print(f'  Line {line_num}: {line_text}')
                            
                            # Look for source title indicators
                            source_indicators = ['source:', 'from:', 'title:', 'book:', 'publication:', 'newspaper:', 'magazine:', 'author:', 'work:', '©', 'copyright']
                            if any(indicator in line_text.lower() for indicator in source_indicators):
                                print(f'    *** POTENTIAL SOURCE TITLE FOUND ***')
                                
                                # Extract potential source title
                                for indicator in source_indicators:
                                    if indicator in line_text.lower():
                                        parts = line_text.lower().split(indicator)
                                        if len(parts) > 1:
                                            potential_source = parts[1].strip()
                                            print(f'    Potential source: "{potential_source}"')
                        
                        # Look for HTML elements containing 1994
                        print('\n--- Analyzing HTML elements with 1994 ---')
                        elements_with_1994 = soup.find_all(text=lambda text: text and '1994' in str(text))
                        
                        for j, element in enumerate(elements_with_1994, 1):
                            parent = element.parent
                            if parent and parent.name:
                                parent_text = parent.get_text().strip()
                                if len(parent_text) > 10:
                                    print(f'\nElement {j}:')
                                    print(f'  Tag: {parent.name}')
                                    print(f'  Class: {parent.get("class", "No class")}')
                                    print(f'  Text: {parent_text[:300]}...' if len(parent_text) > 300 else f'  Text: {parent_text}')
                                    
                                    # Check for source attribution patterns
                                    if any(pattern in parent_text.lower() for pattern in ['source:', 'from:', 'title:', '©', 'copyright']):
                                        print(f'    *** SOURCE ATTRIBUTION FOUND ***')
                        
                        # Save detailed analysis
                        analysis_file = os.path.join('workspace', f'collins_archived_1994_analysis.txt')
                        with open(analysis_file, 'w', encoding='utf-8') as f:
                            f.write('COLLINS DICTIONARY ARCHIVED VERSION - CAMINATA 1994 ANALYSIS\n')
                            f.write('='*60 + '\n\n')
                            f.write(f'Archive URL: {archive_url}\n')
                            f.write(f'Archive date: {archive_date[:4]}-{archive_date[4:6]}-{archive_date[6:8]}\n')
                            f.write(f'Original URL: {target_url}\n')
                            f.write(f'Analysis timestamp: {time.strftime("%Y-%m-%d %H:%M:%S")}\n\n')
                            
                            f.write(f'Lines containing "1994": {len(lines_with_1994)}\n\n')
                            
                            if lines_with_1994:
                                f.write('LINES WITH 1994:\n')
                                f.write('-'*40 + '\n')
                                for line_num, line_text in lines_with_1994:
                                    f.write(f'Line {line_num}: {line_text}\n')
                            
                            f.write('\n\nHTML ELEMENTS WITH 1994:\n')
                            f.write('-'*40 + '\n')
                            for j, element in enumerate(elements_with_1994, 1):
                                parent = element.parent
                                if parent and parent.name:
                                    parent_text = parent.get_text().strip()
                                    if len(parent_text) > 10:
                                        f.write(f'\nElement {j}:\n')
                                        f.write(f'Tag: {parent.name}\n')
                                        f.write(f'Class: {parent.get("class", "No class")}\n')
                                        f.write(f'Text: {parent_text}\n')
                                        f.write('-'*20 + '\n')
                        
                        print(f'\n✓ Detailed analysis saved to: {analysis_file}')
                        
                    else:
                        print('\nNo 1994 content found in archived version')
                        
                        # Still analyze the page structure
                        print('\n--- Analyzing archived page structure ---')
                        
                        # Get page title
                        title = soup.find('title')
                        if title:
                            print(f'Page title: {title.get_text().strip()}')
                        
                        # Look for example sections
                        example_sections = soup.find_all(['div', 'section', 'span'], class_=lambda x: x and any(term in str(x).lower() for term in ['example', 'sentence', 'usage', 'citation']))
                        print(f'Found {len(example_sections)} potential example sections')
                        
                        # Check if this is actually a Collins dictionary page
                        content_lower = page_text.lower()
                        is_collins = 'collins' in content_lower and 'dictionary' in content_lower
                        has_caminata = 'caminata' in content_lower
                        
                        print(f'Is Collins dictionary page: {is_collins}')
                        print(f'Contains "caminata": {has_caminata}')
                        
                        if is_collins and has_caminata:
                            print('✓ Confirmed: This is a Collins dictionary page for "caminata"')
                        else:
                            print('⚠ Warning: This may not be the expected Collins dictionary content')
                
                else:
                    print(f'✗ Failed to access archived version - Status: {archive_response.status_code}')
            
            else:
                print('✗ No archived version available in Wayback Machine')
        
        else:
            print('✗ No archived snapshots found for this URL')
    
    else:
        print(f'✗ Failed to check Wayback Machine - Status: {avail_response.status_code}')

except Exception as e:
    print(f'✗ Error accessing Wayback Machine: {str(e)}')

# Alternative approach: Search for other archived dictionary sources
print('\n' + '='*80)
print('=== ALTERNATIVE: SEARCH FOR ACADEMIC/LINGUISTIC SOURCES ===')
print('Looking for academic sources that might reference Collins 1994 examples\n')

# Get SerpAPI key for additional searches
api_key = os.getenv("SERPAPI_API_KEY")

if api_key:
    print('Searching for academic sources mentioning Collins Spanish dictionary 1994 examples...')
    
    academic_queries = [
        '"Collins Spanish dictionary" "1994" "caminata" example sentence source',
        'Collins Spanish-English dictionary 1994 example citation "caminata"',
        'site:edu "Collins dictionary" "caminata" 1994 example source title',
        '"Collins Spanish dictionary" 1994 edition "caminata" example sentence'
    ]
    
    for i, query in enumerate(academic_queries, 1):
        print(f'\n--- Academic Search {i}/4: {query} ---')
        
        try:
            params = {
                "q": query,
                "api_key": api_key,
                "engine": "google",
                "google_domain": "google.com",
                "safe": "off",
                "num": 5,
                "type": "search"
            }
            
            response = requests.get("https://serpapi.com/search.json", params=params)
            
            if response.status_code == 200:
                results = response.json()
                
                if results.get("organic_results"):
                    for j, result in enumerate(results['organic_results'], 1):
                        title = result.get('title', 'No title')
                        url = result.get('link', 'No link')
                        snippet = result.get('snippet', 'No snippet')
                        
                        print(f'  Result {j}: {title}')
                        print(f'    URL: {url}')
                        print(f'    Snippet: {snippet[:100]}...' if len(snippet) > 100 else f'    Snippet: {snippet}')
                        
                        # Check for promising academic sources
                        text_to_check = f"{title} {snippet}".lower()
                        if any(term in text_to_check for term in ['collins', '1994', 'caminata', 'dictionary']):
                            if any(domain in url for domain in ['.edu', '.org', 'academia', 'researchgate']):
                                print(f'    *** PROMISING ACADEMIC SOURCE ***')
                else:
                    print('  No results found')
            
        except Exception as e:
            print(f'  Error in academic search {i}: {e}')
        
        time.sleep(1)

print('\n=== SUMMARY AND RECOMMENDATIONS ===')
print('Current status: Collins dictionary direct access blocked, archived versions searched')
print('\nBased on the search attempts:')
print('1. Current Collins online dictionary shows loading screens (Chinese "please wait")')
print('2. Direct HTTP access returns 403 Forbidden errors')
print('3. Selenium access bypasses blocks but gets loading screens')
print('4. Search results found Collins dictionary URLs but no 1994 references')
print('\nPossible conclusions:')
print('- The 1994 example sentence may not exist in current online Collins dictionary')
print('- The example might be from a print edition or older online version')
print('- Collins may have updated their example sentences over time')
print('\nRecommended next steps:')
print('1. Check if archived versions contain the 1994 example')
print('2. Search for Collins Spanish dictionary print editions from 1994 era')
print('3. Look for academic linguistic databases with Collins citations')
print('4. Consider that the task may reference a specific Collins edition no longer online')
```