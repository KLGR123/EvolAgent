### Development Step 1: Identify unusual walk-nicknamed player with 29 steals in 1970, traded for Tommy McCraw

**Description**: Search for information about a baseball player who had an unusual walk style nickname, stole 29 bases in the 1970 season, and was involved in a trade between the Chicago White Sox and another team in 1971 where Tommy McCraw was exchanged. Focus on identifying this player's distinctive nickname related to his walking style, his 1970 season statistics showing exactly 29 stolen bases, and the specific 1971 trade details involving McCraw going to the team that had previously traded this player to the White Sox.

**Use Cases**:
- Baseball journalism research and article generation: Automatically retrieve a player’s 1970 stolen base totals, 1971 trade details involving Tommy McCraw, and nickname origin for writing in-depth profiles on sports news sites.
- Sports analytics pipeline enrichment: Integrate the script into a baseball team’s internal database to keep season-by-season stolen base leaders, unique player nicknames, and historical trade records up to date.
- Fantasy baseball advisory tool: Identify under-the-radar players with distinctive playing quirks and past stolen base performance (e.g., exactly 29 steals in 1970) to inform draft recommendations and waiver wire pickups.
- Academic sports history study: Compile and analyze transaction networks and nickname folklore among MLB players for a thesis on cultural influences in 1970s baseball.
- Museum exhibit content curation: Feed the collected player nickname stories, stolen base stats, and trade timelines into an interactive touchscreen display at a baseball hall of fame.
- Fan trivia mobile app backend: Dynamically supply quiz questions about obscure player walk-style nicknames, 1970 stolen base counts, and 1971 trade partners like Tommy McCraw for daily baseball trivia challenges.
- Social media content automation for MLB teams: Generate and schedule historical “On This Day” posts highlighting unique player nicknames, exact stolen base numbers, and milestone trades in franchise history.
- Memorabilia authentication and value analysis: Cross-reference a signed baseball or trading card’s player statistics, nickname usage, and trade history to verify provenance and estimate collectible worth.

```
import requests
import json
import os
from bs4 import BeautifulSoup
import time

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

print("=== SEARCHING FOR 1970 BASEBALL PLAYER WITH UNUSUAL WALK STYLE NICKNAME ===")
print("Target criteria:")
print("- Had unusual walk style nickname")
print("- Stole exactly 29 bases in 1970 season")
print("- Involved in 1971 trade between Chicago White Sox and another team")
print("- Tommy McCraw was part of this trade")
print()

# First, let's search for information about Tommy McCraw and 1971 trades
# This will help us identify the trade and the other player involved

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

print("Step 1: Searching for Tommy McCraw 1971 trade information...")

# Try Baseball-Reference for Tommy McCraw's career page
tommy_mccraw_url = "https://www.baseball-reference.com/players/m/mccrato01.shtml"

try:
    response = requests.get(tommy_mccraw_url, headers=headers, timeout=30)
    print(f"Tommy McCraw Baseball-Reference response: {response.status_code}")
    
    if response.status_code == 200:
        print("Successfully accessed Tommy McCraw's Baseball-Reference page")
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Save the raw HTML for analysis
        with open('workspace/tommy_mccraw_baseball_reference.html', 'w', encoding='utf-8') as f:
            f.write(response.text)
        
        print("Tommy McCraw page saved to workspace/tommy_mccraw_baseball_reference.html")
        
        # Look for transaction information or career timeline
        # Search for text containing '1971', 'trade', 'White Sox', 'Chicago'
        page_text = soup.get_text().lower()
        
        print("\n=== Searching for 1971 trade information in Tommy McCraw page ===")
        
        # Look for transaction/trade sections
        transaction_sections = soup.find_all(['div', 'section', 'table'], 
                                           attrs={'id': lambda x: x and ('transaction' in x.lower() or 'trade' in x.lower()) if x else False})
        
        if transaction_sections:
            print(f"Found {len(transaction_sections)} transaction-related sections")
            for i, section in enumerate(transaction_sections):
                print(f"\nTransaction section {i+1}:")
                print(section.get_text()[:500])  # First 500 characters
        
        # Look for any mention of 1971 and related terms
        lines = page_text.split('\n')
        relevant_lines = []
        for line in lines:
            if '1971' in line and any(term in line for term in ['trade', 'white sox', 'chicago', 'acquired', 'sent']):
                relevant_lines.append(line.strip())
        
        if relevant_lines:
            print(f"\n=== Found {len(relevant_lines)} lines mentioning 1971 trades ===")
            for i, line in enumerate(relevant_lines[:5]):  # Show first 5 relevant lines
                print(f"{i+1}. {line}")
        else:
            print("\nNo direct 1971 trade information found in Tommy McCraw page text")
        
        # Also look for team history or year-by-year stats
        stats_tables = soup.find_all('table')
        print(f"\nFound {len(stats_tables)} tables on Tommy McCraw page")
        
        # Check if any tables show team changes around 1971
        for i, table in enumerate(stats_tables[:5]):  # Check first 5 tables
            headers = table.find_all('th')
            header_text = [th.get_text().strip() for th in headers]
            
            if any('year' in h.lower() or 'team' in h.lower() for h in header_text):
                print(f"\n*** Table {i+1} appears to show year/team data ***")
                print(f"Headers: {header_text[:8]}")
                
                # Look for 1971 data
                rows = table.find_all('tr')
                for row in rows:
                    row_text = row.get_text()
                    if '1971' in row_text:
                        print(f"1971 row found: {row_text.strip()}")
        
    else:
        print(f"Failed to access Tommy McCraw page: HTTP {response.status_code}")
        
except Exception as e:
    print(f"Error accessing Tommy McCraw page: {str(e)}")

print("\n" + "="*60)
print("Step 2: Searching for 1970 stolen base leaders to find player with 29 steals...")

# Search for 1970 stolen base statistics
stolen_base_url = "https://www.baseball-reference.com/years/1970/leaders.shtml"

try:
    response = requests.get(stolen_base_url, headers=headers, timeout=30)
    print(f"1970 leaders page response: {response.status_code}")
    
    if response.status_code == 200:
        print("Successfully accessed 1970 MLB leaders page")
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Save the HTML
        with open('workspace/1970_mlb_leaders.html', 'w', encoding='utf-8') as f:
            f.write(response.text)
        
        print("1970 leaders page saved to workspace/1970_mlb_leaders.html")
        
        # Look for stolen base statistics
        page_text = soup.get_text().lower()
        
        # Search for "29" in context of stolen bases
        lines = page_text.split('\n')
        sb_lines = []
        for line in lines:
            if '29' in line and any(term in line for term in ['sb', 'stolen', 'steal', 'base']):
                sb_lines.append(line.strip())
        
        if sb_lines:
            print(f"\n=== Found {len(sb_lines)} lines mentioning 29 stolen bases ===")
            for i, line in enumerate(sb_lines):
                print(f"{i+1}. {line}")
        
        # Look for stolen base tables
        tables = soup.find_all('table')
        print(f"\nFound {len(tables)} tables on 1970 leaders page")
        
        for i, table in enumerate(tables):
            # Check if table is about stolen bases
            table_text = table.get_text().lower()
            if 'stolen' in table_text or 'sb' in table_text:
                print(f"\n*** Table {i+1} appears to contain stolen base data ***")
                
                rows = table.find_all('tr')
                print(f"Table has {len(rows)} rows")
                
                # Look for rows with 29 steals
                for j, row in enumerate(rows[:15]):  # Check first 15 rows
                    cells = row.find_all(['td', 'th'])
                    cell_data = [cell.get_text().strip() for cell in cells]
                    
                    if '29' in ' '.join(cell_data):
                        print(f"*** Row {j+1} contains '29': {cell_data} ***")
                        
                        # This could be our player!
                        if len(cell_data) >= 2:  # Should have player name and stats
                            potential_player = cell_data[0] if cell_data[0] != '29' else cell_data[1] if len(cell_data) > 1 else 'Unknown'
                            print(f"*** POTENTIAL PLAYER WITH 29 STEALS: {potential_player} ***")
    
    else:
        print(f"Failed to access 1970 leaders page: HTTP {response.status_code}")
        
except Exception as e:
    print(f"Error accessing 1970 leaders page: {str(e)}")

print("\n" + "="*60)
print("INITIAL SEARCH SUMMARY:")
print("1. Searched Tommy McCraw's Baseball-Reference page for 1971 trade info")
print("2. Searched 1970 MLB leaders page for players with 29 stolen bases")
print("3. Saved HTML files for detailed analysis in next step")
print("\nNext steps:")
print("- Parse saved HTML files to extract specific trade and stolen base data")
print("- Cross-reference players to find the one matching all criteria")
print("- Search for nickname information once player is identified")
```