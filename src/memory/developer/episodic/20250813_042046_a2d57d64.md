### Development Step 12: Locate 1839 Robertson Novel Set in Scotland/Wales Featuring Glasgow Orphan Clerk and Dickens Illustrator

**Description**: Search for novels published by Saunders and Otley in 1839 that were authored by either William Parish Robertson or John Parish Robertson. Focus on identifying a novel set in rural Scotland and Wales featuring a young orphan clerk residing in Glasgow. Also search for information about which artist illustrated this novel, specifically looking for an illustrator known for working with Charles Dickens who also created 'The Great 100 Rat Match' circa 1858. Use search terms including 'Robertson Saunders Otley 1839 novel', 'Scotland Wales orphan clerk Glasgow novel 1839', and 'Dickens illustrator Great 100 Rat Match 1858'.

**Use Cases**:
- Rare book dealer verifying 19th-century publication metadata for Saunders & Otley novels to authenticate inventory before listing valuable first editions
- University library catalog enrichment automating discovery of missing bibliographic records for obscure travel writings by the Robertson brothers in 1839
- Digital humanities project indexing Victorian-era illustrations and attributions in an open-access archive of Charles Dickens‚Äô collaborators
- Museum exhibit curator sourcing high-resolution scans and contextual details of ‚ÄúThe Great 100 Rat Match‚Äù for a sporting art display on Victorian pastimes
- Literary scholar cross-referencing orphan-clerk protagonists and rural Scotland/Wales settings for a thematic analysis of regional 19th-century fiction
- Academic publisher preparing a critical edition of Parish Robertson‚Äôs travel narratives by aggregating variant titles, editions, and illustrator credits
- Genealogist tracing the Parish Robertson family‚Äôs literary output by extracting publication dates, publishers, and artist collaborators from digitized archives
- Content marketing team building a niche blog series on Victorian animal sports illustrations by automating the attribution of works to Dickens‚Äô illustrators such as Phiz

```
import os
import requests
from bs4 import BeautifulSoup
import json
import time
from urllib.parse import quote_plus, urljoin
import re

print('=== ROBERTSON BROTHERS 1839 NOVEL & DICKENS ILLUSTRATOR RESEARCH ===')
print('APPROACH: Direct web search with robust error handling')
print('TARGET 1: Robertson brothers novel published by Saunders & Otley (1839)')
print('         - Setting: Rural Scotland and Wales, orphan clerk in Glasgow')
print('TARGET 2: Dickens illustrator who created "The Great 100 Rat Match" (1858)')
print('\nSTRATEGY: Use multiple search engines with fallback methods')
print('=' * 80 + '\n')

# Ensure workspace directory exists
os.makedirs('workspace', exist_ok=True)

# Headers for web requests - defined at module level
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Connection': 'keep-alive',
    'Cache-Control': 'no-cache'
}

# Initialize comprehensive results storage
research_results = {
    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'research_objective': 'Identify Robertson brothers 1839 Saunders & Otley novel and Dickens illustrator',
    'search_method': 'Direct web search with multiple engines and robust error handling',
    'searches_conducted': [],
    'robertson_novel_findings': [],
    'illustrator_findings': [],
    'analysis_summary': {},
    'technical_notes': 'Implemented without external library dependencies, fixed f-string syntax'
}

print('=== PHASE 1: ROBERTSON BROTHERS NOVEL RESEARCH ===\n')

# Comprehensive search queries for Robertson novel identification
novel_search_queries = [
    # Direct publisher and author combinations
    'William Parish Robertson "Saunders and Otley" 1839',
    'John Parish Robertson "Saunders Otley" 1839 novel',
    '"Parish Robertson" "Saunders & Otley" 1839 publisher',
    
    # Geographic and character-based searches
    'Robertson 1839 novel Scotland Wales Glasgow orphan clerk',
    '"Saunders and Otley" 1839 Scotland Wales novel Robertson',
    'Parish Robertson 1839 rural Scotland Wales Glasgow',
    
    # Known works searches
    '"Letters on South America" Robertson "Saunders Otley" 1839',
    'Robertson brothers "Letters on Paraguay" 1839 publisher',
    'William John Parish Robertson 1839 published works',
    
    # Bibliographic searches
    'Robertson brothers bibliography 1839 Saunders Otley',
    '"A History of America" Robertson 1839 Saunders',
    'Parish Robertson travel writing 1839 publisher Scotland'
]

print(f'Conducting {len(novel_search_queries)} Robertson novel searches:')
for i, query in enumerate(novel_search_queries, 1):
    print(f'  {i:2d}. {query}')

# Function to perform web search with error handling
def perform_web_search(query, search_index, search_type='novel'):
    """Perform web search using DuckDuckGo HTML interface with comprehensive error handling"""
    
    print(f'\n--- {search_type.title()} Search {search_index}: {query} ---')
    
    try:
        # Use DuckDuckGo HTML search interface
        search_url = 'https://html.duckduckgo.com/html/'
        params = {'q': query}
        
        print(f'Searching: {search_url}?q={quote_plus(query)}')
        
        # Make request with timeout and error handling
        response = requests.get(search_url, params=params, headers=headers, timeout=30)
        print(f'Response status: {response.status_code}')
        
        if response.status_code == 200:
            # Save raw HTML for analysis
            clean_query = re.sub(r'[^\w\s-]', '', query).replace(' ', '_')[:50]
            html_filename = f'{search_type}_search_{search_index:02d}_{clean_query}.html'
            html_filepath = os.path.join('workspace', html_filename)
            
            with open(html_filepath, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            print(f'HTML saved: {html_filename}')
            
            # Parse HTML for search results
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Extract search result links and text
            search_results = []
            
            # Look for result containers (DuckDuckGo uses various classes)
            result_containers = soup.find_all(['div', 'article'], class_=lambda x: x and any(
                term in str(x).lower() for term in ['result', 'web-result', 'results__result']
            ))
            
            # Fallback: look for links that appear to be search results
            if not result_containers:
                result_containers = soup.find_all('a', href=True)
            
            print(f'Found {len(result_containers)} potential result containers')
            
            for i, container in enumerate(result_containers[:15], 1):
                try:
                    # Extract title, URL, and snippet
                    if container.name == 'a':
                        title = container.get_text().strip()
                        url = container.get('href')
                        snippet = ''
                    else:
                        # Look for title link
                        title_link = container.find('a', href=True)
                        title = title_link.get_text().strip() if title_link else 'No title'
                        url = title_link.get('href') if title_link else 'No URL'
                        
                        # Look for snippet text
                        snippet_elem = container.find(['p', 'span', 'div'], class_=lambda x: x and 'snippet' in str(x).lower())
                        if not snippet_elem:
                            snippet_elem = container.find_all(text=True)
                            snippet = ' '.join([t.strip() for t in snippet_elem if t.strip()])[:300]
                        else:
                            snippet = snippet_elem.get_text().strip()
                    
                    # Clean and validate URL
                    if url and not url.startswith('http'):
                        if url.startswith('//'):
                            url = 'https:' + url
                        elif url.startswith('/'):
                            url = 'https://duckduckgo.com' + url
                    
                    # Skip if title or URL is too short or invalid
                    if len(title) < 10 or not url or 'duckduckgo.com' in url:
                        continue
                    
                    # Calculate relevance score
                    combined_text = f'{title} {snippet}'.lower()
                    
                    if search_type == 'novel':
                        relevance_score = calculate_novel_relevance_score(combined_text)
                        indicators = extract_novel_indicators(combined_text)
                    else:
                        relevance_score = calculate_illustrator_relevance_score(combined_text)
                        indicators = extract_illustrator_indicators(combined_text)
                    
                    if relevance_score >= 6:  # Lower threshold to catch more results
                        print(f'\n  üìã Result {i} (Relevance: {relevance_score})')
                        print(f'    Title: {title[:100]}...')
                        print(f'    URL: {url}')
                        print(f'    Snippet: {snippet[:150]}...')
                        # FIXED: Proper string formatting instead of f-string with complex expression
                        indicators_str = ', '.join(indicators)
                        print(f'    Indicators: {indicators_str}')
                        
                        search_results.append({
                            'title': title,
                            'url': url,
                            'snippet': snippet,
                            'relevance_score': relevance_score,
                            'indicators': indicators,
                            'search_query': query,
                            'search_index': search_index
                        })
                
                except Exception as e:
                    print(f'    Error processing result {i}: {str(e)}')
                    continue
            
            # Store results
            if search_type == 'novel':
                research_results['robertson_novel_findings'].extend(search_results)
            else:
                research_results['illustrator_findings'].extend(search_results)
            
            # Record search metadata
            research_results['searches_conducted'].append({
                'query': query,
                'search_index': search_index,
                'search_type': search_type,
                'results_found': len(search_results),
                'html_file': html_filename,
                'status': 'success'
            })
            
            print(f'\n‚úÖ Search completed: {len(search_results)} relevant results found')
            return True
            
        elif response.status_code == 202:
            print('‚ùå Search blocked (HTTP 202) - implementing delay and retry')
            time.sleep(5)
            return False
        else:
            print(f'‚ùå Search failed with status {response.status_code}')
            return False
            
    except requests.exceptions.Timeout:
        print('‚ùå Search timed out after 30 seconds')
        return False
    except requests.exceptions.RequestException as e:
        print(f'‚ùå Network error: {str(e)}')
        return False
    except Exception as e:
        print(f'‚ùå Unexpected error: {str(e)}')
        return False

# Helper function to calculate novel relevance score
def calculate_novel_relevance_score(text):
    """Calculate relevance score for Robertson novel searches"""
    score = 0
    
    # Primary search terms (high value)
    primary_terms = {
        'robertson': 4, 'parish': 4, 'william': 2, 'john': 2,
        'saunders': 5, 'otley': 5, '1839': 6,
        'novel': 3, 'book': 2, 'published': 2, 'publisher': 3
    }
    
    # Geographic and character terms
    context_terms = {
        'scotland': 3, 'wales': 3, 'glasgow': 4, 'scottish': 2, 'welsh': 2,
        'orphan': 4, 'clerk': 3, 'rural': 2, 'young': 1
    }
    
    # Subject matter terms
    subject_terms = {
        'letters': 3, 'america': 2, 'south america': 4, 'paraguay': 3,
        'travel': 2, 'journey': 2, 'voyage': 2, 'history': 2
    }
    
    # Count occurrences and add to score
    for term, value in {**primary_terms, **context_terms, **subject_terms}.items():
        if term in text:
            score += value
    
    # Bonus for key combinations
    if 'saunders' in text and 'otley' in text:
        score += 6
    if 'robertson' in text and '1839' in text:
        score += 5
    if 'scotland' in text and 'wales' in text:
        score += 4
    if 'orphan' in text and 'clerk' in text:
        score += 3
    if 'letters' in text and 'america' in text:
        score += 3
    
    return score

# Helper function to extract novel indicators
def extract_novel_indicators(text):
    """Extract indicators for Robertson novel identification"""
    indicators = []
    
    if 'saunders' in text and 'otley' in text:
        indicators.append('SAUNDERS & OTLEY PUBLISHER')
    if 'robertson' in text and '1839' in text:
        indicators.append('ROBERTSON 1839')
    if any(term in text for term in ['scotland', 'wales', 'glasgow', 'scottish', 'welsh']):
        indicators.append('SCOTTISH/WELSH CONTENT')
    if any(term in text for term in ['orphan', 'clerk']):
        indicators.append('CHARACTER ELEMENTS')
    if 'letters' in text and 'america' in text:
        indicators.append('LETTERS ON AMERICA')
    if any(term in text for term in ['novel', 'book', 'published']):
        indicators.append('LITERARY WORK')
    if any(term in text for term in ['william', 'john']) and 'parish' in text:
        indicators.append('PARISH ROBERTSON BROTHERS')
    
    return indicators

# Helper function to calculate illustrator relevance score
def calculate_illustrator_relevance_score(text):
    """Calculate relevance score for illustrator searches"""
    score = 0
    
    # Core search terms
    core_terms = {
        'rat match': 6, 'great 100': 5, '100 rat': 5, 'rat': 2,
        '1858': 5, 'dickens': 4, 'charles dickens': 5
    }
    
    # Illustrator identification terms
    illustrator_terms = {
        'phiz': 5, 'hablot': 5, 'browne': 3, 'hablot browne': 6,
        'cruikshank': 4, 'george cruikshank': 5,
        'illustrator': 3, 'illustration': 2, 'artist': 2, 'drawing': 2
    }
    
    # Period and context terms
    context_terms = {
        'victorian': 3, '19th century': 2, 'nineteenth': 2,
        'sporting': 2, 'sport': 1, 'match': 1, 'competition': 1
    }
    
    # Count occurrences
    for term, value in {**core_terms, **illustrator_terms, **context_terms}.items():
        if term in text:
            score += value
    
    # Bonus combinations
    if 'dickens' in text and 'illustrator' in text:
        score += 4
    if 'rat match' in text and '1858' in text:
        score += 6
    if any(name in text for name in ['phiz', 'hablot browne', 'george cruikshank']):
        score += 3
    
    return score

# Helper function to extract illustrator indicators
def extract_illustrator_indicators(text):
    """Extract indicators for illustrator identification"""
    indicators = []
    
    if 'rat match' in text:
        indicators.append('RAT MATCH REFERENCE')
    if 'great 100' in text or '100 rat' in text:
        indicators.append('GREAT 100 REFERENCE')
    if '1858' in text:
        indicators.append('1858 DATE')
    if 'dickens' in text:
        indicators.append('DICKENS CONNECTION')
    if 'phiz' in text or 'hablot browne' in text:
        indicators.append('PHIZ/HABLOT BROWNE')
    if 'cruikshank' in text:
        indicators.append('CRUIKSHANK')
    if any(term in text for term in ['illustrator', 'illustration', 'artist']):
        indicators.append('ILLUSTRATION WORK')
    if 'victorian' in text:
        indicators.append('VICTORIAN PERIOD')
    
    return indicators

# Execute Robertson novel searches
print('\nExecuting Robertson novel searches...')
successful_novel_searches = 0

for i, query in enumerate(novel_search_queries, 1):
    if perform_web_search(query, i, 'novel'):
        successful_novel_searches += 1
    
    # Rate limiting between searches
    time.sleep(3)

print(f'\n=== PHASE 2: DICKENS ILLUSTRATOR RESEARCH ===\n')

# Comprehensive search queries for illustrator identification
illustrator_search_queries = [
    # Direct "Great 100 Rat Match" searches
    '"The Great 100 Rat Match" 1858 illustrator',
    '"Great 100 Rat Match" Dickens illustrator 1858',
    '"100 Rat Match" Victorian illustrator 1858',
    
    # Dickens illustrator searches
    'Dickens illustrator "Great Rat Match" 1858',
    'Charles Dickens illustrator "rat match" 1858',
    'Phiz "Great 100 Rat Match" Dickens 1858',
    'Hablot Browne "Great 100 Rat Match" 1858',
    'George Cruikshank "Great 100 Rat Match" 1858',
    
    # Victorian sporting illustration searches
    'Victorian rat baiting illustration 1858 Dickens',
    '1858 sporting illustration "rat match" Victorian',
    'Punch magazine 1858 rat match illustration',
    'Victorian sporting art "100 rats" 1858'
]

print(f'Conducting {len(illustrator_search_queries)} illustrator searches:')
for i, query in enumerate(illustrator_search_queries, 1):
    print(f'  {i:2d}. {query}')

# Execute illustrator searches
print('\nExecuting illustrator searches...')
successful_illustrator_searches = 0

for i, query in enumerate(illustrator_search_queries, 1):
    search_index = len(novel_search_queries) + i
    if perform_web_search(query, search_index, 'illustrator'):
        successful_illustrator_searches += 1
    
    # Rate limiting between searches
    time.sleep(3)

print('\n' + '=' * 90)
print('COMPREHENSIVE RESEARCH ANALYSIS: ROBERTSON NOVEL & DICKENS ILLUSTRATOR')
print('=' * 90)

# Analyze and summarize findings
total_searches = len(novel_search_queries) + len(illustrator_search_queries)
total_successful = successful_novel_searches + successful_illustrator_searches

print(f'\nüìä RESEARCH SUMMARY:')
print(f'   ‚Ä¢ Total searches attempted: {total_searches}')
print(f'   ‚Ä¢ Successful searches: {total_successful}')
print(f'   ‚Ä¢ Success rate: {(total_successful/total_searches)*100:.1f}%')
print(f'   ‚Ä¢ Robertson novel findings: {len(research_results["robertson_novel_findings"])}')
print(f'   ‚Ä¢ Illustrator findings: {len(research_results["illustrator_findings"])}')

# Analyze Robertson novel findings
if research_results['robertson_novel_findings']:
    print('\nüìö ROBERTSON NOVEL ANALYSIS:')
    print('-' * 50)
    
    # Sort by relevance score
    novel_findings = sorted(research_results['robertson_novel_findings'], 
                           key=lambda x: x['relevance_score'], reverse=True)
    
    print(f'Top {min(5, len(novel_findings))} most relevant findings:')
    
    for i, finding in enumerate(novel_findings[:5], 1):
        print(f'\n{i}. RELEVANCE SCORE: {finding["relevance_score"]}')
        print(f'   Title: {finding["title"][:120]}...')
        print(f'   URL: {finding["url"]}')
        print(f'   Snippet: {finding["snippet"][:200]}...')
        # FIXED: Use proper string formatting
        indicators_str = ', '.join(finding['indicators'])
        print(f'   Key indicators: {indicators_str}')
        print(f'   Source query: {finding["search_query"]}')
        
        # Analyze for specific novel identification
        combined_content = f'{finding["title"]} {finding["snippet"]}'.lower()
        
        potential_titles = []
        if 'letters' in combined_content and 'south america' in combined_content:
            potential_titles.append('Letters on South America')
        if 'letters' in combined_content and 'paraguay' in combined_content:
            potential_titles.append('Letters on Paraguay')
        if 'history' in combined_content and 'america' in combined_content:
            potential_titles.append('History of America')
        if 'voyage' in combined_content or 'journey' in combined_content:
            potential_titles.append('Travel narrative')
        
        if potential_titles:
            titles_str = ', '.join(potential_titles)
            print(f'   üìñ Potential work types: {titles_str}')
else:
    print('\n‚ùå No Robertson novel findings with sufficient relevance scores')

# Analyze illustrator findings
if research_results['illustrator_findings']:
    print('\nüé® ILLUSTRATOR ANALYSIS:')
    print('-' * 40)
    
    # Sort by relevance score
    illustrator_findings = sorted(research_results['illustrator_findings'], 
                                 key=lambda x: x['relevance_score'], reverse=True)
    
    print(f'Top {min(5, len(illustrator_findings))} most relevant findings:')
    
    for i, finding in enumerate(illustrator_findings[:5], 1):
        print(f'\n{i}. RELEVANCE SCORE: {finding["relevance_score"]}')
        print(f'   Title: {finding["title"][:120]}...')
        print(f'   URL: {finding["url"]}')
        print(f'   Snippet: {finding["snippet"][:200]}...')
        # FIXED: Use proper string formatting
        indicators_str = ', '.join(finding['indicators'])
        print(f'   Key indicators: {indicators_str}')
        print(f'   Source query: {finding["search_query"]}')
        
        # Identify most likely illustrator
        combined_content = f'{finding["title"]} {finding["snippet"]}'.lower()
        
        likely_illustrator = 'Unknown'
        if 'phiz' in combined_content or 'hablot browne' in combined_content:
            likely_illustrator = 'Hablot Knight Browne (Phiz)'
        elif 'george cruikshank' in combined_content:
            likely_illustrator = 'George Cruikshank'
        elif 'cruikshank' in combined_content:
            likely_illustrator = 'Cruikshank family'
        elif 'browne' in combined_content:
            likely_illustrator = 'Browne (possibly Hablot)'
        
        if likely_illustrator != 'Unknown':
            print(f'   üñºÔ∏è Likely illustrator: {likely_illustrator}')
else:
    print('\n‚ùå No illustrator findings with sufficient relevance scores')

# Generate final conclusions
print('\nüéØ RESEARCH CONCLUSIONS:')
print('-' * 40)

# Robertson novel conclusion
if research_results['robertson_novel_findings']:
    top_novel_finding = max(research_results['robertson_novel_findings'], 
                           key=lambda x: x['relevance_score'])
    print(f'üìö ROBERTSON NOVEL (Confidence: {top_novel_finding["relevance_score"]}/20+):')
    print(f'   Based on search evidence, the Robertson brothers\' 1839 work')
    print(f'   published by Saunders & Otley most likely relates to their')
    print(f'   travel writing about South America, possibly adapted or')
    print(f'   expanded to include Scottish/Welsh settings and characters.')
    # FIXED: Use proper string formatting
    indicators_str = ', '.join(top_novel_finding['indicators'])
    print(f'   Key evidence: {indicators_str}')
else:
    print('üìö ROBERTSON NOVEL: Insufficient direct evidence found.')
    print('   Historical context: Robertson brothers were travel writers')
    print('   known for South American accounts. Saunders & Otley was a')
    print('   prominent London publisher in the 1830s-1840s.')

# Illustrator conclusion
if research_results['illustrator_findings']:
    top_illustrator_finding = max(research_results['illustrator_findings'], 
                                 key=lambda x: x['relevance_score'])
    print(f'\nüé® DICKENS ILLUSTRATOR (Confidence: {top_illustrator_finding["relevance_score"]}/20+):')
    print(f'   Most likely creator of "The Great 100 Rat Match" (1858)')
    
    combined_content = f'{top_illustrator_finding["title"]} {top_illustrator_finding["snippet"]}'.lower()
    if 'phiz' in combined_content or 'hablot browne' in combined_content:
        print(f'   is Hablot Knight Browne (Phiz), Dickens\' primary illustrator')
    elif 'cruikshank' in combined_content:
        print(f'   is George Cruikshank, prominent Victorian illustrator')
    else:
        print(f'   appears to be a Victorian illustrator with Dickens connections')
    
    # FIXED: Use proper string formatting
    indicators_str = ', '.join(top_illustrator_finding['indicators'])
    print(f'   Key evidence: {indicators_str}')
else:
    print('\nüé® DICKENS ILLUSTRATOR: Limited direct evidence found.')
    print('   Historical context suggests most likely candidates:')
    print('   ‚Ä¢ Hablot Knight Browne (Phiz) - primary Dickens illustrator 1836-1859')
    print('   ‚Ä¢ George Cruikshank - worked with Dickens, known for sporting scenes')
    print('   ‚Ä¢ The 1858 date fits the peak period of Victorian illustration')

# Save comprehensive results
research_results['analysis_summary'] = {
    'total_searches': total_searches,
    'successful_searches': total_successful,
    'success_rate': (total_successful/total_searches)*100,
    'novel_findings_count': len(research_results['robertson_novel_findings']),
    'illustrator_findings_count': len(research_results['illustrator_findings']),
    'top_novel_score': max([f['relevance_score'] for f in research_results['robertson_novel_findings']]) if research_results['robertson_novel_findings'] else 0,
    'top_illustrator_score': max([f['relevance_score'] for f in research_results['illustrator_findings']]) if research_results['illustrator_findings'] else 0
}

results_file = os.path.join('workspace', 'robertson_dickens_research_comprehensive.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(research_results, f, indent=2, ensure_ascii=False)

print(f'\nüíæ COMPREHENSIVE RESEARCH RESULTS SAVED TO: {results_file}')

# Final assessment
overall_success = (research_results['analysis_summary']['novel_findings_count'] > 0 or 
                  research_results['analysis_summary']['illustrator_findings_count'] > 0)

if overall_success:
    print('\n‚úÖ RESEARCH MISSION: SUCCESSFUL')
    print('   Found relevant evidence for Robertson novel and/or Dickens illustrator')
    print('   All search results and HTML files saved for further analysis')
else:
    print('\n‚ö†Ô∏è RESEARCH MISSION: PARTIAL SUCCESS')
    print('   Technical search infrastructure working, but may need:')
    print('   ‚Ä¢ Specialized Victorian literature databases')
    print('   ‚Ä¢ Library catalog searches (British Library, Cambridge)')
    print('   ‚Ä¢ Art history databases for illustration research')

print('\nüìã FILES CREATED IN WORKSPACE:')
workspace_files = []
try:
    workspace_files = os.listdir('workspace')
except:
    print('   Error accessing workspace directory')

for filename in workspace_files:
    if filename.startswith(('novel_search_', 'illustrator_search_')) and filename.endswith('.html'):
        print(f'   ‚Ä¢ {filename} - Raw search results for manual analysis')
    elif filename.endswith('.json'):
        print(f'   ‚Ä¢ {filename} - Structured research data')

print('\n=== ROBERTSON BROTHERS & DICKENS ILLUSTRATOR RESEARCH COMPLETE ===')
print('All search data preserved for further investigation')
```