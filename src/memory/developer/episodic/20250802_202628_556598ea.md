### Development Step 20: Search 2011 Bulgarian Census Data on Tertiary Education Completion by Gender

**Description**: Search for the 2011 Bulgarian census data on tertiary education completion by gender. Look for official census results from Bulgaria's National Statistical Institute or other authoritative sources that provide the specific breakdown of men and women who completed tertiary education in 2011.

**Use Cases**:
- Government policy analyst automates extraction of gender-disaggregated tertiary education figures from the 2011 Bulgarian census to update national education equity reports
- Academic researcher in comparative education studies uses the pipeline to mine Bulgarian NSI HTML tables and PDF documents for male vs. female university completion rates in 2011
- Data journalism team incorporates extracted Bulgarian 2011 tertiary education data into an interactive web dashboard visualizing regional gender disparities
- EdTech platform integrates automated parsing of Bulgarian census statistics to enrich its learner profiling engine with real-world education attainment metrics
- NGO working on womenâ€™s empowerment aggregates the 2011 gendered education statistics to support grant proposals and policy briefs
- Market intelligence firm feeds Bulgarian tertiary education by gender figures into demographic segmentation models for targeted product launches
- Data engineering team schedules this script to periodically scan NSI releases and update a centralized data lake for longitudinal education research

```
import os
import json
from bs4 import BeautifulSoup
import re

print("=== BULGARIAN 2011 CENSUS TERTIARY EDUCATION BY GENDER - FINAL EXTRACTION ===")
print("Strategy: Thorough analysis with explicit variable definitions\n")

# Check workspace
workspace_path = 'workspace'
if not os.path.exists(workspace_path):
    print("No workspace directory found")
    exit()

all_files = os.listdir(workspace_path)
print(f"Total files in workspace: {len(all_files)}")

# Categorize files explicitly
html_files = []
json_files = []
pdf_files = []
xls_files = []

for file in all_files:
    if file.endswith('.html'):
        html_files.append(file)
    elif file.endswith('.json'):
        json_files.append(file)
    elif file.endswith('.pdf'):
        pdf_files.append(file)
    elif file.endswith('.xls'):
        xls_files.append(file)

print(f"HTML files: {len(html_files)}")
print(f"JSON files: {len(json_files)}")
print(f"PDF files: {len(pdf_files)}")
print(f"Excel files: {len(xls_files)}")

# Examine existing analysis files first
print("\n=== EXAMINING EXISTING ANALYSIS FILES ===")
for json_file in json_files:
    if 'analysis' in json_file.lower() or 'results' in json_file.lower():
        print(f"\nInspecting: {json_file}")
        filepath = os.path.join(workspace_path, json_file)
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"  Keys: {list(data.keys())[:10]}")
            
            # Look for detailed findings
            if 'detailed_findings' in data:
                findings = data['detailed_findings']
                print(f"  Detailed findings: {len(findings)} files analyzed")
                
                for finding in findings:
                    print(f"    - {finding.get('filename', 'Unknown')}: {finding.get('relevance_score', 0)} relevance")
                    if finding.get('good_sentences'):
                        print(f"      Sentences: {len(finding['good_sentences'])}")
                    if finding.get('statistical_matches'):
                        print(f"      Statistical matches: {len(finding['statistical_matches'])}")
                    if finding.get('education_tables'):
                        print(f"      Education tables: {len(finding['education_tables'])}")
            
            # Look for specific census data
            if 'tertiary_education_findings' in data:
                findings = data['tertiary_education_findings']
                print(f"  Tertiary education findings: {len(findings)}")
                for finding in findings[:3]:
                    print(f"    Match: {finding.get('match', 'No match')}")
                    print(f"    Context: {finding.get('context', 'No context')[:100]}...")
        
        except Exception as e:
            print(f"  Error reading {json_file}: {str(e)}")

# Identify priority HTML files using explicit loops
print("\n=== ANALYZING MOST PROMISING HTML SOURCES ===")

priority_files = []
for html_file in html_files:
    filepath = os.path.join(workspace_path, html_file)
    file_size = os.path.getsize(filepath)
    
    # Skip very small files
    if file_size < 10000:
        continue
    
    # Check filename for relevant terms
    filename_lower = html_file.lower()
    is_nsi = 'nsi' in filename_lower
    is_census = 'census' in filename_lower
    is_demographics = 'demographics' in filename_lower
    is_education = 'education' in filename_lower
    
    if is_nsi or is_census or is_demographics or is_education:
        priority_files.append((html_file, file_size))

# Sort by file size (larger files likely have more content)
priority_files.sort(key=lambda x: x[1], reverse=True)

print(f"Priority files identified: {len(priority_files)}")
for filename, size in priority_files[:5]:
    print(f"  - {filename}: {size:,} bytes")

# Analyze the top priority files for specific tertiary education data
tertiary_education_data = []

files_to_analyze = priority_files[:3]  # Analyze top 3

for filename, size in files_to_analyze:
    print(f"\n=== ANALYZING: {filename} ===")
    filepath = os.path.join(workspace_path, filename)
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        page_title = soup.find('title')
        title_text = page_title.get_text().strip() if page_title else 'No title'
        
        print(f"Title: {title_text}")
        print(f"Content length: {len(html_content):,} characters")
        
        # Extract all text for analysis
        all_text = soup.get_text()
        
        # Search for specific patterns related to tertiary education and gender in 2011
        patterns_to_search = [
            # Pattern 1: Direct tertiary education statistics
            r'tertiary education[^.]{0,200}(?:men|women|male|female)[^.]{0,100}(\d+[.,]?\d*\s*%?)',
            # Pattern 2: Gender followed by tertiary education
            r'(?:men|women|male|female)[^.]{0,200}tertiary education[^.]{0,100}(\d+[.,]?\d*\s*%?)',
            # Pattern 3: Higher education statistics
            r'higher education[^.]{0,200}(?:men|women|male|female)[^.]{0,100}(\d+[.,]?\d*\s*%?)',
            # Pattern 4: 2011 census education data
            r'2011[^.]{0,300}(?:tertiary|higher)[^.]{0,200}(?:men|women|male|female)[^.]{0,100}(\d+[.,]?\d*\s*%?)',
            # Pattern 5: University completion by gender
            r'university[^.]{0,200}(?:completed|graduated|attained)[^.]{0,200}(?:men|women|male|female)[^.]{0,100}(\d+[.,]?\d*\s*%?)',
            # Pattern 6: Educational attainment statistics
            r'educational attainment[^.]{0,200}(?:men|women|male|female)[^.]{0,100}(\d+[.,]?\d*\s*%?)'
        ]
        
        matches_found = []
        for i, pattern in enumerate(patterns_to_search, 1):
            matches = list(re.finditer(pattern, all_text, re.IGNORECASE | re.DOTALL))
            print(f"  Pattern {i} matches: {len(matches)}")
            
            for match in matches:
                # Get broader context around the match
                context_start = max(0, match.start() - 400)
                context_end = min(len(all_text), match.end() + 400)
                context = all_text[context_start:context_end]
                
                # Check if context mentions Bulgaria and 2011
                context_lower = context.lower()
                has_bulgaria = 'bulgaria' in context_lower or 'bulgarian' in context_lower
                has_2011 = '2011' in context_lower
                
                if has_bulgaria or has_2011:
                    matches_found.append({
                        'pattern_number': i,
                        'match_text': match.group(),
                        'context': context,
                        'has_bulgaria': has_bulgaria,
                        'has_2011': has_2011,
                        'file': filename
                    })
        
        print(f"  Relevant matches found: {len(matches_found)}")
        
        # Display the most relevant matches
        if matches_found:
            print("  \n  TOP MATCHES:")
            for i, match in enumerate(matches_found[:3], 1):
                print(f"    {i}. Pattern {match['pattern_number']}: {match['match_text']}")
                print(f"       Bulgaria: {match['has_bulgaria']}, 2011: {match['has_2011']}")
                print(f"       Context: {match['context'][:200]}...")
                print()
        
        tertiary_education_data.extend(matches_found)
        
        # Also look for tables with structured data
        tables = soup.find_all('table')
        relevant_tables = []
        
        for table_idx, table in enumerate(tables):
            table_text = table.get_text()
            table_lower = table_text.lower()
            
            # Check if table contains education and gender data
            education_terms = ['education', 'tertiary', 'university', 'degree', 'higher']
            gender_terms = ['men', 'women', 'male', 'female', 'gender']
            
            has_education_terms = False
            for term in education_terms:
                if term in table_lower:
                    has_education_terms = True
                    break
            
            has_gender_terms = False
            for term in gender_terms:
                if term in table_lower:
                    has_gender_terms = True
                    break
            
            has_2011_data = '2011' in table_lower
            has_numbers = bool(re.search(r'\d+', table_text))
            
            if has_education_terms and has_gender_terms and has_numbers:
                # Extract table structure
                headers = []
                for th in table.find_all('th'):
                    headers.append(th.get_text().strip())
                
                rows = table.find_all('tr')
                
                # Get sample data rows
                sample_rows = []
                for row in rows[1:4]:  # Skip header, take next 3
                    cells = []
                    for cell in row.find_all(['td', 'th']):
                        cells.append(cell.get_text().strip())
                    if cells:
                        has_content = False
                        for cell in cells:
                            if cell.strip():
                                has_content = True
                                break
                        if has_content:
                            sample_rows.append(cells)
                
                relevant_tables.append({
                    'table_index': table_idx,
                    'headers': headers,
                    'sample_rows': sample_rows,
                    'total_rows': len(rows),
                    'has_2011': has_2011_data
                })
        
        if relevant_tables:
            print(f"  \n  RELEVANT TABLES FOUND: {len(relevant_tables)}")
            for i, table in enumerate(relevant_tables[:2], 1):
                print(f"    Table {i}:")
                print(f"      Headers: {table['headers'][:5]}")
                print(f"      Rows: {table['total_rows']}, Has 2011: {table['has_2011']}")
                if table['sample_rows']:
                    print(f"      Sample row: {table['sample_rows'][0][:3]}")
    
    except Exception as e:
        print(f"  Error analyzing {filename}: {str(e)}")

# Compile final results
print(f"\n=== FINAL COMPILATION ===")
print(f"Total tertiary education matches found: {len(tertiary_education_data)}")

# Save comprehensive results
final_results = {
    'objective': 'Bulgarian 2011 census tertiary education completion by gender',
    'analysis_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'files_analyzed': len(files_to_analyze),
    'total_matches_found': len(tertiary_education_data),
    'detailed_matches': tertiary_education_data,
    'summary': {
        'files_with_matches': len(set(match['file'] for match in tertiary_education_data)) if tertiary_education_data else 0,
        'matches_with_bulgaria': len([m for m in tertiary_education_data if m['has_bulgaria']]),
        'matches_with_2011': len([m for m in tertiary_education_data if m['has_2011']])
    }
}

results_file = os.path.join(workspace_path, 'bulgarian_census_tertiary_education_final_extraction.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(final_results, f, indent=2, ensure_ascii=False)

print(f"Results saved to: {results_file}")

# Display key findings
if tertiary_education_data:
    print("\n=== KEY FINDINGS ===")
    
    # Group by relevance (Bulgaria + 2011)
    high_relevance = []
    medium_relevance = []
    
    for m in tertiary_education_data:
        if m['has_bulgaria'] and m['has_2011']:
            high_relevance.append(m)
        elif m['has_bulgaria'] or m['has_2011']:
            medium_relevance.append(m)
    
    print(f"High relevance matches (Bulgaria + 2011): {len(high_relevance)}")
    print(f"Medium relevance matches (Bulgaria or 2011): {len(medium_relevance)}")
    
    # Show the best matches
    best_matches = high_relevance if high_relevance else medium_relevance
    
    for i, match in enumerate(best_matches[:5], 1):
        print(f"\n{i}. File: {match['file']}")
        print(f"   Pattern: {match['pattern_number']}")
        print(f"   Match: {match['match_text']}")
        print(f"   Context: {match['context'][:300]}...")
        print(f"   Bulgaria: {match['has_bulgaria']}, 2011: {match['has_2011']}")

else:
    print("\n=== NO SPECIFIC MATCHES FOUND ===")
    print("No specific tertiary education by gender statistics found in the analyzed files.")
    print("The data may be in a different format or require access to the actual statistical tables.")
    
    # Let's examine what content we do have
    print("\n=== EXAMINING AVAILABLE CONTENT ===")
    
    # Look at the most promising file in detail
    if priority_files:
        top_file, _ = priority_files[0]
        print(f"Examining top file: {top_file}")
        
        filepath = os.path.join(workspace_path, top_file)
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            soup = BeautifulSoup(content, 'html.parser')
            text = soup.get_text()
            
            # Look for any education-related content
            education_sentences = []
            sentences = text.split('.')
            
            for sentence in sentences:
                sentence_clean = sentence.strip()
                if len(sentence_clean) > 50:
                    sentence_lower = sentence_clean.lower()
                    if ('education' in sentence_lower and 
                        ('bulgaria' in sentence_lower or '2011' in sentence_lower) and
                        re.search(r'\d+', sentence_clean)):
                        education_sentences.append(sentence_clean)
            
            print(f"Education-related sentences found: {len(education_sentences)}")
            for i, sentence in enumerate(education_sentences[:3], 1):
                print(f"  {i}. {sentence[:200]}...")
        
        except Exception as e:
            print(f"Error examining {top_file}: {str(e)}")

print("\n=== EXTRACTION COMPLETE ===")
print("Comprehensive analysis of Bulgarian 2011 census tertiary education data completed.")
```