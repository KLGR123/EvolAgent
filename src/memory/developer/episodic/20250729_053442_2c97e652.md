### Development Step 4: 2022 Legume Wikipedia Logs: Identifying Content Violations and the ‘R’ in Three Core Policies

**Description**: Search for information about the Legume Wikipedia page and identify what content violations occurred in its public logs during 2022 before December. Focus on finding the specific type of content that was violated and the associated three core policies, particularly identifying what 'R' stands for in those policies.

**Use Cases**:
- NGO compliance team auditing Wikipedia edit logs on agricultural topics to flag defamatory or biased content violations before December 2022
- Academic research group analyzing policy breach patterns on the Legume page to study misinformation and content removal trends in 2022
- Fact-checking organization monitoring public edit histories to detect undisclosed conflicts of interest and R-category violations on nutrition-related entries
- Government regulatory body reviewing political neutrality policy compliance in public logs of food and nutrition Wikipedia pages for year-end reporting
- Data journalism team extracting and visualizing the types of content violations and associated core policies from 2022 edit histories for an investigative feature
- Enterprise knowledge management department automating the detection of policy-violating edits in internal wiki logs using a similar analysis pipeline
- Machine learning engineers collecting R-policy labeled examples from public edit logs to train a classifier for automated violation detection

```
import os
import json

print("=== INSPECTING SAVED ANALYSIS FILE ===\n")
print("Objective: Review the detailed analysis results to understand what content was found\n")

# Locate the workspace directory
workspace_dirs = [d for d in os.listdir('.') if d.startswith('workspace')]
if not workspace_dirs:
    print("No workspace directory found.")
    exit()

workspace_dir = workspace_dirs[0]
print(f"Using workspace directory: {workspace_dir}")

# Check for the analysis file
analysis_file = f'{workspace_dir}/legume_violation_analysis.json'
if not os.path.exists(analysis_file):
    print(f"Analysis file not found: {analysis_file}")
    exit()

print(f"Analysis file found: {analysis_file}")
file_size = os.path.getsize(analysis_file)
print(f"File size: {file_size:,} bytes\n")

# Inspect the JSON structure first
with open(analysis_file, 'r') as f:
    analysis_data = json.load(f)

print("=== JSON FILE STRUCTURE ===\n")
print("Top-level keys:")
for key, value in analysis_data.items():
    if isinstance(value, dict):
        print(f"  {key}: Dictionary with {len(value)} keys")
        # Show nested keys
        for nested_key, nested_value in value.items():
            if isinstance(nested_value, list):
                print(f"    {nested_key}: List with {len(nested_value)} items")
            elif isinstance(nested_value, dict):
                print(f"    {nested_key}: Dictionary with {len(nested_value)} keys")
            else:
                print(f"    {nested_key}: {nested_value}")
    elif isinstance(value, list):
        print(f"  {key}: List with {len(value)} items")
    else:
        print(f"  {key}: {value}")

print("\n=== EXAMINING DETAILED FINDINGS ===\n")

if 'detailed_findings' in analysis_data:
    findings = analysis_data['detailed_findings']
    
    for source_name, source_data in findings.items():
        print(f"--- {source_name.upper()} RESULTS ---")
        
        # Check 2022 content
        if '2022_content' in source_data:
            content_2022 = source_data['2022_content']
            print(f"2022 content entries: {len(content_2022)}")
            
            if content_2022:
                print("Sample 2022 content (first 3 entries):")
                for i, entry in enumerate(content_2022[:3], 1):
                    print(f"  {i}. Line {entry['line_index']}:")
                    print(f"     Content: {entry['content'][:150]}...")
                    print(f"     Policy-related: {entry['has_policy_content']}")
                    print(f"     Before December: {entry['before_december']}")
                    if 'context' in entry and entry['context']:
                        context_preview = ' '.join(entry['context'])[:200]
                        print(f"     Context preview: {context_preview}...")
                    print()
        
        # Check policy matches
        if 'policy_matches' in source_data:
            policy_matches = source_data['policy_matches']
            print(f"Policy matches: {len(policy_matches)}")
            
            if policy_matches:
                print("Sample policy matches (first 2):")
                for i, match in enumerate(policy_matches[:2], 1):
                    print(f"  {i}. Pattern: {match['pattern']}")
                    print(f"     Match: {match['match']}")
                    print(f"     Context: {match['context'][:200]}...")
                    print()
        
        # Check R matches
        if 'r_matches' in source_data:
            r_matches = source_data['r_matches']
            print(f"R matches: {len(r_matches)}")
            
            if r_matches:
                print("Sample R matches (first 2):")
                for i, match in enumerate(r_matches[:2], 1):
                    print(f"  {i}. Pattern: {match['pattern']}")
                    print(f"     Match: {match['match']}")
                    print(f"     Context: {match['context'][:200]}...")
                    print()
        
        print()

print("=== ANALYSIS FILE INSPECTION COMPLETE ===\n")
print("Based on the inspection, I can now determine if:")
print("1. The search patterns need refinement")
print("2. The data contains hidden violation information")
print("3. Alternative search methods are needed")
print("\nNext: Refine search strategy based on actual content found")
```