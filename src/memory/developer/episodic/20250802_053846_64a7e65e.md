### Development Step 19: Download University of Leicester Dragon Diet Fish Supply Research Paper

**Description**: Conduct a web search for the University of Leicester paper titled "Can Hiccup Supply Enough Fish to Maintain a Dragon’s Diet?" and download the full PDF of that paper into workspace/dragon_diet_fish_bag.pdf.

**Use Cases**:
- Research consortium automating retrieval of environmental impact assessment PDFs from government portals for comparative analysis
- Pharmaceutical R&D team collecting clinical trial protocols published on university domains to inform study designs
- Legal department scanning court websites and downloading recent case judgments in PDF for compliance monitoring
- Financial analysts aggregating quarterly earnings reports from public company investor relations sites into a centralized workspace
- University librarians ingesting newly published theses and dissertations in PDF format into the institutional repository
- Data journalists scraping city planning PDFs from municipal websites to extract zoning changes and urban development data
- Patent researchers bulk-downloading patent specification PDFs from official patent office domains for prior art searches
- Marketing intelligence teams gathering competitor whitepapers and technical briefs from corporate subdomains for product strategy

```
import os
import sys
import re
import requests

# Step 1: Ensure workspace directory exists
workspace = 'workspace'
if not os.path.isdir(workspace):
    print(f"ERROR: Workspace directory '{workspace}' does not exist.")
    sys.exit(1)
print(f"[INFO] Using workspace: {workspace}\n")

# Step 2: Perform a live Bing search for the target paper PDF on le.ac.uk
search_url = 'https://www.bing.com/search'
query = 'site:le.ac.uk "Can Hiccup Supply Enough Fish to Maintain a Dragon’s Diet?" filetype:pdf'
params = {'q': query}
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                  'AppleWebKit/537.36 (KHTML, like Gecko) '
                  'Chrome/91.0.4472.124 Safari/537.36',
    'Accept-Language': 'en-US,en;q=0.9',
    'Accept': 'text/html'
}
print(f"[SEARCH] Querying Bing: {query}")
try:
    resp = requests.get(search_url, params=params, headers=headers, timeout=30)
    resp.raise_for_status()
    html = resp.text
    print(f"[SEARCH] Received {len(html)} characters of HTML from Bing.")
except Exception as e:
    print(f"ERROR: Failed to fetch Bing search results: {e}")
    sys.exit(1)

# Step 3: Extract all .pdf URLs from the HTML
print("[PARSE] Extracting .pdf links from search results...")
all_pdfs = re.findall(r'https?://[^\s'\"]+\.pdf', html)
print(f"[PARSE] Found {len(all_pdfs)} total .pdf URLs in the HTML.")

# Step 4: Filter for le.ac.uk domain
leicester_pdfs = []
for link in set(all_pdfs):
    if 'le.ac.uk' in link.lower():
        print(f"  [MATCH] le.ac.uk PDF link: {link}")
        leicester_pdfs.append(link)

if not leicester_pdfs:
    print("ERROR: No .pdf links on le.ac.uk found in Bing results.")
    print("Please verify that the paper is hosted on le.ac.uk or adjust the query.")
    sys.exit(1)

# Step 5: Download the first matching PDF
pdf_url = leicester_pdfs[0]
pdf_path = os.path.join(workspace, 'dragon_diet_fish_bag.pdf')
print(f"[DOWNLOAD] Downloading PDF from: {pdf_url}")
try:
    rpdf = requests.get(pdf_url, headers=headers, stream=True, timeout=60)
    rpdf.raise_for_status()
    with open(pdf_path, 'wb') as f:
        for chunk in rpdf.iter_content(chunk_size=8192):
            if chunk:
                f.write(chunk)
    size = os.path.getsize(pdf_path)
    print(f"[SUCCESS] Saved PDF to: {pdf_path}")
    print(f"[INFO] File size: {size} bytes ({size/1024:.2f} KB)")
    if size < 10 * 1024:
        print("WARNING: PDF file is smaller than 10 KB. It may not be the correct paper.")
        sys.exit(1)
    print("[COMPLETE] PDF download appears successful and exceeds size threshold.")
except Exception as e:
    print(f"ERROR: Failed to download PDF: {e}")
    if os.path.exists(pdf_path):
        os.remove(pdf_path)
    sys.exit(1)
```