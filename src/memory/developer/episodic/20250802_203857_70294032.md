### Development Step 44: 2011 Bulgarian Census: Tertiary Education Completion Numbers by Gender

**Description**: Search for the official 2011 Bulgarian census data from the Bulgarian National Statistical Institute (NSI) or other authoritative government sources that specifically contain the tertiary education completion numbers by gender. Focus on finding the exact counts or percentages of men and women who completed tertiary education according to the 2011 census results.

**Use Cases**:
- Government labor ministry automation for extracting male and female tertiary education completion by region to allocate funding for vocational retraining programs in provinces with low university graduation rates
- University admissions office analytics pipeline to compare historical tertiary enrollment and completion by gender across Bulgarian provinces and tailor outreach programs for underrepresented student groups
- NGO gender equality policy report generation using extracted census tables to quantify progress in women’s tertiary education attainment and support scholarship advocacy campaigns
- Market research firm compilation of regional gender breakdowns of university graduates to inform an ed-tech startup’s targeted course offerings for urban female and male professionals
- Data journalist interactive dashboard development by quickly locating official PDF and Excel census data on tertiary education by gender for visualizing higher education gaps in news articles
- Economic research group integration of male/female tertiary degree completion statistics into macroeconomic models correlating educational attainment with wage growth by gender
- HR compliance team benchmarking local talent acquisition against national tertiary graduate demographics to ensure equitable recruitment practices in multinational corporations
- Demographic analytics startup public API creation by automating retrieval and parsing of 2011 gender-disaggregated tertiary education data for developers building mapping and trend-analysis applications

```
import os
import json
from bs4 import BeautifulSoup
import re
import time

workspace_dir = 'workspace'

print("=== PARSING NSI CENSUS FILES FOR 2011 BULGARIAN TERTIARY EDUCATION DATA BY GENDER ===")
print("\nObjective: Extract official 2011 Bulgarian census tertiary education completion statistics by gender\n")

# First, inspect workspace files to understand what we have
print("--- Inspecting Workspace Files ---")
if os.path.exists(workspace_dir):
    all_files = os.listdir(workspace_dir)
    print(f"Total files in workspace: {len(all_files)}")
    
    # Look for NSI census source files
    nsi_files = [f for f in all_files if f.startswith('nsi_census_source_') and f.endswith('.html')]
    print(f"\nNSI census HTML files found: {len(nsi_files)}")
    for f in sorted(nsi_files):
        filepath = os.path.join(workspace_dir, f)
        file_size = os.path.getsize(filepath)
        print(f"  - {f} ({file_size:,} bytes)")
else:
    print("Workspace directory not found!")
    exit(1)

if not nsi_files:
    print("No NSI census files found. Cannot proceed with analysis.")
    exit(1)

print(f"\n=== PHASE 1: SYSTEMATIC ANALYSIS OF NSI CENSUS FILES ===\n")

analysis_results = []

for filename in sorted(nsi_files):
    print(f"--- Analyzing: {filename} ---")
    
    filepath = os.path.join(workspace_dir, filename)
    with open(filepath, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    print(f"File size: {len(html_content):,} characters")
    
    # Parse with BeautifulSoup
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # Get page title
    title = soup.find('title')
    page_title = title.get_text().strip() if title else 'No title found'
    print(f"Page title: {page_title}")
    
    # Get all text content for analysis
    content_text = soup.get_text()
    content_lower = content_text.lower()
    
    # Count key terms related to our search
    education_indicators = {
        'tertiary': content_lower.count('tertiary'),
        'higher_education': content_lower.count('higher education'),
        'university': content_lower.count('university'),
        'education': content_lower.count('education'),
        'degree': content_lower.count('degree'),
        'educational_attainment': content_lower.count('educational attainment')
    }
    
    gender_indicators = {
        'male': content_lower.count('male'),
        'female': content_lower.count('female'),
        'men': content_lower.count('men'),
        'women': content_lower.count('women'),
        'gender': content_lower.count('gender'),
        'by_sex': content_lower.count('by sex')
    }
    
    census_indicators = {
        '2011': content_lower.count('2011'),
        'census': content_lower.count('census'),
        'population': content_lower.count('population'),
        'statistics': content_lower.count('statistics')
    }
    
    print(f"Education indicators: {education_indicators}")
    print(f"Gender indicators: {gender_indicators}")
    print(f"Census indicators: {census_indicators}")
    
    # Find all tables
    tables = soup.find_all('table')
    print(f"Tables found: {len(tables)}")
    
    # Analyze tables for relevant content - COMPLETELY RESTRUCTURE TO AVOID SCOPING ISSUES
    relevant_tables = []
    
    # Process each table individually to avoid variable scoping issues
    for i, table in enumerate(tables):
        # Extract table text at the very beginning
        current_table_text = table.get_text().lower()
        
        # Check content flags
        education_flag = False
        gender_flag = False
        census_flag = False
        numbers_flag = False
        
        # Check for education terms
        education_terms = ['education', 'tertiary', 'university', 'degree', 'higher']
        for term in education_terms:
            if term in current_table_text:
                education_flag = True
                break
        
        # Check for gender terms
        gender_terms = ['male', 'female', 'men', 'women', 'gender', 'sex']
        for term in gender_terms:
            if term in current_table_text:
                gender_flag = True
                break
        
        # Check for census terms
        if '2011' in current_table_text or 'census' in current_table_text:
            census_flag = True
        
        # Check for numbers
        if re.search(r'\d+[,.]?\d*\s*%?', current_table_text):
            numbers_flag = True
        
        print(f"  Table {i}: Education={education_flag}, Gender={gender_flag}, Census={census_flag}, Numbers={numbers_flag}")
        
        # If table has any relevant content, analyze further
        if education_flag or gender_flag or census_flag:
            # Extract table headers for analysis
            headers_list = []
            header_cells = table.find_all(['th', 'td'])[:15]  # First 15 cells as potential headers
            for cell in header_cells:
                cell_text = cell.get_text().strip()
                if cell_text and len(cell_text) < 100:  # Reasonable header length
                    headers_list.append(cell_text)
            
            # Get a sample of the table content
            table_sample = current_table_text[:300] if len(current_table_text) > 300 else current_table_text
            
            relevant_tables.append({
                'table_index': i,
                'has_education': education_flag,
                'has_gender': gender_flag,
                'has_census': census_flag,
                'has_numbers': numbers_flag,
                'headers': headers_list[:8],  # First 8 headers
                'table_text_sample': table_sample
            })
            
            print(f"    Headers: {headers_list[:5]}")  # Show first 5 headers
            print(f"    Sample: {table_sample[:150]}...")
    
    if relevant_tables:
        print(f"\nRelevant tables found: {len(relevant_tables)}")
    else:
        print("\nNo relevant tables found in this file")
    
    # Look for downloadable files - PROPER VARIABLE DEFINITION
    download_links = []
    all_links = soup.find_all('a', href=True)
    print(f"\nTotal links found: {len(all_links)}")
    
    for link in all_links:
        # PROPERLY DEFINE VARIABLES FIRST
        link_href = link.get('href', '')
        link_text = link.get_text().strip()
        
        # Check for data file extensions or relevant content
        is_data_file = any(ext in link_href.lower() for ext in ['.xls', '.xlsx', '.pdf', '.csv', '.doc', '.docx'])
        is_relevant_text = any(term in link_text.lower() for term in ['education', 'census', '2011', 'data', 'table', 'statistics', 'demographic'])
        
        if is_data_file or is_relevant_text:
            # Construct full URL
            if link_href.startswith('http'):
                full_url = link_href
            elif link_href.startswith('/'):
                full_url = f"https://www.nsi.bg{link_href}"
            else:
                full_url = f"https://www.nsi.bg/en/{link_href}"
            
            download_links.append({
                'text': link_text,
                'href': link_href,
                'full_url': full_url,
                'is_data_file': is_data_file,
                'is_relevant_text': is_relevant_text
            })
    
    print(f"Relevant download links found: {len(download_links)}")
    if download_links:
        print("Top download links:")
        for i, link in enumerate(download_links[:5], 1):
            print(f"  {i}. '{link['text']}'")
            print(f"     URL: {link['full_url']}")
            print(f"     Data file: {link['is_data_file']}, Relevant: {link['is_relevant_text']}")
    
    # Search for specific education content patterns
    education_content_matches = []
    
    # Patterns to find tertiary education by gender
    search_patterns = [
        r'tertiary education.*?(?:male|female|men|women|gender|sex)',
        r'higher education.*?(?:male|female|men|women|gender|sex)',
        r'university.*?(?:male|female|men|women|gender|sex)',
        r'(?:male|female|men|women).*?tertiary',
        r'(?:male|female|men|women).*?higher education',
        r'education.*?by.*?(?:gender|sex)',
        r'2011.*?census.*?education',
        r'educational attainment.*?(?:male|female)',
        r'completed.*?tertiary.*?education',
        r'bachelor.*?degree.*?(?:male|female)',
        r'university.*?graduate.*?(?:male|female)',
        r'\d+[,.]?\d*\s*%.*?(?:tertiary|higher education).*?(?:male|female)',
        r'(?:male|female).*?\d+[,.]?\d*\s*%.*?(?:tertiary|higher education)'
    ]
    
    for pattern in search_patterns:
        matches = re.findall(pattern, content_text, re.IGNORECASE | re.DOTALL)
        for match in matches[:3]:  # Limit to 3 matches per pattern
            clean_match = re.sub(r'\s+', ' ', match.strip())[:300]  # Clean and limit length
            if clean_match and clean_match not in education_content_matches:  # Avoid duplicates
                education_content_matches.append(clean_match)
    
    if education_content_matches:
        print(f"\nEducation content matches found: {len(education_content_matches)}")
        for i, match in enumerate(education_content_matches[:3], 1):
            print(f"  {i}. {match[:150]}...")
    
    # Calculate relevance score
    relevance_score = (
        sum(education_indicators.values()) * 3 +
        sum(gender_indicators.values()) * 2 +
        sum(census_indicators.values()) * 2 +
        len(relevant_tables) * 15 +
        len(education_content_matches) * 10 +
        len(download_links) * 5
    )
    
    print(f"\nRelevance score for {filename}: {relevance_score}")
    
    if relevance_score > 100:
        print("*** VERY HIGH PRIORITY - LIKELY CONTAINS TARGET DATA ***")
    elif relevance_score > 50:
        print("** HIGH PRIORITY - GOOD POTENTIAL FOR DATA **")
    elif relevance_score > 20:
        print("* MODERATE PRIORITY *")
    else:
        print("Low priority for tertiary education data")
    
    # Store analysis results
    analysis_results.append({
        'filename': filename,
        'page_title': page_title,
        'file_size': len(html_content),
        'education_indicators': education_indicators,
        'gender_indicators': gender_indicators,
        'census_indicators': census_indicators,
        'tables_count': len(tables),
        'relevant_tables': relevant_tables,
        'download_links': download_links,
        'education_content_matches': education_content_matches,
        'relevance_score': relevance_score
    })
    
    print("\n" + "="*60 + "\n")

# Sort by relevance score
analysis_results.sort(key=lambda x: x['relevance_score'], reverse=True)

print(f"=== ANALYSIS SUMMARY ===\n")
print(f"Files analyzed: {len(analysis_results)}")

if analysis_results:
    print("\nFiles ranked by relevance to tertiary education by gender:")
    for i, result in enumerate(analysis_results, 1):
        print(f"\n{i}. {result['filename']} (Score: {result['relevance_score']})")
        print(f"   Title: {result['page_title']}")
        print(f"   Size: {result['file_size']:,} characters")
        print(f"   Tables: {result['tables_count']}, Relevant: {len(result['relevant_tables'])}")
        print(f"   Download links: {len(result['download_links'])}")
        print(f"   Education matches: {len(result['education_content_matches'])}")
        
        # Show key indicators for high-scoring files
        if result['relevance_score'] > 30:
            print(f"   Education indicators: {result['education_indicators']}")
            print(f"   Gender indicators: {result['gender_indicators']}")
            print(f"   Census indicators: {result['census_indicators']}")
        
        # Show top download links for files with good potential
        if result['download_links'] and result['relevance_score'] > 30:
            print(f"   Top download links:")
            for j, link in enumerate(result['download_links'][:3], 1):
                print(f"     {j}. '{link['text']}'")
                print(f"        {link['full_url']}")
                if link['is_data_file']:
                    print(f"        *** DATA FILE - HIGH PRIORITY ***")

# Save comprehensive analysis
final_analysis = {
    'objective': '2011 Bulgarian Census - Tertiary Education by Gender Analysis',
    'analysis_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'files_analyzed': len(analysis_results),
    'analysis_results': analysis_results,
    'summary': {
        'very_high_priority': len([r for r in analysis_results if r['relevance_score'] > 100]),
        'high_priority': len([r for r in analysis_results if 50 < r['relevance_score'] <= 100]),
        'moderate_priority': len([r for r in analysis_results if 20 < r['relevance_score'] <= 50]),
        'low_priority': len([r for r in analysis_results if r['relevance_score'] <= 20])
    },
    'next_steps': [
        'Access highest-priority download links for detailed census data',
        'Parse relevant tables for specific tertiary education statistics',
        'Extract male/female tertiary education completion numbers',
        'Verify data is from official 2011 Bulgarian census'
    ]
}

final_analysis_file = os.path.join(workspace_dir, 'nsi_census_tertiary_education_final_analysis.json')
with open(final_analysis_file, 'w', encoding='utf-8') as f:
    json.dump(final_analysis, f, indent=2, ensure_ascii=False)

print(f"\n=== COMPREHENSIVE ANALYSIS COMPLETE ===\n")
print(f"Analysis results saved to: {final_analysis_file}")

if analysis_results:
    top_result = analysis_results[0]
    print(f"\nHighest priority file: {top_result['filename']} (Score: {top_result['relevance_score']})")
    print(f"Title: {top_result['page_title']}")
    print(f"Contains {len(top_result['relevant_tables'])} relevant tables and {len(top_result['download_links'])} download links")
    
    if top_result['education_content_matches']:
        print(f"\nMost promising education content from top file:")
        for i, match in enumerate(top_result['education_content_matches'][:3], 1):
            print(f"  {i}. {match[:200]}...")
    
    if top_result['download_links']:
        print(f"\nMost promising download links from top file:")
        for i, link in enumerate(top_result['download_links'][:5], 1):
            print(f"  {i}. '{link['text']}'")
            print(f"     {link['full_url']}")
            if link['is_data_file']:
                print(f"     *** DATA FILE - HIGH PRIORITY FOR DOWNLOAD ***")
    
    print(f"\nReady to extract specific tertiary education completion data by gender from the highest-priority sources.")
    
    # Show the most promising files for next steps
    high_priority_files = [r for r in analysis_results if r['relevance_score'] > 30]
    if high_priority_files:
        print(f"\n=== NEXT STEPS RECOMMENDATIONS ===\n")
        print(f"Files with good potential for tertiary education data: {len(high_priority_files)}")
        for result in high_priority_files:
            print(f"\n- {result['filename']} (Score: {result['relevance_score']})")
            if result['download_links']:
                data_files = [link for link in result['download_links'] if link['is_data_file']]
                if data_files:
                    print(f"  Contains {len(data_files)} downloadable data files")
                    for df in data_files[:2]:
                        print(f"    - {df['text']}: {df['full_url']}")
else:
    print("\nNo analysis results generated. Check file availability and content.")
```