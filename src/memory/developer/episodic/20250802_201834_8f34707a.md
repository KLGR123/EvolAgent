### Development Step 2: 2011 Bulgarian Census Tertiary Education Completion by Gender

**Description**: Search for the 2011 Bulgarian census data on tertiary education completion by gender. Look for official census results from Bulgaria's National Statistical Institute or other authoritative sources that provide the specific breakdown of men and women who completed tertiary education in 2011.

**Use Cases**:
- Government policy analysis and funding allocation by gender: automatically retrieve and compare 2011 Bulgarian tertiary education completion rates for men and women to inform regional education budgets and targeted scholarship programs.
- Academic demographic research and publication support: extract and preprocess census tables, sentences, and statistics on higher education by gender to conduct in-depth studies on gender parity and publish findings in scholarly journals.
- NGO program design for educational equity: gather granular gender-split data on university graduates from multiple sources to identify under-served regions and tailor community outreach and skill-building initiatives.
- International development consultancy reporting: compile and validate tertiary education statistics by gender from EU, UN, and World Bank portals to create comprehensive briefings for European Commission education funding proposals.
- Data journalism and investigative reporting: scrape, analyze, and extract PDF links and numerical context to produce visual stories on the gender gap in Bulgarian higher education for news outlets and online platforms.
- EdTech market intelligence and course targeting: ingest official 2011 census education data by gender to uncover potential demand for women-focused online learning modules and customize marketing campaigns.
- Business intelligence for private training providers: automate sourcing of government and EU statistics on tertiary degree attainment by gender to adjust service offerings, price models, and regional expansion strategies.
- Machine learning dataset creation for education forecasting: aggregate historical gender-disaggregated tertiary education figures from diverse sources to train predictive models on future higher education trends in Bulgaria.

```
import os
import requests
from bs4 import BeautifulSoup
import json
import time
import re

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

print("=== BULGARIAN 2011 CENSUS: ALTERNATIVE SEARCH APPROACH ===")
print("Objective: Find tertiary education by gender data using alternative sources")
print("Previous attempt failed due to API quota limits on direct NSI access\n")

# Alternative search strategy: Use multiple approaches to find the data
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

# Try alternative sources for Bulgarian census data
alternative_sources = [
    "https://en.wikipedia.org/wiki/2011_census_in_Bulgaria",
    "https://en.wikipedia.org/wiki/Education_in_Bulgaria",
    "https://ec.europa.eu/eurostat",  # EU statistical office
    "https://data.worldbank.org",     # World Bank data
    "https://unstats.un.org"          # UN Statistics
]

print("Step 1: Trying alternative data sources...\n")

successful_sources = []
failed_sources = []

for url in alternative_sources:
    print(f"Accessing: {url}")
    try:
        response = requests.get(url, headers=headers, timeout=15)
        print(f"Status: {response.status_code}")
        
        if response.status_code == 200:
            print(f"✓ Successfully accessed {url}")
            
            # Save content
            filename = url.replace('https://', '').replace('http://', '').replace('/', '_').replace('.', '_') + '.html'
            filepath = f'workspace/{filename}'
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            # Analyze content for Bulgarian census and education data
            soup = BeautifulSoup(response.content, 'html.parser')
            title = soup.find('title')
            title_text = title.get_text().strip() if title else 'No title found'
            
            content_text = soup.get_text().lower()
            
            # Look for specific Bulgarian census and education indicators
            bulgaria_indicators = ['bulgaria', 'bulgarian']
            census_indicators = ['2011', 'census', 'population']
            education_indicators = ['tertiary', 'education', 'university', 'higher education', 'degree']
            gender_indicators = ['gender', 'men', 'women', 'male', 'female']
            
            has_bulgaria = any(indicator in content_text for indicator in bulgaria_indicators)
            has_census = any(indicator in content_text for indicator in census_indicators)
            has_education = any(indicator in content_text for indicator in education_indicators)
            has_gender = any(indicator in content_text for indicator in gender_indicators)
            
            relevance_score = sum([has_bulgaria, has_census, has_education, has_gender])
            
            successful_sources.append({
                'url': url,
                'title': title_text,
                'filename': filepath,
                'has_bulgaria': has_bulgaria,
                'has_census': has_census,
                'has_education': has_education,
                'has_gender': has_gender,
                'relevance_score': relevance_score,
                'content_length': len(response.text)
            })
            
            print(f"  Title: {title_text}")
            print(f"  Bulgaria content: {has_bulgaria}")
            print(f"  Census content: {has_census}")
            print(f"  Education content: {has_education}")
            print(f"  Gender content: {has_gender}")
            print(f"  Relevance score: {relevance_score}/4")
            
        else:
            failed_sources.append({'url': url, 'status': response.status_code})
            print(f"✗ Failed - Status: {response.status_code}")
            
    except Exception as e:
        failed_sources.append({'url': url, 'error': str(e)})
        print(f"✗ Error: {str(e)}")
    
    print()
    time.sleep(1)  # Brief pause between requests

print(f"=== ALTERNATIVE SEARCH RESULTS ===\n")
print(f"Successfully accessed: {len(successful_sources)} sources")
print(f"Failed to access: {len(failed_sources)} sources\n")

# Sort sources by relevance score
successful_sources.sort(key=lambda x: x['relevance_score'], reverse=True)

# Analyze the most relevant sources
if successful_sources:
    print("--- Top Sources by Relevance ---\n")
    
    for i, source in enumerate(successful_sources[:3], 1):  # Top 3 sources
        print(f"{i}. {source['url']} (Score: {source['relevance_score']}/4)")
        print(f"   Title: {source['title']}")
        print(f"   File: {source['filename']}")
        
        if source['relevance_score'] >= 2:  # Analyze sources with decent relevance
            print(f"   *** ANALYZING THIS SOURCE ***")
            
            with open(source['filename'], 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # Look for tables with statistical data
            tables = soup.find_all('table')
            print(f"   Found {len(tables)} tables")
            
            # Search for specific Bulgarian education statistics
            text_content = soup.get_text()
            
            # Look for sentences mentioning Bulgaria, education, and gender/statistics
            sentences = text_content.split('.')
            relevant_sentences = []
            
            for sentence in sentences:
                sentence_lower = sentence.lower().strip()
                if len(sentence_lower) > 20:  # Skip very short sentences
                    has_bulgaria = 'bulgaria' in sentence_lower
                    has_education_terms = any(term in sentence_lower for term in ['tertiary', 'education', 'university', 'higher', 'degree'])
                    has_numbers = bool(re.search(r'\d+', sentence_lower))
                    has_2011 = '2011' in sentence_lower
                    
                    if has_bulgaria and (has_education_terms or has_2011) and has_numbers:
                        relevant_sentences.append(sentence.strip())
            
            print(f"   Found {len(relevant_sentences)} potentially relevant sentences")
            
            # Look for specific numerical patterns that might be education statistics
            education_numbers = []
            number_patterns = re.findall(r'\d+[,.]?\d*\s*%?', text_content)
            
            # Context search around numbers
            for match in re.finditer(r'\d+[,.]?\d*\s*%?', text_content):
                start = max(0, match.start() - 100)
                end = min(len(text_content), match.end() + 100)
                context = text_content[start:end].lower()
                
                if 'bulgaria' in context and any(term in context for term in ['education', 'tertiary', 'university']):
                    education_numbers.append({
                        'number': match.group(),
                        'context': text_content[start:end].strip()
                    })
            
            print(f"   Found {len(education_numbers)} numbers in educational context")
            
            # Save detailed analysis
            detailed_analysis = {
                'source_url': source['url'],
                'relevance_score': source['relevance_score'],
                'tables_count': len(tables),
                'relevant_sentences': relevant_sentences[:10],  # Top 10 sentences
                'education_numbers': education_numbers[:5],     # Top 5 number contexts
                'content_sample': text_content[:3000]           # First 3000 characters
            }
            
            analysis_file = f'workspace/detailed_analysis_{i}.json'
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(detailed_analysis, f, indent=2, ensure_ascii=False)
            
            print(f"   Detailed analysis saved to: {analysis_file}")
            
            # Show some key findings
            if relevant_sentences:
                print(f"   Sample relevant sentence: {relevant_sentences[0][:150]}...")
            
            if education_numbers:
                print(f"   Sample education number: {education_numbers[0]['number']} - Context: {education_numbers[0]['context'][:100]}...")
        
        print()

# Try to find direct census report downloads or PDFs
print("=== SEARCHING FOR DIRECT CENSUS REPORTS ===\n")

# Look through the successful sources for PDF links or download links
report_links = []

for source in successful_sources:
    if source['relevance_score'] >= 2:
        print(f"Searching for reports in: {source['url']}")
        
        with open(source['filename'], 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Look for PDF links, Excel files, or other data downloads
        links = soup.find_all('a', href=True)
        
        for link in links:
            href = link['href']
            link_text = link.get_text().lower().strip()
            
            # Check for census/education related downloads
            is_data_file = any(ext in href.lower() for ext in ['.pdf', '.xls', '.xlsx', '.csv', '.zip'])
            has_relevant_text = any(term in link_text for term in ['census', 'education', 'bulgaria', '2011', 'statistics'])
            
            if is_data_file and has_relevant_text:
                report_links.append({
                    'source': source['url'],
                    'link_text': link.get_text().strip(),
                    'href': href,
                    'file_type': href.split('.')[-1] if '.' in href else 'unknown'
                })
        
        print(f"  Found {len([r for r in report_links if r['source'] == source['url']])} potential report links")

print(f"\nTotal potential report links found: {len(report_links)}")

if report_links:
    print("\n--- Potential Census/Education Reports ---")
    for i, link in enumerate(report_links[:10], 1):  # Show top 10
        print(f"{i}. {link['link_text']} ({link['file_type'].upper()})")
        print(f"   Source: {link['source']}")
        print(f"   Link: {link['href']}")
        print()

# Save comprehensive search results
search_results = {
    'search_objective': 'Bulgarian 2011 census tertiary education by gender',
    'search_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'approach': 'Alternative sources due to NSI API quota exhaustion',
    'sources_accessed': len(successful_sources),
    'sources_failed': len(failed_sources),
    'relevant_sources': len([s for s in successful_sources if s['relevance_score'] >= 2]),
    'potential_reports_found': len(report_links),
    'successful_sources': successful_sources,
    'failed_sources': failed_sources,
    'potential_reports': report_links
}

with open('workspace/bulgarian_census_alternative_search.json', 'w', encoding='utf-8') as f:
    json.dump(search_results, f, indent=2, ensure_ascii=False)

print(f"=== ALTERNATIVE SEARCH COMPLETE ===\n")
print(f"Search results saved to: workspace/bulgarian_census_alternative_search.json")
print(f"Sources successfully accessed: {len(successful_sources)}")
print(f"Highly relevant sources: {len([s for s in successful_sources if s['relevance_score'] >= 3])}")
print(f"Potential data reports identified: {len(report_links)}")
print(f"\nNext steps: Analyze detailed findings and attempt to access identified reports")
```