### Development Step 3: Identify MLB player with quirky walk nickname, 29 steals in 1970, 1971 McCraw trade details

**Description**: Search for information about a baseball player who had an unusual walk style nickname, stole 29 bases in the 1970 season, and was involved in a trade between the Chicago White Sox and another team in 1971 where Tommy McCraw was exchanged. Focus on identifying this player's distinctive nickname related to his walking style, his 1970 season statistics showing exactly 29 stolen bases, and the specific 1971 trade details involving McCraw going to the team that had previously traded this player to the White Sox.

**Use Cases**:
- Sports historian workflow for compiling detailed biographies by automatically extracting player nicknames, trade transactions, and seasonal stolen‐base totals from Baseball‐Reference
- Fantasy baseball analytics pipeline that identifies undervalued base stealers with quirky nicknames and analyzes their trade history for draft strategy optimization
- E-commerce sports memorabilia site enrichment to scrape and append players’ distinctive walk‐style nicknames, 1970 stolen base stats, and 1971 trade details to product descriptions
- Sports journalism editorial automation for generating feature stories by pulling player transaction lines, career statistics, and anecdotal nicknames from archived HTML pages
- Betting research model input preparation that aggregates player steal counts, team movements, and historical transaction context to improve in‐play odds algorithms
- Academic sports analytics project studying the impact of mid-career trades on base‐stealing performance by programmatically harvesting season‐by‐season stats and trade logs
- Mobile trivia app content assembly that dynamically creates baseball quiz questions using scraped data on unusual player nicknames, steal totals, and key trades
- Digital archive initiative for a public sports library, automating the preservation of transaction records, player statistics, and nickname lore by parsing and storing Baseball-Reference pages

```
import os
from bs4 import BeautifulSoup
import re
import requests
import json

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

print("=== FIXING VARIABLE SCOPE ERROR AND CONTINUING SEARCH ===")
print("Issue: Variable scope error in generator expression - fixing with proper loop structure")
print()

# First, let's properly parse the saved Tommy McCraw HTML file
tommy_file = 'workspace/tommy_mccraw_baseball_reference.html'

if os.path.exists(tommy_file):
    print("Step 1: Analyzing saved Tommy McCraw Baseball-Reference page...")
    
    with open(tommy_file, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # Look for transaction information more systematically
    print("\n=== Searching for 1971 trade information ===")
    
    # Get all text and split into lines properly - FIXED VARIABLE SCOPE
    page_text = soup.get_text()
    text_lines = page_text.split('\n')
    
    # Search for 1971 trade information - using proper loop structure
    trade_lines = []
    for current_line in text_lines:  # Using clear variable name
        current_line = current_line.strip()
        if current_line and '1971' in current_line:
            # Check for trade-related terms in the current line
            trade_terms = ['trade', 'traded', 'acquired', 'sent', 'white sox', 'chicago']
            if any(term in current_line.lower() for term in trade_terms):
                trade_lines.append(current_line)
    
    if trade_lines:
        print(f"Found {len(trade_lines)} lines mentioning 1971 trades:")
        for i, line in enumerate(trade_lines):
            print(f"{i+1}. {line}")
    else:
        print("No explicit 1971 trade information found in text")
    
    # Look for career statistics table to see team changes
    print("\n=== Analyzing career statistics for team changes ===")
    
    # Find tables that might contain yearly stats
    tables = soup.find_all('table')
    print(f"Found {len(tables)} tables on page")
    
    mccraw_career_data = []
    
    for i, table in enumerate(tables):
        # Check if table has year and team columns
        headers = table.find_all('th')
        header_texts = [th.get_text().strip() for th in headers]
        
        # Look for tables with year/team information
        has_year = any('year' in h.lower() for h in header_texts)
        has_team = any('tm' in h.lower() or 'team' in h.lower() for h in header_texts)
        
        if has_year and has_team:
            print(f"\n*** Table {i+1} contains year/team data ***")
            print(f"Headers: {header_texts}")
            
            # Extract all rows to understand McCraw's career timeline
            rows = table.find_all('tr')
            for j, row in enumerate(rows):
                cells = row.find_all(['td', 'th'])
                cell_data = [cell.get_text().strip() for cell in cells]
                
                if len(cell_data) > 1:
                    # Look for years around 1971
                    row_text = ' '.join(cell_data)
                    if any(year in row_text for year in ['1970', '1971', '1972']):
                        print(f"Relevant year row: {cell_data}")
                        mccraw_career_data.append({
                            'table_index': i+1,
                            'row_index': j+1,
                            'data': cell_data
                        })
    
    # Save McCraw career analysis
    mccraw_analysis = {
        'trade_lines_found': trade_lines,
        'career_data_around_1971': mccraw_career_data,
        'total_tables_analyzed': len(tables)
    }
    
    with open('workspace/mccraw_career_analysis.json', 'w') as f:
        json.dump(mccraw_analysis, f, indent=2)
    
    print(f"\nMcCraw career analysis saved to workspace/mccraw_career_analysis.json")
    
else:
    print(f"Tommy McCraw HTML file not found: {tommy_file}")
    print("Available files in workspace:")
    if os.path.exists('workspace'):
        for file in os.listdir('workspace'):
            print(f"  - {file}")

print("\n" + "="*60)
print("Step 2: Alternative approach for 1970 stolen base data...")

# Since the leaders page failed, let's try different approaches
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

# Try searching for 1970 American League stolen base leaders
print("Trying alternative URLs for 1970 stolen base statistics...")

alternative_urls = [
    "https://www.baseball-reference.com/years/1970-batting.shtml",
    "https://www.baseball-reference.com/leagues/AL/1970-batting.shtml",
    "https://www.baseball-reference.com/leagues/NL/1970-batting.shtml"
]

successful_downloads = []

for url_index, url in enumerate(alternative_urls):
    try:
        print(f"\nAttempt {url_index + 1}: {url}")
        response = requests.get(url, headers=headers, timeout=30)
        print(f"Response: {response.status_code}")
        
        if response.status_code == 200:
            print(f"Success! Accessing {url}")
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Save the HTML
            filename = f"1970_batting_{url_index + 1}.html"
            filepath = f'workspace/{filename}'
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            print(f"Saved to {filepath}")
            successful_downloads.append(filepath)
            
            # Quick search for "29" in stolen base context
            page_text = soup.get_text().lower()
            
            # Look for tables with stolen base data
            tables = soup.find_all('table')
            print(f"Found {len(tables)} tables")
            
            players_with_29_steals = []
            
            for i, table in enumerate(tables):
                table_text = table.get_text()
                
                # Check if table contains stolen base information
                if 'sb' in table_text.lower() or 'stolen' in table_text.lower():
                    print(f"\n*** Table {i+1} may contain stolen base data ***")
                    
                    # Look for "29" in this table
                    if '29' in table_text:
                        print(f"*** Table {i+1} contains '29' - potential match! ***")
                        
                        # Extract rows to find the player with 29 steals
                        rows = table.find_all('tr')
                        for j, row in enumerate(rows[:25]):  # Check first 25 rows
                            cells = row.find_all(['td', 'th'])
                            cell_data = [cell.get_text().strip() for cell in cells]
                            
                            if '29' in cell_data:
                                print(f"Row {j+1} with '29': {cell_data}")
                                
                                # Try to identify the player name and context
                                for k, cell in enumerate(cell_data):
                                    if cell == '29':
                                        # Look for player name in the same row
                                        potential_player = None
                                        if k > 0 and cell_data[k-1] and not cell_data[k-1].isdigit():
                                            potential_player = cell_data[k-1]
                                        elif len(cell_data) > 0 and not cell_data[0].isdigit():
                                            potential_player = cell_data[0]
                                        
                                        if potential_player:
                                            print(f"*** POTENTIAL PLAYER: {potential_player} with 29 steals ***")
                                            players_with_29_steals.append({
                                                'player': potential_player,
                                                'row_data': cell_data,
                                                'table_index': i+1,
                                                'source_file': filename
                                            })
            
            if players_with_29_steals:
                print(f"\nFound {len(players_with_29_steals)} potential players with 29 steals in {url}")
                
                # Save the findings
                with open(f'workspace/players_29_steals_{url_index + 1}.json', 'w') as f:
                    json.dump(players_with_29_steals, f, indent=2)
                
                print(f"Saved findings to workspace/players_29_steals_{url_index + 1}.json")
            else:
                print(f"No '29' stolen base data found in {url}")
        
        else:
            print(f"Failed: HTTP {response.status_code}")
            
    except Exception as e:
        print(f"Error with {url}: {str(e)}")

print("\n" + "="*60)
print("=== CURRENT PROGRESS SUMMARY ===")
print("✓ Fixed variable scope error in text parsing")
print("✓ Properly analyzed Tommy McCraw HTML file for 1971 trade information")
print(f"✓ Attempted {len(alternative_urls)} alternative URLs for 1970 stolen base data")
print(f"✓ Successfully downloaded {len(successful_downloads)} files for analysis")
print("\nFiles created in workspace/:")
if os.path.exists('workspace'):
    for file in os.listdir('workspace'):
        print(f"  - {file}")

print("\nNext step: Analyze saved JSON files to cross-reference players and identify the mystery player")
```