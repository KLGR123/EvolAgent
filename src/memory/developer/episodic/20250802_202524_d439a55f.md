### Development Step 16: 2011 Bulgarian Census: Tertiary Education Completion by Gender Data Search

**Description**: Search for the 2011 Bulgarian census data on tertiary education completion by gender. Look for official census results from Bulgaria's National Statistical Institute or other authoritative sources that provide the specific breakdown of men and women who completed tertiary education in 2011.

**Use Cases**:
- Government policy analysis for gender equality: Automated extraction of 2011 Bulgarian tertiary education by gender to inform national strategies on closing educational attainment gaps.
- Academic demographic research: Streamlined scraping of NSI census HTML pages to compile datasets on male and female higher‐education completion for longitudinal studies.
- NGO program impact assessment: Collecting historical gender‐disaggregated education statistics to evaluate the effectiveness of international female empowerment and scholarship initiatives in Bulgaria.
- EdTech market planning: Aggregating regional tertiary education rates by gender from official census data to identify target demographics for new online learning platforms.
- Data journalism on gender disparity: Rapid parsing of census tables and key sentences to produce data‐driven reports highlighting differences in university attainment between men and women in 2011.
- Population statistics portal population: Automated pipeline populating a public database with historical tertiary education figures by gender to support researchers and policymakers.
- Workforce talent analytics: Integrating 2011 Bulgarian census education breakdowns into BI dashboards for HR firms to assess the availability of skilled graduates across male and female cohorts.

```
import os
import json
from bs4 import BeautifulSoup
import re
import time

print("=== BULGARIAN 2011 CENSUS TERTIARY EDUCATION - FIXED SCOPING APPROACH ===")
print("Strategy: Fixed variable scoping with proper list comprehension\n")

# Check workspace
workspace_path = 'workspace'
if not os.path.exists(workspace_path):
    print("No workspace directory found")
    exit()

all_files = os.listdir(workspace_path)
html_files = [f for f in all_files if f.endswith('.html')]

print(f"Total files: {len(all_files)}")
print(f"HTML files: {len(html_files)}")

# Show all HTML files with sizes
print("\n=== ALL HTML FILES ===\n")
for i, html_file in enumerate(html_files, 1):
    filepath = os.path.join(workspace_path, html_file)
    file_size = os.path.getsize(filepath)
    print(f"{i:2d}. {html_file}")
    print(f"    Size: {file_size:,} bytes")

# Select promising files - FIXED variable scoping
promising_files = []
for html_filename in html_files:
    filepath = os.path.join(workspace_path, html_filename)
    file_size = os.path.getsize(filepath)
    
    # Skip very small files
    if file_size < 40000:  # Less than 40KB likely error pages
        continue
    
    # Look for key terms in filename
    filename_lower = html_filename.lower()
    if any(term in filename_lower for term in ['demographics', 'education', 'census', 'nsi']):
        promising_files.append(html_filename)

print(f"\nPromising files to analyze: {len(promising_files)}")
for pf in promising_files:
    print(f"  - {pf}")

print("\n=== ANALYZING FILES WITH FIXED APPROACH ===\n")

# Results storage
all_findings = []

# Analyze each promising file
for current_filename in promising_files[:3]:  # Analyze top 3
    print(f"Analyzing: {current_filename}")
    
    filepath = os.path.join(workspace_path, current_filename)
    
    try:
        # Read and parse HTML
        with open(filepath, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        page_title = soup.find('title')
        title_text = page_title.get_text().strip() if page_title else 'No title'
        
        # Get all text - direct usage
        all_text = soup.get_text()
        
        print(f"  Title: {title_text}")
        print(f"  Content length: {len(all_text):,} characters")
        
        # Check relevance using direct string operations
        has_bulgaria = 'bulgaria' in all_text.lower() or 'bulgarian' in all_text.lower()
        has_2011 = '2011' in all_text.lower()
        has_census = 'census' in all_text.lower()
        has_tertiary = 'tertiary' in all_text.lower() or 'higher education' in all_text.lower()
        has_gender = any(term in all_text.lower() for term in ['men', 'women', 'male', 'female'])
        has_education = 'education' in all_text.lower()
        
        relevance = sum([has_bulgaria, has_2011, has_census, has_tertiary, has_gender, has_education])
        
        print(f"  Bulgaria: {has_bulgaria} | 2011: {has_2011} | Census: {has_census}")
        print(f"  Tertiary: {has_tertiary} | Gender: {has_gender} | Education: {has_education}")
        print(f"  Relevance: {relevance}/6")
        
        if relevance >= 3:
            print("  *** EXTRACTING DATA ***")
            
            # Look for sentences with key terms and numbers
            sentences = all_text.split('.')
            good_sentences = []
            
            for sentence in sentences:
                if len(sentence.strip()) < 30:
                    continue
                    
                s_lower = sentence.lower()
                
                # Check for Bulgaria + education + numbers + gender/year
                if (('bulgaria' in s_lower or 'bulgarian' in s_lower) and 
                    ('education' in s_lower or 'tertiary' in s_lower or 'university' in s_lower) and
                    re.search(r'\d+', sentence) and
                    ('2011' in s_lower or 'men' in s_lower or 'women' in s_lower or 'male' in s_lower or 'female' in s_lower)):
                    
                    good_sentences.append(sentence.strip())
            
            print(f"  Good sentences found: {len(good_sentences)}")
            
            # Look for statistical patterns
            stat_patterns = [
                r'tertiary education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'(?:men|women|male|female)[^.]*?tertiary education[^.]*?(\d+[.,]?\d*\s*%?)',
                r'higher education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'2011[^.]*?education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'(?:men|women)[^.]*?(?:completed|attained|achieved)[^.]*?(?:tertiary|higher|university)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'(?:tertiary|higher|university)[^.]*?(?:completed|attained|achieved)[^.]*?(?:men|women)[^.]*?(\d+[.,]?\d*\s*%?)'
            ]
            
            stat_matches = []
            for pattern in stat_patterns:
                matches = re.finditer(pattern, all_text, re.IGNORECASE)
                for match in matches:
                    context_start = max(0, match.start() - 200)
                    context_end = min(len(all_text), match.end() + 200)
                    context = all_text[context_start:context_end]
                    
                    if 'bulgaria' in context.lower():
                        stat_matches.append({
                            'match': match.group(),
                            'context': context,
                            'file': current_filename
                        })
            
            print(f"  Statistical matches: {len(stat_matches)}")
            
            # Look for tables with education and gender data
            tables = soup.find_all('table')
            education_tables = []
            
            for table_idx, table in enumerate(tables):
                table_text = table.get_text().lower()
                
                # Check if table has education and gender information
                has_education_content = any(term in table_text for term in 
                                          ['education', 'tertiary', 'university', 'degree'])
                has_gender_content = any(term in table_text for term in 
                                       ['men', 'women', 'male', 'female', 'gender'])
                has_numbers = bool(re.search(r'\d+', table.get_text()))
                
                if has_education_content and has_gender_content and has_numbers:
                    # Extract table headers
                    headers = [th.get_text().strip() for th in table.find_all('th')]
                    
                    # Extract sample rows
                    rows = table.find_all('tr')
                    sample_rows = []
                    
                    for row in rows[1:4]:  # Skip header, take next 3 rows
                        cells = [cell.get_text().strip() for cell in row.find_all(['td', 'th'])]
                        if cells and any(cell for cell in cells if cell.strip()):
                            sample_rows.append(cells)
                    
                    education_tables.append({
                        'table_index': table_idx,
                        'headers': headers,
                        'sample_rows': sample_rows,
                        'total_rows': len(rows)
                    })
            
            print(f"  Education tables found: {len(education_tables)}")
            
            # Store findings
            file_findings = {
                'filename': current_filename,
                'title': title_text,
                'relevance_score': relevance,
                'good_sentences': good_sentences[:5],  # Top 5
                'statistical_matches': stat_matches[:3],  # Top 3
                'education_tables': education_tables[:2],  # Top 2
                'indicators': {
                    'bulgaria': has_bulgaria,
                    '2011': has_2011,
                    'census': has_census,
                    'tertiary': has_tertiary,
                    'gender': has_gender,
                    'education': has_education
                }
            }
            
            all_findings.append(file_findings)
            
            # Show key findings
            if good_sentences:
                print(f"  Sample sentence: {good_sentences[0][:200]}...")
            
            if stat_matches:
                print(f"  Sample match: {stat_matches[0]['match']}")
                print(f"  Context: {stat_matches[0]['context'][:150]}...")
            
            if education_tables:
                print(f"  Table headers: {education_tables[0]['headers'][:5]}")
                if education_tables[0]['sample_rows']:
                    print(f"  Sample row: {education_tables[0]['sample_rows'][0][:3]}")
        
        else:
            print(f"  Lower relevance - skipping detailed analysis")
        
        print()
        
    except Exception as e:
        print(f"  ERROR: {str(e)}")
        print()

# Save results
print("=== SAVING RESULTS ===\n")

results = {
    'objective': 'Bulgarian 2011 census tertiary education by gender',
    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'html_files_total': len(html_files),
    'promising_files_analyzed': len(promising_files[:3]),
    'files_with_findings': len(all_findings),
    'detailed_findings': all_findings
}

results_file = os.path.join(workspace_path, 'bulgarian_census_final_analysis.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2, ensure_ascii=False)

print(f"Results saved to: {results_file}")
print(f"Files analyzed: {len(promising_files[:3])}")
print(f"Files with findings: {len(all_findings)}")

# Summary of findings
if all_findings:
    print("\n=== SUMMARY OF FINDINGS ===\n")
    
    total_sentences = sum(len(f['good_sentences']) for f in all_findings)
    total_matches = sum(len(f['statistical_matches']) for f in all_findings)
    total_tables = sum(len(f['education_tables']) for f in all_findings)
    
    print(f"Total relevant sentences: {total_sentences}")
    print(f"Total statistical matches: {total_matches}")
    print(f"Total education tables: {total_tables}")
    
    print("\nDetailed findings:")
    for i, finding in enumerate(all_findings, 1):
        print(f"{i}. {finding['filename']} (Relevance: {finding['relevance_score']}/6)")
        print(f"   Title: {finding['title']}")
        print(f"   Sentences: {len(finding['good_sentences'])}, Matches: {len(finding['statistical_matches'])}, Tables: {len(finding['education_tables'])}")
        
        if finding['good_sentences']:
            print(f"   Sample sentence: {finding['good_sentences'][0][:180]}...")
        
        if finding['statistical_matches']:
            print(f"   Statistical match: {finding['statistical_matches'][0]['match']}")
        
        if finding['education_tables']:
            print(f"   Table headers: {finding['education_tables'][0]['headers'][:3]}")
        
        print()

else:
    print("\n=== NO FINDINGS ===\n")
    print("No specific tertiary education by gender data found in the analyzed files.")
    print("The data may be in a different format or require more specific sources.")

print("\n=== ANALYSIS COMPLETE ===\n")
print("Fixed scoping analysis completed successfully")
```