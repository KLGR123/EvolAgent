### Development Step 1: Extract Survivor Seasons 1–44 Winner List from Wikipedia to JSON

**Description**: Access the Wikipedia page https://en.wikipedia.org/wiki/Survivor_(American_TV_series) and extract the table of winners for seasons 1 through 44, saving each season number with its corresponding winner name into workspace/survivor_winners_list.json.

**Use Cases**:
- Mobile trivia game development and dynamic question generation using the auto-extracted Survivor winners list for seasons 1–44
- Social media campaign automation for a streaming service: scheduled “On this day” posts featuring past Survivor winners
- Academic research on reality TV diversity: compiling winners data to correlate demographics with show ratings and viewer engagement
- Entertainment news site infographic automation: generating season-by-season Survivor champions timelines for article embeds
- Messenger chatbot knowledge base enhancement: powering fan queries like “Who won Survivor Season 15?” with up-to-date JSON data
- Business intelligence dashboard for network executives: combining Survivor winners with viewership metrics to guide programming decisions
- Digital journalism workshop on web scraping: using the Survivor winners extraction script as a hands-on case study in automated data collection

```
import os
import json
import requests
from bs4 import BeautifulSoup

# Ensure workspace directory exists
workspace_dir = 'workspace'
if not os.path.exists(workspace_dir):
    os.makedirs(workspace_dir)

url = 'https://en.wikipedia.org/wiki/Survivor_(American_TV_series)'
print(f"Fetching page: {url}")
response = requests.get(url)
response.raise_for_status()
print("Page fetched successfully, parsing HTML...")

soup = BeautifulSoup(response.text, 'html.parser')

# Find the correct table: it should have headers including 'Season' and 'Winner'
tables = soup.find_all('table', {'class': 'wikitable'})
print(f"Found {len(tables)} wikitable(s) on the page.")

target_table = None
for idx, table in enumerate(tables, start=1):
    # Extract header texts
    header = table.find('tr')
    if not header:
        continue
    th_texts = [th.get_text(strip=True).lower() for th in header.find_all('th')]
    # Check for 'season' and 'winner' in headers
    if any('season' == t or t.startswith('season') for t in th_texts) and any('winner' == t or 'winner' in t for t in th_texts):
        print(f"Selecting table #{idx} as it contains headers: {th_texts}")
        target_table = table
        break

if target_table is None:
    raise RuntimeError("Could not find the winners table with 'Season' and 'Winner' headers.")

# Parse rows
rows = target_table.find_all('tr')[1:]  # skip header row
winners = []
for row in rows:
    cols = row.find_all(['th', 'td'])
    if len(cols) < 2:
        continue
    # First column: Season number
    season_cell = cols[0]
    for sup in season_cell.find_all('sup'):
        sup.decompose()
    season_text = season_cell.get_text(strip=True)
    # Try to parse integer season
    try:
        season_num = int(season_text)
    except ValueError:
        # Skip rows where season isn't numeric
        continue
    if season_num > 44:
        # Only seasons 1-44 per PLAN
        continue
    # Winner column might be under a header index; find the index of 'winner'
    # We can re-extract header to find winner column index
    winner_idx = None
    header = target_table.find('tr')
    ths = header.find_all('th')
    for i, th in enumerate(ths):
        text = th.get_text(strip=True).lower()
        if 'winner' in text and not 'winners' == text:
            winner_idx = i
            break
    if winner_idx is None or winner_idx >= len(cols):
        # Fallback: assume winner is second column
        winner_cell = cols[1]
    else:
        winner_cell = cols[winner_idx]
    # Clean winner cell
    for sup in winner_cell.find_all('sup'):
        sup.decompose()
    winner_name = winner_cell.get_text(strip=True)
    print(f"Parsed Season {season_num}: winner -> {winner_name}")
    winners.append({'season': season_num, 'winner': winner_name})

# Sort by season
winners_sorted = sorted(winners, key=lambda x: x['season'])
print(f"Total winners extracted for seasons 1-44: {len(winners_sorted)}")

# Save to JSON
output_path = os.path.join(workspace_dir, 'survivor_winners_list.json')
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(winners_sorted, f, indent=2)
print(f"Winners list saved to: {output_path}")

```