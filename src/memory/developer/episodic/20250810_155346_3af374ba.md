### Development Step 3: Surrey Lodge: Origins, Victorian Temperance Hall, 1935 Rotating Stage, WWII Damage, Burnley Relocation

**Description**: Conduct a comprehensive web search to identify Surrey Lodge in South London and trace its historical development during the Victorian era. Focus on finding information about: (1) the original organization that developed Surrey Lodge, (2) its transformation into a temperance hall, (3) the installation of the UK's first rotating stage in 1935, (4) World War II bomb damage, and (5) the company's relocation to Burnley. Use search terms like 'Surrey Lodge South London Victorian era temperance hall', 'first rotating stage UK 1935 temperance hall', 'Surrey Lodge bomb damage World War II Burnley', and 'Victorian temperance organization Surrey Lodge founder'.

**Use Cases**:
- Heritage architecture research for conservation specialists analyzing Surrey Lodge‚Äôs Victorian origins, temperance hall transformation, and WWII damage to inform restoration projects
- Digital archiving for local history museums automating extraction of founding organization details, rotating stage installation in 1935, and relocation events to create enriched exhibit metadata
- Curriculum development for history educators generating interactive timelines and textual snippers about Surrey Lodge‚Äôs evolution for classroom modules on South London heritage
- Urban planning risk assessment for property developers evaluating past bomb damage, historical uses, and relocation patterns of sites like Surrey Lodge to guide redevelopment proposals
- Genealogy support tools for family historians mining HTML archives for references to temperance organizations and community halls where ancestors may have participated
- Cultural tourism itinerary building for guide operators compiling thematic tours that highlight Surrey Lodge‚Äôs first rotating stage and other unique historical milestones
- Academic digital humanities research on tracing organizational transformations and societal impact by scraping web records for evidence of Victorian temperance movements and subsequent relocations
- Heritage insurance underwriting systems assessing structural history, wartime damages, and refurbishment records of listed buildings such as Surrey Lodge to calculate coverage and premiums

```
import os
import json
from bs4 import BeautifulSoup
import re
from collections import Counter

print('=== SURREY LODGE HISTORICAL ANALYSIS - PROPERLY FIXED VARIABLE SCOPE ===') 
print('Objective: Analyze Surrey Lodge HTML files with corrected variable handling')
print('Issue identified: page_text variable scope problem - implementing proper fix\n')

# Ensure workspace directory exists
os.makedirs('workspace', exist_ok=True)

# Check available HTML files
html_files = [f for f in os.listdir('workspace') if f.startswith('surrey_lodge_search_') and f.endswith('.html')]
print(f'Found {len(html_files)} Surrey Lodge HTML files to analyze')

if not html_files:
    print('‚ùå No Surrey Lodge HTML files found')
    exit()

# Initialize analysis results
analysis_results = {
    'timestamp': '2024-12-19',
    'objective': 'Analyze Surrey Lodge South London historical development',
    'files_processed': [],
    'historical_findings': [],
    'evidence_summary': {},
    'timeline_info': []
}

# Define key terms for relevance scoring
key_terms = {
    'surrey lodge': 10,
    'south london': 8, 
    'temperance': 8,
    'temperance hall': 10,
    'victorian': 6,
    'rotating stage': 10,
    '1935': 8,
    'first rotating stage': 12,
    'bomb damage': 8,
    'world war': 6,
    'wwii': 6,
    'burnley': 8,
    'relocation': 6,
    'theatre': 5,
    'organization': 5,
    'founder': 6
}

print('\n=== PROCESSING HTML FILES WITH PROPER ERROR HANDLING ===') 
print('=' * 70)

# Process each file with proper variable scope
for i, html_file in enumerate(html_files, 1):
    print(f'\n--- File {i}/{len(html_files)}: {html_file} ---')
    
    # Initialize variables for this file
    file_analysis = {
        'filename': html_file,
        'status': 'processing',
        'relevance_score': 0,
        'found_terms': [],
        'historical_indicators': [],
        'text_snippets': [],
        'error': None
    }
    
    try:
        filepath = os.path.join('workspace', html_file)
        
        # Read HTML content
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            html_content = f.read()
        
        print(f'File size: {len(html_content):,} characters')
        file_analysis['file_size'] = len(html_content)
        
        # Parse HTML - ensure soup is properly created
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Extract text - CRITICAL FIX: Define page_text in proper scope
        raw_text = soup.get_text()
        page_text = raw_text.lower()  # Define page_text here in the try block
        
        print(f'Extracted text: {len(page_text):,} characters')
        file_analysis['text_length'] = len(page_text)
        
        # Now process the text - page_text is properly defined
        found_terms = []
        relevance_score = 0
        
        # Check for key terms
        for term, weight in key_terms.items():
            if term in page_text:
                found_terms.append(term)
                relevance_score += weight
        
        file_analysis['found_terms'] = found_terms
        file_analysis['relevance_score'] = relevance_score
        
        print(f'Relevance score: {relevance_score}')
        print(f'Found terms ({len(found_terms)}): {", ".join(found_terms[:6])}')
        
        # Extract historical indicators
        historical_indicators = []
        
        if 'surrey lodge' in page_text:
            historical_indicators.append('Surrey Lodge confirmed')
            print('üéØ SURREY LODGE CONFIRMED!')
        
        if 'temperance hall' in page_text or ('temperance' in page_text and 'hall' in page_text):
            historical_indicators.append('Temperance hall connection found')
            print('üèõÔ∏è TEMPERANCE HALL CONNECTION!')
        
        if 'rotating stage' in page_text:
            historical_indicators.append('Rotating stage reference found')
            print('üé≠ ROTATING STAGE FOUND!')
            
            if '1935' in page_text:
                historical_indicators.append('1935 rotating stage date confirmed')
                print('üìÖ 1935 DATE CONFIRMED!')
        
        if any(term in page_text for term in ['bomb damage', 'bombed', 'war damage', 'blitz']):
            historical_indicators.append('WWII damage reference found')
            print('üí• WWII DAMAGE FOUND!')
        
        if 'burnley' in page_text:
            historical_indicators.append('Burnley connection found')
            print('üè≠ BURNLEY CONNECTION FOUND!')
        
        file_analysis['historical_indicators'] = historical_indicators
        
        # Extract relevant text snippets
        text_snippets = []
        sentences = page_text.split('.')
        
        for sentence in sentences:
            sentence = sentence.strip()
            if 20 < len(sentence) < 300:
                if 'surrey lodge' in sentence:
                    text_snippets.append(sentence)
                elif any(term in sentence for term in ['temperance hall', 'rotating stage', 'burnley', '1935']):
                    text_snippets.append(sentence)
        
        # Remove duplicates and limit
        unique_snippets = list(set(text_snippets))[:5]
        file_analysis['text_snippets'] = unique_snippets
        
        if unique_snippets:
            print(f'Text snippets found: {len(unique_snippets)}')
            for j, snippet in enumerate(unique_snippets[:2], 1):
                print(f'  {j}. {snippet[:150]}...')
        
        file_analysis['status'] = 'completed'
        
        # Show relevance assessment
        if relevance_score >= 15:
            print('üìö HIGH RELEVANCE!')
        elif relevance_score >= 5:
            print('üìù Moderate relevance')
        else:
            print('‚ùå Low relevance')
    
    except Exception as e:
        error_msg = str(e)
        print(f'‚ùå Error processing file: {error_msg}')
        file_analysis['status'] = 'error'
        file_analysis['error'] = error_msg
    
    # Store file analysis results
    analysis_results['files_processed'].append(file_analysis)
    
    # Add to overall findings if successful
    if file_analysis['status'] == 'completed':
        analysis_results['historical_findings'].extend(file_analysis['historical_indicators'])

print('\n=== COMPREHENSIVE ANALYSIS RESULTS ===') 
print('=' * 60)

# Count successful vs failed processing
successful = [f for f in analysis_results['files_processed'] if f['status'] == 'completed']
failed = [f for f in analysis_results['files_processed'] if f['status'] == 'error']

print(f'Successfully processed: {len(successful)} files')
print(f'Failed processing: {len(failed)} files')

if successful:
    # Sort by relevance score
    successful.sort(key=lambda x: x['relevance_score'], reverse=True)
    
    print('\nüìä TOP RELEVANCE RESULTS:')
    print('-' * 40)
    
    for i, file_data in enumerate(successful[:5], 1):
        print(f'\n{i}. {file_data["filename"]}:')
        print(f'   Score: {file_data["relevance_score"]}')
        print(f'   Terms: {", ".join(file_data["found_terms"][:6])}')
        print(f'   Indicators: {", ".join(file_data["historical_indicators"])}')
        if file_data.get('text_snippets'):
            print(f'   Sample: {file_data["text_snippets"][0][:100]}...')
    
    # Analyze all historical findings
    all_findings = analysis_results['historical_findings']
    finding_counts = Counter(all_findings)
    
    print('\nüìà HISTORICAL EVIDENCE FREQUENCY:')
    print('-' * 45)
    for finding, count in finding_counts.most_common():
        print(f'  ‚Ä¢ {finding}: {count} files')
    
    # Evidence analysis for focus areas
    evidence_summary = {
        'surrey_lodge_identified': 'Surrey Lodge confirmed' in all_findings,
        'temperance_hall_connection': 'Temperance hall connection found' in all_findings,
        'rotating_stage_1935': ('Rotating stage reference found' in all_findings and 
                               '1935 rotating stage date confirmed' in all_findings),
        'wwii_damage_confirmed': 'WWII damage reference found' in all_findings,
        'burnley_relocation': 'Burnley connection found' in all_findings
    }
    
    analysis_results['evidence_summary'] = evidence_summary
    
    print('\nüîç FOCUS AREA EVIDENCE ANALYSIS:')
    print('-' * 45)
    for area, confirmed in evidence_summary.items():
        status = '‚úÖ' if confirmed else '‚ùå'
        print(f'{status} {area.replace("_", " ").title()}: {confirmed}')
    
    # Calculate success rate
    confirmed_count = sum(evidence_summary.values())
    success_rate = (confirmed_count / len(evidence_summary)) * 100
    
    print(f'\nüìà RESEARCH SUCCESS RATE: {success_rate:.1f}% ({confirmed_count}/{len(evidence_summary)} areas confirmed)')
    analysis_results['success_rate'] = success_rate
    
    # Compile timeline information
    timeline_info = []
    for file_data in successful:
        if file_data.get('text_snippets'):
            for snippet in file_data['text_snippets']:
                if any(term in snippet for term in ['1935', 'victorian', 'war', 'bomb']):
                    timeline_info.append(snippet)
    
    unique_timeline = list(set(timeline_info))[:8]
    analysis_results['timeline_info'] = unique_timeline
    
    if unique_timeline:
        print('\nüìÖ TIMELINE INFORMATION:')
        print('-' * 35)
        for i, info in enumerate(unique_timeline[:5], 1):
            print(f'{i}. {info[:200]}...')
else:
    print('‚ùå No files successfully processed')

if failed:
    print('\n‚ùå PROCESSING ERRORS:')
    for file_data in failed:
        print(f'  ‚Ä¢ {file_data["filename"]}: {file_data["error"]}')

# Save results
results_file = os.path.join('workspace', 'surrey_lodge_final_analysis.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(analysis_results, f, indent=2, ensure_ascii=False)

print(f'\nüíæ Analysis results saved to: {results_file}')

# Create summary report
summary = f'''SURREY LODGE SOUTH LONDON HISTORICAL ANALYSIS
FINAL RESULTS SUMMARY

FILES PROCESSED: {len(analysis_results["files_processed"])}
‚Ä¢ Successful: {len(successful)}
‚Ä¢ Failed: {len(failed)}

'''

if analysis_results.get('success_rate'):
    summary += f'RESEARCH SUCCESS RATE: {analysis_results["success_rate"]:.1f}%\n\n'

if analysis_results.get('evidence_summary'):
    summary += 'EVIDENCE ANALYSIS:\n'
    for area, confirmed in analysis_results['evidence_summary'].items():
        status = 'CONFIRMED' if confirmed else 'NOT FOUND'
        summary += f'‚Ä¢ {area.replace("_", " ").title()}: {status}\n'
    summary += '\n'

if successful:
    summary += 'TOP FINDINGS:\n'
    for i, file_data in enumerate(successful[:3], 1):
        summary += f'{i}. {file_data["filename"]} (Score: {file_data["relevance_score"]})\n'
        summary += f'   Indicators: {", ".join(file_data["historical_indicators"])}\n'
    summary += '\n'

summary += 'FILES GENERATED:\n'
summary += '‚Ä¢ surrey_lodge_final_analysis.json - Complete analysis data\n'
summary += '‚Ä¢ surrey_lodge_summary_report.txt - This summary\n'

summary_file = os.path.join('workspace', 'surrey_lodge_summary_report.txt')
with open(summary_file, 'w', encoding='utf-8') as f:
    f.write(summary)

print(f'üìã Summary report saved to: {summary_file}')

print('\n' + '=' * 80)
print('SURREY LODGE HISTORICAL ANALYSIS - PROPERLY COMPLETED')
print('=' * 80)

if len(successful) >= 8:
    print('‚úÖ ANALYSIS SUCCESSFUL - Most files processed')
elif len(successful) >= 5:
    print('‚ö†Ô∏è PARTIAL SUCCESS - Some files processed')
else:
    print('‚ùå LIMITED SUCCESS - Few files processed successfully')

print('\nüìä FINAL STATISTICS:')
print(f'   ‚Ä¢ Files successfully analyzed: {len(successful)}')
print(f'   ‚Ä¢ Files with errors: {len(failed)}')
print(f'   ‚Ä¢ Historical indicators found: {len(set(analysis_results["historical_findings"]))}')
print(f'   ‚Ä¢ Timeline references: {len(analysis_results.get("timeline_info", []))}')

if analysis_results.get('evidence_summary'):
    confirmed_areas = [area.replace('_', ' ').title() for area, confirmed in analysis_results['evidence_summary'].items() if confirmed]
    if confirmed_areas:
        print('\nüéØ CONFIRMED RESEARCH AREAS:')
        for area in confirmed_areas:
            print(f'   ‚úÖ {area}')

print('\n=== SURREY LODGE ANALYSIS COMPLETE ===\n')
```