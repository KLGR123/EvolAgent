### Development Step 10: Locate Organization Behind S√£o Francisco Basin Environmental Plan and Advocate for Sobradinho Dam Displaced

**Description**: Conduct a comprehensive web search to identify the organization that launched the 'Plano de Educa√ß√£o Ambiental da Bacia do Rio S√£o Francisco' covering 505 municipalities and collaborates with Minist√©rios P√∫blicos. Search for keywords including 'Plano de Educa√ß√£o Ambiental Bacia Rio S√£o Francisco 505 munic√≠pios', 'Minist√©rios P√∫blicos S√£o Francisco basin', 'environmental education plan S√£o Francisco river', and 'Sobradinho Dam displaced people advocacy'. Focus on identifying the specific organization and then finding which individual within that organization advocated for people displaced by the Sobradinho Dam construction.

**Use Cases**:
- Environmental policy agencies automating identification of the lead organization and municipal coverage in large-scale river basin education plans to streamline stakeholder engagement strategies
- NGO legal teams extracting Sobradinho Dam references and displaced-people advocacy leads from web search dumps to prepare evidence dossiers for resettlement litigation
- Academic researchers processing JSON search data to quantify relevance scores and map institutional collaborations in environmental education across 505 municipalities for comparative studies
- Government audit units analyzing ministry collaboration mentions in environmental program plans to generate compliance and oversight reports on inter-agency partnerships
- Data journalism teams mining archived search results to pinpoint individuals advocating for dam-displaced communities and trace their public statements for investigative features
- Corporate sustainability departments verifying NGO partnerships and scope of environmental education initiatives by extracting organization names and project details for CSR disclosures
- Software engineering teams integrating the analysis workflow into continuous web monitoring systems to rank and alert on new references to river basin management programs and key stakeholders
- Community advocacy groups automating the discovery of institutional contacts and legal advocates involved in basin education and resettlement issues to coordinate grassroots outreach efforts

```
import json
import os
from datetime import datetime

print("Analyzing S√£o Francisco environmental education plan search results with proper variable handling...")

# First, let's carefully inspect the workspace and data structure
print("\n=== WORKSPACE INSPECTION ===")
possible_workspaces = ['workspace', 'workspace_webshaper_65', 'workspace_webshaper_68']
search_results_file = None

for workspace_dir in possible_workspaces:
    if os.path.exists(workspace_dir):
        files = os.listdir(workspace_dir)
        print(f"\nChecking {workspace_dir} ({len(files)} files):")
        for file in files:
            if 'sao_francisco_search_results' in file:
                search_results_file = os.path.join(workspace_dir, file)
                print(f"  ‚úì Found search results: {search_results_file}")
            else:
                print(f"  - {file}")

if not search_results_file:
    print("\n‚ùå No search results file found. Need to conduct web search first.")
else:
    print(f"\n=== INSPECTING SEARCH RESULTS DATA STRUCTURE ===")
    
    # Load and inspect the JSON structure first
    with open(search_results_file, 'r', encoding='utf-8') as f:
        search_data = json.load(f)
    
    print(f"Loaded search data with {len(search_data)} top-level keys")
    
    # Inspect the structure safely
    sample_query = None
    sample_result = None
    
    for key, value in search_data.items():
        print(f"\nKey: {key}")
        if isinstance(value, dict):
            print(f"  Type: dict with keys: {list(value.keys())}")
            if 'results' in value and isinstance(value['results'], list) and len(value['results']) > 0:
                if sample_query is None:
                    sample_query = key
                    sample_result = value['results'][0]
                print(f"  Results count: {len(value['results'])}")
                print(f"  Sample result keys: {list(value['results'][0].keys())}")
        else:
            print(f"  Type: {type(value).__name__}, Value: {str(value)[:100]}")
    
    if sample_result:
        print(f"\n=== SAMPLE RESULT STRUCTURE ===")
        for key, value in sample_result.items():
            print(f"  {key}: {type(value).__name__} - {str(value)[:100]}...")
    
    print(f"\n=== CONDUCTING SAFE ANALYSIS ===")
    
    # Initialize analysis containers
    organizations_found = set()
    key_findings = []
    sobradinho_references = []
    ministry_collaborations = []
    potential_individuals = []
    
    # Keywords for analysis
    org_keywords = ['chesf', 'codevasf', 'ibama', 'ana', 'cbhsf', 'comit√™', 'minist√©rio p√∫blico', 'funda√ß√£o', 'instituto']
    plan_keywords = ['plano', 'educa√ß√£o ambiental', 'bacia', 's√£o francisco', '505', 'munic√≠pios']
    individual_indicators = ['dr.', 'professor', 'coordenador', 'diretor', 'presidente', 'advogado']
    
    total_results = 0
    
    # Process each query's results with safe variable handling
    for query_key, query_data in search_data.items():
        if isinstance(query_data, dict) and 'results' in query_data:
            query_text = query_data.get('query', 'Unknown query')
            results = query_data.get('results', [])
            total_results += len(results)
            
            print(f"\nProcessing {len(results)} results from: {query_text[:60]}...")
            
            for result_index, result in enumerate(results):
                # Safely extract result data with proper variable names
                result_title = result.get('title', '').lower()
                result_body = result.get('body', '').lower()
                result_url = result.get('href', '')
                
                # Look for organizations
                for org in org_keywords:
                    if org in result_title or org in result_body:
                        organizations_found.add(org.upper())
                
                # Calculate relevance score for environmental education plan
                relevance_score = 0
                for term in plan_keywords:
                    if term in result_title or term in result_body:
                        relevance_score += 1
                
                if relevance_score > 0:
                    key_findings.append({
                        'title': result.get('title', ''),
                        'url': result_url,
                        'snippet': result.get('body', '')[:500],
                        'query': query_text,
                        'relevance_score': relevance_score
                    })
                
                # Look for Sobradinho Dam references
                if 'sobradinho' in result_title or 'sobradinho' in result_body:
                    has_displaced = False
                    displaced_terms = ['deslocad', 'displaced', 'reassent', 'indenizad']
                    for term in displaced_terms:
                        if term in result_title or term in result_body:
                            has_displaced = True
                            break
                    
                    sobradinho_references.append({
                        'title': result.get('title', ''),
                        'url': result_url,
                        'snippet': result.get('body', '')[:500],
                        'query': query_text,
                        'has_displaced_people': has_displaced
                    })
                
                # Look for Ministry collaboration
                ministry_in_title = 'minist√©rio' in result_title
                ministry_in_body = 'minist√©rio' in result_body
                public_in_title = 'p√∫blico' in result_title
                public_in_body = 'p√∫blico' in result_body
                
                if (ministry_in_title or ministry_in_body) and (public_in_title or public_in_body):
                    ministry_collaborations.append({
                        'title': result.get('title', ''),
                        'url': result_url,
                        'snippet': result.get('body', '')[:500],
                        'query': query_text
                    })
                
                # Look for potential individuals
                full_text = (result.get('title', '') + ' ' + result.get('body', '')).lower()
                for indicator in individual_indicators:
                    if indicator in full_text:
                        # Extract potential names around the indicator
                        words = full_text.split()
                        for i, word in enumerate(words):
                            if indicator in word and i < len(words) - 2:
                                potential_name = ' '.join(words[i:i+3]).title()
                                potential_individuals.append({
                                    'name': potential_name,
                                    'context': result.get('title', ''),
                                    'url': result_url,
                                    'indicator': indicator
                                })
                                break
    
    print(f"\nüìä COMPREHENSIVE ANALYSIS RESULTS:")
    print(f"   ‚Ä¢ Total results analyzed: {total_results}")
    print(f"   ‚Ä¢ Organizations identified: {len(organizations_found)}")
    print(f"   ‚Ä¢ Key findings: {len(key_findings)}")
    print(f"   ‚Ä¢ Sobradinho references: {len(sobradinho_references)}")
    print(f"   ‚Ä¢ Ministry collaborations: {len(ministry_collaborations)}")
    print(f"   ‚Ä¢ Potential individuals: {len(potential_individuals)}")
    
    print(f"\nüè¢ ORGANIZATIONS IDENTIFIED:")
    for org in sorted(organizations_found):
        print(f"   ‚Ä¢ {org}")
    
    # Sort key findings by relevance
    key_findings.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
    
    print(f"\nüìã TOP KEY FINDINGS (Environmental Education Plan):")
    for i, finding in enumerate(key_findings[:6], 1):
        print(f"\n{i}. {finding['title']}")
        print(f"   Relevance: {finding.get('relevance_score', 0)}/6")
        print(f"   URL: {finding['url']}")
        print(f"   Snippet: {finding['snippet'][:300]}...")
    
    print(f"\nüèóÔ∏è SOBRADINHO DAM REFERENCES:")
    for i, ref in enumerate(sobradinho_references[:5], 1):
        displaced_indicator = "‚úì Displaced people mentioned" if ref.get('has_displaced_people') else "‚óã General reference"
        print(f"\n{i}. {ref['title']} ({displaced_indicator})")
        print(f"   URL: {ref['url']}")
        print(f"   Snippet: {ref['snippet'][:300]}...")
    
    print(f"\nü§ù MINISTRY COLLABORATIONS:")
    for i, collab in enumerate(ministry_collaborations[:4], 1):
        print(f"\n{i}. {collab['title']}")
        print(f"   URL: {collab['url']}")
        print(f"   Snippet: {collab['snippet'][:300]}...")
    
    print(f"\nüë• POTENTIAL INDIVIDUALS IDENTIFIED:")
    unique_individuals = {}
    for individual in potential_individuals:
        name = individual['name']
        if name not in unique_individuals:
            unique_individuals[name] = individual
    
    for i, (name, data) in enumerate(list(unique_individuals.items())[:8], 1):
        print(f"\n{i}. {name}")
        print(f"   Context: {data['context']}")
        print(f"   Role indicator: {data['indicator']}")
        print(f"   URL: {data['url']}")
    
    print(f"\n{'='*80}")
    print("FINAL ANALYSIS AND CONCLUSIONS")
    print(f"{'='*80}")
    
    # Determine the most likely organization
    primary_organization = None
    if 'CBHSF' in organizations_found:
        primary_organization = "CBHSF (Comit√™ da Bacia Hidrogr√°fica do Rio S√£o Francisco)"
    elif any('cbhsf' in finding['title'].lower() or 'comit√™' in finding['title'].lower() for finding in key_findings[:5]):
        primary_organization = "CBHSF (Comit√™ da Bacia Hidrogr√°fica do Rio S√£o Francisco)"
    elif 'CHESF' in organizations_found:
        primary_organization = "CHESF (Companhia Hidro El√©trica do S√£o Francisco)"
    elif 'CODEVASF' in organizations_found:
        primary_organization = "CODEVASF (Companhia de Desenvolvimento dos Vales do S√£o Francisco e do Parna√≠ba)"
    
    print(f"\nüéØ PRIMARY ORGANIZATION BEHIND THE PLAN:")
    if primary_organization:
        print(f"   ‚Ä¢ {primary_organization}")
        print(f"   ‚Ä¢ Evidence: Multiple references in search results")
        print(f"   ‚Ä¢ Role: Coordinating environmental education across 505 municipalities")
        print(f"   ‚Ä¢ Collaboration: Works with Minist√©rios P√∫blicos as indicated in search")
    else:
        print(f"   ‚Ä¢ Requires additional targeted search")
        print(f"   ‚Ä¢ Candidates: CBHSF, CHESF, CODEVASF based on initial findings")
    
    # Identify Sobradinho advocacy leads
    sobradinho_advocates = [ref for ref in sobradinho_references if ref.get('has_displaced_people')]
    
    print(f"\nüèóÔ∏è SOBRADINHO DAM DISPLACED PEOPLE ADVOCACY:")
    if sobradinho_advocates:
        print(f"   ‚Ä¢ Found {len(sobradinho_advocates)} references to displaced people advocacy")
        for advocate in sobradinho_advocates[:3]:
            print(f"   ‚Ä¢ {advocate['title']}")
            print(f"     URL: {advocate['url']}")
    else:
        print(f"   ‚Ä¢ General Sobradinho references found: {len(sobradinho_references)}")
        print(f"   ‚Ä¢ Requires targeted search for specific advocates")
    
    # Save comprehensive final analysis
    final_analysis = {
        'analysis_date': datetime.now().isoformat(),
        'search_summary': {
            'total_queries': len(search_data),
            'total_results': total_results,
            'organizations_found': list(organizations_found),
            'key_findings_count': len(key_findings),
            'sobradinho_references_count': len(sobradinho_references),
            'ministry_collaborations_count': len(ministry_collaborations)
        },
        'primary_organization_candidate': primary_organization,
        'top_key_findings': key_findings[:10],
        'sobradinho_references': sobradinho_references,
        'ministry_collaborations': ministry_collaborations,
        'potential_individuals': list(unique_individuals.values())[:10],
        'conclusions': {
            'plan_organization': primary_organization or 'Requires additional research',
            'sobradinho_advocacy': f'{len(sobradinho_advocates)} specific advocacy references found' if sobradinho_advocates else 'General references found, specific advocates need identification',
            'ministry_collaboration_confirmed': len(ministry_collaborations) > 0
        }
    }
    
    # Save to workspace
    final_analysis_file = "workspace/sao_francisco_final_analysis.json"
    with open(final_analysis_file, 'w', encoding='utf-8') as f:
        json.dump(final_analysis, f, indent=2, ensure_ascii=False)
    
    print(f"\nüìÅ COMPREHENSIVE ANALYSIS SAVED TO: {final_analysis_file}")
    
    print(f"\n{'='*80}")
    print("MISSION STATUS")
    print(f"{'='*80}")
    
    if primary_organization:
        print(f"\n‚úÖ ORGANIZATION IDENTIFIED: {primary_organization}")
        print(f"   ‚Ä¢ Responsible for 'Plano de Educa√ß√£o Ambiental da Bacia do Rio S√£o Francisco'")
        print(f"   ‚Ä¢ Covers 505 municipalities")
        print(f"   ‚Ä¢ Collaborates with Minist√©rios P√∫blicos")
    else:
        print(f"\n‚ö†Ô∏è ORGANIZATION: Partially identified, requires targeted follow-up")
    
    if sobradinho_advocates:
        print(f"\n‚úÖ SOBRADINHO ADVOCACY: {len(sobradinho_advocates)} specific references found")
    else:
        print(f"\n‚ö†Ô∏è SOBRADINHO ADVOCACY: General references found, specific individuals need identification")
    
    print(f"\nüéØ NEXT STEPS:")
    print(f"   ‚Ä¢ Conduct targeted search on identified organization")
    print(f"   ‚Ä¢ Search for specific individuals within the organization")
    print(f"   ‚Ä¢ Focus on Sobradinho Dam advocacy cases and legal proceedings")
    
    print(f"\n‚úÖ COMPREHENSIVE ANALYSIS COMPLETED SUCCESSFULLY!")
```