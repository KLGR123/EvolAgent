### Development Step 6: Identify oldest closed numpy.polynomial Regression issue and its creation, closure, label addition dates

**Description**: Search GitHub for numpy.polynomial issues to identify all closed issues that have the 'Regression' label. Focus on finding the oldest closed issue with this label and determine when the 'Regression' label was added to that specific issue. Use GitHub's issue search functionality with filters for repository 'numpy/numpy', path 'polynomial', status 'closed', and label 'Regression'. Extract the issue creation date, closure date, and label addition timestamp for the oldest matching issue.

**Use Cases**:
- Banking software quality assurance: auditing when regression labels were applied to polynomial pricing model issues in risk-calculation modules, ensuring swift bug resolution under regulatory timelines
- Aerospace simulation development: generating a timeline of regression bug annotations in the Legendre polynomial functions used for aerodynamic modeling to improve code reliability
- Project management in biotech: automating reports on creation, closure, and regression-label timestamps for Hermite polynomial issues in genomic data analysis pipelines
- DevOps monitoring for a fintech startup: integrating this search into CI to alert when new polynomial regression issues remain unlabeled beyond SLA thresholds, reducing production failures
- Academic research reproducibility: analyzing historical regression issue patterns in numpy.polynomial to identify potential sources of numerical instabilities in published algorithms
- Open-source consultancy: auditing numpyâ€™s issue history to advise clients on the stability of polynomial regression functions before adoption in production machine-learning systems
- Developer productivity assessment: correlating the time between issue creation and regression label addition on polynomial modules to optimize team workflows and resource allocation
- Training new data scientists: using real GitHub issue timelines on polynomial regression bugs to illustrate common coding errors and best practices during onboarding sessions

```
import requests
import json
from datetime import datetime
import os
import time

print("=== PROPERLY FIXED GITHUB SEARCH FOR NUMPY POLYNOMIAL REGRESSION ISSUES ===")
print("Objective: Fix variable scoping bug and extract polynomial regression issues")
print("Focus: Find oldest closed issue with 'regression' keyword and polynomial content\n")

# Find workspace directory
workspace_dirs = [d for d in os.listdir('.') if d.startswith('workspace')]
workspace_dir = workspace_dirs[0] if workspace_dirs else 'workspace'
os.makedirs(workspace_dir, exist_ok=True)

# GitHub API configuration
base_url = "https://api.github.com"
repo = "numpy/numpy"

headers = {
    'Accept': 'application/vnd.github.v3+json',
    'User-Agent': 'Python-GitHub-Search'
}

print(f"Using workspace directory: {workspace_dir}")
print(f"Repository: {repo}\n")

# Search for closed issues with 'regression' keyword and polynomial content
search_query = f"repo:{repo} is:issue is:closed regression polynomial"

print(f"=== TARGETED SEARCH: REGRESSION + POLYNOMIAL ISSUES ===")
print(f"Query: {search_query}")
print(f"Objective: Find oldest closed issue with regression and polynomial content\n")

search_url = f"{base_url}/search/issues"
params = {
    'q': search_query,
    'sort': 'created',  # Sort by creation date
    'order': 'asc',     # Ascending order (oldest first)
    'per_page': 100     # Get more results per page
}

print("Making GitHub API request...")
response = requests.get(search_url, headers=headers, params=params)

print(f"Response status: {response.status_code}")
if response.status_code != 200:
    print(f"Error response: {response.text}")
    exit()

search_results = response.json()
total_count = search_results['total_count']
items = search_results['items']

print(f"Total issues found: {total_count}")
print(f"Issues retrieved in this page: {len(items)}\n")

if not items:
    print("No issues found with the search criteria.")
    exit()

print("=== ANALYZING REGRESSION + POLYNOMIAL ISSUES ===")
print("Filtering and analyzing issues for polynomial relevance...\n")

# Process each issue with proper variable definitions - FIX THE BUG HERE
polynomial_regression_issues = []
polynomial_keywords = ['polynomial', 'poly', 'chebyshev', 'legendre', 'hermite', 'laguerre']

for i, issue in enumerate(items, 1):
    # FIX: Define ALL variables at the beginning of the loop before any usage
    title = issue['title'] or ''
    body = issue['body'] or ''
    title_lower = title.lower()
    body_lower = body.lower()
    
    # Now check if issue is polynomial-related (variables are properly defined)
    is_polynomial_related = any(keyword in title_lower or keyword in body_lower for keyword in polynomial_keywords)
    
    # Check if issue mentions regression
    has_regression = 'regression' in title_lower or 'regression' in body_lower
    
    print(f"{i}. Issue #{issue['number']}: {title[:80]}...")
    print(f"   Created: {issue['created_at']}")
    print(f"   Closed: {issue['closed_at']}")
    print(f"   State: {issue['state']}")
    print(f"   Labels: {[label['name'] for label in issue['labels']]}")
    print(f"   Polynomial-related: {is_polynomial_related}")
    print(f"   Has regression keyword: {has_regression}")
    print(f"   URL: {issue['html_url']}")
    
    # Store relevant issues (both polynomial and regression related)
    if is_polynomial_related or has_regression:
        issue_data = {
            'number': issue['number'],
            'title': title,
            'created_at': issue['created_at'],
            'closed_at': issue['closed_at'],
            'state': issue['state'],
            'labels': [label['name'] for label in issue['labels']],
            'html_url': issue['html_url'],
            'api_url': issue['url'],
            'is_polynomial_related': is_polynomial_related,
            'has_regression': has_regression,
            'body_preview': body[:500] if body else '',
            'relevance_score': (2 if is_polynomial_related else 0) + (1 if has_regression else 0)
        }
        polynomial_regression_issues.append(issue_data)
    
    print()

print(f"=== SUMMARY OF RELEVANT ISSUES ===")
print(f"Total issues analyzed: {len(items)}")
print(f"Polynomial/regression relevant issues: {len(polynomial_regression_issues)}\n")

# Sort by creation date to find the oldest, then by relevance score
polynomial_regression_issues.sort(key=lambda x: (x['created_at'], -x['relevance_score']))

if polynomial_regression_issues:
    print("=== OLDEST RELEVANT ISSUES (sorted by creation date) ===")
    for i, issue in enumerate(polynomial_regression_issues[:10], 1):  # Show top 10 oldest
        print(f"{i}. Issue #{issue['number']}: {issue['title'][:60]}...")
        print(f"   Created: {issue['created_at']}")
        print(f"   Closed: {issue['closed_at']}")
        print(f"   Labels: {issue['labels']}")
        print(f"   Polynomial: {issue['is_polynomial_related']}, Regression: {issue['has_regression']}")
        print(f"   Relevance Score: {issue['relevance_score']}")
        print(f"   URL: {issue['html_url']}")
        print()
    
    # Identify the oldest issue for detailed timeline analysis
    oldest_issue = polynomial_regression_issues[0]
    print(f"=== OLDEST RELEVANT ISSUE IDENTIFIED ===")
    print(f"Issue #{oldest_issue['number']}: {oldest_issue['title']}")
    print(f"Created: {oldest_issue['created_at']}")
    print(f"Closed: {oldest_issue['closed_at']}")
    print(f"Current labels: {oldest_issue['labels']}")
    print(f"Polynomial-related: {oldest_issue['is_polynomial_related']}")
    print(f"Has regression: {oldest_issue['has_regression']}")
    print(f"API URL: {oldest_issue['api_url']}")
    print(f"\nNext step: Get detailed timeline for this issue to check label addition history")
    
    # Check if any issues have 'Regression' or related labels
    print(f"\n=== LABEL ANALYSIS ===")
    all_labels = set()
    regression_labeled_issues = []
    
    for issue in polynomial_regression_issues:
        all_labels.update(issue['labels'])
        # Check for regression-related labels
        regression_labels = [label for label in issue['labels'] if 'regression' in label.lower() or 'regress' in label.lower()]
        if regression_labels:
            regression_labeled_issues.append({
                'issue': issue,
                'regression_labels': regression_labels
            })
    
    print(f"All unique labels found: {sorted(list(all_labels))}")
    print(f"Issues with regression-related labels: {len(regression_labeled_issues)}")
    
    if regression_labeled_issues:
        print("\nIssues with regression-related labels:")
        for item in regression_labeled_issues:
            issue = item['issue']
            print(f"  Issue #{issue['number']}: {issue['title'][:50]}...")
            print(f"    Regression labels: {item['regression_labels']}")
            print(f"    Created: {issue['created_at']}")
            print()

# Save comprehensive results
results_data = {
    'search_timestamp': datetime.now().isoformat(),
    'search_query': search_query,
    'repository': repo,
    'total_issues_found': total_count,
    'issues_analyzed': len(items),
    'relevant_issues_count': len(polynomial_regression_issues),
    'oldest_issue': oldest_issue if polynomial_regression_issues else None,
    'all_relevant_issues': polynomial_regression_issues,
    'unique_labels_found': sorted(list(all_labels)) if polynomial_regression_issues else [],
    'regression_labeled_issues_count': len(regression_labeled_issues) if polynomial_regression_issues else 0,
    'next_action': 'Get detailed timeline for oldest issue to find label addition timestamp'
}

with open(f'{workspace_dir}/polynomial_regression_issues_fixed_analysis.json', 'w') as f:
    json.dump(results_data, f, indent=2)

print(f"\nDetailed analysis saved to: {workspace_dir}/polynomial_regression_issues_fixed_analysis.json")
print("Ready for next step: Timeline analysis of the oldest relevant issue to find when 'Regression' label was added")
```