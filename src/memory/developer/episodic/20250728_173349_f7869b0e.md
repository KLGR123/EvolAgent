### Development Step 3: Find Number of Encoder Layers in Transformer from ‘Attention is All You Need’ Paper

**Description**: Search for the original 'Attention is All You Need' paper to identify the number of encoder layers in the Transformer architecture. Use these search approaches: (1) Search for the paper title 'Attention is All You Need' on Google Scholar or arXiv, (2) Look for the official paper PDF which should be available on arXiv, (3) Extract the architecture details specifically focusing on the encoder structure and number of layers/blocks mentioned in the model description.

**Use Cases**:
- Automated extraction of encoder/decoder layer counts from NLP research papers to speed up AI architecture comparisons
- Patent due diligence for tech startups: scanning patent PDFs to pull out the number of claims, layers, or modules for portfolio analysis
- Clinical trial document analysis: extracting patient sample sizes and trial phase counts from medical study PDFs for regulatory reporting
- Financial compliance monitoring: scanning annual reports (10-K/20-F) to identify and extract specific risk disclosure sections with keyword and numeric patterns
- Legal contract review automation: pulling out clause numbers, renewal terms, and penalty figures from lengthy contract PDFs to populate a legal database
- Academic meta-analysis support: summarizing methodology details (e.g., number of participants, experimental groups) across dozens of research articles
- Product whitepaper feature auditing: extracting technical specification counts (e.g., sensor layers, processing modules) from IoT hardware whitepapers to inform R&D decisions
- Educational content indexing: analyzing textbook or lecture PDF files to automatically list chapter and section counts for curriculum management

```
from langchain_community.document_loaders import PyPDFLoader
import re
import os

# The path to the PDF file we downloaded
pdf_path = "workspace/attention_is_all_you_need.pdf"

# First, verify the PDF exists
if not os.path.exists(pdf_path):
    print(f"Error: PDF file '{pdf_path}' does not exist.")
else:
    print(f"PDF file found: {pdf_path}")
    print(f"File size: {os.path.getsize(pdf_path)} bytes")
    
    # Load and split PDF into pages using LangChain
    print("\nLoading PDF content using LangChain PyPDFLoader...")
    loader = PyPDFLoader(pdf_path)
    pages = loader.load_and_split()
    
    print(f"Total pages in PDF: {len(pages)}")
    
    if len(pages) == 0:
        print("No pages found in this PDF file.")
    else:
        # Let's search for architecture-related information in the first few pages
        # The model architecture is typically described early in the paper
        print("\nSearching for Transformer architecture details...")
        
        # Combine content from first 8 pages (where architecture details are likely to be)
        search_pages = pages[:8]
        combined_content = "\n".join([page.page_content for page in search_pages])
        
        print(f"\nAnalyzing first {len(search_pages)} pages for encoder layer information...")
        
        # Search for patterns related to encoder layers
        encoder_patterns = [
            r'encoder.*?layers?.*?(\d+)',
            r'(\d+).*?encoder.*?layers?',
            r'N\s*=\s*(\d+).*?encoder',
            r'encoder.*?N\s*=\s*(\d+)',
            r'layers?.*?N\s*=\s*(\d+)',
            r'(\d+).*?layers?.*?encoder',
            r'stack.*?(\d+).*?encoder.*?layers?',
            r'encoder.*?stack.*?(\d+).*?layers?'
        ]
        
        found_matches = []
        
        for pattern in encoder_patterns:
            matches = re.findall(pattern, combined_content, re.IGNORECASE)
            if matches:
                found_matches.extend([(pattern, match) for match in matches])
                print(f"Pattern '{pattern}' found matches: {matches}")
        
        # Also search for specific mentions of "6" in context of encoder or layers
        six_pattern = r'(?:encoder|layers?|stack).*?6|6.*?(?:encoder|layers?|stack)'
        six_matches = re.findall(six_pattern, combined_content, re.IGNORECASE)
        if six_matches:
            print(f"\nFound '6' in context of encoder/layers: {six_matches[:5]}")
        
        # Look for specific sections mentioning model architecture
        print("\nSearching for model architecture sections...")
        
        # Search for sections that might contain architecture details
        arch_keywords = ['model architecture', 'encoder', 'decoder', 'transformer', 'stack', 'layer']
        
        for i, page in enumerate(search_pages):
            content = page.page_content.lower()
            
            # Check if this page contains architecture-related keywords
            keyword_count = sum(1 for keyword in arch_keywords if keyword in content)
            
            if keyword_count >= 3:  # If page has multiple architecture keywords
                print(f"\n=== PAGE {i+1} - High architecture content ====")
                
                # Extract sentences containing 'encoder' and numbers
                sentences = page.page_content.split('.')
                for sentence in sentences:
                    if 'encoder' in sentence.lower() and any(char.isdigit() for char in sentence):
                        print(f"Relevant sentence: {sentence.strip()}")
                        
                # Look for specific patterns in this page
                page_encoder_matches = re.findall(r'[^.]*encoder[^.]*\d+[^.]*', page.page_content, re.IGNORECASE)
                if page_encoder_matches:
                    print(f"Encoder-related matches on page {i+1}:")
                    for match in page_encoder_matches[:3]:
                        print(f"  - {match.strip()}")
        
        # Save the extracted content to workspace for further analysis
        with open('workspace/attention_paper_content.txt', 'w', encoding='utf-8') as f:
            f.write(f"Attention is All You Need - PDF Content Analysis\n")
            f.write(f"={'='*50}\n\n")
            f.write(f"Total pages: {len(pages)}\n")
            f.write(f"Analyzed pages: {len(search_pages)}\n\n")
            f.write("COMBINED CONTENT FROM FIRST 8 PAGES:\n")
            f.write("="*50 + "\n")
            f.write(combined_content)
        
        print(f"\nPDF content saved to workspace/attention_paper_content.txt for detailed analysis")
        
        # Summary of findings
        print(f"\n=== SUMMARY ===")
        print(f"Total pattern matches found: {len(found_matches)}")
        if found_matches:
            print("Key findings:")
            for pattern, match in found_matches[:10]:  # Show first 10 matches
                print(f"  - Found number '{match}' with pattern: {pattern}")
        else:
            print("No clear encoder layer count found in initial pattern search.")
            print("Content saved to workspace/ for manual inspection.")
```