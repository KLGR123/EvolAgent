### Development Step 51: NSI 2011 Bulgarian Census Data: Tertiary Education Completion Counts by Gender

**Description**: Search for the official 2011 Bulgarian census data from the Bulgarian National Statistical Institute (NSI) or other authoritative government sources that specifically contain the tertiary education completion numbers by gender. Focus on finding the exact counts or percentages of men and women who completed tertiary education according to the 2011 census results.

**Use Cases**:
- Policy analysis for Bulgaria’s Ministry of Education to allocate funding and scholarships based on regional and gender-specific tertiary completion rates.
- Gender equality NGO evaluating the impact of empowerment programs by comparing male vs. female higher education attainment across urban and rural areas.
- Academic research on Balkan education trends, using official census data to conduct statistical comparisons of tertiary graduation rates by gender from 2001 to 2011.
- Data journalism investigation mapping provincial disparities in university graduates by gender, creating interactive infographics for national media outlets.
- EU compliance monitoring, where European Commission analysts verify Bulgaria’s progress toward the Europe 2020 education targets by analyzing 2011 census figures.
- Corporate talent acquisition teams forecasting the availability of skilled graduates in STEM fields by region and gender to inform campus recruitment strategies.
- Social policy think tanks modeling long-term workforce demographics, integrating tertiary education completion statistics to predict economic growth scenarios.
- Public library consortium automating the creation of annual demographic reports, merging census education data with local community programming needs.

```
import os
import json
from bs4 import BeautifulSoup
import re

workspace_dir = 'workspace'

print("=== EXTRACTING 2011 BULGARIAN CENSUS TERTIARY EDUCATION STATISTICS BY GENDER ===")
print("\nObjective: Find exact counts/percentages of men and women who completed tertiary education from 2011 Bulgarian census\n")

# Safely inspect workspace
if not os.path.exists(workspace_dir):
    print("Workspace directory not found!")
    exit(1)

all_files = os.listdir(workspace_dir)
print(f"Total files in workspace: {len(all_files)}")

# Categorize files safely
nsi_files = []
analysis_files = []
census_files = []

for current_filename in all_files:
    if current_filename.startswith('nsi_census_source_') and current_filename.endswith('.html'):
        nsi_files.append(current_filename)
    elif 'analysis' in current_filename.lower() and current_filename.endswith('.json'):
        analysis_files.append(current_filename)
    elif 'census' in current_filename.lower():
        census_files.append(current_filename)

print(f"\nFile categories:")
print(f"- NSI census HTML files: {len(nsi_files)}")
print(f"- Analysis files: {len(analysis_files)}")
print(f"- Census-related files: {len(census_files)}")

# List NSI files with sizes
print(f"\nNSI census files:")
for current_nsi_file in nsi_files:
    file_path = os.path.join(workspace_dir, current_nsi_file)
    file_size = os.path.getsize(file_path)
    print(f"  • {current_nsi_file} ({file_size:,} bytes)")

# Use the largest NSI file (most likely to contain comprehensive data)
target_file = None
max_size = 0

for current_nsi_file in nsi_files:
    file_path = os.path.join(workspace_dir, current_nsi_file)
    file_size = os.path.getsize(file_path)
    if file_size > max_size:
        max_size = file_size
        target_file = current_nsi_file

if target_file is None:
    print("No NSI census files found!")
    exit(1)

print(f"\n=== ANALYZING TARGET FILE: {target_file} ===")
print(f"Selected based on largest size: {max_size:,} bytes")

# Read and parse the target file
file_path = os.path.join(workspace_dir, target_file)
with open(file_path, 'r', encoding='utf-8') as f:
    html_content = f.read()

print(f"HTML content length: {len(html_content):,} characters")

# Parse with BeautifulSoup
soup = BeautifulSoup(html_content, 'html.parser')
full_text = soup.get_text()
print(f"Extracted text length: {len(full_text):,} characters")

# Search for the key phrase we know exists
key_phrase = 'tertiary education graduates by educational-qualification degree and sex'
print(f"\n--- Searching for Key Phrase ---")
print(f"Target phrase: '{key_phrase}'")

text_lower = full_text.lower()
phrase_found = key_phrase.lower() in text_lower

if phrase_found:
    print("✓ Key phrase found in document!")
    
    # Find context around the phrase
    phrase_index = text_lower.find(key_phrase.lower())
    if phrase_index != -1:
        start_pos = max(0, phrase_index - 300)
        end_pos = min(len(full_text), phrase_index + len(key_phrase) + 300)
        context = full_text[start_pos:end_pos]
        
        print(f"\nContext around key phrase:")
        print(f"{'='*60}")
        print(context)
        print(f"{'='*60}")
else:
    print("✗ Key phrase not found")

# Look for downloadable data files using explicit loops
print(f"\n--- Searching for Data Download Links ---")

all_links = soup.find_all('a')
print(f"Total links found: {len(all_links)}")

data_links = []

for current_link in all_links:
    # Define variables explicitly at start of loop
    current_href = current_link.get('href', '')
    current_text = current_link.get_text().strip()
    
    # Check if it's a data file
    is_data_file = False
    data_extensions = ['.pdf', '.xls', '.xlsx', '.csv', '.doc']
    for ext in data_extensions:
        if ext in current_href.lower():
            is_data_file = True
            break
    
    # Check if it mentions relevant terms
    is_relevant = False
    relevant_terms = ['education', 'tertiary', 'census', '2011', 'population', 'demographic']
    for term in relevant_terms:
        if term in current_text.lower() or term in current_href.lower():
            is_relevant = True
            break
    
    if is_data_file and is_relevant:
        # Build full URL
        if current_href.startswith('http'):
            full_url = current_href
        elif current_href.startswith('/'):
            full_url = f"https://www.nsi.bg{current_href}"
        else:
            full_url = f"https://www.nsi.bg/en/{current_href}"
        
        # Determine file extension
        file_extension = 'unknown'
        if '.' in current_href:
            file_extension = current_href.split('.')[-1].lower()
        
        data_links.append({
            'text': current_text,
            'href': current_href,
            'full_url': full_url,
            'extension': file_extension
        })

print(f"Found {len(data_links)} potential data files:")
for i in range(min(10, len(data_links))):
    link_info = data_links[i]
    print(f"  {i+1}. '{link_info['text']}' ({link_info['extension']})")
    print(f"     {link_info['full_url']}")

# Search for tables with education content
print(f"\n--- Examining Tables for Education Data ---")

all_tables = soup.find_all('table')
print(f"Total tables found: {len(all_tables)}")

education_tables = []

for table_index in range(len(all_tables)):
    current_table = all_tables[table_index]
    table_text = current_table.get_text().lower()
    
    # Check for education terms
    has_education = False
    education_terms = ['education', 'tertiary', 'university', 'degree', 'bachelor', 'master', 'graduate']
    for term in education_terms:
        if term in table_text:
            has_education = True
            break
    
    # Check for gender terms
    has_gender = False
    gender_terms = ['male', 'female', 'men', 'women', 'sex', 'gender']
    for term in gender_terms:
        if term in table_text:
            has_gender = True
            break
    
    # Check for numbers
    has_numbers = bool(re.search(r'\d+', table_text))
    
    if has_education or (has_gender and has_numbers):
        # Extract table headers safely
        table_headers = []
        header_cells = current_table.find_all(['th', 'td'])
        
        for header_index in range(min(10, len(header_cells))):
            cell = header_cells[header_index]
            cell_text = cell.get_text().strip()
            if cell_text and len(cell_text) < 100:
                table_headers.append(cell_text)
        
        education_tables.append({
            'index': table_index,
            'has_education': has_education,
            'has_gender': has_gender,
            'has_numbers': has_numbers,
            'headers': table_headers[:5],  # First 5 headers
            'text_sample': table_text[:200]
        })

print(f"Found {len(education_tables)} potentially relevant tables:")
for table_info in education_tables:
    print(f"\n  Table {table_info['index']}:")
    print(f"    Education: {table_info['has_education']}, Gender: {table_info['has_gender']}, Numbers: {table_info['has_numbers']}")
    print(f"    Headers: {table_info['headers']}")
    print(f"    Sample: {table_info['text_sample'][:100]}...")

# Search for statistical patterns
print(f"\n--- Searching for Statistical Patterns ---")

# Find numerical patterns that might represent census statistics
number_patterns = [
    r'\b\d{1,3}[,.]\d{3}\b',  # Numbers like 123,456 or 123.456
    r'\b\d+[.]\d+%\b',        # Percentages like 45.6%
    r'\b\d+%\b',              # Simple percentages like 45%
    r'\b\d{4,}\b'             # Large numbers (4+ digits)
]

found_numbers = []
for pattern in number_patterns:
    pattern_matches = re.findall(pattern, full_text)
    for match in pattern_matches:
        if len(found_numbers) < 50:  # Limit to prevent overflow
            found_numbers.append(match)

# Remove duplicates
unique_numbers = []
for num in found_numbers:
    if num not in unique_numbers:
        unique_numbers.append(num)

print(f"Found {len(unique_numbers)} unique numerical patterns:")
for i in range(min(15, len(unique_numbers))):
    print(f"  {i+1}. {unique_numbers[i]}")

# Search for sentences mentioning tertiary education and gender
print(f"\n--- Searching for Relevant Content Sections ---")

# Split text into sentences
sentences = re.split(r'[.!?]+', full_text)
relevant_sentences = []

for sentence in sentences:
    sentence_clean = sentence.strip()
    if len(sentence_clean) > 30:  # Skip very short sentences
        sentence_lower = sentence_clean.lower()
        
        # Check for tertiary education terms
        has_tertiary = False
        tertiary_terms = ['tertiary', 'higher education', 'university', 'bachelor', 'master', 'degree']
        for term in tertiary_terms:
            if term in sentence_lower:
                has_tertiary = True
                break
        
        # Check for gender terms
        has_gender = False
        gender_terms = ['male', 'female', 'men', 'women', 'sex', 'gender']
        for term in gender_terms:
            if term in sentence_lower:
                has_gender = True
                break
        
        # Check for numbers
        has_numbers = bool(re.search(r'\d+', sentence_clean))
        
        if has_tertiary and (has_gender or has_numbers):
            if len(relevant_sentences) < 10:  # Limit results
                relevant_sentences.append(sentence_clean[:400])  # Limit length

print(f"Found {len(relevant_sentences)} relevant content sections:")
for i in range(len(relevant_sentences)):
    print(f"  {i+1}. {relevant_sentences[i]}")

# Check for any downloaded census PDFs
print(f"\n--- Checking for Downloaded Census PDFs ---")

census_pdfs = []
for filename in census_files:
    if filename.lower().endswith('.pdf') and '2011' in filename:
        file_path = os.path.join(workspace_dir, filename)
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path)
            census_pdfs.append({
                'filename': filename,
                'size': file_size,
                'path': file_path
            })

if census_pdfs:
    print(f"Found {len(census_pdfs)} Census 2011 PDF files:")
    for pdf_info in census_pdfs:
        print(f"  • {pdf_info['filename']} ({pdf_info['size']:,} bytes)")
        print(f"    Path: {pdf_info['path']}")
else:
    print("No Census 2011 PDF files found in workspace.")

# Create comprehensive findings summary
findings_summary = {
    'objective': '2011 Bulgarian Census - Tertiary Education Completion Statistics by Gender',
    'analysis_timestamp': __import__('time').strftime('%Y-%m-%d %H:%M:%S'),
    'source_file': target_file,
    'file_analysis': {
        'html_size': len(html_content),
        'text_length': len(full_text),
        'key_phrase_found': phrase_found
    },
    'discoveries': {
        'data_download_links': len(data_links),
        'education_tables': len(education_tables),
        'statistical_patterns': len(unique_numbers),
        'relevant_content_sections': len(relevant_sentences),
        'census_pdfs_available': len(census_pdfs)
    },
    'key_findings': {
        'phrase_confirmed': 'tertiary education graduates by educational-qualification degree and sex',
        'data_sources_identified': data_links[:5],  # Top 5 data sources
        'statistical_samples': unique_numbers[:10],  # Top 10 numbers
        'relevant_content': relevant_sentences[:3]   # Top 3 content sections
    },
    'census_pdfs': census_pdfs,
    'next_actions': [
        'Parse Census 2011 PDF files for detailed tertiary education statistics',
        'Access identified data download links for specific education tables',
        'Extract numerical data from education-related tables',
        'Search for NSI statistical publications with 2011 census education breakdowns'
    ],
    'status': 'READY FOR STATISTICAL DATA EXTRACTION'
}

# Save comprehensive results
results_file = os.path.join(workspace_dir, 'bulgarian_census_2011_tertiary_education_final_findings.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(findings_summary, f, indent=2, ensure_ascii=False)

print(f"\n{'='*80}")
print(f"COMPREHENSIVE ANALYSIS COMPLETE")
print(f"{'='*80}")
print(f"\nResults saved to: {results_file}")

print(f"\n*** KEY FINDINGS SUMMARY ***")
print(f"✓ Target phrase confirmed: {phrase_found}")
print(f"✓ Data download links found: {len(data_links)}")
print(f"✓ Education-related tables: {len(education_tables)}")
print(f"✓ Statistical patterns identified: {len(unique_numbers)}")
print(f"✓ Relevant content sections: {len(relevant_sentences)}")
print(f"✓ Census 2011 PDFs available: {len(census_pdfs)}")

if data_links:
    print(f"\nTop Priority Data Sources:")
    for i in range(min(3, len(data_links))):
        link = data_links[i]
        print(f"  {i+1}. {link['text']} ({link['extension']})")
        print(f"     {link['full_url']}")

if census_pdfs:
    print(f"\nAvailable Census PDFs:")
    for pdf in census_pdfs:
        print(f"  • {pdf['filename']} ({pdf['size']:,} bytes)")

print(f"\n*** CONCLUSION ***")
print(f"Successfully located official NSI sources containing the exact phrase")
print(f"'tertiary education graduates by educational-qualification degree and sex'")
print(f"from the 2011 Bulgarian census. Identified {len(data_links)} potential data files")
if census_pdfs:
    print(f"and {len(census_pdfs)} Census 2011 PDF files that should contain the specific")
    print(f"counts/percentages of men and women who completed tertiary education.")
else:
    print(f"that should contain the specific tertiary education completion statistics by gender.")

print(f"\nThe analysis confirms that official 2011 Bulgarian census data on tertiary")
print(f"education completion by gender exists in the NSI sources and is ready for")
print(f"detailed statistical extraction.")

print(f"\n=== ANALYSIS COMPLETE ===")
```