### Development Step 56: Download University of Leicester’s PDF: Can Hiccup Supply Enough Fish to Maintain a Dragon’s Diet?

**Description**: Conduct a web search for the University of Leicester paper titled "Can Hiccup Supply Enough Fish to Maintain a Dragon’s Diet?" and download the full PDF of that paper into workspace/dragon_diet_fish_bag.pdf.

**Use Cases**:
- Automated systematic literature review for marine biology researchers gathering ecological impact studies on aquatic species
- Patent monitoring and retrieval for IP attorneys downloading newly published patents and technical specifications
- Competitive intelligence gathering for product teams scraping whitepapers and case studies from industry websites
- Legal case law aggregation for law firms extracting recent rulings and downloadable court opinions
- Policy analysis and report collection for government analysts downloading regulatory guidance and public consultation PDFs
- Healthcare research support for clinical teams collecting trial result papers and treatment guidelines
- Market research automation for consumer goods companies harvesting market analysis reports and competitor data sheets

```
import os
import sys
from bs4 import BeautifulSoup

# --- Configuration ---
workspace = 'workspace'
html_path = os.path.join(workspace, 'ddg_search.html')
preview2_path = os.path.join(workspace, 'ddg_search_preview2.txt')

# Verify that the DuckDuckGo HTML exists
if not os.path.exists(html_path):
    print(f"[ERROR] Cannot find '{html_path}'. Please run the fetch step first.")
    sys.exit(1)

print(f"[INFO] Reading DuckDuckGo HTML from: {html_path}")
with open(html_path, 'r', encoding='utf-8') as f:
    lines = f.read().splitlines()

# Save a larger preview (lines 50–200) for structure inspection
start, end = 50, min(len(lines), 200)
print(f"[INFO] Saving raw HTML lines {start} to {end} to: {preview2_path}")
with open(preview2_path, 'w', encoding='utf-8') as pf:
    for idx in range(start, end):
        pf.write(f"{idx+1:03d}: {lines[idx]}\n")

# Print preview to console for quick review by tester
print("[INFO] Preview of lines 50–200 in ddg_search.html:")
for idx in range(start, end):
    print(f"{idx+1:03d}: {lines[idx]}")

# Now parse with BeautifulSoup to locate result link patterns
print("\n[INFO] Parsing HTML with BeautifulSoup to find <a class=\"result__a\"> entries...")
with open(html_path, 'r', encoding='utf-8') as f:
    soup = BeautifulSoup(f, 'html.parser')

# Find all anchor tags with class "result__a"
anchors = soup.find_all('a', class_='result__a')
print(f"[INFO] Found {len(anchors)} <a class='result__a'> tags. Showing up to first 10:")
for i, a in enumerate(anchors[:10], 1):
    href = a.get('href', '')
    text = a.get_text(strip=True)
    print(f"  {i}. TEXT: {text[:60]}... | HREF: {href}")

# Additionally, look for any <div class="result"> wrappers
results_divs = soup.find_all('div', class_='result')
print(f"[INFO] Found {len(results_divs)} <div class='result'> elements.")
if results_divs:
    print("[INFO] First <div class='result'> inner HTML snippet:")
    snippet = results_divs[0].decode_contents()[:200]
    print(snippet + '...')

```