### Development Step 30: Search 2011 Bulgarian NSI Census for Tertiary Education Completion Numbers by Gender

**Description**: Search for the official 2011 Bulgarian census data from the Bulgarian National Statistical Institute (NSI) or other authoritative government sources that specifically contain the tertiary education completion numbers by gender. Focus on finding the exact counts or percentages of men and women who completed tertiary education according to the 2011 census results.

**Use Cases**:
- Public policy dashboard for the Bulgarian Ministry of Education to visualize and compare 2011 tertiary education completion rates by gender across regions, guiding targeted scholarship programs.
- Gender equality research report for an NGO analyzing male vs. female university graduation counts from the 2011 census to measure progress and propose new interventions.
- University admissions office forecasting tool that integrates 2011 gender‐segmented tertiary attainment data to predict applicant pools and tailor recruitment campaigns.
- Workforce planning model for a multinational corporation using regional tertiary education by gender from the 2011 census to decide on office locations and local talent acquisition strategies.
- Academic study on socio‐demographic trends automating extraction of 2011 Bulgarian census tertiary education figures by gender to perform longitudinal analyses in peer-reviewed publications.
- Data journalism investigation mapping historical gender gaps in higher education across Bulgarian provinces by scraping official NSI census tables and generating interactive infographics.
- Demographic forecasting system for a financial services firm that incorporates 2011 census tertiary qualification rates by gender to model future consumer behavior and credit scoring.

```
import os
import json
from bs4 import BeautifulSoup
import re

# Let's examine the most promising JSON file to understand its structure
workspace_dir = 'workspace'
promising_file = 'bulgarian_census_tertiary_education_comprehensive_final.json'
filepath = os.path.join(workspace_dir, promising_file)

print("=== DETAILED INSPECTION OF MOST PROMISING ANALYSIS FILE ===\n")
print(f"Examining: {promising_file}\n")

if os.path.exists(filepath):
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print("Complete file structure:")
    print(json.dumps(data, indent=2, ensure_ascii=False)[:2000] + "..." if len(json.dumps(data, indent=2)) > 2000 else json.dumps(data, indent=2, ensure_ascii=False))
    
    print("\n=== KEY SECTIONS ANALYSIS ===\n")
    
    # Examine detailed_data section
    if 'detailed_data' in data and data['detailed_data']:
        print("DETAILED_DATA section contains:")
        detailed_data = data['detailed_data']
        if isinstance(detailed_data, list):
            print(f"  - List with {len(detailed_data)} items")
            for i, item in enumerate(detailed_data[:3], 1):
                print(f"  Item {i}: {type(item)} - {str(item)[:200]}...")
        elif isinstance(detailed_data, dict):
            print(f"  - Dictionary with keys: {list(detailed_data.keys())}")
            for key, value in list(detailed_data.items())[:3]:
                print(f"  {key}: {type(value)} - {str(value)[:200]}...")
        else:
            print(f"  - {type(detailed_data)}: {str(detailed_data)[:200]}...")
    
    # Examine statistical_findings
    if 'statistical_findings' in data and data['statistical_findings']:
        print(f"\nSTATISTICAL_FINDINGS section (count: {data.get('statistical_findings', 0)}):")
        # This might be a count, let's see if there are actual findings stored elsewhere
        for key, value in data.items():
            if 'finding' in key.lower() or 'statistic' in key.lower():
                print(f"  {key}: {value}")
    
    # Examine census_2011_findings
    if 'census_2011_findings' in data and data['census_2011_findings']:
        print(f"\nCENSUS_2011_FINDINGS section (count: {data.get('census_2011_findings', 0)}):")
        # Look for actual census data
        for key, value in data.items():
            if '2011' in key.lower() or 'census' in key.lower():
                print(f"  {key}: {value}")
    
    print("\n=== SEARCHING FOR ACTUAL DATA VALUES ===\n")
    
    # Recursively search for any numerical data or gender-related information
    def find_data_recursively(obj, path=""):
        findings = []
        if isinstance(obj, dict):
            for key, value in obj.items():
                current_path = f"{path}.{key}" if path else key
                
                # Check if this key might contain relevant data
                key_lower = key.lower()
                if any(term in key_lower for term in ['gender', 'male', 'female', 'men', 'women', 'tertiary', 'education', 'university', 'higher']):
                    findings.append((current_path, type(value), str(value)[:300]))
                
                # Recurse into nested structures
                findings.extend(find_data_recursively(value, current_path))
        
        elif isinstance(obj, list):
            for i, item in enumerate(obj):
                current_path = f"{path}[{i}]"
                findings.extend(find_data_recursively(item, current_path))
        
        elif isinstance(obj, str):
            # Look for numerical patterns in strings
            if re.search(r'\d+', obj) and any(term in obj.lower() for term in ['education', 'tertiary', 'university', 'male', 'female', 'gender']):
                findings.append((path, "string_with_numbers", obj[:300]))
        
        return findings
    
    relevant_findings = find_data_recursively(data)
    
    if relevant_findings:
        print("Relevant data found in file:")
        for path, data_type, content in relevant_findings[:10]:  # Show first 10 findings
            print(f"  Path: {path}")
            print(f"  Type: {data_type}")
            print(f"  Content: {content}")
            print()
    else:
        print("No relevant gender/education data found in this file.")

else:
    print(f"File not found: {filepath}")

print("\n=== EXAMINING ACTUAL NSI HTML FILES FOR DIRECT PARSING ===\n")

# Since the JSON files don't seem to contain the actual data, let's try to directly parse
# the NSI HTML files, but first let's check if they actually contain readable content

nsi_files_to_check = [
    'www_nsi_bg_en_content_6710_population_education.html',
    'www_nsi_bg_en_content_6704_population_census_2011.html', 
    'nsi_source_1.html'
]

for nsi_file in nsi_files_to_check:
    filepath = os.path.join(workspace_dir, nsi_file)
    if os.path.exists(filepath):
        print(f"\n--- Direct parsing attempt: {nsi_file} ---")
        
        with open(filepath, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        print(f"File size: {len(html_content):,} characters")
        
        # Check if file contains actual HTML or is empty/corrupted
        if '<html' in html_content.lower() or '<body' in html_content.lower():
            print("✓ File contains HTML structure")
            
            # Parse with BeautifulSoup
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # Look for title
            title = soup.find('title')
            if title and title.get_text().strip():
                print(f"Page title: {title.get_text().strip()}")
            
            # Look for any text content
            text_content = soup.get_text().strip()
            if text_content:
                print(f"Text content length: {len(text_content)} characters")
                
                # Search for key terms
                text_lower = text_content.lower()
                key_terms = ['tertiary education', 'higher education', 'university', '2011', 'census', 'gender', 'male', 'female']
                
                found_terms = []
                for term in key_terms:
                    if term in text_lower:
                        count = text_lower.count(term)
                        found_terms.append(f"{term}: {count}")
                
                if found_terms:
                    print(f"Key terms found: {', '.join(found_terms)}")
                    
                    # If we found relevant terms, look for tables or structured data
                    tables = soup.find_all('table')
                    if tables:
                        print(f"Tables found: {len(tables)}")
                        
                        # Examine first table for structure
                        first_table = tables[0]
                        rows = first_table.find_all('tr')
                        print(f"First table has {len(rows)} rows")
                        
                        if rows:
                            # Show table headers
                            header_cells = rows[0].find_all(['th', 'td'])
                            headers = [cell.get_text().strip() for cell in header_cells]
                            print(f"Headers: {headers}")
                    
                    # Look for specific statistical data patterns
                    number_patterns = re.findall(r'\b\d{1,3}(?:,\d{3})*\b', text_content)
                    if number_patterns:
                        large_numbers = [n for n in number_patterns if len(n.replace(',', '')) >= 4]
                        if large_numbers:
                            print(f"Statistical numbers found: {large_numbers[:5]}")
                
                else:
                    print("No relevant terms found in content")
            else:
                print("No readable text content found")
        else:
            print("✗ File does not contain proper HTML structure")
            # Show first 500 characters to understand what's in the file
            print(f"File preview: {html_content[:500]}...")

print("\n=== ANALYSIS COMPLETE ===\n")
print("Summary: Examining existing data to determine if 2011 Bulgarian census tertiary education by gender data has been successfully extracted.")
```