### Development Step 3: Find ‚ÄòSacred Desire‚Äô Protagonist: Former Soviet Paratrooper Co-Founder Who Fled 1992 Crackdown

**Description**: Conduct a comprehensive web search to identify the book 'Sacred Desire' and its protagonist, focusing on finding information about a former Soviet paratrooper who co-founded an organization and fled due to a 1992 crackdown. Search for keywords including 'Sacred Desire book protagonist Soviet paratrooper', 'Sacred Desire novel former Soviet paratrooper co-founder', '1992 crackdown organization Soviet paratrooper fled', and 'Sacred Desire character co-founded organization 1992'. Extract details about the protagonist's identity, the organization they co-founded, and the circumstances of the 1992 crackdown.

**Use Cases**:
- Genealogical research tracing a former Soviet paratrooper ancestor who co-founded an organization and fled after the 1992 crackdown, compiling web evidence to build an accurate family history
- Academic historian mapping post-Soviet veteran associations by extracting founder identities, organization timelines, and suppression events for a conference paper on early Russian political movements
- Investigative journalist verifying a book‚Äôs claims about a Soviet airborne forces veteran turned dissident, cross-referencing multiple search engines to validate dates, biographies, and organizational ties
- Legal due-diligence team fact-checking the protagonist‚Äôs background and associated organization in ‚ÄúSacred Desire‚Äù to ensure biographies used in publishing contracts are accurate and defensible
- Library metadata specialist enriching catalog entries for Cold War-era literature by harvesting character details, organizational founding dates, and historical context from web sources
- Human-rights NGO documenting state crackdowns on veteran groups in early 1990s Russia, aggregating URLs, eyewitness accounts, and legal documents to support advocacy reports
- Data analyst building a knowledge graph of ex-Soviet military figures, applying scoring and keyword matches to web-scraped results for an intelligence database on political dissidents
- Publishing rights clearance department automating targeted web searches to identify obscure titles, authors, and character backstories to streamline international licensing negotiations

```
import json
import os
from ddgs import DDGS
import time
from datetime import datetime

# First, let's inspect the existing search results file to understand its structure
results_file = 'workspace/sacred_desire_comprehensive_search_results.json'

print('=== INSPECTING AND FIXING PREVIOUS SEARCH RESULTS ===') 
print('=' * 60)

if os.path.exists(results_file):
    print(f'‚úÖ Found previous search results file: {results_file}')
    
    # Load and inspect the JSON structure
    with open(results_file, 'r', encoding='utf-8') as f:
        previous_results = json.load(f)
    
    print(f'\nüìã FILE STRUCTURE INSPECTION:')
    for key in previous_results.keys():
        if isinstance(previous_results[key], list):
            print(f'  ‚Ä¢ {key}: list with {len(previous_results[key])} items')
        elif isinstance(previous_results[key], dict):
            print(f'  ‚Ä¢ {key}: dict with keys: {list(previous_results[key].keys())}')
        else:
            print(f'  ‚Ä¢ {key}: {type(previous_results[key])} - {str(previous_results[key])[:100]}')
    
    # Inspect the structure of individual results
    if 'all_results' in previous_results and len(previous_results['all_results']) > 0:
        print(f'\nüîç SAMPLE RESULT STRUCTURE:')
        sample_result = previous_results['all_results'][0]
        for key, value in sample_result.items():
            print(f'  ‚Ä¢ {key}: {type(value)} - {str(value)[:100]}{"..." if len(str(value)) > 100 else ""}')
        
        print(f'\nüîß RE-ANALYZING {len(previous_results["all_results"])} SEARCH RESULTS WITH FIXED LOGIC')
        print('-' * 60)
        
        # Initialize corrected analysis containers
        corrected_analysis = {
            'high_relevance_results': [],
            'book_candidates': [],
            'protagonist_details': [],
            'soviet_paratrooper_matches': [],
            'organization_matches': [],
            'crackdown_1992_matches': []
        }
        
        # Re-analyze each result with corrected logic - FIX THE SCOPE BUG
        for result_idx, result in enumerate(previous_results['all_results'], 1):
            title = result.get('title', 'No title')
            description = result.get('description', 'No description')
            url = result.get('url', 'No URL')
            
            print(f'\nProcessing result {result_idx}: {title[:50]}...')
            print(f'  URL: {url}')
            
            # FIX: Define combined_text properly in the correct scope
            combined_text = f'{title.lower()} {description.lower()}'
            
            # Recalculate relevance score with corrected logic
            relevance_score = 0
            matched_terms = []
            
            # Enhanced key terms and weights
            key_terms = {
                'sacred desire': 5,
                'soviet': 3,
                'paratrooper': 4,
                'co-founded': 3,
                'organization': 2,
                '1992': 3,
                'crackdown': 3,
                'fled': 2,
                'protagonist': 2,
                'character': 1,
                'book': 2,
                'novel': 2,
                'military': 1,
                'veteran': 2,
                'founder': 2
            }
            
            # Calculate relevance score
            for term, weight in key_terms.items():
                if term in combined_text:
                    relevance_score += weight
                    matched_terms.append(term)
            
            # Update result with corrected analysis
            result['corrected_relevance_score'] = relevance_score
            result['corrected_matched_terms'] = matched_terms
            result['combined_text_length'] = len(combined_text)
            
            print(f'  Corrected Score: {relevance_score}')
            print(f'  Matched Terms: {matched_terms}')
            
            # Categorize results with corrected logic - FIX: Use local combined_text variable
            if relevance_score >= 8:
                corrected_analysis['high_relevance_results'].append(result)
                print('  ‚≠ê HIGH RELEVANCE')
            
            if 'sacred desire' in combined_text and relevance_score >= 5:
                corrected_analysis['book_candidates'].append(result)
                print('  üìö BOOK CANDIDATE')
            
            # FIX: Check terms directly in combined_text instead of using generator
            has_soviet_or_paratrooper = 'soviet' in combined_text or 'paratrooper' in combined_text
            if has_soviet_or_paratrooper and relevance_score >= 4:
                corrected_analysis['protagonist_details'].append(result)
                print('  üë§ PROTAGONIST DETAIL')
            
            # Specific category matches - FIX: Use direct checks
            if 'soviet' in combined_text and 'paratrooper' in combined_text:
                corrected_analysis['soviet_paratrooper_matches'].append(result)
                print('  ü™ñ SOVIET PARATROOPER MATCH')
            
            has_org_terms = ('organization' in combined_text or 
                           'co-founded' in combined_text or 
                           'founder' in combined_text)
            if has_org_terms:
                corrected_analysis['organization_matches'].append(result)
                print('  üè¢ ORGANIZATION MATCH')
            
            has_crackdown_terms = ('crackdown' in combined_text or 'fled' in combined_text)
            if '1992' in combined_text and has_crackdown_terms:
                corrected_analysis['crackdown_1992_matches'].append(result)
                print('  üìÖ 1992 CRACKDOWN MATCH')
        
        # Display corrected analysis results
        print('\n' + '=' * 60)
        print('üìä CORRECTED ANALYSIS RESULTS')
        print('=' * 60)
        
        print(f'\nüìà CATEGORY BREAKDOWN:')
        print(f'  ‚Ä¢ High relevance results: {len(corrected_analysis["high_relevance_results"])}')
        print(f'  ‚Ä¢ Book candidates: {len(corrected_analysis["book_candidates"])}')
        print(f'  ‚Ä¢ Protagonist details: {len(corrected_analysis["protagonist_details"])}')
        print(f'  ‚Ä¢ Soviet paratrooper matches: {len(corrected_analysis["soviet_paratrooper_matches"])}')
        print(f'  ‚Ä¢ Organization matches: {len(corrected_analysis["organization_matches"])}')
        print(f'  ‚Ä¢ 1992 crackdown matches: {len(corrected_analysis["crackdown_1992_matches"])}')
        
        # Show detailed results by category
        if corrected_analysis['high_relevance_results']:
            print(f'\nüéØ HIGH-RELEVANCE RESULTS:')
            sorted_high = sorted(corrected_analysis['high_relevance_results'], 
                               key=lambda x: x['corrected_relevance_score'], reverse=True)
            for i, result in enumerate(sorted_high, 1):
                print(f'\n{i}. SCORE: {result["corrected_relevance_score"]}')
                print(f'   Title: {result["title"]}')
                print(f'   URL: {result["url"]}')
                print(f'   Terms: {result["corrected_matched_terms"]}')
                print(f'   Description: {result["description"][:200]}...')
        
        if corrected_analysis['book_candidates']:
            print(f'\nüìö BOOK CANDIDATES:')
            for i, result in enumerate(corrected_analysis['book_candidates'], 1):
                print(f'\n{i}. {result["title"]}')
                print(f'   Score: {result["corrected_relevance_score"]}')
                print(f'   URL: {result["url"]}')
                print(f'   Terms: {result["corrected_matched_terms"]}')
                print(f'   Description: {result["description"][:150]}...')
        
        if corrected_analysis['soviet_paratrooper_matches']:
            print(f'\nü™ñ SOVIET PARATROOPER MATCHES:')
            for i, result in enumerate(corrected_analysis['soviet_paratrooper_matches'], 1):
                print(f'\n{i}. {result["title"]}')
                print(f'   Score: {result["corrected_relevance_score"]}')
                print(f'   URL: {result["url"]}')
                print(f'   Terms: {result["corrected_matched_terms"]}')
        
        if corrected_analysis['organization_matches']:
            print(f'\nüè¢ ORGANIZATION MATCHES:')
            for i, result in enumerate(corrected_analysis['organization_matches'], 1):
                print(f'\n{i}. {result["title"]}')
                print(f'   Score: {result["corrected_relevance_score"]}')
                print(f'   URL: {result["url"]}')
                print(f'   Terms: {result["corrected_matched_terms"]}')
        
        # Save corrected analysis
        corrected_results = previous_results.copy()
        corrected_results['corrected_analysis'] = corrected_analysis
        corrected_results['analysis_timestamp'] = datetime.now().isoformat()
        corrected_results['bug_fix_applied'] = 'Fixed combined_text variable scope issue'
        
        corrected_file = 'workspace/sacred_desire_corrected_analysis.json'
        with open(corrected_file, 'w', encoding='utf-8') as f:
            json.dump(corrected_results, f, indent=2, ensure_ascii=False)
        
        print(f'\nüíæ Corrected analysis saved to: {corrected_file}')
        
    else:
        print('\n‚ùå No search results data found in previous file')
else:
    print(f'‚ùå Previous search results file not found: {results_file}')

# Since the corrected analysis may still not find the specific book, let's conduct new targeted searches
print('\n' + '=' * 60)
print('üîç CONDUCTING ADDITIONAL TARGETED SEARCHES')
print('=' * 60)

# New search queries focusing on different aspects without requiring "Sacred Desire"
additional_queries = [
    'Soviet paratrooper co-founded organization 1992 crackdown fled',
    '1992 Russia military veteran organization crackdown suppression',
    'Soviet airborne forces veteran organization 1992 disbanded',
    'Russian paratrooper political organization 1992 government action',
    'post-Soviet military veterans association 1992 banned',
    'VDV paratrooper organization Russia 1992 closed',
    'Soviet veteran group 1992 political crackdown fled country'
]

# Initialize new search results
new_search_results = {
    'search_timestamp': datetime.now().isoformat(),
    'additional_queries': additional_queries,
    'new_results': [],
    'relevant_findings': [],
    'search_summary': {}
}

print(f'Executing {len(additional_queries)} additional targeted searches...')

successful_searches = 0
total_new_results = 0

for query_num, query in enumerate(additional_queries, 1):
    print(f'\nüîç SEARCH {query_num}/{len(additional_queries)}: {query}')
    print('-' * 50)
    
    try:
        searcher = DDGS(timeout=15)
        results = searcher.text(
            query,
            max_results=12,
            page=1,
            backend=["google", "duckduckgo", "bing", "yahoo"],
            safesearch="off",
            region="en-us"
        )
        
        if results == []:
            print(f'‚ùå No results for: "{query}"')
        else:
            print(f'‚úÖ Found {len(results)} results')
            successful_searches += 1
            total_new_results += len(results)
            
            for result_num, result in enumerate(results, 1):
                title = result.get('title', 'No title')
                body = result.get('body', 'No description')
                href = result.get('href', 'No URL')
                
                # Analyze for relevance to our target
                combined_text = f'{title.lower()} {body.lower()}'
                
                relevance_indicators = []
                if 'soviet' in combined_text or 'russian' in combined_text or 'ussr' in combined_text:
                    relevance_indicators.append('soviet/russian')
                if 'paratrooper' in combined_text or 'airborne' in combined_text or 'vdv' in combined_text:
                    relevance_indicators.append('paratrooper/airborne')
                if 'organization' in combined_text or 'co-founded' in combined_text or 'association' in combined_text:
                    relevance_indicators.append('organization')
                if '1992' in combined_text:
                    relevance_indicators.append('1992')
                if 'crackdown' in combined_text or 'suppression' in combined_text or 'banned' in combined_text:
                    relevance_indicators.append('crackdown/suppression')
                if 'fled' in combined_text or 'exile' in combined_text or 'escaped' in combined_text:
                    relevance_indicators.append('fled/exile')
                
                result_data = {
                    'query': query,
                    'title': title,
                    'url': href,
                    'description': body,
                    'relevance_indicators': relevance_indicators,
                    'relevance_count': len(relevance_indicators)
                }
                
                new_search_results['new_results'].append(result_data)
                
                # Flag highly relevant results
                if len(relevance_indicators) >= 3:
                    new_search_results['relevant_findings'].append(result_data)
                    print(f'\n  ‚≠ê HIGHLY RELEVANT Result {result_num}:')
                    print(f'     Title: {title}')
                    print(f'     URL: {href}')
                    print(f'     Indicators ({len(relevance_indicators)}): {relevance_indicators}')
                    print(f'     Description: {body[:200]}...')
                elif len(relevance_indicators) >= 2:
                    print(f'\n  ‚úì Relevant Result {result_num}: {title[:60]}...')
                    print(f'    Indicators ({len(relevance_indicators)}): {relevance_indicators}')
                
    except Exception as e:
        print(f'‚ùå Error in search {query_num}: {str(e)}')
    
    # Rate limiting
    if query_num < len(additional_queries):
        print(f'‚è≥ Waiting 3 seconds before next search...')
        time.sleep(3)

# Compile search summary
new_search_results['search_summary'] = {
    'queries_attempted': len(additional_queries),
    'successful_searches': successful_searches,
    'total_new_results': total_new_results,
    'relevant_findings_count': len(new_search_results['relevant_findings'])
}

# Final analysis
print('\n' + '=' * 60)
print('üìã COMPREHENSIVE FINAL ANALYSIS')
print('=' * 60)

print(f'\nüìä ADDITIONAL SEARCH SUMMARY:')
print(f'  ‚Ä¢ Queries attempted: {len(additional_queries)}')
print(f'  ‚Ä¢ Successful searches: {successful_searches}')
print(f'  ‚Ä¢ New results collected: {total_new_results}')
print(f'  ‚Ä¢ Highly relevant findings: {len(new_search_results["relevant_findings"])}')

if new_search_results['relevant_findings']:
    print(f'\nüéØ TOP RELEVANT NEW FINDINGS:')
    sorted_new = sorted(new_search_results['relevant_findings'], 
                       key=lambda x: x['relevance_count'], reverse=True)
    
    for i, finding in enumerate(sorted_new[:5], 1):
        print(f'\n{i}. Relevance Score: {finding["relevance_count"]}/6')  
        print(f'   Title: {finding["title"]}')
        print(f'   URL: {finding["url"]}')
        print(f'   Indicators: {finding["relevance_indicators"]}')
        print(f'   Description: {finding["description"][:250]}...')
        print(f'   Query: {finding["query"]}')
else:
    print('\n‚ö†Ô∏è  No highly relevant findings in additional searches')

# Save additional search results
additional_file = 'workspace/sacred_desire_additional_searches.json'
with open(additional_file, 'w', encoding='utf-8') as f:
    json.dump(new_search_results, f, indent=2, ensure_ascii=False)

print(f'\nüíæ Additional search results saved to: {additional_file}')

print('\nüéØ FINAL CONCLUSION:')
if new_search_results['relevant_findings']:
    print('‚úÖ Found relevant information about Soviet paratroopers and 1992 events')
    print('üìã Investigate specific findings for potential "Sacred Desire" connections')
    print('üîç Consider following up on URLs with highest relevance scores')
else:
    print('‚ö†Ô∏è  "Sacred Desire" with the specified protagonist characteristics may be:')
    print('   ‚Ä¢ A fictional work not widely available online')
    print('   ‚Ä¢ Known by a different or translated title')
    print('   ‚Ä¢ Part of a larger anthology or collection')
    print('   ‚Ä¢ An unpublished or limited circulation work')
    print('üìã Recommend: Contact specialized literary databases or Russian literature experts')

print('\nüìÅ FILES CREATED:')
print('  ‚Ä¢ workspace/sacred_desire_corrected_analysis.json (fixed analysis of original results)')
print('  ‚Ä¢ workspace/sacred_desire_additional_searches.json (new targeted search results)')

print('\n=== COMPREHENSIVE SEARCH AND ANALYSIS COMPLETE ===')
```