### Development Step 14: Compile U.S. Presidents’ Birthplaces with City, State, and Geographic Coordinates in JSON

**Description**: Collect a complete list of all United States presidents with their official birth city names and state names, then obtain the geographic coordinates (longitude and latitude) for each birth city using authoritative sources such as official presidential biographies or Wikipedia infoboxes. Save the results in a structured format (e.g., CSV or JSON) at workspace/presidential_birthplaces.json.

**Use Cases**:
- Developing an interactive educational map for a history e-learning platform that plots each U.S. president’s birth city and state using geocoded coordinates to enhance student engagement
- Powering a political science research dashboard that correlates presidential birth regions with historical voting patterns and demographic shifts
- Automating content generation for a travel app’s “Presidential Birthplaces Tour,” using latitude/longitude data to recommend driving routes between birth towns
- Enriching a digital museum exhibit on American presidents by verifying birthplace locations and displaying accurate city markers on a touchscreen display
- Feeding a genealogy software’s timeline view with precise birth city coordinates to help users visualize ancestral connections to presidential origins
- Supporting a data journalism investigation into geographic diversity in U.S. leadership by overlaying presidential birth locations onto socio-economic maps
- Enabling a civic-tech hackathon project that sends location-based notifications about nearby presidential birth sites with historical context
- Integrating birthplace coordinate data into a mobile quiz game that challenges users to match presidents to their birth cities on a real-time interactive map

```
import os
import re
import time
import json
import requests
from bs4 import BeautifulSoup, NavigableString
from geopy.geocoders import Nominatim

# Ensure workspace directory exists
workspace = 'workspace'
os.makedirs(workspace, exist_ok=True)

# 1. Load or fetch the Wikipedia page listing U.S. presidents
list_html_path = os.path.join(workspace, 'presidents_list.html')
if os.path.exists(list_html_path):
    print(f"Loading cached presidents list from {list_html_path}")
    with open(list_html_path, 'r', encoding='utf-8') as f:
        list_html = f.read()
else:
    list_url = 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States'
    print(f"Fetching presidents list: {list_url}")
    resp = requests.get(list_url, timeout=10)
    resp.raise_for_status()
    list_html = resp.text
    with open(list_html_path, 'w', encoding='utf-8') as f:
        f.write(list_html)
    print(f"Saved HTML to {list_html_path}")

# 2. Parse the main table of presidents
soup = BeautifulSoup(list_html, 'html.parser')
table = soup.find('table', class_='wikitable')
rows = table.find_all('tr')[1:]
print(f"Found {len(rows)} rows (including acting entries) in the presidents table")

# 3. Collect name and individual page URL for each president
presidents = []
for row in rows:
    cols = row.find_all('td')
    if len(cols) < 2:
        continue
    link = cols[1].find('a', href=True)
    if not link:
        continue
    name = link.get_text(strip=True)
    url = 'https://en.wikipedia.org' + link['href']
    presidents.append({'name': name, 'url': url})
print(f"Collected {len(presidents)} president entries to process")

# 4. Utility to extract birthplace from a president's page soup
unwanted_trailing = re.compile(r'^(British America|United States|U\.?S\.?A?\.?|USA)$', re.I)

def extract_birthplace(soup):
    # Try <span class="birthplace">
    span_bp = soup.select_one('span.birthplace')
    if span_bp and span_bp.get_text(strip=True):
        return span_bp.get_text(strip=True)
    # Fallback: look for the 'Born' row in the infobox
    infobox = soup.find('table', class_=lambda c: c and 'infobox' in c)
    if infobox:
        born_tr = infobox.find(lambda tag: tag.name == 'tr'
                                and tag.th
                                and tag.th.get_text(strip=True).startswith('Born'))
        if born_tr:
            td = born_tr.find('td')
            if td:
                # Split HTML on <br> to separate date from place
                parts = re.split(r'<br\s*/?>', str(td), flags=re.IGNORECASE)
                if len(parts) >= 2:
                    place_html = parts[1]
                    # Remove <small> annotations
                    place_html = re.sub(r'<small[^>]*>.*?</small>', '', place_html,
                                        flags=re.DOTALL|re.IGNORECASE)
                    # Extract clean text
                    return BeautifulSoup(place_html, 'html.parser').get_text(separator=' ', strip=True)
    return ''

# 5. Initialize geocoder and results container
geolocator = Nominatim(user_agent='presidential_birth_locator')
results = []

# 6. Process each president
for idx, pres in enumerate(presidents, start=1):
    name = pres['name']
    url = pres['url']
    print(f"\n[{idx}/{len(presidents)}] {name}\nFetching page: {url}")
    # Fetch the president's page
    try:
        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
        page_soup = BeautifulSoup(resp.text, 'html.parser')
    except Exception as e:
        print(f"  -> Error fetching '{name}': {e}")
        # Append placeholder and continue
        results.append({
            'name': name,
            'birth_city': None,
            'birth_state': None,
            'latitude': None,
            'longitude': None
        })
        continue
    time.sleep(1)

    # Extract raw birthplace string
    raw_place = extract_birthplace(page_soup)
    if raw_place:
        print(f"  Raw birthplace: '{raw_place}'")
    else:
        print(f"  Warning: could not extract birthplace for {name}")

    # 7. Clean the raw_place
    clean = re.sub(r'\([^)]*\)', '', raw_place)   # remove parentheses
    clean = re.sub(r'\[.*?\]', '', clean)         # remove citations
    clean = clean.strip()

    # 8. Tokenize by comma and drop date-like tokens
    tokens = [tok.strip() for tok in clean.split(',') if tok.strip()]
    while tokens and re.search(r'\d', tokens[0]):
        tokens.pop(0)
    # Drop trailing unwanted tokens
    while tokens and unwanted_trailing.match(tokens[-1]):
        tokens.pop()
    birth_clean = ', '.join(tokens)
    print(f"  Tokens after cleaning: {tokens}")
    print(f"  Cleaned birthplace: '{birth_clean}'")

    # 9. Derive city and state
    city = tokens[0] if len(tokens) >= 1 else None
    state = tokens[1] if len(tokens) >= 2 else None
    print(f"  Parsed city='{city}', state='{state}'")

    # 10. Geocode: try 'City, State, USA' then fallback to full place
    latitude = longitude = None
    if city and state:
        for query in [f"{city}, {state}, USA", f"{birth_clean}, USA"]:
            print(f"  Geocoding '{query}'...")
            try:
                loc = geolocator.geocode(query, timeout=10)
            except Exception as ge:
                print(f"   -> Geocoding exception: {ge}")
                loc = None
            time.sleep(1)
            if loc:
                latitude, longitude = loc.latitude, loc.longitude
                print(f"   -> Coordinates: ({latitude}, {longitude})")
                break
    else:
        print(f"  Insufficient data to geocode for {name}")

    # 11. Record the result
    entry = {
        'name': name,
        'birth_city': city,
        'birth_state': state,
        'latitude': latitude,
        'longitude': longitude
    }
    results.append(entry)
    print(f"  Recorded entry: {entry}")

# 12. Save all results to JSON
out_path = os.path.join(workspace, 'presidential_birthplaces.json')
with open(out_path, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2)
print(f"\nFinished: {len(results)} president records saved to {out_path}")

```