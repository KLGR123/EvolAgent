### Development Step 6: Identify Illustrator, Publication Details, and Writer Collaborations for the “Little Monsters” Comic Book

**Description**: Search for information about the comic book 'Little Monsters' to identify its illustrator/artist. Focus on finding the artist who illustrated this comic and any information about their collaborations with writers. Look for official publication details, creator credits, and any collaborative relationships mentioned in connection with this work.

**Use Cases**:
- Automated metadata enrichment for a comic book database by scraping creator credits and publication details of “Little Monsters” to ensure accurate catalog entries in a digital library
- Due-diligence verification of artist and writer collaborations for licensing negotiations in a graphic-novel publishing house
- Fan-wiki content generation that compiles illustrator biographies and partnership histories for niche comic communities
- Market research analysis of indie horror comics by extracting illustrator names and publisher affiliations to identify emerging talent trends
- Academic study of comic-book collaboration networks by harvesting “art by” and “written by” attributions across multiple “Little Monsters” editions
- Automated quality control in a comic-distribution workflow that flags missing or inconsistent artist credits before print runs
- Competitive intelligence gathering for a digital comics platform by monitoring new “Little Monsters” releases and their creative teams across publishers

```
import os
import requests
from bs4 import BeautifulSoup
import json
import time
from urllib.parse import quote
import re
from collections import Counter

# Create workspace directory if it doesn't exist
os.makedirs('workspace', exist_ok=True)

print("=== SEARCHING FOR 'LITTLE MONSTERS' COMIC ARTIST/ILLUSTRATOR ===")
print("Objective: Identify the artist who illustrated the 'Little Monsters' comic")
print("Focus: Creator credits, publication details, collaborative relationships")
print("=" * 70)

# Initialize search results storage
search_results = {
    'comic_matches_found': [],
    'artist_information': [],
    'publication_details': [],
    'search_attempts': [],
    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
}

print("\nSTEP 1: Conducting targeted Google searches for 'Little Monsters' comic")
print("-" * 60)

# Specific search queries to find the comic and its artist
search_queries = [
    '"Little Monsters" comic book artist illustrator creator',
    'Little Monsters comic series artist name writer',
    'Little Monsters graphic novel publication artist credits',
    'Little Monsters comic book "created by" "art by" "written by"',
    'Little Monsters horror comic artist illustrator indie'
]

for i, query in enumerate(search_queries, 1):
    print(f"\nSearch {i}: {query}")
    
    # Define headers within the loop to avoid scoping issues
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Connection': 'keep-alive'
    }
    
    # Construct Google search URL
    google_url = f"https://www.google.com/search?q={quote(query)}"
    
    try:
        print(f"Requesting: {google_url}")
        response = requests.get(google_url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
        
        # Get clean text content
        text_content = soup.get_text()
        
        # Look for search result containers
        search_snippets = []
        
        # Try multiple selectors for Google search results
        result_selectors = ['.g', '.tF2Cxc', '.MjjYud', '.yuRUbf']
        results = []
        
        for selector in result_selectors:
            found_results = soup.select(selector)
            if found_results:
                results = found_results[:5]  # First 5 results
                break
        
        print(f"  Found {len(results)} search result containers")
        
        # Extract information from search results
        for result in results:
            # Try to find title and description
            title_elem = result.find(['h3', 'a'])
            desc_elem = result.find(['span', 'div'], string=lambda text: text and len(text) > 20)
            
            title = title_elem.get_text() if title_elem else ''
            description = desc_elem.get_text() if desc_elem else ''
            
            # Combine title and description for analysis
            combined_text = f"{title} {description}".lower()
            
            # Look for creator-related keywords
            creator_keywords = ['artist', 'illustrator', 'creator', 'writer', 'by ', 'created by', 'art by', 'illustrated by']
            
            if any(keyword in combined_text for keyword in creator_keywords) and 'little monsters' in combined_text:
                search_snippets.append({
                    'title': title[:150],
                    'description': description[:300],
                    'relevance_score': sum(1 for kw in creator_keywords if kw in combined_text)
                })
                
                print(f"    RELEVANT: {title[:80]}...")
                print(f"    Desc: {description[:120]}...")
        
        # Also search the full page text for artist mentions
        artist_mentions = []
        lines = text_content.split('\n')
        
        for line in lines:
            line_lower = line.strip().lower()
            if ('little monsters' in line_lower and 
                any(keyword in line_lower for keyword in ['artist', 'illustrator', 'creator', 'by '])):
                
                # Clean up the line
                clean_line = ' '.join(line.strip().split())
                if len(clean_line) > 20 and len(clean_line) < 200:
                    artist_mentions.append(clean_line)
        
        if artist_mentions:
            print(f"  Found {len(artist_mentions)} potential artist mentions:")
            for mention in artist_mentions[:3]:  # Show first 3
                print(f"    - {mention[:100]}...")
        
        # Record search attempt
        search_results['search_attempts'].append({
            'query': query,
            'source': 'Google Search',
            'results_found': len(search_snippets),
            'snippets': search_snippets,
            'artist_mentions': artist_mentions[:5]  # Limit to 5 mentions
        })
        
        # Save raw HTML for manual inspection
        filename = f"workspace/google_search_{i}.html"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(response.text)
        print(f"  Raw HTML saved to: {filename}")
        
    except Exception as e:
        print(f"  ✗ Request failed: {e}")
        search_results['search_attempts'].append({
            'query': query,
            'source': 'Google Search',
            'status': 'Failed',
            'error': str(e)
        })
    
    # Add delay between requests to be respectful
    time.sleep(3)

print("\nSTEP 2: Searching for specific comic publishers and 'Little Monsters'")
print("-" * 60)

# Search for specific publisher connections
publisher_queries = [
    'Little Monsters Image Comics artist creator credits',
    'Little Monsters Dark Horse Comics illustrator',
    'Little Monsters IDW Publishing artist writer',
    'Little Monsters Boom Studios creator team',
    'Little Monsters Oni Press artist illustrator'
]

for query in publisher_queries:
    print(f"\nPublisher search: {query}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Connection': 'keep-alive'
    }
    
    google_url = f"https://www.google.com/search?q={quote(query)}"
    
    try:
        response = requests.get(google_url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        text_content = soup.get_text().lower()
        
        # Check for specific publisher mentions with Little Monsters
        publisher_found = False
        
        if 'image comics' in text_content and 'little monsters' in text_content:
            publisher_found = 'Image Comics'
        elif 'dark horse' in text_content and 'little monsters' in text_content:
            publisher_found = 'Dark Horse Comics'
        elif 'idw' in text_content and 'little monsters' in text_content:
            publisher_found = 'IDW Publishing'
        elif 'boom studios' in text_content and 'little monsters' in text_content:
            publisher_found = 'Boom Studios'
        elif 'oni press' in text_content and 'little monsters' in text_content:
            publisher_found = 'Oni Press'
        
        if publisher_found:
            print(f"  ✓ Found connection: {publisher_found}")
            
            # Look for artist information in this context
            lines = text_content.split('\n')
            relevant_lines = []
            
            for line in lines:
                if ('little monsters' in line and 
                    publisher_found.lower().replace(' ', '') in line.replace(' ', '') and
                    any(kw in line for kw in ['artist', 'creator', 'illustrator'])):
                    relevant_lines.append(line.strip()[:150])
            
            search_results['publication_details'].append({
                'publisher': publisher_found,
                'query': query,
                'relevant_info': relevant_lines[:3]
            })
            
            if relevant_lines:
                print(f"    Relevant info found: {len(relevant_lines)} lines")
                for line in relevant_lines[:2]:
                    print(f"      {line[:80]}...")
        else:
            print(f"  No specific publisher connection found")
            
    except Exception as e:
        print(f"  ✗ Publisher search failed: {e}")
    
    time.sleep(2)

print("\nSTEP 3: Analyzing collected information for artist identification")
print("-" * 60)

# Analyze all collected search results
total_searches = len(search_results['search_attempts'])
successful_searches = len([s for s in search_results['search_attempts'] if s.get('status') != 'Failed'])

print(f"Total searches conducted: {total_searches}")
print(f"Successful searches: {successful_searches}")

# Compile potential artist names from all searches
all_artist_mentions = []
for search in search_results['search_attempts']:
    if 'artist_mentions' in search:
        all_artist_mentions.extend(search['artist_mentions'])

print(f"\nTotal artist mentions found: {len(all_artist_mentions)}")

if all_artist_mentions:
    print("\nSample artist mentions:")
    for mention in all_artist_mentions[:5]:
        print(f"  - {mention[:100]}...")

# Look for recurring names or patterns
print("\nAnalyzing mentions for potential artist names...")

# Common patterns that might indicate artist names
name_patterns = []
for mention in all_artist_mentions:
    # Look for "by [Name]" patterns
    
    # Pattern: "by [First Last]"
    by_pattern = re.findall(r'by\s+([A-Z][a-z]+\s+[A-Z][a-z]+)', mention)
    name_patterns.extend(by_pattern)
    
    # Pattern: "artist [First Last]"
    artist_pattern = re.findall(r'artist\s+([A-Z][a-z]+\s+[A-Z][a-z]+)', mention)
    name_patterns.extend(artist_pattern)
    
    # Pattern: "illustrated by [First Last]"
    illustrated_pattern = re.findall(r'illustrated\s+by\s+([A-Z][a-z]+\s+[A-Z][a-z]+)', mention)
    name_patterns.extend(illustrated_pattern)

if name_patterns:
    print(f"\nPotential artist names extracted: {len(name_patterns)}")
    # Count frequency of names
    name_frequency = Counter(name_patterns)
    
    print("Most frequently mentioned names:")
    for name, count in name_frequency.most_common(5):
        print(f"  {name}: mentioned {count} time(s)")
        
        search_results['artist_information'].append({
            'name': name,
            'frequency': count,
            'confidence': 'Medium' if count > 1 else 'Low'
        })
else:
    print("No clear artist names extracted from patterns")

# Save comprehensive search results
results_file = 'workspace/little_monsters_comprehensive_search.json'
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(search_results, f, indent=2, ensure_ascii=False)

print(f"\n✓ Comprehensive search results saved to: {results_file}")

print("\n" + "=" * 70)
print("LITTLE MONSTERS COMIC ARTIST SEARCH SUMMARY")
print("=" * 70)

if search_results['artist_information']:
    print("\n*** POTENTIAL ARTISTS IDENTIFIED ***")
    for artist in search_results['artist_information']:
        print(f"Artist: {artist['name']}")
        print(f"Confidence: {artist['confidence']} (mentioned {artist['frequency']} times)")
        print()
else:
    print("\n*** ANALYSIS RESULTS ***")
    if successful_searches > 0:
        print(f"Successfully conducted {successful_searches} web searches")
        print("Search data collected but no definitive artist names extracted automatically")
        print("\nThis suggests:")
        print("1. Multiple comics may share the 'Little Monsters' title")
        print("2. The specific comic may have limited online creator credit information")
        print("3. Manual review of saved HTML files may reveal additional details")
    else:
        print("No successful searches conducted - check network connectivity")

print("\nSearch completed. Files created:")
for file in os.listdir('workspace'):
    if file.endswith(('.html', '.json')):
        print(f"  - {file}")

print("\nNext steps: Manual review of HTML files may reveal specific artist information.")
print("The saved HTML files contain the actual Google search results for detailed inspection.")
```