### Development Step 8: Abel Hugo: Military Service, Map Publications, and Madrid Tenure under Napoleonâ€™s Reign

**Description**: Research Abel Hugo, Victor Hugo's brother, focusing on his military service during the Napoleonic Wars and his time in Madrid. Search for information about his authorship of works containing maps of Napoleon's camps in Spain, his connection to the Hospital de Saint Louis in Madrid (converted to military hospital in 1809), and identify during which ruler's reign these events occurred. Look for biographical details about Abel Hugo's military career, his publications, and the specific timeframe when he was in Madrid with Victor Hugo.

**Use Cases**:
- Historical genealogy automation for tracing Abel Hugoâ€™s family ties and military service by extracting and cross-referencing biographical details from Wikipedia and Google Books sources.
- Digital humanities mapping tool for visualizing Napoleonic camp locations in Spain by parsing historical publications and integrating map references into a GIS platform.
- Museum exhibit content generator that compiles service records, hospital conversions (e.g., 1809 Saint Louis in Madrid), and ruler context to create interactive timelines and informational panels.
- Academic literature review assistant for military historiography, automatically aggregating publications, authorship data, and relevance scores on Abel Hugoâ€™s writings and Napoleonic campaigns.
- Educational publishing workflow that fact-checks dates, publications, and biographical facts across multiple online encyclopedias to prepare accurate history textbook entries.
- Cultural heritage website updater for enriching Madrid tourism pages with soldier biographies, hospital histories, and period ruler information extracted from mixed online sources.
- Military history consultancy tool for defense analysts to quickly identify and summarize 19th-century French officer career details and campaign narratives from digital archives.
- Content QA pipeline for a publishing house, automating keyword-based verification of dates (e.g., 1809), rulers, and publications to ensure historical accuracy in new releases.

```
import requests
import json
import os
from datetime import datetime
from bs4 import BeautifulSoup
import time

print("Abel Hugo research - final implementation with proper variable scoping...")

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

# First, let's inspect and load existing research data properly
print("\n=== LOADING EXISTING RESEARCH DATA ===")
existing_files = ['abel_hugo_final_research.json', 'abel_hugo_complete_research.json', 'abel_hugo_final_comprehensive_research.json']

existing_google_books = []
for filename in existing_files:
    filepath = f'workspace/{filename}'
    if os.path.exists(filepath):
        try:
            print(f"Loading from: {filename}")
            with open(filepath, 'r') as f:
                data = json.load(f)
            
            if 'all_results' in data:
                results = data['all_results']
                books = [r for r in results if r.get('source') == 'Google Books']
                existing_google_books.extend(books)
                print(f"  Loaded {len(books)} Google Books results")
                
        except Exception as e:
            print(f"  Error loading {filename}: {str(e)}")

# Remove duplicates from Google Books results
seen_titles = set()
unique_books = []
for book in existing_google_books:
    title = book.get('title', '')
    if title and title not in seen_titles:
        seen_titles.add(title)
        unique_books.append(book)

print(f"Unique Google Books results preserved: {len(unique_books)}")

# Initialize results storage
all_results = []
search_errors = []

print("\n=== WIKIPEDIA SEARCH FOR ABEL HUGO WITH FIXED PARSING ===")

# Wikipedia URLs to search
wikipedia_urls = [
    "https://en.wikipedia.org/wiki/Abel_Hugo",
    "https://fr.wikipedia.org/wiki/Abel_Hugo",
    "https://en.wikipedia.org/wiki/Victor_Hugo"
]

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

for url in wikipedia_urls:
    try:
        print(f"\nFetching: {url}")
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Extract title
        title_elem = soup.find('h1', class_='firstHeading')
        title = title_elem.get_text(strip=True) if title_elem else 'Unknown Title'
        print(f"Page title: {title}")
        
        # Extract main content - SIMPLE APPROACH
        content_div = soup.find('div', {'id': 'mw-content-text'})
        if content_div:
            # Remove only scripts and styles
            for script in content_div.find_all('script'):
                script.decompose()
            for style in content_div.find_all('style'):
                style.decompose()
            
            # Get all text content
            content_text = content_div.get_text(separator=' ', strip=True)
            print(f"Content length: {len(content_text)} characters")
            
            # Target keywords for Abel Hugo research
            target_keywords = [
                'abel hugo', 'victor hugo', 'napoleonic wars', 'madrid', 'spain', 
                'military service', 'military hospital', 'hospital',
                'napoleon', 'camps', 'maps', 'publications', 'author', 'brother',
                '1809', 'peninsular war', 'french army', 'officer', 'career',
                'joseph bonaparte', 'ferdinand vii', 'saint louis', 'saint-louis'
            ]
            
            # Find matching keywords
            content_lower = content_text.lower()
            found_keywords = []
            for keyword in target_keywords:
                if keyword in content_lower:
                    found_keywords.append(keyword)
            
            print(f"Keywords found: {', '.join(found_keywords)}")
            
            if found_keywords:
                result = {
                    'title': title,
                    'url': url,
                    'content': content_text[:8000],  # First 8000 characters
                    'keywords_found': found_keywords,
                    'source': 'Wikipedia',
                    'relevance_score': len(found_keywords)
                }
                all_results.append(result)
                print(f"âœ“ Added result with {len(found_keywords)} keyword matches")
                
                # Special analysis for Abel Hugo content
                if 'abel hugo' in content_lower:
                    print("\n*** ABEL HUGO BIOGRAPHICAL CONTENT FOUND ***")
                    
                    # Extract sentences mentioning Abel Hugo
                    sentences = content_text.split('.')
                    abel_sentences = []
                    
                    for sentence in sentences:
                        sentence_clean = sentence.strip()
                        if len(sentence_clean) > 20:
                            sentence_lower = sentence_clean.lower()
                            if 'abel hugo' in sentence_lower:
                                abel_sentences.append(sentence_clean)
                    
                    print(f"Found {len(abel_sentences)} sentences about Abel Hugo:")
                    for i, sentence in enumerate(abel_sentences[:5], 1):
                        print(f"  {i}. {sentence[:350]}...")
            
        time.sleep(2)  # Be respectful to Wikipedia
        
    except Exception as e:
        error_msg = f"Error fetching {url}: {str(e)}"
        print(error_msg)
        search_errors.append(error_msg)

# Combine all results
all_results.extend(unique_books)
all_results.sort(key=lambda x: x['relevance_score'], reverse=True)

print(f"\n=== COMPREHENSIVE ANALYSIS WITH PROPER VARIABLE SCOPING ===")
print(f"Total results: {len(all_results)}")
print(f"Wikipedia results: {len([r for r in all_results if r['source'] == 'Wikipedia'])}")
print(f"Google Books results: {len([r for r in all_results if r['source'] == 'Google Books'])}")

# Analyze all results for Abel Hugo information - WITH PROPER VARIABLE INITIALIZATION
abel_hugo_findings = {
    'military_service_details': [],
    'madrid_connections': [],
    'napoleon_maps_camps': [],
    'hospital_saint_louis': [],
    'publications_authorship': [],
    'timeframe_1809': [],
    'ruler_context': [],
    'family_relations': [],
    'biographical_sources': []
}

for result in all_results:
    # PROPERLY INITIALIZE VARIABLES FOR EACH RESULT
    text_content = ''
    original_text = ''
    
    # Get text content for analysis
    if 'content' in result and result['content']:
        text_content = result['content'].lower()
        original_text = result['content']
    elif 'description' in result and result['description']:
        text_content = result['description'].lower()
        original_text = result['description']
    elif 'title' in result:
        text_content = result['title'].lower()
        original_text = result['title']
    
    # Check for Abel Hugo relevance
    is_relevant = (('abel hugo' in text_content) or 
                  ('abel' in text_content and 'hugo' in text_content and 'victor' in text_content) or
                  (result['relevance_score'] >= 3))
    
    if is_relevant:
        print(f"\nAnalyzing: {result['title']} (Score: {result['relevance_score']})")
        
        # Military service
        military_terms = ['military', 'army', 'officer', 'service', 'soldier', 'war', 'campaign']
        if any(term in text_content for term in military_terms):
            abel_hugo_findings['military_service_details'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': original_text[:1000],
                'keywords': result['keywords_found'],
                'score': result['relevance_score']
            })
            print("  âœ“ Military service information found")
        
        # Madrid connections
        if 'madrid' in text_content:
            abel_hugo_findings['madrid_connections'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': original_text[:1000],
                'keywords': result['keywords_found'],
                'score': result['relevance_score']
            })
            print("  âœ“ Madrid connection found")
        
        # Napoleon maps/camps
        if 'napoleon' in text_content and ('maps' in text_content or 'camps' in text_content):
            abel_hugo_findings['napoleon_maps_camps'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': original_text[:1000],
                'keywords': result['keywords_found'],
                'score': result['relevance_score']
            })
            print("  âœ“ Napoleon maps/camps reference found")
        
        # Hospital Saint Louis
        if 'hospital' in text_content and ('saint louis' in text_content or 'saint-louis' in text_content):
            abel_hugo_findings['hospital_saint_louis'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': original_text[:1000],
                'keywords': result['keywords_found'],
                'score': result['relevance_score']
            })
            print("  âœ“ Hospital Saint Louis reference found")
        
        # Publications and authorship
        publication_terms = ['author', 'wrote', 'published', 'publication', 'work', 'book']
        if any(term in text_content for term in publication_terms):
            abel_hugo_findings['publications_authorship'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': original_text[:1000],
                'keywords': result['keywords_found'],
                'score': result['relevance_score']
            })
            print("  âœ“ Publication/authorship information found")
        
        # 1809 timeframe
        if '1809' in text_content:
            abel_hugo_findings['timeframe_1809'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': original_text[:1000],
                'keywords': result['keywords_found'],
                'score': result['relevance_score']
            })
            print("  âœ“ 1809 timeframe reference found")
        
        # Ruler context
        ruler_terms = ['joseph bonaparte', 'napoleon', 'ferdinand vii', 'charles iv']
        if any(ruler in text_content for ruler in ruler_terms):
            abel_hugo_findings['ruler_context'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': original_text[:1000],
                'keywords': result['keywords_found'],
                'score': result['relevance_score']
            })
            print("  âœ“ Ruler context found")
        
        # Family relations
        if 'victor hugo' in text_content and 'brother' in text_content:
            abel_hugo_findings['family_relations'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': original_text[:1000],
                'keywords': result['keywords_found'],
                'score': result['relevance_score']
            })
            print("  âœ“ Family relations found")
        
        # Add to biographical sources
        abel_hugo_findings['biographical_sources'].append({
            'source': result['title'],
            'url': result.get('url', ''),
            'text_sample': original_text[:1200],
            'keywords': result['keywords_found'],
            'score': result['relevance_score'],
            'source_type': result['source']
        })

# Save final comprehensive research
final_research_data = {
    'research_date': datetime.now().isoformat(),
    'research_objective': 'Abel Hugo research: military service during Napoleonic Wars, Madrid connections, Napoleon camp maps, Hospital de Saint Louis, publications, ruler context during 1809',
    'search_summary': {
        'total_results': len(all_results),
        'wikipedia_results': len([r for r in all_results if r['source'] == 'Wikipedia']),
        'google_books_results': len([r for r in all_results if r['source'] == 'Google Books']),
        'search_errors': len(search_errors),
        'highest_relevance_score': max([r['relevance_score'] for r in all_results]) if all_results else 0
    },
    'all_research_results': all_results,
    'abel_hugo_detailed_findings': abel_hugo_findings,
    'search_errors': search_errors
}

final_output_file = 'workspace/abel_hugo_research_final.json'
with open(final_output_file, 'w') as f:
    json.dump(final_research_data, f, indent=2)

print(f"\n{'='*80}")
print("ABEL HUGO RESEARCH - FINAL COMPREHENSIVE SUMMARY")
print(f"{'='*80}")
print(f"Complete research saved to: {final_output_file}")
print(f"Total sources analyzed: {len(all_results)}")
print(f"Wikipedia pages successfully processed: {len([r for r in all_results if r['source'] == 'Wikipedia'])}")
print(f"Google Books sources included: {len([r for r in all_results if r['source'] == 'Google Books'])}")

# Display key research findings
print(f"\n=== ABEL HUGO KEY RESEARCH FINDINGS ===")
for category, findings in abel_hugo_findings.items():
    if findings and category != 'biographical_sources':
        print(f"\n{category.replace('_', ' ').title()}: {len(findings)} sources found")
        # Show the highest scoring source for this category
        best_source = max(findings, key=lambda x: x['score'])
        print(f"  Best source: {best_source['source']} (Score: {best_source['score']})")
        print(f"  Keywords: {', '.join(best_source['keywords'])}")
        print(f"  Sample text: {best_source['text_sample'][:400]}...")

# Display top overall sources
print(f"\n=== TOP SOURCES FOR ABEL HUGO RESEARCH ===")
for i, result in enumerate(all_results[:8], 1):
    print(f"\n{i}. {result['title']} (Relevance Score: {result['relevance_score']})")
    print(f"   Source: {result['source']}")
    if 'authors' in result:
        print(f"   Authors: {', '.join(result['authors'])}")
    print(f"   Keywords: {', '.join(result['keywords_found'])}")
    
    # Display content preview
    if 'content' in result and len(result['content']) > 100:
        print(f"   Content preview: {result['content'][:300]}...")
    elif 'description' in result:
        print(f"   Description: {result['description'][:300]}...")

# Extract key biographical information from Wikipedia results
print(f"\n=== KEY BIOGRAPHICAL INFORMATION EXTRACTED ===")
wikipedia_results = [r for r in all_results if r['source'] == 'Wikipedia']
for wiki_result in wikipedia_results:
    if 'abel hugo' in wiki_result['title'].lower():
        print(f"\nFrom {wiki_result['title']}:")
        content = wiki_result['content']
        
        # Extract key facts
        if '15 november 1798' in content.lower():
            print("  âœ“ Birth date: 15 November 1798, Paris")
        if '7 february 1855' in content.lower() or '8 february 1855' in content.lower():
            print("  âœ“ Death date: 7-8 February 1855, Paris")
        if 'french military officer' in content.lower():
            print("  âœ“ Profession: French military officer, essayist, and historian")
        if 'victor hugo' in content.lower() and 'brother' in content.lower():
            print("  âœ“ Family: Brother of novelist Victor Hugo")
        if 'histoire de la campagne d\'espagne' in content.lower():
            print("  âœ“ Notable work: Histoire de la campagne d'Espagne en 1823")
        if 'france militaire' in content.lower():
            print("  âœ“ Major publication: La France Militaire (multi-volume work)")

print(f"\n=== RESEARCH COMPLETION STATUS ===")
if search_errors:
    print(f"Search errors encountered: {len(search_errors)}")
    for error in search_errors:
        print(f"  - {error}")
else:
    print("No search errors - all sources processed successfully!")

print(f"\nðŸŽ¯ RESEARCH SUMMARY FOR PLAN OBJECTIVES:")
print(f"âœ“ Abel Hugo biographical information: Successfully extracted from Wikipedia")
print(f"âœ“ Military service details: Found in {len(abel_hugo_findings['military_service_details'])} sources")
print(f"âœ“ Madrid connections: Found in {len(abel_hugo_findings['madrid_connections'])} sources")
print(f"âœ“ Napoleon maps/camps: Found in {len(abel_hugo_findings['napoleon_maps_camps'])} sources")
print(f"âœ“ Hospital Saint Louis: Found in {len(abel_hugo_findings['hospital_saint_louis'])} sources")
print(f"âœ“ Publications/authorship: Found in {len(abel_hugo_findings['publications_authorship'])} sources")
print(f"âœ“ 1809 timeframe: Found in {len(abel_hugo_findings['timeframe_1809'])} sources")
print(f"âœ“ Ruler context: Found in {len(abel_hugo_findings['ruler_context'])} sources")
print(f"âœ“ Family relations: Found in {len(abel_hugo_findings['family_relations'])} sources")

print(f"\nAbel Hugo research completed successfully! Full results available in {final_output_file}")
```