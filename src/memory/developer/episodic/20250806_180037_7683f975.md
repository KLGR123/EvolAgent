### Development Step 1: Locate USGS Data on Invasive Clownfish (Finding Nemo) Occurrences in U.S. Pre-2020

**Description**: Identify the main character fish species from the movie Finding Nemo and then search for USGS databases or reports documenting nonnative fish species occurrences in the United States before 2020. Focus on finding official USGS records that include specific location data with zip codes for where this species was found as an invasive or nonnative population.

**Use Cases**:
- State environmental agency mapping nonnative clownfish occurrences by zip code to prioritize containment efforts in coastal regions
- Marine biology research group conducting historical trend analysis of Amphiprion percula invasions across US waters using USGS zip‐code level data
- Aquarium import companies automating compliance checks by cross‐referencing shipment destinations against zip‐coded USGS invasive species records
- Environmental consultancy firm preparing impact assessment reports for coastal development projects by extracting zip‐specific nonindigenous aquatic species data
- NGO conservation campaign developing interactive maps of invasive clownfish sightings at the neighborhood level for public awareness
- Insurance underwriters in the pet trade evaluating risk profiles of aquarium leak claims based on regional nonnative fish occurrences
- Mobile citizen‐science application enabling hobbyists to verify if their zip code has documented nonnative clownfish invasions via USGS records
- State legislature drafting evidence‐based regulations on aquarium fish trade by analyzing pre‐2020 nonnative species location datasets

```
print("=== FINDING NEMO CHARACTER IDENTIFICATION ===\n")

# The main character fish species from Finding Nemo
main_character_species = {
    'character_name': 'Nemo (and his father Marlin)',
    'species_common_name': 'Clownfish (specifically Orange Clownfish or False Percula Clownfish)',
    'species_scientific_name': 'Amphiprion ocellatus (Orange Clownfish) or Amphiprion percula (False Percula Clownfish)',
    'movie': 'Finding Nemo (2003)',
    'description': 'Small orange fish with white stripes and black borders, living in sea anemones'
}

print("Main Character Fish Species from Finding Nemo:")
for key, value in main_character_species.items():
    print(f"{key.replace('_', ' ').title()}: {value}")

print("\n" + "="*80)
print("SEARCHING FOR USGS NONNATIVE FISH SPECIES DATA")
print("="*80)

# Search for USGS databases and reports on nonnative clownfish occurrences in the US before 2020
import os
import requests

# Get SerpAPI key from environment variables
api_key = os.getenv("SERPAPI_API_KEY")

if api_key is None:
    print("Error: Missing API key. Make sure you have SERPAPI_API_KEY in your environment variables.")
else:
    print(f"\nAPI key available: {api_key[:10]}...")
    
    # Multiple search queries to find USGS nonnative fish data
    search_queries = [
        'USGS nonnative fish species clownfish Amphiprion United States before:2020',
        'USGS invasive fish database clownfish orange clownfish United States zip code',
        'site:usgs.gov nonnative fish species database location zip code clownfish',
        'USGS nonindigenous aquatic species clownfish Amphiprion percula United States',
        '"USGS Nonindigenous Aquatic Species Database" clownfish location data'
    ]
    
    all_search_results = []
    
    for i, query in enumerate(search_queries, 1):
        print(f"\n=== SEARCH {i}: {query} ===\n")
        
        # Prepare API request parameters
        params = {
            "q": query,
            "api_key": api_key,
            "engine": "google",
            "google_domain": "google.com",
            "safe": "off",
            "num": 10,
            "type": "search",
        }
        
        try:
            # Make API request to SerpAPI
            response = requests.get("https://serpapi.com/search.json", params=params)
            
            if response.status_code == 200:
                results = response.json()
                
                if results.get("organic_results"):
                    print(f"Found {len(results['organic_results'])} results for query {i}")
                    
                    # Analyze results for USGS and location data relevance
                    usgs_results = []
                    location_data_results = []
                    
                    for j, result in enumerate(results["organic_results"]):
                        title = result.get('title', 'No title')
                        link = result.get('link', 'No link')
                        snippet = result.get('snippet', 'No snippet')
                        
                        print(f"\nResult {j+1}:")
                        print(f"Title: {title}")
                        print(f"Link: {link}")
                        print(f"Snippet: {snippet[:200]}..." if len(snippet) > 200 else f"Snippet: {snippet}")
                        
                        # Check for USGS relevance
                        if 'usgs' in link.lower() or 'usgs' in title.lower():
                            usgs_results.append(result)
                            print("*** USGS OFFICIAL SOURCE IDENTIFIED ***")
                        
                        # Check for location/database relevance
                        location_indicators = ['database', 'location', 'zip', 'coordinate', 'occurrence', 'record', 'species']
                        if any(indicator in (title + snippet).lower() for indicator in location_indicators):
                            location_data_results.append(result)
                            print("*** CONTAINS LOCATION/DATABASE CONTENT ***")
                        
                        # Check for clownfish/nonnative relevance
                        species_indicators = ['clownfish', 'amphiprion', 'nonnative', 'invasive', 'nonindigenous', 'aquatic species']
                        if any(indicator in (title + snippet).lower() for indicator in species_indicators):
                            print("*** CONTAINS SPECIES/NONNATIVE CONTENT ***")
                        
                        print("-" * 60)
                    
                    # Store results for this query
                    query_results = {
                        'query': query,
                        'total_results': len(results['organic_results']),
                        'usgs_results': len(usgs_results),
                        'location_data_results': len(location_data_results),
                        'results': results['organic_results'],
                        'top_usgs_links': [r['link'] for r in usgs_results[:3]],
                        'top_location_links': [r['link'] for r in location_data_results[:3]]
                    }
                    
                    all_search_results.append(query_results)
                    
                else:
                    print(f"No organic results found for query {i}")
                    if 'error' in results:
                        print(f"API Error: {results['error']}")
                        
            else:
                print(f"Error: API request failed with status {response.status_code}: {response.text}")
                
        except Exception as e:
            print(f"Error during search {i}: {e}")
    
    # Save comprehensive search results
    import json
    
    search_data = {
        'target_species': main_character_species,
        'search_objective': 'Find USGS databases or reports documenting nonnative clownfish occurrences in the United States before 2020 with location data including zip codes',
        'search_queries_used': search_queries,
        'total_searches_conducted': len(search_queries),
        'search_results_by_query': all_search_results,
        'summary': {
            'total_results_found': sum(len(qr.get('results', [])) for qr in all_search_results),
            'usgs_sources_identified': sum(qr.get('usgs_results', 0) for qr in all_search_results),
            'location_data_sources': sum(qr.get('location_data_results', 0) for qr in all_search_results)
        }
    }
    
    with open('workspace/usgs_clownfish_search_results.json', 'w') as f:
        json.dump(search_data, f, indent=2)
    
    print(f"\n=== SEARCH SUMMARY ===\n")
    print(f"Target Species: {main_character_species['species_common_name']}")
    print(f"Scientific Name: {main_character_species['species_scientific_name']}")
    print(f"Total Search Queries: {len(search_queries)}")
    print(f"Total Results Found: {search_data['summary']['total_results_found']}")
    print(f"USGS Sources Identified: {search_data['summary']['usgs_sources_identified']}")
    print(f"Location Data Sources: {search_data['summary']['location_data_sources']}")
    
    print(f"\nSearch results saved to: workspace/usgs_clownfish_search_results.json")
    
    # Identify most promising USGS links for next step
    all_usgs_links = []
    for query_result in all_search_results:
        all_usgs_links.extend(query_result.get('top_usgs_links', []))
    
    unique_usgs_links = list(set(all_usgs_links))
    
    print(f"\n=== MOST PROMISING USGS LINKS FOR DETAILED ANALYSIS ===\n")
    for i, link in enumerate(unique_usgs_links[:5], 1):
        print(f"{i}. {link}")
    
    # Save target links for next step
    target_links = {
        'primary_target': 'USGS Nonindigenous Aquatic Species Database',
        'species_focus': 'Clownfish (Amphiprion species)',
        'data_requirements': [
            'Location data with zip codes',
            'Occurrence records before 2020',
            'Nonnative/invasive status documentation',
            'Specific geographic coordinates or areas'
        ],
        'usgs_links_to_investigate': unique_usgs_links[:5],
        'next_steps': [
            'Access USGS Nonindigenous Aquatic Species Database',
            'Search for Amphiprion species records',
            'Extract location data with zip codes',
            'Filter for records before 2020',
            'Document specific occurrence locations'
        ]
    }
    
    with open('workspace/usgs_target_links.json', 'w') as f:
        json.dump(target_links, f, indent=2)
    
    print(f"\nTarget investigation plan saved to: workspace/usgs_target_links.json")
```