### Development Step 63: Extract American Idol Season Winners Table to JSON File

**Description**: Access the Wikipedia page https://en.wikipedia.org/wiki/American_Idol and extract the season-by-season winners table into workspace/american_idol_winners_list.json, capturing each season number and winner name.

**Use Cases**:
- Entertainment news platform automates extraction of American Idol winners to instantly update its “On This Day” and “Winner Spotlight” sections without manual editing
- Social media management tool integrates winner data to schedule and personalize “Winner Anniversary” posts for increased fan engagement on Facebook and Instagram
- Television network analytics team scrapes winners list to benchmark American Idol’s talent outcomes against their own competition show and refine casting strategies
- Market research agency compiles winner names and seasons to correlate contestant success with brand sponsorship deals and advertising ROI reports
- Academic pop culture researcher uses the structured JSON dataset to perform demographic trend analysis of reality TV winners across two decades
- Mobile trivia game app fetches the latest winners from the JSON file to auto-generate new quiz questions and keep content fresh for daily players
- AI chatbot for entertainment FAQs pulls in-season winner information to answer user queries in real time on messaging platforms and voice assistants

```
import os
import requests
import json
from bs4 import BeautifulSoup

# Ensure workspace directory exists
workspace_dir = 'workspace'
os.makedirs(workspace_dir, exist_ok=True)

url = 'https://en.wikipedia.org/wiki/American_Idol'
print(f"Fetching page: {url}")
response = requests.get(url)
print(f"  HTTP status code: {response.status_code}")
response.raise_for_status()

soup = BeautifulSoup(response.text, 'html.parser')

# Find all wikitables on the page
tables = soup.find_all('table', class_='wikitable')
print(f"Found {len(tables)} 'wikitable' tables on the page.")

target_table = None
# Select the first table whose headers include both 'Season' and 'Winner'
for idx, table in enumerate(tables, start=1):
    header_row = table.find('tr')
    headers = [th.get_text(strip=True) for th in header_row.find_all('th')]
    headers_lower = [h.lower() for h in headers]
    print(f"Table {idx} headers: {headers}")
    if 'season' in headers_lower and 'winner' in headers_lower:
        print(f"--> Selecting table {idx} (contains both 'Season' and 'Winner').")
        target_table = table
        break

if not target_table:
    raise RuntimeError("Could not find a table with both 'Season' and 'Winner' columns.")

# Extract exact headers and compute indices
top_row = target_table.find('tr')
headers = [th.get_text(strip=True) for th in top_row.find_all('th')]
print(f"Using headers from selected table: {headers}")
season_header_idx = headers.index('Season')
winner_header_idx = headers.index('Winner')
# In each data row, the <th> holds the 'Season' value and <td>s hold remaining columns
winner_td_idx = winner_header_idx - 1  # offset because first column is in <th>
print(f"Season header index: {season_header_idx}, Winner header index: {winner_header_idx}, Winner in <td>s at index: {winner_td_idx}")

# Parse each data row
winners = []
rows = target_table.find_all('tr')[1:]
print(f"Parsing {len(rows)} rows from the selected table.")
for row_idx, row in enumerate(rows, start=1):
    # Season is in the <th> cell of the row
    season_cell = row.find('th')
    if not season_cell:
        print(f"  Skipping row {row_idx}: no <th> season cell found.")
        continue
    season = season_cell.get_text(strip=True)
    # All other columns are <td> in order
    tds = row.find_all('td')
    if len(tds) <= winner_td_idx:
        print(f"  Skipping row {row_idx}: only {len(tds)} <td> cells found, need at least {winner_td_idx+1}.")
        continue
    winner = tds[winner_td_idx].get_text(strip=True)
    print(f"  Row {row_idx}: Season = '{season}', Winner = '{winner}'")
    winners.append({'season': season, 'winner': winner})

print(f"Total season/winner pairs extracted: {len(winners)}")

# Save results to JSON
output_path = os.path.join(workspace_dir, 'american_idol_winners_list.json')
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(winners, f, ensure_ascii=False, indent=2)
print(f"Winners list successfully saved to: {output_path}")

```