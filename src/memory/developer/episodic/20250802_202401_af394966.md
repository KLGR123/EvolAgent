### Development Step 11: Retrieve 2011 Bulgarian Census Data on Tertiary Education Completion by Gender

**Description**: Search for the 2011 Bulgarian census data on tertiary education completion by gender. Look for official census results from Bulgaria's National Statistical Institute or other authoritative sources that provide the specific breakdown of men and women who completed tertiary education in 2011.

**Use Cases**:
- Government statistical office automating extraction of 2011 Bulgarian tertiary education gender breakdown to update the national education dashboard
- NGO policy analyst compiling gender equality reports by parsing census HTML files for detailed tertiary education completion rates
- University research department conducting a longitudinal study on male vs. female higher education trends in Bulgaria using structured census data
- Data journalism team scraping archived Bulgarian census pages to visualize regional disparities in tertiary degree attainment by gender
- HR consulting firm benchmarking workforce qualifications in Bulgaria by gender to guide corporate diversity and hiring strategies
- Education technology startup integrating official census statistics into its platform to recommend targeted upskilling programs for under-represented genders
- Market research agency analyzing demographic and education data from the 2011 Bulgarian census to advise real estate developers on student housing demand

```
import os
import json
from bs4 import BeautifulSoup
import re
import time

print("=== BULGARIAN 2011 CENSUS TERTIARY EDUCATION BY GENDER - FINAL EXTRACTION ===")
print("Objective: Extract specific tertiary education completion statistics by gender from 2011 Bulgarian census")
print("Strategy: Direct file analysis with completely fixed variable scoping\n")

# Check workspace contents
workspace_path = 'workspace'
if not os.path.exists(workspace_path):
    print("No workspace directory found")
    exit()

all_files = os.listdir(workspace_path)
html_files = [f for f in all_files if f.endswith('.html')]

print(f"Total files in workspace: {len(all_files)}")
print(f"HTML files available: {len(html_files)}")

# Identify the most promising files for Bulgarian census education data
priority_files = []
for filename in html_files:
    filepath = os.path.join(workspace_path, filename)
    file_size = os.path.getsize(filepath)
    
    # Skip very small files (likely error pages)
    if file_size < 15000:  # Less than 15KB
        continue
    
    filename_lower = filename.lower()
    
    # Calculate priority score
    score = 0
    if 'demographics' in filename_lower:
        score += 5
    if 'education' in filename_lower:
        score += 5
    if 'census' in filename_lower:
        score += 4
    if 'bulgaria' in filename_lower:
        score += 3
    if 'nsi' in filename_lower:
        score += 3
    if 'eurostat' in filename_lower:
        score += 2
    
    if score > 0:
        priority_files.append({
            'filename': filename,
            'score': score,
            'size': file_size
        })

# Sort by priority score
priority_files.sort(key=lambda x: x['score'], reverse=True)

print(f"\nPriority files for analysis: {len(priority_files)}")
for i, pf in enumerate(priority_files[:5], 1):
    print(f"{i}. {pf['filename']} (Score: {pf['score']}, Size: {pf['size']:,} bytes)")

print("\n=== ANALYZING FILES WITH PROPER VARIABLE HANDLING ===\n")

# Results storage
analysis_results = []
tertiary_education_findings = []

# Analyze top 3 files to extract tertiary education data
for file_info in priority_files[:3]:
    filename = file_info['filename']
    print(f"Analyzing: {filename}")
    
    filepath = os.path.join(workspace_path, filename)
    
    try:
        # Read HTML file
        with open(filepath, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        # Parse HTML
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Get page title
        title_element = soup.find('title')
        page_title = title_element.get_text().strip() if title_element else 'No title'
        
        # Extract all text content
        page_text = soup.get_text()
        
        # CRITICAL FIX: Define lowercase version immediately after page_text
        page_text_lower = page_text.lower()
        
        print(f"  Title: {page_title}")
        print(f"  Content length: {len(page_text):,} characters")
        
        # Now safely check for key indicators using the properly defined variable
        has_bulgaria = 'bulgaria' in page_text_lower or 'bulgarian' in page_text_lower
        has_2011 = '2011' in page_text_lower
        has_census = 'census' in page_text_lower
        has_tertiary = any(term in page_text_lower for term in ['tertiary', 'tertiary education', 'higher education'])
        has_gender = any(term in page_text_lower for term in ['men', 'women', 'male', 'female', 'gender', 'sex'])
        has_education = 'education' in page_text_lower
        
        relevance_score = sum([has_bulgaria, has_2011, has_census, has_tertiary, has_gender, has_education])
        
        print(f"  Bulgaria: {has_bulgaria} | 2011: {has_2011} | Census: {has_census}")
        print(f"  Tertiary: {has_tertiary} | Gender: {has_gender} | Education: {has_education}")
        print(f"  Relevance score: {relevance_score}/6")
        
        if relevance_score >= 4:  # High relevance files
            print(f"  *** HIGH RELEVANCE - EXTRACTING TERTIARY EDUCATION DATA ***")
            
            # Search for specific tertiary education statistics by gender
            education_patterns = [
                r'tertiary education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'(?:men|women|male|female)[^.]*?tertiary education[^.]*?(\d+[.,]?\d*\s*%?)',
                r'higher education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'(?:men|women|male|female)[^.]*?higher education[^.]*?(\d+[.,]?\d*\s*%?)',
                r'university[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'completed[^.]*?tertiary[^.]*?(\d+[.,]?\d*\s*%?)',
                r'2011[^.]*?education[^.]*?(?:men|women|male|female)[^.]*?(\d+[.,]?\d*\s*%?)',
                r'census[^.]*?2011[^.]*?education[^.]*?(\d+[.,]?\d*\s*%?)'
            ]
            
            pattern_matches = []
            for pattern in education_patterns:
                matches = re.finditer(pattern, page_text, re.IGNORECASE | re.DOTALL)
                for match in matches:
                    # Get extended context around the match
                    start = max(0, match.start() - 300)
                    end = min(len(page_text), match.end() + 300)
                    context = page_text[start:end].strip()
                    
                    # Ensure context mentions Bulgaria
                    if 'bulgaria' in context.lower() or 'bulgarian' in context.lower():
                        pattern_matches.append({
                            'match_text': match.group(),
                            'context': context,
                            'pattern_used': pattern,
                            'source_file': filename
                        })
            
            print(f"  Pattern matches found: {len(pattern_matches)}")
            
            # Look for sentences with tertiary education and gender data
            relevant_sentences = []
            sentences = page_text.split('.')
            
            for sentence in sentences:
                sentence_clean = sentence.strip()
                if len(sentence_clean) < 40:  # Skip very short sentences
                    continue
                
                sentence_lower = sentence_clean.lower()
                
                # Check for Bulgaria + education + numbers + gender terms
                has_bulgaria_ref = 'bulgaria' in sentence_lower or 'bulgarian' in sentence_lower
                has_education_ref = any(term in sentence_lower for term in 
                                      ['education', 'tertiary', 'university', 'higher', 'degree', 'graduate'])
                has_numbers = bool(re.search(r'\d+[.,]?\d*\s*%?', sentence_clean))
                has_gender_ref = any(term in sentence_lower for term in ['men', 'women', 'male', 'female'])
                has_year_ref = '2011' in sentence_lower
                
                if has_bulgaria_ref and has_education_ref and has_numbers and (has_gender_ref or has_year_ref):
                    relevant_sentences.append(sentence_clean)
            
            print(f"  Relevant sentences: {len(relevant_sentences)}")
            
            # Analyze tables for structured education data
            tables = soup.find_all('table')
            education_tables = []
            
            for table_idx, table in enumerate(tables):
                table_text = table.get_text().lower()
                
                # Check if table contains education and gender information
                has_education_content = any(term in table_text for term in 
                                          ['education', 'tertiary', 'university', 'degree'])
                has_gender_content = any(term in table_text for term in 
                                       ['men', 'women', 'male', 'female', 'gender'])
                
                if has_education_content and has_gender_content:
                    # Extract table headers
                    headers = []
                    for th in table.find_all('th'):
                        headers.append(th.get_text().strip())
                    
                    # Extract sample rows
                    rows = table.find_all('tr')
                    sample_rows = []
                    
                    for row in rows[1:4]:  # Skip header, take next 3 rows
                        cells = []
                        for cell in row.find_all(['td', 'th']):
                            cells.append(cell.get_text().strip())
                        if cells and any(cell for cell in cells if cell.strip()):
                            sample_rows.append(cells)
                    
                    education_tables.append({
                        'table_index': table_idx,
                        'headers': headers,
                        'sample_rows': sample_rows,
                        'total_rows': len(rows)
                    })
            
            print(f"  Education tables found: {len(education_tables)}")
            
            # Store comprehensive analysis results
            analysis_result = {
                'filename': filename,
                'title': page_title,
                'content_length': len(page_text),
                'relevance_score': relevance_score,
                'pattern_matches': pattern_matches[:5],  # Top 5 matches
                'relevant_sentences': relevant_sentences[:5],  # Top 5 sentences
                'education_tables': education_tables[:3],  # Top 3 tables
                'indicators': {
                    'bulgaria': has_bulgaria,
                    '2011': has_2011,
                    'census': has_census,
                    'tertiary': has_tertiary,
                    'gender': has_gender,
                    'education': has_education
                }
            }
            
            analysis_results.append(analysis_result)
            
            # Add specific findings to the main findings list
            for match in pattern_matches:
                tertiary_education_findings.append({
                    'type': 'statistical_pattern',
                    'source_file': filename,
                    'match': match['match_text'],
                    'context': match['context'],
                    'pattern': match['pattern_used']
                })
            
            for sentence in relevant_sentences:
                tertiary_education_findings.append({
                    'type': 'relevant_sentence',
                    'source_file': filename,
                    'content': sentence
                })
            
            # Display key findings from this file
            if pattern_matches:
                print(f"  Key statistical match: {pattern_matches[0]['match_text']}")
                print(f"  Context: {pattern_matches[0]['context'][:200]}...")
            
            if relevant_sentences:
                print(f"  Key sentence: {relevant_sentences[0][:250]}...")
            
            if education_tables:
                print(f"  Table headers example: {education_tables[0]['headers'][:6]}")
        
        else:
            print(f"  Lower relevance (score {relevance_score}) - basic analysis only")
            analysis_results.append({
                'filename': filename,
                'title': page_title,
                'content_length': len(page_text),
                'relevance_score': relevance_score,
                'basic_analysis': True
            })
        
        print()
        
    except Exception as e:
        print(f"  ERROR analyzing {filename}: {str(e)}")
        print()

# Compile and save final results
print("=== COMPILING FINAL RESULTS ===\n")

final_compilation = {
    'search_objective': 'Bulgarian 2011 census tertiary education completion by gender',
    'extraction_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'html_files_total': len(html_files),
    'priority_files_identified': len(priority_files),
    'files_successfully_analyzed': len(analysis_results),
    'tertiary_education_findings_count': len(tertiary_education_findings),
    'detailed_analysis_results': analysis_results,
    'tertiary_education_findings': tertiary_education_findings
}

# Save comprehensive results
final_results_file = os.path.join(workspace_path, 'bulgarian_2011_tertiary_education_gender_final.json')
with open(final_results_file, 'w', encoding='utf-8') as f:
    json.dump(final_compilation, f, indent=2, ensure_ascii=False)

print(f"Final results saved to: {final_results_file}")
print(f"Total HTML files: {len(html_files)}")
print(f"Files analyzed: {len(analysis_results)}")
print(f"Tertiary education findings: {len(tertiary_education_findings)}")

# Display summary of key findings
if tertiary_education_findings:
    print("\n=== KEY TERTIARY EDUCATION FINDINGS ===\n")
    
    # Group findings by type
    statistical_patterns = [f for f in tertiary_education_findings if f['type'] == 'statistical_pattern']
    relevant_sentences = [f for f in tertiary_education_findings if f['type'] == 'relevant_sentence']
    
    print(f"Statistical patterns found: {len(statistical_patterns)}")
    print(f"Relevant sentences found: {len(relevant_sentences)}")
    
    # Show top findings
    print("\nTop findings:")
    for i, finding in enumerate(tertiary_education_findings[:8], 1):
        print(f"{i}. Type: {finding['type']}")
        print(f"   Source: {finding['source_file']}")
        
        if finding['type'] == 'statistical_pattern':
            print(f"   Match: {finding['match']}")
            print(f"   Context: {finding['context'][:180]}...")
        else:
            print(f"   Content: {finding['content'][:200]}...")
        print()

else:
    print("\n=== NO SPECIFIC TERTIARY EDUCATION FINDINGS ===\n")
    print("The analyzed files may not contain the specific 2011 Bulgarian census")
    print("tertiary education completion statistics by gender that we're looking for.")
    print("This could indicate that:")
    print("1. The data exists but uses different terminology")
    print("2. The data is in a different format (images, PDFs, etc.)")
    print("3. More specific official sources are needed")

print("\n=== EXTRACTION COMPLETE ===\n")
print("Bulgarian 2011 census tertiary education by gender analysis completed")
print("All findings have been systematically extracted and saved for review")
```