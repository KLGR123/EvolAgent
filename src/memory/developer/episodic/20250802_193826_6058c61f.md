### Development Step 2: Locate Emily Midkiff’s June 2014 Dragon Article and Identify Hreidmar Son’s Journal

**Description**: Search for information about Emily Midkiff's June 2014 article, focusing on identifying the journal named after one of Hreidmar's sons from Norse mythology. Research Hreidmar's sons (Fafnir, Regin, and Otr) to determine which one has a journal named after them, then locate Midkiff's specific article from June 2014 that discusses dragon depictions and contains quotes from two different authors expressing distaste.

**Use Cases**:
- Legal case law retrieval and document compilation for litigation teams tracking recent appellate opinions
- Competitive product launch tracking and media coverage aggregation for market intelligence analysts
- Academic literature discovery and citation extraction for systematic reviews in medical research
- Pharmaceutical trial results monitoring and adverse effect quote collection for pharmacovigilance reporting
- Cybersecurity vulnerability scanning and advisory link prioritization for threat intelligence operations
- Real estate market data scraping and property lead generation for investment analysis
- Social media influencer brand mention tracking and sentiment ranking for digital marketing campaigns
- Technical standards compliance search and regulatory update monitoring for engineering quality assurance

```
import os
import requests
from bs4 import BeautifulSoup
import json
import time
from urllib.parse import quote_plus, urljoin

print('=== FIXING SEARCH IMPLEMENTATION FOR HREIDMAR\'S SONS RESEARCH ===')
print('Previous attempt failed due to variable scope issue - fixing and executing searches')
print('Objective: Find Emily Midkiff\'s June 2014 article in a journal named after one of Hreidmar\'s sons\n')

# Ensure workspace directory exists
os.makedirs('workspace', exist_ok=True)

# First, let's check if we have any previous research data
analysis_file = os.path.join('workspace', 'hreidmar_sons_midkiff_research.json')
if os.path.exists(analysis_file):
    print('=== INSPECTING PREVIOUS RESEARCH DATA ===')
    with open(analysis_file, 'r', encoding='utf-8') as f:
        previous_data = json.load(f)
    
    print('Previous research file structure:')
    for key in previous_data.keys():
        print(f'  - {key}: {type(previous_data[key])}')
    
    if 'hreidmar_sons_research' in previous_data:
        print('\nHreidmar\'s sons from previous research:')
        for son, info in previous_data['hreidmar_sons_research'].items():
            print(f'  {son}: {info["description"]}')
else:
    print('No previous research data found, starting fresh')

# Define search base URL at the top to avoid scope issues
search_base_url = 'https://html.duckduckgo.com/html/'
print(f'Search base URL: {search_base_url}')

# Headers for web requests
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5'
}

# Hreidmar's sons research data
hreidmar_sons = {
    'Fafnir': {
        'description': 'Transformed into a dragon, guards treasure',
        'alternate_spellings': ['Fáfnir', 'Fafner'],
        'significance': 'Most famous dragon in Norse mythology'
    },
    'Regin': {
        'description': 'Dwarf smith, foster father of Sigurd',
        'alternate_spellings': ['Reginn'],
        'significance': 'Craftsman and mentor figure'
    },
    'Otr': {
        'description': 'Could transform into an otter, killed by Loki',
        'alternate_spellings': ['Ótr', 'Otter'],
        'significance': 'His death triggered the curse on the gold'
    }
}

print('\n=== HREIDMAR\'S SONS RESEARCH ===')
for son, info in hreidmar_sons.items():
    print(f'{son}: {info["description"]}')
    print(f'  Alternate spellings: {", ".join(info["alternate_spellings"])}')

# Function to perform search and save results (with proper variable scope)
def perform_search(query, search_type, base_url, request_headers):
    print(f'\nSearching for: {query}')
    try:
        params = {'q': query}
        response = requests.get(base_url, params=params, headers=request_headers, timeout=30)
        print(f'  Status: {response.status_code}')
        
        if response.status_code == 200:
            # Save raw HTML
            safe_filename = query.replace(' ', '_').replace('"', '').replace('/', '_')[:50]
            filename = f'{search_type}_{safe_filename}.html'
            filepath = os.path.join('workspace', filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            print(f'  Saved: {filepath}')
            print(f'  Content length: {len(response.text):,} characters')
            
            # Parse for quick analysis
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Look for result links and analyze content
            result_links = []
            page_text = soup.get_text().lower()
            
            # Count key term occurrences
            key_terms = ['midkiff', 'fafnir', 'regin', 'dragon', 'journal', '2014', 'june']
            term_counts = {term: page_text.count(term) for term in key_terms}
            
            print(f'  Key term occurrences: {term_counts}')
            
            # Extract links with relevance scoring
            for link in soup.find_all('a', href=True):
                href = link.get('href')
                text = link.get_text().strip()
                
                if href and text and len(text) > 10:
                    # Calculate relevance score
                    relevance_score = 0
                    text_lower = text.lower()
                    href_lower = href.lower()
                    
                    # Score based on key terms in link text
                    for term in key_terms:
                        if term in text_lower:
                            relevance_score += 2
                        if term in href_lower:
                            relevance_score += 1
                    
                    # Bonus for academic sources
                    academic_domains = ['.edu', 'academia', 'jstor', 'project', 'muse', 'oxford', 'cambridge']
                    if any(domain in href_lower for domain in academic_domains):
                        relevance_score += 3
                    
                    if relevance_score > 0:
                        result_links.append({
                            'url': href,
                            'text': text[:200],
                            'relevance_score': relevance_score
                        })
            
            # Sort by relevance
            result_links.sort(key=lambda x: x['relevance_score'], reverse=True)
            
            print(f'  Found {len(result_links)} relevant links')
            if result_links:
                print('  Top 3 results:')
                for i, link in enumerate(result_links[:3], 1):
                    print(f'    {i}. Score {link["relevance_score"]}: {link["text"][:100]}...')
                    print(f'       URL: {link["url"][:100]}...')
            
            return {
                'html_file': filepath,
                'status_code': response.status_code,
                'relevant_links': result_links[:15],  # Top 15 most relevant
                'total_links_found': len(result_links),
                'term_counts': term_counts,
                'content_length': len(response.text)
            }
        else:
            print(f'  Failed: HTTP {response.status_code}')
            return None
            
    except Exception as e:
        print(f'  Error: {str(e)}')
        return None

# Priority search queries focusing on most likely scenarios
print('\n=== CONDUCTING TARGETED SEARCHES ===')

# Start with Fafnir since it's the most famous dragon-related son
fafnir_journal_queries = [
    'Fafnir journal academic publication',
    '"Fafnir journal" medieval studies',
    'Fafnir academic journal Norse mythology',
    'journal Fafnir dragon studies'
]

# Emily Midkiff searches with focus on 2014 and dragons
midkiff_queries = [
    'Emily Midkiff June 2014 dragon',
    '"Emily Midkiff" 2014 dragon depictions',
    'Emily Midkiff dragon mythology 2014',
    'Emily Midkiff Fafnir journal 2014'
]

# Combined searches
combined_queries = [
    'Emily Midkiff Fafnir 2014',
    'Emily Midkiff Regin journal 2014',
    'Midkiff dragon distaste quotes 2014'
]

search_results = {}

print('\n--- FAFNIR JOURNAL SEARCHES ---')
for query in fafnir_journal_queries:
    result = perform_search(query, 'fafnir_journal', search_base_url, headers)
    if result:
        search_results[query] = result
    time.sleep(2)  # Rate limiting

print('\n--- EMILY MIDKIFF SEARCHES ---')
for query in midkiff_queries:
    result = perform_search(query, 'midkiff', search_base_url, headers)
    if result:
        search_results[query] = result
    time.sleep(2)  # Rate limiting

print('\n--- COMBINED SEARCHES ---')
for query in combined_queries:
    result = perform_search(query, 'combined', search_base_url, headers)
    if result:
        search_results[query] = result
    time.sleep(2)  # Rate limiting

# Analyze all search results
print('\n=== ANALYZING SEARCH RESULTS ===')

high_relevance_findings = []
journal_candidates = []
midkiff_candidates = []

for query, results in search_results.items():
    print(f'\nQuery: {query}')
    print(f'  Total relevant links: {results["total_links_found"]}')
    print(f'  Key term counts: {results["term_counts"]}')
    
    # Analyze top results
    for link in results['relevant_links'][:5]:
        if link['relevance_score'] >= 4:  # High relevance threshold
            high_relevance_findings.append({
                'query': query,
                'link': link,
                'category': 'high_relevance'
            })
            
            # Categorize findings
            text_lower = link['text'].lower()
            if 'journal' in text_lower and any(son.lower() in text_lower for son in hreidmar_sons.keys()):
                journal_candidates.append({
                    'query': query,
                    'link': link,
                    'potential_journal': True
                })
            
            if 'midkiff' in text_lower and ('2014' in text_lower or 'dragon' in text_lower):
                midkiff_candidates.append({
                    'query': query,
                    'link': link,
                    'potential_article': True
                })

print(f'\n*** SEARCH ANALYSIS SUMMARY ***')
print(f'Total searches conducted: {len(search_results)}')
print(f'High-relevance findings: {len(high_relevance_findings)}')
print(f'Journal candidates: {len(journal_candidates)}')
print(f'Midkiff article candidates: {len(midkiff_candidates)}')

if journal_candidates:
    print('\n=== POTENTIAL JOURNALS NAMED AFTER HREIDMAR\'S SONS ===')
    for i, candidate in enumerate(journal_candidates, 1):
        print(f'{i}. Query: {candidate["query"]}')
        print(f'   Score: {candidate["link"]["relevance_score"]}')
        print(f'   Text: {candidate["link"]["text"][:150]}...')
        print(f'   URL: {candidate["link"]["url"]}')
        print()

if midkiff_candidates:
    print('\n=== POTENTIAL EMILY MIDKIFF ARTICLES ===')
    for i, candidate in enumerate(midkiff_candidates, 1):
        print(f'{i}. Query: {candidate["query"]}')
        print(f'   Score: {candidate["link"]["relevance_score"]}')
        print(f'   Text: {candidate["link"]["text"][:150]}...')
        print(f'   URL: {candidate["link"]["url"]}')
        print()

# Save comprehensive results
final_analysis = {
    'research_objective': 'Find Emily Midkiff June 2014 article in journal named after Hreidmar\'s son',
    'hreidmar_sons_research': hreidmar_sons,
    'search_execution': {
        'total_searches': len(search_results),
        'successful_searches': len([r for r in search_results.values() if r is not None]),
        'queries_used': list(search_results.keys())
    },
    'findings': {
        'high_relevance_count': len(high_relevance_findings),
        'journal_candidates': journal_candidates,
        'midkiff_candidates': midkiff_candidates,
        'all_high_relevance': high_relevance_findings
    },
    'search_results_summary': {
        query: {
            'html_file': results['html_file'],
            'total_relevant_links': results['total_links_found'],
            'term_counts': results['term_counts'],
            'top_links': results['relevant_links'][:3]
        } for query, results in search_results.items()
    },
    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
}

results_file = os.path.join('workspace', 'hreidmar_midkiff_search_results.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(final_analysis, f, indent=2, ensure_ascii=False)

print(f'\n*** SEARCH EXECUTION COMPLETE ***')
print(f'✓ Fixed variable scope issue and executed {len(search_results)} searches')
print(f'✓ Found {len(high_relevance_findings)} high-relevance results')
print(f'✓ Identified {len(journal_candidates)} potential journal matches')
print(f'✓ Identified {len(midkiff_candidates)} potential Midkiff article matches')
print(f'✓ All HTML search results saved to workspace/')
print(f'✓ Comprehensive analysis saved to: {results_file}')
print('\nNext steps:')
print('1. Review the most promising journal and article candidates')
print('2. Access the identified sources to confirm the journal name')
print('3. Locate and extract the specific Emily Midkiff June 2014 article')
print('4. Identify the two quoted authors expressing distaste about dragons')
```