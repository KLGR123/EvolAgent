### Development Step 6: Locate 1994 Example Sentence Source for 'Caminata' in Collins Spanish-English Dictionary for Translation

**Description**: Search for the Spanish word 'caminata' in the Collins Spanish-to-English dictionary online to locate the 1994 example sentence. Focus on finding the Collins dictionary entry that contains an example sentence from 1994, then identify the source title of that example sentence and prepare it for Google translation.

**Use Cases**:
- Linguistic research on historical usage of Spanish vocabulary, extracting example sentences and their sources for corpus analysis
- Automated preparation of bilingual teaching materials by locating authentic dictionary examples with publication references
- Legal translation workflow requiring precise citation of dictionary example sentences from specific years and sources
- Academic study of language change, retrieving dated dictionary examples to track semantic evolution over time
- Publishing editorial review, verifying dictionary example attributions for copyright compliance in educational resources
- Automated content curation for language learning apps, sourcing real-world example sentences with publication metadata
- Cross-referencing dictionary citations for scholarly articles on Spanish literature, ensuring accurate source identification
- Data mining for AI language models, gathering timestamped example sentences and source titles for training datasets

```
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import time
import os

print('=== SELENIUM-BASED COLLINS DICTIONARY ACCESS FOR CAMINATA 1994 EXAMPLE ===')
print('Using automated browser to bypass 403 restrictions\n')

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

# Configure Chrome options for headless browsing
chrome_options = Options()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
chrome_options.add_argument('--disable-gpu')
chrome_options.add_argument('--window-size=1920,1080')
chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')

# Collins dictionary URLs to try
collins_urls = [
    'https://www.collinsdictionary.com/dictionary/spanish-english/caminata',
    'https://www.collinsdictionary.com/us/sentences/spanish/caminata'
]

successful_extractions = []
failed_extractions = []

for i, url in enumerate(collins_urls, 1):
    print(f'=== SELENIUM ACCESS ATTEMPT {i}/2 ===')
    print(f'Target URL: {url}')
    
    driver = None
    try:
        # Initialize Chrome driver
        driver = webdriver.Chrome(options=chrome_options)
        driver.set_page_load_timeout(30)
        
        print('✓ Chrome driver initialized')
        
        # Navigate to the Collins dictionary page
        print('Loading Collins dictionary page...')
        driver.get(url)
        
        # Wait for page to load
        time.sleep(5)
        
        print('✓ Page loaded successfully')
        print(f'Page title: {driver.title}')
        
        # Get page source and analyze
        page_source = driver.page_source
        print(f'Page source length: {len(page_source):,} characters')
        
        # Save the page source
        filename = f'collins_selenium_page_{i}.html'
        filepath = os.path.join('workspace', filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(page_source)
        
        print(f'Page source saved to: {filepath}')
        
        # Parse with BeautifulSoup for analysis
        soup = BeautifulSoup(page_source, 'html.parser')
        page_text = soup.get_text()
        
        # Check for 1994 references
        has_1994 = '1994' in page_text
        print(f'Contains "1994": {has_1994}')
        
        if has_1994:
            print('\n*** 1994 CONTENT FOUND - DETAILED ANALYSIS ***')
            
            # Find all lines containing 1994
            lines = page_text.split('\n')
            lines_with_1994 = []
            
            for line_num, line in enumerate(lines, 1):
                if '1994' in line and line.strip():
                    lines_with_1994.append((line_num, line.strip()))
            
            print(f'Found {len(lines_with_1994)} lines containing "1994":')
            
            for line_num, line_text in lines_with_1994:
                print(f'  Line {line_num}: {line_text}')
                
                # Look for source indicators
                source_indicators = ['source:', 'from:', 'title:', 'book:', 'publication:', 'newspaper:', 'magazine:', 'author:', 'work:']
                if any(indicator in line_text.lower() for indicator in source_indicators):
                    print(f'    *** POTENTIAL SOURCE TITLE FOUND ***')
                    
                # Check if line contains example sentence context
                example_indicators = ['example', 'sentence', 'usage', 'quote', 'citation']
                if any(indicator in line_text.lower() for indicator in example_indicators):
                    print(f'    *** EXAMPLE SENTENCE CONTEXT ***')
            
            # Look for HTML elements containing 1994
            print('\n--- Searching HTML elements with 1994 ---')
            elements_with_1994 = soup.find_all(text=lambda text: text and '1994' in str(text))
            
            for j, element in enumerate(elements_with_1994, 1):
                parent = element.parent
                if parent and parent.name:
                    parent_text = parent.get_text().strip()
                    if len(parent_text) > 10:  # Skip very short elements
                        print(f'\nElement {j}:')
                        print(f'  Tag: {parent.name}')
                        print(f'  Class: {parent.get("class", "No class")}')
                        print(f'  Text: {parent_text[:200]}...' if len(parent_text) > 200 else f'  Text: {parent_text}')
                        
                        # Check for source title patterns in the element
                        if any(pattern in parent_text.lower() for pattern in ['source:', 'from:', 'title:', '©', 'copyright']):
                            print(f'    *** POTENTIAL SOURCE ATTRIBUTION ***')
            
            # Try to find specific example sentence structures
            print('\n--- Searching for example sentence structures ---')
            
            # Look for common dictionary example patterns
            example_selectors = [
                '.example',
                '.citation', 
                '.quote',
                '.sentence',
                '[class*="example"]',
                '[class*="citation"]',
                '[class*="quote"]',
                '[class*="sentence"]'
            ]
            
            found_examples = []
            for selector in example_selectors:
                try:
                    elements = driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        element_text = element.text.strip()
                        if element_text and '1994' in element_text:
                            found_examples.append({
                                'selector': selector,
                                'text': element_text,
                                'element': element
                            })
                            print(f'Found example with selector {selector}:')
                            print(f'  Text: {element_text[:150]}...' if len(element_text) > 150 else f'  Text: {element_text}')
                except Exception as e:
                    print(f'  Error with selector {selector}: {e}')
            
            # Save detailed analysis of 1994 content
            analysis_file = os.path.join('workspace', f'collins_1994_analysis_{i}.txt')
            with open(analysis_file, 'w', encoding='utf-8') as f:
                f.write('COLLINS DICTIONARY CAMINATA 1994 ANALYSIS\n')
                f.write('='*50 + '\n\n')
                f.write(f'Source URL: {url}\n')
                f.write(f'Analysis timestamp: {time.strftime("%Y-%m-%d %H:%M:%S")}\n')
                f.write(f'Page title: {driver.title}\n\n')
                
                f.write(f'Lines containing "1994": {len(lines_with_1994)}\n\n')
                
                if lines_with_1994:
                    f.write('LINES WITH 1994:\n')
                    f.write('-'*30 + '\n')
                    for line_num, line_text in lines_with_1994:
                        f.write(f'Line {line_num}: {line_text}\n')
                
                if found_examples:
                    f.write('\n\nEXAMPLE ELEMENTS WITH 1994:\n')
                    f.write('-'*30 + '\n')
                    for example in found_examples:
                        f.write(f'Selector: {example["selector"]}\n')
                        f.write(f'Text: {example["text"]}\n')
                        f.write('-'*20 + '\n')
            
            print(f'\n✓ Detailed 1994 analysis saved to: {analysis_file}')
        
        else:
            print('\nNo 1994 content found in this page')
            
            # Still check for general example structures
            print('\n--- Analyzing general example sentence structures ---')
            
            try:
                # Look for example sections
                example_elements = driver.find_elements(By.CSS_SELECTOR, '[class*="example"], [class*="sentence"], [class*="usage"]')
                print(f'Found {len(example_elements)} potential example elements')
                
                for j, element in enumerate(example_elements[:5], 1):  # Limit to first 5
                    element_text = element.text.strip()
                    if element_text:
                        print(f'\nExample element {j}:')
                        print(f'  Tag: {element.tag_name}')
                        print(f'  Class: {element.get_attribute("class")}')
                        print(f'  Text: {element_text[:100]}...' if len(element_text) > 100 else f'  Text: {element_text}')
            
            except Exception as e:
                print(f'Error analyzing example elements: {e}')
        
        successful_extractions.append({
            'url': url,
            'filename': filepath,
            'has_1994': has_1994,
            'page_title': driver.title,
            'content_length': len(page_source)
        })
        
    except Exception as e:
        print(f'✗ Error accessing {url}: {str(e)}')
        failed_extractions.append({
            'url': url,
            'error': str(e)
        })
    
    finally:
        if driver:
            driver.quit()
            print('Chrome driver closed')
    
    print('\n' + '='*80 + '\n')
    time.sleep(2)

print('=== SELENIUM ACCESS SUMMARY ===')
print(f'Successfully accessed: {len(successful_extractions)} Collins pages')
print(f'Failed to access: {len(failed_extractions)} pages')

if successful_extractions:
    print('\n--- Successfully Accessed Pages ---')
    for page in successful_extractions:
        print(f'✓ {page["url"]}')
        print(f'  Title: {page["page_title"]}')
        print(f'  File: {page["filename"]}')
        print(f'  Has 1994: {page["has_1994"]}')
        print(f'  Size: {page["content_length"]:,} characters')
        
        if page['has_1994']:
            print('  *** CONTAINS 1994 REFERENCE - READY FOR SOURCE EXTRACTION ***')

if failed_extractions:
    print('\n--- Failed Access Attempts ---')
    for page in failed_extractions:
        print(f'✗ {page["url"]}')  
        print(f'  Error: {page["error"]}')

# Save comprehensive summary
summary_file = os.path.join('workspace', 'collins_selenium_summary.txt')
with open(summary_file, 'w', encoding='utf-8') as f:
    f.write('COLLINS DICTIONARY SELENIUM ACCESS SUMMARY\n')
    f.write('='*50 + '\n\n')
    f.write(f'Access method: Selenium WebDriver\n')
    f.write(f'Timestamp: {time.strftime("%Y-%m-%d %H:%M:%S")}\n')
    f.write(f'Target: Collins Spanish-English dictionary "caminata" 1994 example\n\n')
    
    f.write(f'URLs attempted: {len(collins_urls)}\n')
    f.write(f'Successful: {len(successful_extractions)}\n')
    f.write(f'Failed: {len(failed_extractions)}\n')
    f.write(f'Pages with 1994: {len([p for p in successful_extractions if p["has_1994"]])}\n\n')
    
    if successful_extractions:
        f.write('SUCCESSFUL EXTRACTIONS:\n')
        f.write('-'*30 + '\n')
        for page in successful_extractions:
            f.write(f'URL: {page["url"]}\n')
            f.write(f'Title: {page["page_title"]}\n')
            f.write(f'File: {page["filename"]}\n')
            f.write(f'Has 1994: {page["has_1994"]}\n')
            f.write(f'Content length: {page["content_length"]:,} characters\n')
            f.write('-'*20 + '\n')
    
    if failed_extractions:
        f.write('\nFAILED EXTRACTIONS:\n')
        f.write('-'*30 + '\n')
        for page in failed_extractions:
            f.write(f'URL: {page["url"]}\n')
            f.write(f'Error: {page["error"]}\n')
            f.write('-'*20 + '\n')

print(f'\n✓ Selenium access summary saved to: {summary_file}')

# Final guidance
print('\n=== RESULTS AND NEXT STEPS ===')
if any(page['has_1994'] for page in successful_extractions):
    print('✓ SUCCESS: Found Collins dictionary content with 1994 references!')
    print('Next: Parse the saved HTML files and analysis to extract:')
    print('  1. The complete 1994 example sentence')
    print('  2. The source title/publication name')
    print('  3. Prepare source title for Google translation')
else:
    print('No 1994 references found in Collins dictionary pages')
    if successful_extractions:
        print('However, Collins dictionary content was successfully accessed')
        print('The 1994 example may not exist in the current online version')
    else:
        print('Collins dictionary access still blocked - may need alternative approach')
```