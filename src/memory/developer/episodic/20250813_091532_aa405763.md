### Development Step 60: Identify Star Trek writer collaborating with Dustin Nguyen on symbiotic expedition comics with Jeff Lemire

**Description**: Search for specific information about Dustin Nguyen's Star Trek comic work to identify which writer he collaborates with on Star Trek projects, particularly focusing on any comics that feature symbiotic relationships, researcher protagonists, or science expeditions. Cross-reference this with the Star Trek Aliens series criteria to find the exact writer-artist collaboration that completes the chain: Star Trek writer → Dustin Nguyen → Jeff Lemire.

**Use Cases**:
- Automating a comic publisher’s discovery process to identify ideal writer–artist pairings (e.g., finding Star Trek scripts by Mike Johnson drawn by Dustin Nguyen) for upcoming science-expedition miniseries
- Enriching a fan website’s Star Trek bibliography by scraping IDW listings to list all Dustin Nguyen collaborations featuring symbiotic relationships and linking each to their writer
- Powering a market analyst’s quarterly report on trending science-fiction comic themes by extracting and quantifying mentions of “symbiotic” and “researcher protagonist” across Star Trek Aliens issues
- Streamlining a library’s digital catalog metadata enhancement by auto-populating creator fields (writer, artist) for Star Trek comics, ensuring accurate cross-references between Dustin Nguyen and Jeff Lemire works
- Supporting an academic study of symbiotic narrative motifs in comics by gathering example panels, author credits, and contextual notes from Star Trek: Aliens entries for text-mining analysis
- Generating enriched product descriptions for an online comic retailer to spotlight issues illustrated by Dustin Nguyen and written by Star Trek veterans, boosting SEO for “science expedition” storylines
- Enabling a news aggregator to automatically surface and summarize new Star Trek comic releases with symbiotic themes and researcher heroes, keeping sci-fi journalism outlets up to date

```
import requests
from bs4 import BeautifulSoup
import json
import time
import re
import os

# Create workspace directory
os.makedirs('workspace', exist_ok=True)

print("=== SEARCHING FOR DUSTIN NGUYEN'S STAR TREK COMIC WORK ===")
print("Goal: Find Star Trek writer who collaborates with Dustin Nguyen")
print("Focus: Comics with symbiotic relationships, researcher protagonists, science expeditions")
print("Chain: Star Trek writer → Dustin Nguyen → Jeff Lemire")
print("=" * 70)

# Headers for web requests
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Connection': 'keep-alive'
}

# Search sources for Dustin Nguyen Star Trek work
search_sources = [
    {
        'name': 'Comic Book Database - Dustin Nguyen',
        'url': 'https://comicbookdb.com/creator.php?ID=3089',
        'search_terms': ['star trek', 'symbiotic', 'researcher', 'science']
    },
    {
        'name': 'MyComicShop - Dustin Nguyen',
        'url': 'https://www.mycomicshop.com/search?TID=285844',
        'search_terms': ['star trek', 'aliens', 'symbiotic']
    },
    {
        'name': 'Grand Comics Database Search',
        'url': 'https://www.comics.org/search/?target=creator&method=icontains&logic=False&keywords=Dustin+Nguyen&submit=Search',
        'search_terms': ['star trek']
    }
]

# Also search for general Star Trek Aliens series information
star_trek_sources = [
    {
        'name': 'Star Trek Aliens Series Search',
        'url': 'https://memory-alpha.fandom.com/wiki/Star_Trek_comics',
        'search_terms': ['aliens', 'symbiotic', 'researcher']
    },
    {
        'name': 'IDW Star Trek Comics',
        'url': 'https://www.idwpublishing.com/product-category/star-trek/',
        'search_terms': ['dustin nguyen', 'aliens', 'symbiotic']
    }
]

all_findings = []

print("\n=== STEP 1: SEARCHING DUSTIN NGUYEN'S COMIC BIBLIOGRAPHY ===\n")

for source in search_sources:
    print(f"Searching {source['name']}...")
    print(f"URL: {source['url']}")
    
    try:
        response = requests.get(source['url'], headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
        
        # Get text content
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        clean_text = ' '.join(chunk for chunk in chunks if chunk)
        
        print(f"✓ Successfully fetched content (Length: {len(clean_text)} chars)")
        
        # Search for Star Trek mentions
        star_trek_mentions = []
        sentences = clean_text.split('.')
        
        for sentence in sentences:
            if 'star trek' in sentence.lower():
                star_trek_mentions.append(sentence.strip())
                print(f"  Star Trek mention: {sentence.strip()[:100]}...")
        
        # Search for writer collaborations
        writer_patterns = [
            r'(written by|story by|script by|writer[:\s]+)([A-Z][a-z]+\s+[A-Z][a-z]+)',
            r'([A-Z][a-z]+\s+[A-Z][a-z]+)\s+(writer|writes|story)',
            r'with\s+([A-Z][a-z]+\s+[A-Z][a-z]+)',
            r'by\s+([A-Z][a-z]+\s+[A-Z][a-z]+)\s+and\s+Dustin\s+Nguyen',
            r'Dustin\s+Nguyen\s+and\s+([A-Z][a-z]+\s+[A-Z][a-z]+)'
        ]
        
        potential_writers = set()
        for pattern in writer_patterns:
            matches = re.findall(pattern, clean_text, re.IGNORECASE)
            for match in matches:
                if isinstance(match, tuple):
                    for name in match:
                        if name and len(name.split()) == 2 and name.lower() != 'dustin nguyen':
                            potential_writers.add(name.strip())
                elif isinstance(match, str) and len(match.split()) == 2:
                    if match.lower() != 'dustin nguyen':
                        potential_writers.add(match.strip())
        
        if potential_writers:
            print(f"  Potential writer collaborators found: {list(potential_writers)}")
        
        # Look for specific terms related to our criteria
        criteria_matches = []
        for term in source['search_terms']:
            if term.lower() in clean_text.lower():
                criteria_matches.append(term)
                # Find context around the term
                term_index = clean_text.lower().find(term.lower())
                if term_index != -1:
                    start = max(0, term_index - 100)
                    end = min(len(clean_text), term_index + 100)
                    context = clean_text[start:end]
                    print(f"  Found '{term}': ...{context}...")
        
        finding = {
            'source': source['name'],
            'url': source['url'],
            'star_trek_mentions': star_trek_mentions[:5],  # First 5 mentions
            'potential_writers': list(potential_writers),
            'criteria_matches': criteria_matches,
            'content_length': len(clean_text)
        }
        
        all_findings.append(finding)
        
        # Save content for detailed inspection
        safe_name = source['name'].lower().replace(' ', '_').replace('-', '_')
        content_file = f"workspace/{safe_name}_content.txt"
        with open(content_file, 'w', encoding='utf-8') as f:
            f.write(f"{source['name']} Content\n")
            f.write(f"URL: {source['url']}\n")
            f.write(f"{'='*50}\n\n")
            f.write(clean_text[:15000])  # Save first 15k characters
        
        print(f"  Content saved to: {content_file}")
        
    except Exception as e:
        print(f"  ✗ Error fetching {source['name']}: {str(e)}")
        continue
    
    print()
    time.sleep(2)  # Be respectful with requests

print("\n=== STEP 2: SEARCHING STAR TREK ALIENS SERIES INFORMATION ===\n")

for source in star_trek_sources:
    print(f"Searching {source['name']}...")
    print(f"URL: {source['url']}")
    
    try:
        response = requests.get(source['url'], headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
        
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        clean_text = ' '.join(chunk for chunk in chunks if chunk)
        
        print(f"✓ Successfully fetched content (Length: {len(clean_text)} chars)")
        
        # Look for Dustin Nguyen mentions
        nguyen_mentions = []
        sentences = clean_text.split('.')
        
        for sentence in sentences:
            if 'dustin nguyen' in sentence.lower() or 'nguyen' in sentence.lower():
                nguyen_mentions.append(sentence.strip())
                print(f"  Nguyen mention: {sentence.strip()[:100]}...")
        
        # Search for aliens series with our criteria
        aliens_patterns = [
            r'aliens?[^.]*symbiotic[^.]*',
            r'symbiotic[^.]*aliens?[^.]*',
            r'researcher[^.]*aliens?[^.]*',
            r'science[^.]*expedition[^.]*aliens?[^.]*'
        ]
        
        relevant_content = []
        for pattern in aliens_patterns:
            matches = re.findall(pattern, clean_text, re.IGNORECASE | re.DOTALL)
            for match in matches:
                if len(match) < 200:  # Keep reasonable length
                    relevant_content.append(match.strip())
                    print(f"  Relevant aliens content: {match.strip()[:100]}...")
        
        finding = {
            'source': source['name'],
            'url': source['url'],
            'nguyen_mentions': nguyen_mentions[:3],
            'relevant_aliens_content': relevant_content[:5],
            'content_length': len(clean_text)
        }
        
        all_findings.append(finding)
        
        # Save content
        safe_name = source['name'].lower().replace(' ', '_').replace('-', '_')
        content_file = f"workspace/{safe_name}_content.txt"
        with open(content_file, 'w', encoding='utf-8') as f:
            f.write(f"{source['name']} Content\n")
            f.write(f"URL: {source['url']}\n")
            f.write(f"{'='*50}\n\n")
            f.write(clean_text[:15000])
        
        print(f"  Content saved to: {content_file}")
        
    except Exception as e:
        print(f"  ✗ Error fetching {source['name']}: {str(e)}")
        continue
    
    print()
    time.sleep(2)

print("\n=== STEP 3: ANALYZING SEARCH RESULTS ===\n")

# Compile all potential writers found
all_writers = set()
star_trek_connections = []

for finding in all_findings:
    if 'potential_writers' in finding:
        all_writers.update(finding['potential_writers'])
    
    if finding.get('star_trek_mentions') or finding.get('nguyen_mentions'):
        star_trek_connections.append({
            'source': finding['source'],
            'star_trek_mentions': finding.get('star_trek_mentions', []),
            'nguyen_mentions': finding.get('nguyen_mentions', [])
        })

print(f"All potential writers found: {list(all_writers)}")
print(f"Sources with Star Trek connections: {len(star_trek_connections)}")

# Known Star Trek comic writers to cross-reference
known_star_trek_writers = [
    'Mike Johnson', 'Ryan Parrott', 'Collin Kelly', 'Jackson Lanzing',
    'Scott Tipton', 'David Tipton', 'John Byrne', 'Peter David',
    'Keith R.A. DeCandido', 'Chris Ryall', 'Roberto Orci', 'Alex Kurtzman'
]

print("\nCross-referencing with known Star Trek writers:")
matching_writers = []
for writer in all_writers:
    for known_writer in known_star_trek_writers:
        if writer.lower() in known_writer.lower() or known_writer.lower() in writer.lower():
            matching_writers.append((writer, known_writer))
            print(f"  Potential match: {writer} ↔ {known_writer}")

print("\n=== STEP 4: FOCUSED SEARCH FOR SPECIFIC COLLABORATIONS ===\n")

# Based on the criteria, let's search more specifically
specific_queries = [
    'Dustin Nguyen Star Trek Aliens symbiotic',
    'Star Trek researcher protagonist symbiotic relationship',
    'Star Trek science expedition aliens comic',
    'IDW Star Trek Aliens series writer artist'
]

print("Searching for specific Star Trek Aliens series information...")

# Manual knowledge injection based on Star Trek comic research
print("\n=== MANUAL RESEARCH ANALYSIS ===\n")
print("Based on Star Trek comic publishing history:")
print("- IDW Publishing has been the main Star Trek comic publisher since 2007")
print("- Star Trek: Aliens series would likely focus on symbiotic relationships")
print("- Common themes include researcher protagonists and science expeditions")

# Check for specific IDW Star Trek series
print("\nKnown IDW Star Trek series with alien/symbiotic themes:")
print("- Star Trek: The Next Generation - various series")
print("- Star Trek: Discovery - various series")
print("- Star Trek: Strange New Worlds")
print("- Star Trek: Lower Decks")

# Save comprehensive results
results = {
    'search_objective': 'Find Star Trek writer who collaborates with Dustin Nguyen',
    'search_criteria': [
        'Symbiotic relationships',
        'Researcher protagonists', 
        'Science expeditions',
        'Star Trek Aliens series'
    ],
    'sources_searched': len(search_sources + star_trek_sources),
    'findings': all_findings,
    'potential_writers': list(all_writers),
    'matching_known_writers': matching_writers,
    'star_trek_connections': star_trek_connections,
    'next_steps': [
        'Search specific IDW Star Trek series',
        'Check comic databases for Dustin Nguyen Star Trek work',
        'Look for recent Star Trek Aliens or symbiotic-themed series'
    ]
}

results_file = 'workspace/dustin_nguyen_star_trek_search.json'
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2, ensure_ascii=False)

print(f"\n✓ Complete search results saved to: {results_file}")
print(f"✓ Individual source content saved to workspace/ directory")

print("\n" + "=" * 70)
print("SEARCH SUMMARY:")
print("=" * 70)
if all_writers:
    print(f"Found {len(all_writers)} potential writer collaborators")
    print(f"Writers: {', '.join(list(all_writers)[:5])}{'...' if len(all_writers) > 5 else ''}")
else:
    print("No clear writer collaborators identified in initial search")

if star_trek_connections:
    print(f"\nFound Star Trek connections in {len(star_trek_connections)} sources")
else:
    print("\nNo direct Star Trek connections found")

print("\nRECOMMENDATIONS:")
print("1. Review saved content files for manual inspection")
print("2. Search more specific comic databases and IDW Publishing")
print("3. Look for recent Star Trek comic releases with alien themes")
print("4. Check for any Dustin Nguyen variant covers on Star Trek comics")
```