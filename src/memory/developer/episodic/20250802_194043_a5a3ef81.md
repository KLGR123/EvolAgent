### Development Step 9: Locate Emily Midkiffâ€™s June 2014 Dragon Depictions Article in Fafnir Journal

**Description**: Search for information about Emily Midkiff's June 2014 article, focusing on identifying the journal named after one of Hreidmar's sons from Norse mythology. Research Hreidmar's sons (Fafnir, Regin, and Otr) to determine which one has a journal named after them, then locate Midkiff's specific article from June 2014 that discusses dragon depictions and contains quotes from two different authors expressing distaste.

**Use Cases**:
- Academic library automation and metadata extraction for Nordic mythology journals to streamline cataloging of articles like Emily Midkiffâ€™s June 2014 dragon study
- Medieval studies research assistants scraping Fafnir journal archives to locate June 2014 articles on dragon depictions by Emily Midkiff for citation verification
- Digital humanities pipelines harvesting author quotes on dragon imagery and performing sentiment analysis on scholarly discussions of mythical creatures
- University IT departments scheduling automated crawls of Fafnir â€“ Nordic Journal to monitor new issue releases, archive completeness, and content availability
- Publishing house QA teams automating link verification and archive integrity checks after website updates to ensure all journal issues are accessible
- Graduate students compiling thematic literature reviews by extracting contextual excerpts around â€˜dragonâ€™, â€˜depictionâ€™, and â€˜distasteâ€™ from multiple journal issues
- SEO specialists tracking citations and mentions of niche academic articles to optimize discoverability and indexing of scholarly content
- Data science teams building dashboards of publication trends in science fiction and fantasy research using scraped issue metadata and key term frequency analysis

```
import os
import json
import requests
from bs4 import BeautifulSoup

print('=== ACCESSING FAFNIR JOURNAL - FIXED VARIABLE SCOPE ===') 
print('Objective: Navigate Fafnir journal website to find Emily Midkiff June 2014 article')
print('Strategy: Fix variable scope issue and systematically search journal archives\n')

# Ensure workspace exists
workspace = 'workspace'
os.makedirs(workspace, exist_ok=True)

# The Fafnir journal URL discovered from previous analysis
fafnir_journal_url = 'https://fafnir.journal.fi/'
print(f'Target URL: {fafnir_journal_url}')
print('Previous attempt confirmed this is "Fafnir â€“ Nordic Journal of Science Fiction and Fantasy Research"')

# Set up headers to mimic a real browser
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Connection': 'keep-alive'
}

print('\n=== STEP 1: ACCESSING FAFNIR JOURNAL HOMEPAGE ===\n')

try:
    print(f'Making request to: {fafnir_journal_url}')
    response = requests.get(fafnir_journal_url, headers=headers, timeout=30)
    
    print(f'Status code: {response.status_code}')
    print(f'Content length: {len(response.content):,} bytes')
    print(f'Content type: {response.headers.get("Content-Type", "unknown")}')
    
    if response.status_code == 200:
        # Save the homepage for analysis
        homepage_path = os.path.join(workspace, 'fafnir_journal_homepage.html')
        with open(homepage_path, 'w', encoding='utf-8') as f:
            f.write(response.text)
        print(f'âœ“ Homepage saved to: {homepage_path}')
        
        # Parse the homepage
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Get page title - FIXED: properly scope the variable
        page_title = soup.find('title')
        if page_title:
            title_text = page_title.get_text().strip()  # Define variable here
            print(f'\nPage title: {title_text}')
            
            # Confirm this is the correct journal
            if any(term in title_text.lower() for term in ['fafnir', 'nordic', 'science fiction', 'fantasy']):
                print('âœ“ CONFIRMED: This is the Fafnir - Nordic Journal of Science Fiction and Fantasy Research')
                print('âœ“ This journal is named after Fafnir, the dragon son of Hreidmar from Norse mythology')
            else:
                print('âš  Title does not clearly match expected journal description')
        else:
            print('No page title found')
        
        print('\n=== STEP 2: SEARCHING FOR ARCHIVE OR NAVIGATION LINKS ===\n')
        
        # Look for navigation links that might lead to archives or past issues
        navigation_patterns = [
            'archive', 'archives', 'past issues', 'back issues', 'volumes', 'issues',
            '2014', 'browse', 'all issues', 'previous', 'older'
        ]
        
        # Find all links on the page
        all_links = soup.find_all('a', href=True)
        print(f'Found {len(all_links)} total links on homepage')
        
        # Filter for navigation/archive links
        archive_links = []
        for link in all_links:
            href = link.get('href', '')
            text = link.get_text().strip()
            
            # Convert relative URLs to absolute
            if href.startswith('/'):
                full_url = f'https://fafnir.journal.fi{href}'
            elif not href.startswith('http'):
                full_url = f'https://fafnir.journal.fi/{href}'
            else:
                full_url = href
            
            # Check if this link might lead to archives
            link_text_lower = text.lower()
            href_lower = href.lower()
            
            relevance_score = 0
            for pattern in navigation_patterns:
                if pattern in link_text_lower:
                    relevance_score += 2
                if pattern in href_lower:
                    relevance_score += 1
            
            if relevance_score > 0 and len(text) > 2:  # Avoid empty or very short links
                archive_links.append({
                    'url': full_url,
                    'text': text[:100],  # Limit text length
                    'score': relevance_score,
                    'contains_2014': '2014' in link_text_lower or '2014' in href_lower
                })
        
        # Sort by relevance score
        archive_links.sort(key=lambda x: x['score'], reverse=True)
        
        print(f'Found {len(archive_links)} potential archive/navigation links:')
        for i, link in enumerate(archive_links[:10], 1):  # Show top 10
            print(f'  {i}. Score {link["score"]}: "{link["text"]}"')
            print(f'     URL: {link["url"]}')
            if link['contains_2014']:
                print('     *** CONTAINS 2014 REFERENCE ***')
            print()
        
        # Also search the homepage content for any direct 2014 or Midkiff references
        homepage_text = soup.get_text().lower()
        
        print('=== STEP 3: SEARCHING HOMEPAGE FOR 2014 AND MIDKIFF REFERENCES ===\n')
        
        # Count key terms on homepage
        key_terms = {
            '2014': homepage_text.count('2014'),
            'midkiff': homepage_text.count('midkiff'),
            'emily': homepage_text.count('emily'),
            'june': homepage_text.count('june'),
            'dragon': homepage_text.count('dragon')
        }
        
        print('Key term occurrences on homepage:')
        for term, count in key_terms.items():
            if count > 0:
                print(f'  {term}: {count}')
        
        # If we found 2014 references, extract contexts
        if key_terms['2014'] > 0:
            print('\n*** 2014 REFERENCES FOUND ON HOMEPAGE ***')
            
            full_homepage_text = soup.get_text()
            start_pos = 0
            contexts_2014 = []
            
            while True:
                pos = homepage_text.find('2014', start_pos)
                if pos == -1:
                    break
                
                context_start = max(0, pos - 100)
                context_end = min(len(full_homepage_text), pos + 150)
                context = full_homepage_text[context_start:context_end].strip()
                contexts_2014.append(context)
                start_pos = pos + 1
            
            print(f'Found {len(contexts_2014)} contexts mentioning 2014:')
            for i, context in enumerate(contexts_2014[:3], 1):
                print(f'  {i}. ...{context}...')
                print()
        
        # Try to access the most promising archive link
        if archive_links:
            # Prioritize links with 2014 references, then by score
            priority_links = [link for link in archive_links if link['contains_2014']]
            if not priority_links:
                priority_links = archive_links[:3]  # Take top 3 by score
            
            target_link = priority_links[0]
            print(f'=== STEP 4: ACCESSING HIGHEST PRIORITY NAVIGATION LINK ===\n')
            print(f'Target: "{target_link["text"]}" (Score: {target_link["score"]})')
            print(f'URL: {target_link["url"]}')
            if target_link['contains_2014']:
                print('*** This link contains 2014 reference! ***')
            
            try:
                print('\nMaking request to archive/navigation page...')
                nav_response = requests.get(target_link['url'], headers=headers, timeout=30)
                print(f'Navigation page status: {nav_response.status_code}')
                
                if nav_response.status_code == 200:
                    # Save navigation page
                    nav_path = os.path.join(workspace, 'fafnir_navigation_page.html')
                    with open(nav_path, 'w', encoding='utf-8') as f:
                        f.write(nav_response.text)
                    print(f'âœ“ Navigation page saved to: {nav_path}')
                    
                    # Parse navigation page
                    nav_soup = BeautifulSoup(nav_response.content, 'html.parser')
                    nav_text = nav_soup.get_text().lower()
                    
                    print(f'\n=== STEP 5: SEARCHING NAVIGATION PAGE FOR 2014 ISSUES ===\n')
                    
                    # Count key terms on navigation page
                    nav_key_terms = {
                        '2014': nav_text.count('2014'),
                        'midkiff': nav_text.count('midkiff'),
                        'emily': nav_text.count('emily'),
                        'june': nav_text.count('june'),
                        'volume': nav_text.count('volume'),
                        'issue': nav_text.count('issue')
                    }
                    
                    print('Key terms on navigation page:')
                    for term, count in nav_key_terms.items():
                        if count > 0:
                            print(f'  {term}: {count}')
                    
                    if nav_key_terms['2014'] > 0:
                        print('\n*** 2014 REFERENCES FOUND ON NAVIGATION PAGE ***')
                        
                        # Look for links containing 2014
                        nav_links = nav_soup.find_all('a', href=True)
                        links_2014 = []
                        
                        for link in nav_links:
                            href = link.get('href', '')
                            text = link.get_text().strip()
                            
                            if '2014' in text.lower() or '2014' in href.lower():
                                # Convert to absolute URL
                                if href.startswith('/'):
                                    full_url = f'https://fafnir.journal.fi{href}'
                                elif not href.startswith('http'):
                                    full_url = f'https://fafnir.journal.fi/{href}'
                                else:
                                    full_url = href
                                
                                links_2014.append({
                                    'url': full_url,
                                    'text': text[:150],  # Limit text length
                                    'contains_june': 'june' in text.lower() or 'june' in href.lower(),
                                    'contains_midkiff': 'midkiff' in text.lower() or 'midkiff' in href.lower()
                                })
                        
                        print(f'Found {len(links_2014)} links related to 2014:')
                        for i, link in enumerate(links_2014[:5], 1):
                            print(f'  {i}. "{link["text"]}"')
                            print(f'     URL: {link["url"]}')
                            if link['contains_june']:
                                print('     *** CONTAINS JUNE REFERENCE ***')
                            if link['contains_midkiff']:
                                print('     *** CONTAINS MIDKIFF REFERENCE ***')
                            print()
                        
                        # Try to access the most promising 2014 link
                        if links_2014:
                            # Prioritize links with June or Midkiff references
                            priority_2014 = [link for link in links_2014 if link['contains_june'] or link['contains_midkiff']]
                            if not priority_2014:
                                priority_2014 = links_2014[:1]  # Take first 2014 link
                            
                            issue_link = priority_2014[0]
                            print(f'=== STEP 6: ACCESSING 2014 ISSUE/VOLUME ===\n')
                            print(f'Target: "{issue_link["text"]}"')
                            print(f'URL: {issue_link["url"]}')
                            
                            try:
                                print('\nMaking request to 2014 issue page...')
                                issue_response = requests.get(issue_link['url'], headers=headers, timeout=30)
                                print(f'Issue page status: {issue_response.status_code}')
                                
                                if issue_response.status_code == 200:
                                    # Save 2014 issue page
                                    issue_path = os.path.join(workspace, 'fafnir_2014_issue.html')
                                    with open(issue_path, 'w', encoding='utf-8') as f:
                                        f.write(issue_response.text)
                                    print(f'âœ“ 2014 issue page saved to: {issue_path}')
                                    
                                    # Parse issue page for Emily Midkiff
                                    issue_soup = BeautifulSoup(issue_response.content, 'html.parser')
                                    issue_text = issue_soup.get_text().lower()
                                    
                                    print(f'\n=== STEP 7: SEARCHING 2014 ISSUE FOR EMILY MIDKIFF ===\n')
                                    
                                    # Count key terms on issue page
                                    issue_key_terms = {
                                        'midkiff': issue_text.count('midkiff'),
                                        'emily': issue_text.count('emily'),
                                        'june': issue_text.count('june'),
                                        'dragon': issue_text.count('dragon'),
                                        'depiction': issue_text.count('depiction')
                                    }
                                    
                                    print('Key terms on 2014 issue page:')
                                    for term, count in issue_key_terms.items():
                                        if count > 0:
                                            print(f'  {term}: {count}')
                                    
                                    if issue_key_terms['midkiff'] > 0:
                                        print('\nðŸŽ¯ *** EMILY MIDKIFF FOUND IN 2014 ISSUE! ***')
                                        
                                        # Extract contexts around Midkiff mentions
                                        full_issue_text = issue_soup.get_text()
                                        midkiff_contexts = []
                                        start_pos = 0
                                        
                                        while True:
                                            pos = issue_text.find('midkiff', start_pos)
                                            if pos == -1:
                                                break
                                            
                                            context_start = max(0, pos - 200)
                                            context_end = min(len(full_issue_text), pos + 300)
                                            context = full_issue_text[context_start:context_end].strip()
                                            midkiff_contexts.append(context)
                                            start_pos = pos + 1
                                        
                                        print(f'Found {len(midkiff_contexts)} Midkiff references:')
                                        for i, context in enumerate(midkiff_contexts, 1):
                                            print(f'\n{i}. Context around Midkiff mention:')
                                            print(f'   ...{context}...')
                                        
                                        # Look for article links containing Midkiff
                                        issue_links = issue_soup.find_all('a', href=True)
                                        midkiff_article_links = []
                                        
                                        for link in issue_links:
                                            href = link.get('href', '')
                                            text = link.get_text().strip()
                                            
                                            if 'midkiff' in text.lower() or 'midkiff' in href.lower():
                                                # Convert to absolute URL
                                                if href.startswith('/'):
                                                    full_url = f'https://fafnir.journal.fi{href}'
                                                elif not href.startswith('http'):
                                                    full_url = f'https://fafnir.journal.fi/{href}'
                                                else:
                                                    full_url = href
                                                
                                                midkiff_article_links.append({
                                                    'url': full_url,
                                                    'text': text[:200]  # Limit text length
                                                })
                                        
                                        if midkiff_article_links:
                                            print(f'\n*** FOUND {len(midkiff_article_links)} MIDKIFF ARTICLE LINKS ***')
                                            for i, link in enumerate(midkiff_article_links, 1):
                                                print(f'  {i}. "{link["text"]}"')
                                                print(f'     URL: {link["url"]}')
                                                print()
                                            
                                            # Save the successful discovery
                                            discovery_results = {
                                                'research_objective': 'Find Emily Midkiff June 2014 article in Fafnir journal about dragon depictions',
                                                'journal_identified': 'Fafnir - Nordic Journal of Science Fiction and Fantasy Research',
                                                'journal_url': fafnir_journal_url,
                                                'mythological_connection': 'Named after Fafnir, dragon son of Hreidmar from Norse mythology',
                                                'search_progress': {
                                                    'homepage_accessed': True,
                                                    'navigation_found': True,
                                                    'year_2014_located': True,
                                                    'emily_midkiff_found': True
                                                },
                                                'midkiff_article_links': midkiff_article_links,
                                                'midkiff_contexts': midkiff_contexts[:3],  # Save first 3 contexts
                                                'next_action': 'Access Emily Midkiff article to find dragon depiction quotes from two authors expressing distaste',
                                                'files_saved': [
                                                    'fafnir_journal_homepage.html',
                                                    'fafnir_navigation_page.html', 
                                                    'fafnir_2014_issue.html'
                                                ],
                                                'timestamp': '2025-01-27 midkiff_article_discovered'
                                            }
                                            
                                            discovery_file = os.path.join(workspace, 'emily_midkiff_article_discovery.json')
                                            with open(discovery_file, 'w', encoding='utf-8') as f:
                                                json.dump(discovery_results, f, indent=2, ensure_ascii=False)
                                            
                                            print(f'ðŸŽ¯ *** MAJOR SUCCESS ***')
                                            print(f'âœ“ Successfully navigated Fafnir journal website')
                                            print(f'âœ“ Located 2014 issue archives')
                                            print(f'âœ“ FOUND Emily Midkiff in 2014 issue!')
                                            print(f'âœ“ Discovered {len(midkiff_article_links)} potential article links')
                                            print(f'âœ“ Complete discovery saved to: {discovery_file}')
                                            print(f'\nOBJECTIVE NEARLY COMPLETE:')
                                            print(f'- âœ“ Identified journal named after Hreidmar\'s son: Fafnir (dragon)')
                                            print(f'- âœ“ Located Emily Midkiff\'s June 2014 article')
                                            print(f'- â†’ Next: Access article to find quotes from two authors expressing distaste about dragons')
                                        
                                        else:
                                            print('Midkiff found in issue text but no direct article links identified')
                                            print('The article content may be embedded in the issue page or require different navigation')
                                    
                                    else:
                                        print('Emily Midkiff not found in this 2014 issue page')
                                        print('May need to check other 2014 issues or try different search approach')
                                
                                else:
                                    print(f'Failed to access 2014 issue page: {issue_response.status_code}')
                            
                            except Exception as e:
                                print(f'Error accessing 2014 issue: {str(e)}')
                        
                        else:
                            print('No 2014 links found on navigation page')
                    
                    else:
                        print('No 2014 references found on navigation page')
                        print('May need to try different navigation approach or search functionality')
                
                else:
                    print(f'Failed to access navigation page: {nav_response.status_code}')
            
            except Exception as e:
                print(f'Error accessing navigation page: {str(e)}')
        
        else:
            print('No archive or navigation links found on homepage')
            print('Will try alternative search approaches')
    
    else:
        print(f'Failed to access Fafnir journal homepage: {response.status_code}')
        print(f'Response preview: {response.text[:300]}...')

except Exception as e:
    print(f'Error during Fafnir journal access: {str(e)}')

print('\n*** FAFNIR JOURNAL NAVIGATION COMPLETE ***')
print('Status: Systematically navigated journal website to locate Emily Midkiff article')
print('Objective: Find June 2014 article about dragon depictions with quotes from two authors expressing distaste')
```