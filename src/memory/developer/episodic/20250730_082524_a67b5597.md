### Development Step 4: Locate Chinstrap Penguin End-2018 Population Figure on Wikipedia, Note Units and Source

**Description**: Search for and access the Wikipedia page about penguin species populations to locate the specific chinstrap penguin population data as of the end of 2018. Extract the population figure, noting whether it's given in breeding pairs or individual penguins, and document the exact source and context of this information.

**Use Cases**:
- Conservation NGOs automating collection of IUCN population data for chinstrap penguins and other species to update annual impact reports and support grant applications
- Marine biodiversity researchers extracting and aggregating 2018 population figures and measurement types from Wikipedia for multivariate statistical modeling of Antarctic ecosystem health
- Educational publishers generating data-driven infographics on penguin populations, automatically pulling exact quotes and citations to ensure academic accuracy in textbooks
- Environmental consultants incorporating up-to-date wildlife population metrics into corporate sustainability assessments, scraping IUCN estimates and source contexts for regulatory compliance documentation
- Data journalism teams verifying public claims about penguin population trends by extracting precise 2018 figures and reference links to fact-check articles on wildlife conservation
- Government wildlife agencies building a centralized database of species population statistics, using automated scraping to integrate Wikipedia’s conservation status sections with GIS-based planning tools
- Software developers creating a mobile app for wildlife enthusiasts, populating species profiles with live population estimates and direct source citations from Wikipedia pages
- Grant-writing specialists compiling authoritative citations for funding proposals, automating extraction of population data and full source context from IUCN references on Wikipedia

```
import os
import json
import re
from bs4 import BeautifulSoup

print("=== CHINSTRAP PENGUIN POPULATION RESEARCH - FINAL STEP ===\n")
print("Objective: Compile complete answer with exact 2018 IUCN population data and full source context")
print("Focus: Extract precise citation details and confirm population measurement type\n")

# First, let's inspect the workspace to understand what files we have
print("Files available in workspace:")
if os.path.exists('workspace'):
    workspace_files = os.listdir('workspace')
    for file in workspace_files:
        file_path = os.path.join('workspace', file)
        file_size = os.path.getsize(file_path)
        print(f"  - {file} ({file_size:,} bytes)")
else:
    print("  No workspace directory found")

# Inspect the main extraction results file structure first
extraction_file = 'workspace/chinstrap_penguin_population_extraction.json'
if os.path.exists(extraction_file):
    print(f"\n=== INSPECTING EXTRACTION RESULTS STRUCTURE ===\n")
    
    with open(extraction_file, 'r') as f:
        extraction_data = json.load(f)
    
    print("Top-level keys in extraction results:")
    for key, value in extraction_data.items():
        if isinstance(value, dict):
            print(f"  {key}: Dictionary with {len(value)} keys")
        elif isinstance(value, list):
            print(f"  {key}: List with {len(value)} items")
        else:
            print(f"  {key}: {value}")
    
    # Examine the pages_data structure
    if 'pages_data' in extraction_data:
        print(f"\nPages data structure:")
        for i, page in enumerate(extraction_data['pages_data']):
            print(f"  Page {i+1}: {page.get('page_name', 'Unknown')}")
            for key in page.keys():
                if key == 'population_matches' and page[key]:
                    print(f"    {key}: {len(page[key])} matches found")
                elif key == 'conservation_sections' and page[key]:
                    print(f"    {key}: {len(page[key])} sections found")
                else:
                    print(f"    {key}: {type(page[key]).__name__}")

# Now let's extract the specific population data we need
print(f"\n=== EXTRACTING FINAL POPULATION DATA ===\n")

if os.path.exists(extraction_file):
    with open(extraction_file, 'r') as f:
        extraction_data = json.load(f)
    
    # Find the Chinstrap penguin page data
    chinstrap_page_data = None
    for page in extraction_data.get('pages_data', []):
        if 'Chinstrap penguin' in page.get('page_name', ''):
            chinstrap_page_data = page
            break
    
    if chinstrap_page_data:
        print("✓ Found Chinstrap penguin page data")
        
        # Extract the best population matches
        population_matches = chinstrap_page_data.get('population_matches', [])
        print(f"Population matches found: {len(population_matches)}")
        
        # Find the most complete match
        best_match = None
        for match in population_matches:
            text = match.get('matched_text', '')
            if 'In 2018' in text and 'IUCN estimated' in text and '8 million specimens' in text:
                best_match = match
                break
        
        if best_match:
            print(f"\n✓ FOUND EXACT POPULATION DATA:")
            print(f"Text: {best_match['matched_text']}")
            
            # Also check conservation sections for additional context
            conservation_sections = chinstrap_page_data.get('conservation_sections', [])
            print(f"\nConservation sections: {len(conservation_sections)}")
            
            for section in conservation_sections:
                print(f"  Section: {section.get('section_title', 'Unknown')}")
                content = section.get('content', '')[:200] + '...' if len(section.get('content', '')) > 200 else section.get('content', '')
                print(f"  Content preview: {content}")

# Also examine the HTML file directly for more detailed citation information
chinstrap_html_file = None
for file in workspace_files:
    if 'chinstrap_penguin.html' in file:
        chinstrap_html_file = f'workspace/{file}'
        break

if chinstrap_html_file:
    print(f"\n=== ANALYZING HTML SOURCE FOR DETAILED CITATION ===\n")
    print(f"HTML file: {chinstrap_html_file}")
    
    with open(chinstrap_html_file, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # Look for the specific conservation status section
    print("Searching for conservation status section...")
    
    # Find conservation status heading
    conservation_heading = soup.find(['h2', 'h3'], string=re.compile(r'Conservation status', re.IGNORECASE))
    if conservation_heading:
        print(f"✓ Found conservation status heading: {conservation_heading.get_text()}")
        
        # Get the content following this heading
        current = conservation_heading.parent if conservation_heading.parent else conservation_heading
        
        # Find the next few paragraphs
        conservation_content = []
        for _ in range(10):  # Look at next 10 elements
            current = current.find_next_sibling()
            if current is None:
                break
            if current.name == 'p':
                text = current.get_text().strip()
                if '2018' in text and 'IUCN' in text:
                    conservation_content.append(text)
                    print(f"\n✓ FOUND DETAILED CONSERVATION TEXT:")
                    print(f"{text}")
                    
                    # Look for citations/references in this paragraph
                    citations = current.find_all(['sup', 'a'], class_=re.compile(r'reference|cite', re.IGNORECASE))
                    if citations:
                        print(f"\nCitations found: {len(citations)}")
                        for cite in citations[:3]:  # Show first 3 citations
                            cite_text = cite.get_text().strip()
                            cite_href = cite.get('href', '')
                            print(f"  Citation: {cite_text} (href: {cite_href})")
                    
                    break
            elif current.name in ['h1', 'h2', 'h3', 'h4']:  # Hit next major section
                break
    
    # Also search for any references section that might contain the IUCN source
    print(f"\n=== SEARCHING FOR REFERENCES TO IUCN 2018 ===\n")
    
    # Look for references or bibliography sections
    ref_sections = soup.find_all(['h2', 'h3'], string=re.compile(r'reference|bibliography|source', re.IGNORECASE))
    print(f"Reference sections found: {len(ref_sections)}")
    
    # Search for IUCN citations in the entire document
    iucn_mentions = soup.find_all(string=re.compile(r'IUCN.*2018|2018.*IUCN', re.IGNORECASE))
    print(f"IUCN 2018 mentions found: {len(iucn_mentions)}")
    
    for i, mention in enumerate(iucn_mentions[:3], 1):  # Show first 3
        clean_mention = ' '.join(mention.strip().split())
        print(f"  {i}. {clean_mention[:150]}...")

# Compile the final answer
print(f"\n=== COMPILING FINAL ANSWER ===\n")

final_answer = {
    'research_objective': 'Find chinstrap penguin population data as of end of 2018',
    'data_found': True,
    'population_figure': '8 million specimens',
    'measurement_type': 'Individual penguins (specimens), not breeding pairs',
    'source_year': '2018',
    'source_organization': 'IUCN (International Union for Conservation of Nature)',
    'exact_quote': 'In 2018, the IUCN estimated that the population of chinstrap penguins was around 8 million specimens.',
    'source_page': 'Wikipedia: Chinstrap penguin',
    'source_url': 'https://en.wikipedia.org/wiki/Chinstrap_penguin',
    'section': 'Conservation status',
    'extraction_timestamp': extraction_data.get('extraction_timestamp', 'Unknown'),
    'confidence_level': 'High - Direct quote from authoritative source with clear attribution'
}

# Save the final answer
with open('workspace/chinstrap_penguin_final_answer.json', 'w') as f:
    json.dump(final_answer, f, indent=2)

print("✓ RESEARCH COMPLETE - FINAL ANSWER COMPILED:")
print(f"")
print(f"Population Figure: {final_answer['population_figure']}")
print(f"Measurement Type: {final_answer['measurement_type']}")
print(f"Source: {final_answer['source_organization']} ({final_answer['source_year']})")
print(f"Exact Quote: '{final_answer['exact_quote']}'")
print(f"Source Page: {final_answer['source_page']}")
print(f"Confidence: {final_answer['confidence_level']}")
print(f"")
print(f"Final answer saved to: workspace/chinstrap_penguin_final_answer.json")
print(f"\n🐧 CHINSTRAP PENGUIN POPULATION RESEARCH SUCCESSFULLY COMPLETED 🐧")
```