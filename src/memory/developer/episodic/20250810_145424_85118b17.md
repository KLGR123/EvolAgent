### Development Step 9: Find and Confirm Greg Chappell’s Death Date Using Obituaries, Cricket Databases, and News Archives

**Description**: Search for information about when Greg Chappell passed away. Focus on finding his death date and year, using search terms including 'Greg Chappell death date', 'Greg Chappell died year', 'Greg Chappell obituary', and 'Greg Chappell Australian cricketer death'. Verify the information from reliable sources such as cricket databases, news archives, or official cricket organizations.

**Use Cases**:
- Life insurance claim automation and death date verification using targeted obituary scraping
- Genealogy research and automated extraction of ancestors’ death records from historical databases
- HR compliance and benefits management with live/deceased status tracking for former employees
- Media fact-checking and journalist workflows for verifying celebrity or public figure death announcements
- Sports analytics and database maintenance for athlete lifecycle management and accurate living status
- Legal due diligence and background checks in M&A by confirming individual stakeholders’ living status
- Estate planning software automation that triggers asset distribution workflows upon death confirmation
- News aggregation and obituary curation for digital memorial platforms via real-time web scraping

```
import os
import requests
import json
import time
from urllib.parse import quote_plus
from bs4 import BeautifulSoup
from collections import Counter
import re

print('=== SEARCHING FOR GREG CHAPPELL DEATH INFORMATION ===')
print('Target: Greg Chappell - Australian cricket legend')
print('Objective: Find death date and year information')
print('Note: This search will help verify if Greg Chappell is still alive or has passed away\n')

# Ensure workspace directory exists
os.makedirs('workspace', exist_ok=True)

# Define targeted search queries for Greg Chappell death information
search_queries = [
    'Greg Chappell death date died',
    'Greg Chappell Australian cricketer death',
    'Greg Chappell obituary death year',
    'Greg Chappell passed away when',
    'Greg Chappell cricket death date',
    'Greg Chappell died year cricket',
    'Greg Chappell Australian cricket captain death',
    'Greg Chappell cricket legend obituary'
]

print(f'Executing {len(search_queries)} targeted searches for Greg Chappell death information:')
for i, query in enumerate(search_queries, 1):
    print(f'  {i}. {query}')

# Headers for web requests to avoid blocking
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Accept-Encoding': 'gzip, deflate',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1'
}

# Initialize results storage
search_results = {
    'search_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'target_person': 'Greg Chappell',
    'objective': 'Find death date and year of Greg Chappell',
    'queries': search_queries,
    'results': [],
    'death_year_candidates': [],
    'biographical_info': [],
    'analysis': {},
    'alive_indicators': [],
    'death_indicators': []
}

print('\n=== EXECUTING DUCKDUCKGO SEARCHES ===')
print('=' * 60)

# Function to extract and analyze search results for biographical information
def analyze_biographical_content(html_content, query):
    """Extract and analyze biographical search results from HTML content"""
    soup = BeautifulSoup(html_content, 'html.parser')
    
    results = []
    
    # Look for various result container patterns
    result_containers = soup.find_all(['div', 'article'], class_=lambda x: x and any(term in str(x).lower() for term in ['result', 'web-result', 'links_main']))
    
    if not result_containers:
        # Fallback: look for any links that might be results
        result_containers = soup.find_all('a', href=True)
    
    for container in result_containers[:20]:  # Check more results for biographical info
        try:
            # Extract title
            title_elem = container.find(['h2', 'h3', 'a']) or container
            title = title_elem.get_text().strip() if title_elem else 'No title'
            
            # Extract link
            link_elem = container.find('a', href=True) or (container if container.name == 'a' else None)
            link = link_elem.get('href') if link_elem else 'No link'
            
            # Extract snippet/description
            snippet_elem = container.find(['p', 'span', 'div'], class_=lambda x: x and 'snippet' in str(x).lower()) or container.find('p')
            snippet = snippet_elem.get_text().strip() if snippet_elem else 'No snippet'
            
            # Skip if no meaningful content
            if len(title) < 5 or title == 'No title':
                continue
                
            # Calculate relevance score for biographical information
            combined_text = f'{title} {snippet} {link}'.lower()
            
            relevance_score = 0
            matched_terms = []
            death_indicators = []
            alive_indicators = []
            
            # Key terms for Greg Chappell biographical information
            key_terms = {
                'greg chappell': 5,
                'death': 4,
                'died': 4,
                'death date': 5,
                'obituary': 4,
                'passed away': 4,
                'biography': 3,
                'biographical': 3,
                'cricket': 2,
                'australian': 2,
                'cricketer': 2,
                'captain': 2,
                'born': 2,
                'life': 1,
                'still alive': 3,
                'living': 2,
                'current': 1,
                'today': 1,
                'recent': 1
            }
            
            # Look for specific death year patterns
            year_patterns = re.findall(r'\b(19\d{2}|20\d{2})\b', combined_text)
            
            for term, weight in key_terms.items():
                if term in combined_text:
                    relevance_score += weight
                    matched_terms.append(term)
            
            # Check for death-related year mentions
            death_words = ['death', 'died', 'obituary', 'passed away', 'demise']
            alive_words = ['still alive', 'living', 'current', 'recent', 'today']
            
            for year in year_patterns:
                for death_word in death_words:
                    if death_word in combined_text:
                        # Check if year appears near death word (within 50 characters)
                        death_pos = combined_text.find(death_word)
                        year_pos = combined_text.find(year)
                        if abs(death_pos - year_pos) < 50:
                            death_indicators.append(f'{year} (near "{death_word}")')
                            relevance_score += 3
            
            # Check for alive indicators
            for alive_word in alive_words:
                if alive_word in combined_text:
                    alive_indicators.append(alive_word)
                    relevance_score += 2
            
            if relevance_score > 0:  # Only include results with some relevance
                results.append({
                    'title': title[:250],
                    'link': link,
                    'snippet': snippet[:400],
                    'relevance_score': relevance_score,
                    'matched_terms': matched_terms,
                    'death_indicators': death_indicators,
                    'alive_indicators': alive_indicators,
                    'years_mentioned': year_patterns,
                    'query': query
                })
                
        except Exception as e:
            continue  # Skip problematic results
    
    return results

# Execute searches for Greg Chappell death information
for i, query in enumerate(search_queries, 1):
    print(f'\nSearch {i}/{len(search_queries)}: {query}')
    print('-' * 50)
    
    try:
        # Construct DuckDuckGo search URL
        search_url = f'https://html.duckduckgo.com/html/?q={quote_plus(query)}'
        
        print(f'Requesting: {search_url}')
        response = requests.get(search_url, headers=headers, timeout=30)
        
        if response.status_code == 200:
            print(f'✅ Successfully retrieved search results (Status: {response.status_code})')
            
            # Save raw HTML for reference
            html_filename = f'greg_chappell_search_{i}_{query.replace(" ", "_").replace("\'\'", "")[:30]}.html'
            html_filepath = os.path.join('workspace', html_filename)
            
            with open(html_filepath, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            print(f'Raw HTML saved to: {html_filepath}')
            
            # Analyze search results
            search_results_batch = analyze_biographical_content(response.text, query)
            
            print(f'Extracted {len(search_results_batch)} relevant results')
            
            # Display high-relevance results
            high_relevance = [r for r in search_results_batch if r['relevance_score'] >= 8]
            moderate_relevance = [r for r in search_results_batch if 5 <= r['relevance_score'] < 8]
            
            if high_relevance:
                print(f'\n🎯 HIGH RELEVANCE RESULTS ({len(high_relevance)}):') 
                for j, result in enumerate(high_relevance, 1):
                    print(f'  {j}. Score: {result["relevance_score"]} | {result["title"][:100]}...')
                    print(f'     Terms: {", ".join(result["matched_terms"][:8])}')
                    print(f'     Death indicators: {result["death_indicators"]}')
                    print(f'     Alive indicators: {result["alive_indicators"]}')
                    print(f'     Years mentioned: {result["years_mentioned"]}')
                    print(f'     Link: {result["link"]}')
                    print(f'     Snippet: {result["snippet"][:200]}...')
                    print()
            
            if moderate_relevance:
                print(f'\n⭐ MODERATE RELEVANCE RESULTS ({len(moderate_relevance)}):') 
                for j, result in enumerate(moderate_relevance[:3], 1):  # Show top 3
                    print(f'  {j}. Score: {result["relevance_score"]} | {result["title"][:80]}...')
                    print(f'     Terms: {", ".join(result["matched_terms"][:5])}')
                    print(f'     Death indicators: {result["death_indicators"]}')
                    print(f'     Alive indicators: {result["alive_indicators"]}')
                    print(f'     Years: {result["years_mentioned"]}')
            
            # Store results
            search_results['results'].extend(search_results_batch)
            
            # Identify death year candidates and alive indicators
            death_candidates = [r for r in search_results_batch if r['death_indicators'] or 
                              (r['relevance_score'] >= 6 and any(term in r['matched_terms'] for term in ['death', 'died']))]
            
            alive_candidates = [r for r in search_results_batch if r['alive_indicators'] or
                              (r['relevance_score'] >= 6 and any(term in r['matched_terms'] for term in ['still alive', 'living']))]
            
            if death_candidates:
                print(f'\n💀 DEATH INDICATORS FOUND ({len(death_candidates)}):') 
                for candidate in death_candidates:
                    print(f'  • {candidate["title"][:120]}...')
                    print(f'    Score: {candidate["relevance_score"]} | Death indicators: {candidate["death_indicators"]}')
                    print(f'    Years: {candidate["years_mentioned"]} | Terms: {", ".join(candidate["matched_terms"][:5])}')
                    search_results['death_year_candidates'].append(candidate)
            
            if alive_candidates:
                print(f'\n✅ ALIVE INDICATORS FOUND ({len(alive_candidates)}):') 
                for candidate in alive_candidates:
                    print(f'  • {candidate["title"][:120]}...')
                    print(f'    Score: {candidate["relevance_score"]} | Alive indicators: {candidate["alive_indicators"]}')
                    print(f'    Terms: {", ".join(candidate["matched_terms"][:5])}')
                    search_results['alive_indicators'].append(candidate)
                    
        else:
            print(f'❌ Request failed with status: {response.status_code}')
            
    except Exception as e:
        print(f'❌ Error in search {i}: {str(e)}')
    
    print(f'Completed search {i}/{len(search_queries)}')
    time.sleep(3)  # Rate limiting

print('\n' + '=' * 80)
print('COMPREHENSIVE ANALYSIS OF GREG CHAPPELL DEATH/ALIVE STATUS')
print('=' * 80)

# Sort all results by relevance score
search_results['results'].sort(key=lambda x: x['relevance_score'], reverse=True)

total_results = len(search_results['results'])
print(f'Total results collected: {total_results}')
print(f'Death indicators found: {len(search_results["death_year_candidates"])}')
print(f'Alive indicators found: {len(search_results["alive_indicators"])}')

if search_results['results']:
    print('\n🏆 TOP 10 HIGHEST SCORING RESULTS:') 
    print('-' * 50)
    
    for i, result in enumerate(search_results['results'][:10], 1):
        print(f'{i:2d}. Score: {result["relevance_score"]} | Query: {result["query"]}')
        print(f'    Title: {result["title"][:120]}...')
        print(f'    Terms: {", ".join(result["matched_terms"][:6])}')
        print(f'    Death indicators: {result["death_indicators"]}')
        print(f'    Alive indicators: {result["alive_indicators"]}')
        print(f'    Years mentioned: {result["years_mentioned"]}')
        print(f'    Link: {result["link"]}')
        print(f'    Snippet: {result["snippet"][:150]}...')
        print()

# Analyze death vs alive indicators
all_death_indicators = []
all_alive_indicators = []
all_years_mentioned = []

for result in search_results['results']:
    all_death_indicators.extend(result['death_indicators'])
    all_alive_indicators.extend(result['alive_indicators'])
    all_years_mentioned.extend(result['years_mentioned'])

death_indicator_frequency = Counter(all_death_indicators)
alive_indicator_frequency = Counter(all_alive_indicators)
year_frequency = Counter(all_years_mentioned)

print('\n📊 DEATH VS ALIVE STATUS ANALYSIS:')
print('-' * 40)
print(f'Total death indicators found: {len(all_death_indicators)}')
print(f'Total alive indicators found: {len(all_alive_indicators)}')

if death_indicator_frequency:
    print('\nDeath indicators found:')
    for indicator, count in death_indicator_frequency.most_common(10):
        print(f'  {indicator}: {count} occurrences')
else:
    print('\nNo specific death indicators found in search results')

if alive_indicator_frequency:
    print('\nAlive indicators found:')
    for indicator, count in alive_indicator_frequency.most_common(10):
        print(f'  {indicator}: {count} occurrences')
else:
    print('\nNo specific alive indicators found in search results')

print('\nAll years mentioned in results:')
for year, count in year_frequency.most_common(15):
    print(f'  {year}: {count} occurrences')

# Determine status based on evidence
print('\n🔍 STATUS DETERMINATION:')
print('-' * 30)

death_evidence_score = len(all_death_indicators) * 2 + len(search_results['death_year_candidates'])
alive_evidence_score = len(all_alive_indicators) * 2 + len(search_results['alive_indicators'])

print(f'Death evidence score: {death_evidence_score}')
print(f'Alive evidence score: {alive_evidence_score}')

if death_evidence_score > alive_evidence_score and death_evidence_score > 0:
    print('\n💀 PRELIMINARY CONCLUSION: Evidence suggests Greg Chappell may have passed away')
    if death_indicator_frequency:
        most_common_death = death_indicator_frequency.most_common(1)[0]
        print(f'Most common death indicator: {most_common_death[0]} ({most_common_death[1]} occurrences)')
elif alive_evidence_score > death_evidence_score and alive_evidence_score > 0:
    print('\n✅ PRELIMINARY CONCLUSION: Evidence suggests Greg Chappell is still alive')
    if alive_indicator_frequency:
        most_common_alive = alive_indicator_frequency.most_common(1)[0]
        print(f'Most common alive indicator: {most_common_alive[0]} ({most_common_alive[1]} occurrences)')
else:
    print('\n❓ INCONCLUSIVE: Insufficient or conflicting evidence found')
    print('Need to examine search results more carefully or try different sources')

# Save comprehensive results
results_file = os.path.join('workspace', 'greg_chappell_death_search.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(search_results, f, indent=2, ensure_ascii=False)

print(f'\n💾 COMPREHENSIVE RESULTS SAVED TO: {results_file}')

# Summary statistics
search_results['analysis'] = {
    'total_results': total_results,
    'high_relevance_count': len([r for r in search_results['results'] if r['relevance_score'] >= 8]),
    'moderate_relevance_count': len([r for r in search_results['results'] if 5 <= r['relevance_score'] < 8]),
    'death_candidates_count': len(search_results['death_year_candidates']),
    'alive_candidates_count': len(search_results['alive_indicators']),
    'death_indicators_found': len(all_death_indicators),
    'alive_indicators_found': len(all_alive_indicators),
    'unique_years_mentioned': len(set(all_years_mentioned)),
    'death_evidence_score': death_evidence_score,
    'alive_evidence_score': alive_evidence_score,
    'most_common_years': dict(year_frequency.most_common(5))
}

print(f'\n📈 FINAL STATISTICS:')
print(f'   • Total results: {search_results["analysis"]["total_results"]}')
print(f'   • High relevance (8+): {search_results["analysis"]["high_relevance_count"]}')
print(f'   • Moderate relevance (5-7): {search_results["analysis"]["moderate_relevance_count"]}')
print(f'   • Death candidates: {search_results["analysis"]["death_candidates_count"]}')
print(f'   • Alive candidates: {search_results["analysis"]["alive_candidates_count"]}')
print(f'   • Death indicators: {search_results["analysis"]["death_indicators_found"]}')
print(f'   • Alive indicators: {search_results["analysis"]["alive_indicators_found"]}')
print(f'   • Unique years mentioned: {search_results["analysis"]["unique_years_mentioned"]}')
print(f'   • Most common years: {list(search_results["analysis"]["most_common_years"].keys())}')

print('\n🎯 PRELIMINARY FINDINGS:')
if search_results['analysis']['death_indicators_found'] > 0:
    print('✅ Death-related information found in search results')
    if search_results['analysis']['death_evidence_score'] > search_results['analysis']['alive_evidence_score']:
        print('✅ Death evidence outweighs alive evidence')
if search_results['analysis']['alive_indicators_found'] > 0:
    print('✅ Alive-related information found in search results')
    if search_results['analysis']['alive_evidence_score'] > search_results['analysis']['death_evidence_score']:
        print('✅ Alive evidence outweighs death evidence')

print('\n📋 NEXT STEPS:')
print('1. 🔍 Review saved HTML files for additional context')
print('2. 🔍 Follow up on high-relevance links for detailed information') 
print('3. 🔍 Cross-reference multiple sources to confirm status')
print('4. 🔍 Search cricket databases or official cricket organizations')
print('5. 🔍 Look for recent news or interviews with Greg Chappell')

print('\n=== GREG CHAPPELL DEATH/ALIVE STATUS SEARCH PHASE COMPLETE ===')
```