### Development Step 3: Permanent U.S. Homeland Security Secretaries Serving Before April 2019

**Description**: Search for a comprehensive list of all United States secretaries of homeland security who served prior to April 2019, excluding those who served in an acting capacity only. Use reliable government sources or authoritative websites for this information.

**Use Cases**:
- Political science research dataset assembly for tenure analysis of DHS cabinet positions, enabling scholars to study turnover rates under different administrations
- News media timeline automation for interactive reporting on departmental leadership changes, allowing editors to embed up‐to‐date secretary lists in breaking‐news articles
- Civic education platform integration for historical leadership quizzes and multimedia modules, providing students with accurate profiles of past DHS secretaries
- Government transparency portal maintenance and automated updates of cabinet member lists, ensuring public access to reliable tenure data without manual edits
- Data migration for Federal archive modernization, converting scattered HTML/PDF records of past secretaries into a structured JSON archive for open‐data repositories
- Risk assessment dashboard enrichment with historical DHS leadership timelines, helping analysts correlate changes in leadership with shifts in department policies
- Contract compliance verification by matching contractor award dates against secretary service periods, streamlining audits of eligibility under specific administrations
- Knowledge graph population for policy analysis using structured cabinet data, feeding accurate secretary names and tenures into AI‐driven decision‐support tools

```
import requests
import re
import os
from bs4 import BeautifulSoup
import json
from datetime import datetime

print("Searching for U.S. Secretaries of Homeland Security prior to April 2019...")

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

# Function to get HTML content from a URL with proper headers
def get_page_content(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        print(f"Fetching: {url}")
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        print(f"Successfully fetched: {url}")
        return response.text
    except Exception as e:
        print(f"Error fetching {url}: {str(e)}")
        return None

# Function to clean up text (remove extra spaces, newlines, etc.)
def clean_text(text):
    if text is None:
        return ""
    # Remove extra whitespace
    cleaned = re.sub(r'\s+', ' ', text)
    # Remove citations/references [1], [2], etc.
    cleaned = re.sub(r'\[\d+\]', '', cleaned)
    # Remove leading/trailing whitespace
    cleaned = cleaned.strip()
    return cleaned

# Function to parse date string into a datetime object for sorting
def parse_date(date_str):
    try:
        # Try to extract year, month, day with regex
        date_pattern = r'(?P<month>[A-Za-z]+)\s+(?P<day>\d+),\s+(?P<year>\d{4})'
        match = re.search(date_pattern, date_str)
        
        if match:
            month_str = match.group('month')
            day_str = match.group('day')
            year_str = match.group('year')
            
            # Convert month name to number
            month_names = ['January', 'February', 'March', 'April', 'May', 'June', 
                          'July', 'August', 'September', 'October', 'November', 'December']
            month_num = month_names.index(month_str.capitalize()) + 1
            
            return datetime(int(year_str), month_num, int(day_str))
        
        # Fallback: just extract the year
        year_match = re.search(r'(\d{4})', date_str)
        if year_match:
            return datetime(int(year_match.group(1)), 1, 1)
            
        return datetime(1900, 1, 1)  # Default for unknown dates
    except Exception as e:
        print(f"Error parsing date '{date_str}': {e}")
        return datetime(1900, 1, 1)  # Default for parsing errors

# Function to parse Wikipedia for the list of secretaries
def parse_wikipedia():
    print("\nTrying to fetch information from Wikipedia...")
    # Use the correct URL for the Secretary of Homeland Security page
    url = "https://en.wikipedia.org/wiki/United_States_Secretary_of_Homeland_Security"
    content = get_page_content(url)
    
    if not content:
        print("Could not access Wikipedia. Trying alternative sources.")
        return None
    
    soup = BeautifulSoup(content, 'html.parser')
    print("Successfully fetched Wikipedia content.")
    
    # Find all tables on the page
    tables = soup.find_all('table', class_='wikitable')
    print(f"Found {len(tables)} tables on the page")
    
    secretaries = []
    found_table = False
    
    # Try to find the correct table with secretary information
    for i, table in enumerate(tables):
        print(f"\nExamining table #{i+1}")
        
        # Check if this looks like the right table
        headers = table.find_all('th')
        header_texts = [h.get_text().strip() for h in headers]
        
        # Print table headers for debugging
        print(f"Table headers: {header_texts}")
        
        # Look for table with secretary information
        # The table we want likely has name, term, president columns
        if any('Secretary' in h for h in header_texts) or \
           any('Name' in h for h in header_texts) and \
           any('Term' in h for h in header_texts) or \
           any('office' in h.lower() for h in header_texts):
            found_table = True
            print("Found a table that likely contains Secretary information.")
            
            rows = table.find_all('tr')
            print(f"Table has {len(rows)} rows")
            
            # Skip the header row(s)
            for row_idx, row in enumerate(rows):
                if row_idx == 0:  # Skip header row
                    continue
                    
                cells = row.find_all(['td', 'th'])
                print(f"Row {row_idx+1} has {len(cells)} cells")
                
                if len(cells) < 3:  # Need at least name, start date, end date
                    print("Row doesn't have enough cells, skipping")
                    continue
                
                # Try different column layouts based on Wikipedia's structure
                # Format 1: [Number, Portrait, Name, Senate vote, Term start, Term end, President]
                # Format 2: [Number, Name, Term start, Term end, President]
                
                # Extract name - usually in the first few columns
                name = None
                for idx in range(min(3, len(cells))):
                    cell_text = clean_text(cells[idx].get_text())
                    # Names usually have capital letters and don't contain dates
                    if re.search(r'[A-Z][a-z]+', cell_text) and not re.search(r'\d{4}', cell_text):
                        name = cell_text
                        break
                
                if not name:
                    print("Couldn't find name in this row, skipping")
                    continue
                    
                # Check if "acting" is in the name or title
                if 'acting' in name.lower():
                    print(f"Skipping acting secretary: {name}")
                    continue
                
                # Try to find term dates - look for columns with year patterns
                term_start = None
                term_end = None
                president = None
                
                for idx, cell in enumerate(cells):
                    cell_text = clean_text(cell.get_text())
                    
                    # Look for dates (contain years like 2003-2019)
                    if re.search(r'\b20[0-1]\d\b', cell_text):
                        if not term_start:
                            term_start = cell_text
                        elif not term_end:
                            term_end = cell_text
                    
                    # President usually in last few columns
                    elif idx >= len(cells) - 3 and re.search(r'(Bush|Obama|Trump|Biden)', cell_text):
                        president = cell_text
                
                # If we couldn't determine values, try a different approach based on row structure
                if not term_start or not term_end:
                    # Try specific columns based on common Wikipedia table structures
                    date_columns = []
                    for idx, cell in enumerate(cells):
                        if re.search(r'\b20[0-1]\d\b', clean_text(cell.get_text())):
                            date_columns.append(idx)
                    
                    if len(date_columns) >= 2:
                        term_start = clean_text(cells[date_columns[0]].get_text())
                        term_end = clean_text(cells[date_columns[1]].get_text())
                
                # Skip if we still don't have the essential information
                if not term_start or not term_end:
                    print(f"Couldn't find term dates for {name}, skipping")
                    continue
                
                secretary_info = {
                    "name": name,
                    "term_start": term_start,
                    "term_end": term_end,
                    "president": president if president else "Unknown"
                }
                
                secretaries.append(secretary_info)
                print(f"Added secretary: {name}, Served: {term_start} to {term_end}")
    
    if not found_table or not secretaries:
        print("Could not find or extract Secretary information from Wikipedia tables.")
        return None
    
    return secretaries

# Function to determine if a secretary served before April 2019
def served_before_april_2019(term_end):
    # Convert term_end to lowercase for case-insensitive matching
    term_end_lower = term_end.lower()
    
    # Simple case: if end date is explicitly before 2019
    if any(year in term_end for year in ['2003', '2004', '2005', '2006', '2007', '2008', 
                                        '2009', '2010', '2011', '2012', '2013', '2014', 
                                        '2015', '2016', '2017', '2018']):
        return True
        
    # Check for April 2019 case
    if '2019' in term_end:
        # Check for month mentions before April
        if any(month in term_end_lower for month in ['january 2019', 'february 2019', 'march 2019']):
            return True
            
        # Check for April 2019 specifically
        if 'april' in term_end_lower and '2019' in term_end:
            # Try to extract day
            day_match = re.search(r'april\s+(\d+)', term_end_lower)
            if day_match:
                day = int(day_match.group(1))
                # April cutoff is April 2019
                return day <= 30
            # If day can't be determined, assume end of April
            return True
    
    # Special case: still in office (incumbent/present)
    if any(term in term_end_lower for term in ['incumbent', 'present']):
        # Need to check if they started before April 2019
        # This is simplified - a real implementation would check their start date
        return False
    
    # Default case: can't determine
    return False

# Main function to coordinate the search and filtering
def find_secretaries_before_april_2019():
    # Try parsing Wikipedia first
    secretaries = parse_wikipedia()
    
    # If online sources fail, use hardcoded data as fallback
    if not secretaries:
        print("\nCould not retrieve the list of secretaries from online sources.")
        print("Using a hardcoded list based on research as fallback.")
        
        # Hardcoded list based on research
        secretaries = [
            {"name": "Tom Ridge", "term_start": "January 24, 2003", "term_end": "February 1, 2005", "president": "George W. Bush"},
            {"name": "Michael Chertoff", "term_start": "February 15, 2005", "term_end": "January 21, 2009", "president": "George W. Bush"},
            {"name": "Janet Napolitano", "term_start": "January 21, 2009", "term_end": "September 6, 2013", "president": "Barack Obama"},
            {"name": "Jeh Johnson", "term_start": "December 23, 2013", "term_end": "January 20, 2017", "president": "Barack Obama"},
            {"name": "John F. Kelly", "term_start": "January 20, 2017", "term_end": "July 31, 2017", "president": "Donald Trump"},
            {"name": "Kirstjen Nielsen", "term_start": "December 6, 2017", "term_end": "April 10, 2019", "president": "Donald Trump"}
        ]
    
    # Filter to secretaries who served before April 2019 and were not acting
    filtered_secretaries = []
    for secretary in secretaries:
        # For hardcoded data, we already know these meet our criteria
        if "term_end" in secretary and served_before_april_2019(secretary["term_end"]):
            filtered_secretaries.append(secretary)
    
    # Sort by term start date (chronological order)
    # Convert dates to datetime objects for proper sorting
    filtered_secretaries.sort(key=lambda x: parse_date(x.get("term_start", ""))) 
    
    # Save to file
    output_file = "workspace/us_secretaries_homeland_security_before_april_2019.json"
    with open(output_file, 'w') as f:
        json.dump(filtered_secretaries, f, indent=2)
    
    print(f"\nSaved the list of {len(filtered_secretaries)} U.S. Secretaries of Homeland Security")
    print(f"who served before April 2019 (excluding acting) to {output_file}")
    
    # Print the results in chronological order
    print("\nU.S. Secretaries of Homeland Security who served before April 2019 (excluding acting):")
    for i, secretary in enumerate(filtered_secretaries, 1):
        print(f"{i}. {secretary['name']} ({secretary['term_start']} - {secretary['term_end']})")
        print(f"   Served under President: {secretary['president']}")
    
    return filtered_secretaries

# Execute the main function
find_secretaries_before_april_2019()
```