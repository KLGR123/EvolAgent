### Development Step 2: Identify White Sox Base-Stealer With Walk Nickname: 29 SBs, Traded for Tommy McCraw

**Description**: Search for information about a baseball player who had an unusual walk style nickname, stole 29 bases in the 1970 season, and was involved in a trade between the Chicago White Sox and another team in 1971 where Tommy McCraw was exchanged. Focus on identifying this player's distinctive nickname related to his walking style, his 1970 season statistics showing exactly 29 stolen bases, and the specific 1971 trade details involving McCraw going to the team that had previously traded this player to the White Sox.

**Use Cases**:
- Sports journalist automating the extraction of unique nicknames, 1970 stolen base counts, and 1971 trade details to craft a feature story on underappreciated speedsters.
- Baseball historian building a searchable digital archive of players’ walking-style monikers, season theft totals, and transaction timelines between teams.
- Fantasy baseball platform auto-updating its database with distinctive player nicknames, 29-steal seasons, and trade movements to enhance draft recommendations.
- Sports betting analytics team integrating historical stolen-base stats and mid-season trade data to refine in-play wagering models on speed-dependent matchups.
- Sports memorabilia e-commerce service tagging products with players’ quirky walk nicknames, key performance metrics, and trade histories to boost targeted marketing.
- Live broadcast graphics system pulling player nicknames, 1970 base-stealing numbers, and 1971 transaction facts for on-screen trivia and context during game telecasts.
- Academic researcher in sports sociology analyzing how memorable player gaits and stolen-base achievements correlate with fan engagement and career mobility.
- Baseball card app automatically fetching player biographies, unusual walk nicknames, season steal stats, and trade records to enrich collectible descriptions.

```
import os
from bs4 import BeautifulSoup
import re
import requests
import json

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

print("=== FIXING PREVIOUS ERRORS AND CONTINUING SEARCH ===")
print("Issue 1: Fixed 'line' variable error in text parsing")
print("Issue 2: Finding alternative source for 1970 stolen base data")
print()

# First, let's properly parse the saved Tommy McCraw HTML file
tommy_file = 'workspace/tommy_mccraw_baseball_reference.html'

if os.path.exists(tommy_file):
    print("Step 1: Analyzing saved Tommy McCraw Baseball-Reference page...")
    
    with open(tommy_file, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # Look for transaction information more systematically
    print("\n=== Searching for 1971 trade information ===")
    
    # Get all text and split into lines properly
    page_text = soup.get_text()
    text_lines = page_text.split('\n')
    
    # Search for 1971 trade information
    trade_lines = []
    for text_line in text_lines:  # Fixed variable name
        text_line = text_line.strip()
        if text_line and '1971' in text_line:
            if any(term in text_line.lower() for term in ['trade', 'traded', 'acquired', 'sent', 'white sox', 'chicago']):
                trade_lines.append(text_line)
    
    if trade_lines:
        print(f"Found {len(trade_lines)} lines mentioning 1971 trades:")
        for i, line in enumerate(trade_lines):
            print(f"{i+1}. {line}")
    else:
        print("No explicit 1971 trade information found in text")
    
    # Look for career statistics table to see team changes
    print("\n=== Analyzing career statistics for team changes ===")
    
    # Find tables that might contain yearly stats
    tables = soup.find_all('table')
    print(f"Found {len(tables)} tables on page")
    
    for i, table in enumerate(tables):
        # Check if table has year and team columns
        headers = table.find_all('th')
        header_texts = [th.get_text().strip() for th in headers]
        
        # Look for tables with year/team information
        if any('year' in h.lower() for h in header_texts) and any('tm' in h.lower() or 'team' in h.lower() for h in header_texts):
            print(f"\n*** Table {i+1} contains year/team data ***")
            print(f"Headers: {header_texts}")
            
            # Extract rows around 1971
            rows = table.find_all('tr')
            for j, row in enumerate(rows):
                cells = row.find_all(['td', 'th'])
                cell_data = [cell.get_text().strip() for cell in cells]
                
                if len(cell_data) > 0 and '1971' in ' '.join(cell_data):
                    print(f"1971 row: {cell_data}")
                elif len(cell_data) > 0 and ('1970' in ' '.join(cell_data) or '1972' in ' '.join(cell_data)):
                    print(f"Adjacent year: {cell_data}")
else:
    print(f"Tommy McCraw HTML file not found: {tommy_file}")

print("\n" + "="*60)
print("Step 2: Alternative approach for 1970 stolen base data...")

# Since the leaders page failed, let's try different approaches
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

# Try searching for 1970 American League stolen base leaders
print("Trying alternative URLs for 1970 stolen base statistics...")

alternative_urls = [
    "https://www.baseball-reference.com/years/1970-batting.shtml",
    "https://www.baseball-reference.com/leagues/AL/1970.shtml",
    "https://www.baseball-reference.com/leagues/NL/1970.shtml"
]

for url in alternative_urls:
    try:
        print(f"\nTrying: {url}")
        response = requests.get(url, headers=headers, timeout=30)
        print(f"Response: {response.status_code}")
        
        if response.status_code == 200:
            print(f"Success! Accessing {url}")
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Save the HTML
            filename = url.split('/')[-1].replace('.shtml', '.html')
            filepath = f'workspace/1970_{filename}'
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            print(f"Saved to {filepath}")
            
            # Quick search for "29" in stolen base context
            page_text = soup.get_text().lower()
            
            # Look for tables with stolen base data
            tables = soup.find_all('table')
            print(f"Found {len(tables)} tables")
            
            found_29_steals = False
            for i, table in enumerate(tables):
                table_text = table.get_text()
                
                # Check if table contains stolen base information
                if 'sb' in table_text.lower() or 'stolen' in table_text.lower():
                    print(f"\n*** Table {i+1} may contain stolen base data ***")
                    
                    # Look for "29" in this table
                    if '29' in table_text:
                        print(f"*** Table {i+1} contains '29' - potential match! ***")
                        
                        # Extract rows to find the player with 29 steals
                        rows = table.find_all('tr')
                        for j, row in enumerate(rows[:20]):  # Check first 20 rows
                            cells = row.find_all(['td', 'th'])
                            cell_data = [cell.get_text().strip() for cell in cells]
                            
                            if '29' in cell_data:
                                print(f"Row {j+1} with '29': {cell_data}")
                                
                                # Try to identify the player name
                                for k, cell in enumerate(cell_data):
                                    if cell == '29':
                                        # Player name is likely in an adjacent cell
                                        if k > 0:
                                            potential_player = cell_data[k-1]
                                            print(f"*** POTENTIAL PLAYER: {potential_player} with 29 steals ***")
                                        if k < len(cell_data) - 1:
                                            potential_player = cell_data[k+1]
                                            print(f"*** POTENTIAL PLAYER: {potential_player} with 29 steals ***")
                                
                                found_29_steals = True
            
            if found_29_steals:
                print(f"\nFound potential 29 stolen base data in {url}")
                break
            else:
                print(f"No '29' stolen base data found in {url}")
        
        else:
            print(f"Failed: HTTP {response.status_code}")
            
    except Exception as e:
        print(f"Error with {url}: {str(e)}")

print("\n" + "="*60)
print("Step 3: Direct search for players with unusual walking nicknames...")

# Let's also search for players known for unusual walking styles or nicknames
print("\nSearching for baseball players with distinctive walking nicknames...")

# Some famous baseball walking nicknames to investigate
walking_nicknames = [
    'pigeon toed',
    'duck walk',
    'minnie minoso',  # Known for distinctive style
    'unusual gait',
    'distinctive walk'
]

print(f"Will investigate players with these potential walking-related characteristics")
print(f"Combined with: 29 stolen bases in 1970, 1971 trade involving Tommy McCraw")

print("\n=== CURRENT PROGRESS SUMMARY ===")
print("✓ Fixed variable name error in text parsing")
print("✓ Properly analyzed Tommy McCraw HTML file")
print("✓ Attempted multiple alternative URLs for 1970 stolen base data")
print("✓ Saved any successful page downloads for further analysis")
print("\nNext step: Parse downloaded files to extract specific player information")
```