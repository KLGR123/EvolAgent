### Development Step 1: Extract Locomotive Info from Excel: Sunset Picnic Trip Steam vs Other Probability Odds

**Description**: Parse and analyze the attached Excel file data/gaia/2023/validation/4d0aa727-86b1-406b-9b33-f870dd14a4a5.xlsx to extract locomotive data including identifying numbers, operating status, and assigned daily excursions. Specifically identify all locomotives assigned to the 'Sunset Picnic Trip' and determine how many are steam locomotives versus other types to calculate the probability odds.

**Use Cases**:
- Railway excursion scheduling and resource optimization for heritage lines, determining how many steam engines versus diesel are assigned to the Sunset Picnic Trip each day
- Heritage tourism capacity planning and passenger experience forecasting by calculating the odds of a steam locomotive powering the Sunset Picnic Trip
- Safety compliance auditing and operational reporting for special event rail services, automatically flagging any excursions lacking required steam-engine assignments
- Predictive maintenance scheduling for locomotive fleets, prioritizing steam engines based on their frequency of assignment to high-visibility trips like the Sunset Picnic Trip
- Insurance risk modeling and premium calculation for scenic rail excursions by analyzing probabilities of steam versus non-steam locomotive deployment
- Academic transportation research on historical locomotive utilization, conducting statistical comparisons of steam and diesel assignments extracted from operational Excel logs
- Real-time dashboard automation for excursion managers, integrating locomotive status and Sunset Picnic Trip assignment odds into daily reporting tools
- Operational cost analysis and budget forecasting for railway heritage operations, comparing maintenance and fuel expenses between steam and other locomotive types on key excursions

```
import os
import pandas as pd
from openpyxl import load_workbook
import json

# The path to the Excel file to be analyzed
xlsx_path = "data/gaia/2023/validation/4d0aa727-86b1-406b-9b33-f870dd14a4a5.xlsx"

print("=== LOCOMOTIVE DATA ANALYSIS - INITIAL EXAMINATION ===")
print(f"Analyzing file: {xlsx_path}")

# Check if file exists
if not os.path.exists(xlsx_path):
    print(f"Error: Excel file '{xlsx_path}' does not exist.")
    exit()

print(f"File exists: {xlsx_path}")
file_size = os.path.getsize(xlsx_path)
print(f"File size: {file_size} bytes")

# Load workbook with openpyxl to examine structure and formatting
print("\nLoading workbook with openpyxl to examine structure...")
wb = load_workbook(xlsx_path, data_only=True)  # Use data_only=True to get calculated values

print(f"Number of worksheets: {len(wb.worksheets)}")
print(f"Worksheet names: {[sheet.title for sheet in wb.worksheets]}")

# Examine each worksheet
for sheet_idx, sheet in enumerate(wb.worksheets):
    print(f"\n=== ANALYZING WORKSHEET: {sheet.title} ===")
    
    max_row = sheet.max_row
    max_col = sheet.max_column
    print(f"Sheet dimensions: {max_row} rows x {max_col} columns")
    
    # Get the range of actual data
    min_row = sheet.min_row
    min_col = sheet.min_column
    print(f"Data range: rows {min_row}-{max_row}, columns {min_col}-{max_col}")
    
    print("\n=== FIRST 15 ROWS PREVIEW ===")
    # Display first 15 rows to understand structure
    for row in range(min_row, min(max_row + 1, min_row + 15)):
        row_data = []
        for col in range(min_col, max_col + 1):
            cell = sheet.cell(row=row, column=col)
            cell_value = cell.value if cell.value is not None else ""
            row_data.append(str(cell_value))
        print(f"Row {row}: {row_data}")
    
    print("\n=== COLUMN HEADERS ANALYSIS ===")
    # Examine the first row as potential headers
    headers = []
    for col in range(min_col, max_col + 1):
        cell = sheet.cell(row=min_row, column=col)
        header_value = cell.value if cell.value is not None else f"Col_{col}"
        headers.append(str(header_value))
        print(f"Column {col}: '{header_value}'")
    
    print(f"\nIdentified headers: {headers}")
    
    # Look for locomotive-related keywords in headers and data
    print("\n=== SEARCHING FOR LOCOMOTIVE-RELATED DATA ===")
    locomotive_keywords = ['locomotive', 'engine', 'steam', 'diesel', 'electric', 'number', 'id', 'type', 'status', 'excursion', 'trip', 'sunset', 'picnic']
    
    found_keywords = []
    for header in headers:
        header_lower = header.lower()
        for keyword in locomotive_keywords:
            if keyword in header_lower:
                found_keywords.append({
                    'header': header,
                    'keyword': keyword,
                    'column_index': headers.index(header)
                })
                print(f"Found keyword '{keyword}' in header: '{header}'")
    
    print(f"\nTotal locomotive-related keywords found in headers: {len(found_keywords)}")
    
    # Sample some data rows to understand content
    print("\n=== DATA SAMPLE (Rows 2-10) ===")
    for row in range(min_row + 1, min(max_row + 1, min_row + 10)):
        if row <= max_row:
            print(f"Row {row}:")
            for col_idx, col in enumerate(range(min_col, max_col + 1)):
                cell = sheet.cell(row=row, column=col)
                cell_value = cell.value if cell.value is not None else ""
                header = headers[col_idx] if col_idx < len(headers) else f"Col_{col}"
                print(f"  {header}: '{cell_value}' (type: {type(cell_value)})")
    
    # Search for 'Sunset Picnic Trip' specifically in the data
    print("\n=== SEARCHING FOR 'SUNSET PICNIC TRIP' ===")
    sunset_picnic_found = []
    for row in range(min_row, max_row + 1):
        for col in range(min_col, max_col + 1):
            cell = sheet.cell(row=row, column=col)
            if cell.value and isinstance(cell.value, str):
                cell_text = cell.value.lower()
                if 'sunset' in cell_text and 'picnic' in cell_text:
                    sunset_picnic_found.append({
                        'row': row,
                        'col': col,
                        'value': cell.value,
                        'header': headers[col - min_col] if (col - min_col) < len(headers) else f"Col_{col}"
                    })
                    print(f"Found 'Sunset Picnic Trip' reference at ({row}, {col}): '{cell.value}'")
    
    print(f"Total 'Sunset Picnic Trip' references found: {len(sunset_picnic_found)}")

# Also load with pandas for easier data manipulation
print("\n" + "="*60)
print("PANDAS DATAFRAME ANALYSIS")
print("="*60)

try:
    # Try to read the Excel file with pandas
    df_dict = pd.read_excel(xlsx_path, sheet_name=None)  # Read all sheets
    
    print(f"Pandas successfully loaded {len(df_dict)} sheet(s)")
    
    for sheet_name, sheet_df in df_dict.items():
        print(f"\n=== PANDAS ANALYSIS: {sheet_name} ===")
        print(f"DataFrame shape: {sheet_df.shape}")
        print(f"Column names: {list(sheet_df.columns)}")
        print(f"Data types:\n{sheet_df.dtypes}")
        
        print("\nFirst 10 rows:")
        print(sheet_df.head(10).to_string())
        
        print("\nBasic statistics for numeric columns:")
        numeric_cols = sheet_df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            print(sheet_df[numeric_cols].describe())
        else:
            print("No numeric columns found")
        
        print("\nMissing values:")
        print(sheet_df.isnull().sum())
        
        # Look for locomotive-specific columns
        print("\n=== LOCOMOTIVE-SPECIFIC COLUMN IDENTIFICATION ===")
        column_names = [col.lower() for col in sheet_df.columns]
        
        potential_id_cols = [col for col in sheet_df.columns if any(keyword in col.lower() for keyword in ['number', 'id', 'locomotive', 'engine'])]
        potential_type_cols = [col for col in sheet_df.columns if any(keyword in col.lower() for keyword in ['type', 'class', 'model', 'steam', 'diesel'])]
        potential_status_cols = [col for col in sheet_df.columns if any(keyword in col.lower() for keyword in ['status', 'operating', 'active', 'condition'])]
        potential_trip_cols = [col for col in sheet_df.columns if any(keyword in col.lower() for keyword in ['trip', 'excursion', 'route', 'assignment', 'service'])]
        
        print(f"Potential locomotive ID columns: {potential_id_cols}")
        print(f"Potential locomotive type columns: {potential_type_cols}")
        print(f"Potential status columns: {potential_status_cols}")
        print(f"Potential trip/excursion columns: {potential_trip_cols}")
        
        # Search for 'Sunset Picnic Trip' in the dataframe
        print("\n=== SEARCHING FOR 'SUNSET PICNIC TRIP' IN DATA ===")
        sunset_picnic_matches = []
        
        for col in sheet_df.columns:
            if sheet_df[col].dtype == 'object':  # String columns
                mask = sheet_df[col].astype(str).str.contains('sunset.*picnic', case=False, na=False, regex=True)
                if mask.any():
                    matches = sheet_df[mask]
                    print(f"Found 'Sunset Picnic Trip' matches in column '{col}':")
                    for idx, row in matches.iterrows():
                        print(f"  Row {idx}: {row[col]}")
                        sunset_picnic_matches.append({
                            'row_index': idx,
                            'column': col,
                            'value': row[col],
                            'full_row': row.to_dict()
                        })
        
        print(f"Total 'Sunset Picnic Trip' matches found: {len(sunset_picnic_matches)}")
        
except Exception as e:
    print(f"Error reading with pandas: {e}")
    print("Will proceed with openpyxl analysis only")

# Save initial analysis
analysis_data = {
    'file_path': xlsx_path,
    'file_size': file_size,
    'worksheets': [sheet.title for sheet in wb.worksheets],
    'analysis_timestamp': pd.Timestamp.now().isoformat()
}

with open('workspace/locomotive_analysis_initial.json', 'w') as f:
    json.dump(analysis_data, f, indent=2)

print(f"\nInitial analysis saved to: workspace/locomotive_analysis_initial.json")
print("Next step: Extract locomotive data and identify Sunset Picnic Trip assignments")
```