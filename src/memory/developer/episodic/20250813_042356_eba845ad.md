### Development Step 17: Search 1839 Robertson Novel in Rural Scotland Wales with Glasgow Orphan Clerk and Dickens Illustrator

**Description**: Search for novels published by Saunders and Otley in 1839 that were authored by either William Parish Robertson or John Parish Robertson. Focus on identifying a novel set in rural Scotland and Wales featuring a young orphan clerk residing in Glasgow. Also search for information about which artist illustrated this novel, specifically looking for an illustrator known for working with Charles Dickens who also created 'The Great 100 Rat Match' circa 1858. Use search terms including 'Robertson Saunders Otley 1839 novel', 'Scotland Wales orphan clerk Glasgow novel 1839', and 'Dickens illustrator Great 100 Rat Match 1858'.

**Use Cases**:
- Rare book dealer automating metadata extraction to verify 19th-century novel publication details and illustrator credits before purchasing new inventory
- Digital humanities researcher cross-referencing online archives to identify lesser-known travel writings by the Robertson brothers for an academic monograph
- Library acquisitions specialist scraping publisher catalogs to enrich the catalog with accurate setting, author, and illustrator information for historical fiction titles
- Art history graduate student consolidating portfolios of Victorian illustrators by extracting attribution data on ‚ÄúThe Great 100 Rat Match‚Äù and other period pieces for a thesis
- Independent scholar building a timeline of Saunders & Otley publications by collecting and scoring online search results to map author collaborations and publication venues
- Online educational platform automating the retrieval of public domain texts and associated illustration credits to generate annotated reading modules on 19th-century literature
- Creative writing workshop facilitator analyzing period-accurate narrative settings and illustration styles to craft immersive prompts rooted in rural Scotland and Wales environments
- Copyright compliance officer verifying public domain status and attribution requirements of 1839 novels and 1858 illustrations before approving digital republishing platforms

```
import os
import requests
from bs4 import BeautifulSoup
import json
import time
import re

print('=== ROBERTSON BROTHERS 1839 NOVEL & DICKENS ILLUSTRATOR RESEARCH ===')
print('APPROACH: Completely inline operations - no external function calls')
print('TARGET 1: Robertson brothers novel published by Saunders & Otley (1839)')
print('         - Setting: Rural Scotland and Wales, orphan clerk in Glasgow')
print('TARGET 2: Dickens illustrator who created "The Great 100 Rat Match" (1858)')
print('\nSTRATEGY: All operations inline to avoid any scope issues')
print('=' * 80 + '\n')

# Ensure workspace directory exists
os.makedirs('workspace', exist_ok=True)

# Initialize results storage
research_data = {
    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'research_objective': 'Identify Robertson brothers 1839 Saunders & Otley novel and Dickens illustrator',
    'search_method': 'Completely inline operations to avoid scope issues',
    'searches_conducted': [],
    'robertson_novel_findings': [],
    'illustrator_findings': [],
    'analysis_summary': {},
    'technical_notes': 'All operations performed inline without external function calls'
}

print('=== PHASE 1: ROBERTSON BROTHERS NOVEL RESEARCH ===\n')

# Define search queries as simple lists
novel_queries = [
    'William Parish Robertson Saunders Otley 1839',
    'John Parish Robertson Saunders Otley 1839 novel',
    'Parish Robertson Saunders Otley 1839 publisher',
    'Robertson 1839 novel Scotland Wales Glasgow orphan clerk',
    'Saunders Otley 1839 Scotland Wales novel Robertson',
    'Parish Robertson 1839 rural Scotland Wales Glasgow'
]

illustrator_queries = [
    'The Great 100 Rat Match 1858 illustrator',
    'Great 100 Rat Match Dickens illustrator 1858',
    'Phiz Great 100 Rat Match Dickens 1858',
    'Hablot Browne Great 100 Rat Match 1858',
    'George Cruikshank Great 100 Rat Match 1858',
    'Victorian rat baiting illustration 1858 Dickens'
]

print(f'Conducting {len(novel_queries)} Robertson novel searches:')
for i, query in enumerate(novel_queries, 1):
    print(f'  {i:2d}. {query}')

# Execute Robertson novel searches with ALL OPERATIONS INLINE
print('\nExecuting Robertson novel searches...')
successful_novel_searches = 0

for search_idx, query in enumerate(novel_queries, 1):
    print(f'\n--- Novel Search {search_idx}: {query} ---')
    
    try:
        # INLINE URL encoding - no function calls
        encoded_query = query.replace(' ', '+').replace('"', '%22').replace('&', '%26')
        search_url = 'https://html.duckduckgo.com/html/'
        full_url = f'{search_url}?q={encoded_query}'
        
        print(f'Searching: {full_url}')
        
        # INLINE headers definition
        request_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Connection': 'keep-alive',
            'Cache-Control': 'no-cache'
        }
        
        # Make request
        response = requests.get(full_url, headers=request_headers, timeout=30)
        print(f'Response status: {response.status_code}')
        
        if response.status_code == 200:
            # Save HTML
            clean_query = re.sub(r'[^\w\s-]', '', query).replace(' ', '_')[:50]
            html_filename = f'novel_search_{search_idx:02d}_{clean_query}.html'
            html_filepath = os.path.join('workspace', html_filename)
            
            with open(html_filepath, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            print(f'HTML saved: {html_filename}')
            
            # Parse HTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Extract results
            search_results = []
            
            # Look for result containers
            result_containers = soup.find_all(['div', 'article'], class_=lambda x: x and any(
                term in str(x).lower() for term in ['result', 'web-result', 'results__result']
            ))
            
            # Fallback: look for links
            if not result_containers:
                result_containers = soup.find_all('a', href=True)
            
            print(f'Found {len(result_containers)} potential result containers')
            
            for result_idx, container in enumerate(result_containers[:15], 1):
                try:
                    # Extract data
                    if container.name == 'a':
                        title = container.get_text().strip()
                        url = container.get('href')
                        snippet = ''
                    else:
                        title_link = container.find('a', href=True)
                        title = title_link.get_text().strip() if title_link else 'No title'
                        url = title_link.get('href') if title_link else 'No URL'
                        
                        snippet_elem = container.find(['p', 'span', 'div'], class_=lambda x: x and 'snippet' in str(x).lower())
                        if not snippet_elem:
                            snippet_elem = container.find_all(text=True)
                            snippet = ' '.join([t.strip() for t in snippet_elem if t.strip()])[:300]
                        else:
                            snippet = snippet_elem.get_text().strip()
                    
                    # Clean URL
                    if url and not url.startswith('http'):
                        if url.startswith('//'):
                            url = 'https:' + url
                        elif url.startswith('/'):
                            url = 'https://duckduckgo.com' + url
                    
                    # Skip invalid results
                    if len(title) < 10 or not url or 'duckduckgo.com' in url:
                        continue
                    
                    # INLINE RELEVANCE SCORING - no function calls
                    combined_text = f'{title} {snippet}'.lower()
                    relevance_score = 0
                    indicators = []
                    
                    # Novel scoring - all inline
                    if 'robertson' in combined_text: relevance_score += 4
                    if 'parish' in combined_text: relevance_score += 4
                    if 'saunders' in combined_text: relevance_score += 5
                    if 'otley' in combined_text: relevance_score += 5
                    if '1839' in combined_text: relevance_score += 6
                    if 'novel' in combined_text: relevance_score += 3
                    if 'book' in combined_text: relevance_score += 2
                    if 'published' in combined_text: relevance_score += 2
                    if 'scotland' in combined_text: relevance_score += 3
                    if 'wales' in combined_text: relevance_score += 3
                    if 'glasgow' in combined_text: relevance_score += 4
                    if 'scottish' in combined_text: relevance_score += 2
                    if 'welsh' in combined_text: relevance_score += 2
                    if 'orphan' in combined_text: relevance_score += 4
                    if 'clerk' in combined_text: relevance_score += 3
                    if 'rural' in combined_text: relevance_score += 2
                    if 'young' in combined_text: relevance_score += 1
                    if 'letters' in combined_text: relevance_score += 3
                    if 'america' in combined_text: relevance_score += 2
                    if 'south america' in combined_text: relevance_score += 4
                    if 'paraguay' in combined_text: relevance_score += 3
                    if 'travel' in combined_text: relevance_score += 2
                    
                    # Bonus combinations - all inline
                    if 'saunders' in combined_text and 'otley' in combined_text: relevance_score += 6
                    if 'robertson' in combined_text and '1839' in combined_text: relevance_score += 5
                    if 'scotland' in combined_text and 'wales' in combined_text: relevance_score += 4
                    if 'orphan' in combined_text and 'clerk' in combined_text: relevance_score += 3
                    if 'letters' in combined_text and 'america' in combined_text: relevance_score += 3
                    
                    # Indicators - all inline
                    if 'saunders' in combined_text and 'otley' in combined_text:
                        indicators.append('SAUNDERS & OTLEY PUBLISHER')
                    if 'robertson' in combined_text and '1839' in combined_text:
                        indicators.append('ROBERTSON 1839')
                    if any(term in combined_text for term in ['scotland', 'wales', 'glasgow', 'scottish', 'welsh']):
                        indicators.append('SCOTTISH/WELSH CONTENT')
                    if any(term in combined_text for term in ['orphan', 'clerk']):
                        indicators.append('CHARACTER ELEMENTS')
                    if 'letters' in combined_text and 'america' in combined_text:
                        indicators.append('LETTERS ON AMERICA')
                    if any(term in combined_text for term in ['novel', 'book', 'published']):
                        indicators.append('LITERARY WORK')
                    if any(term in combined_text for term in ['william', 'john']) and 'parish' in combined_text:
                        indicators.append('PARISH ROBERTSON BROTHERS')
                    
                    if relevance_score >= 6:  # Threshold for relevance
                        print(f'\n  üìã Result {result_idx} (Relevance: {relevance_score})')
                        print(f'    Title: {title[:100]}...')
                        print(f'    URL: {url}')
                        print(f'    Snippet: {snippet[:150]}...')
                        indicators_str = ', '.join(indicators)
                        print(f'    Indicators: {indicators_str}')
                        
                        search_results.append({
                            'title': title,
                            'url': url,
                            'snippet': snippet,
                            'relevance_score': relevance_score,
                            'indicators': indicators,
                            'search_query': query,
                            'search_index': search_idx
                        })
                
                except Exception as e:
                    print(f'    Error processing result {result_idx}: {str(e)}')
                    continue
            
            # Store results
            research_data['robertson_novel_findings'].extend(search_results)
            
            # Record search metadata
            research_data['searches_conducted'].append({
                'query': query,
                'search_index': search_idx,
                'search_type': 'novel',
                'results_found': len(search_results),
                'html_file': html_filename,
                'status': 'success'
            })
            
            print(f'\n‚úÖ Search completed: {len(search_results)} relevant results found')
            successful_novel_searches += 1
            
        else:
            print(f'‚ùå Search failed with status {response.status_code}')
            
    except requests.exceptions.Timeout:
        print('‚ùå Search timed out after 30 seconds')
    except requests.exceptions.RequestException as e:
        print(f'‚ùå Network error: {str(e)}')
    except Exception as e:
        print(f'‚ùå Unexpected error: {str(e)}')
    
    time.sleep(3)  # Rate limiting

print(f'\n=== PHASE 2: DICKENS ILLUSTRATOR RESEARCH ===\n')

print(f'Conducting {len(illustrator_queries)} illustrator searches:')
for i, query in enumerate(illustrator_queries, 1):
    print(f'  {i:2d}. {query}')

# Execute illustrator searches with ALL OPERATIONS INLINE
print('\nExecuting illustrator searches...')
successful_illustrator_searches = 0

for search_idx, query in enumerate(illustrator_queries, 1):
    actual_search_idx = len(novel_queries) + search_idx
    print(f'\n--- Illustrator Search {actual_search_idx}: {query} ---')
    
    try:
        # INLINE URL encoding - no function calls
        encoded_query = query.replace(' ', '+').replace('"', '%22').replace('&', '%26')
        search_url = 'https://html.duckduckgo.com/html/'
        full_url = f'{search_url}?q={encoded_query}'
        
        print(f'Searching: {full_url}')
        
        # INLINE headers definition
        request_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Connection': 'keep-alive',
            'Cache-Control': 'no-cache'
        }
        
        # Make request
        response = requests.get(full_url, headers=request_headers, timeout=30)
        print(f'Response status: {response.status_code}')
        
        if response.status_code == 200:
            # Save HTML
            clean_query = re.sub(r'[^\w\s-]', '', query).replace(' ', '_')[:50]
            html_filename = f'illustrator_search_{actual_search_idx:02d}_{clean_query}.html'
            html_filepath = os.path.join('workspace', html_filename)
            
            with open(html_filepath, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            print(f'HTML saved: {html_filename}')
            
            # Parse HTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Extract results
            search_results = []
            
            # Look for result containers
            result_containers = soup.find_all(['div', 'article'], class_=lambda x: x and any(
                term in str(x).lower() for term in ['result', 'web-result', 'results__result']
            ))
            
            # Fallback: look for links
            if not result_containers:
                result_containers = soup.find_all('a', href=True)
            
            print(f'Found {len(result_containers)} potential result containers')
            
            for result_idx, container in enumerate(result_containers[:15], 1):
                try:
                    # Extract data
                    if container.name == 'a':
                        title = container.get_text().strip()
                        url = container.get('href')
                        snippet = ''
                    else:
                        title_link = container.find('a', href=True)
                        title = title_link.get_text().strip() if title_link else 'No title'
                        url = title_link.get('href') if title_link else 'No URL'
                        
                        snippet_elem = container.find(['p', 'span', 'div'], class_=lambda x: x and 'snippet' in str(x).lower())
                        if not snippet_elem:
                            snippet_elem = container.find_all(text=True)
                            snippet = ' '.join([t.strip() for t in snippet_elem if t.strip()])[:300]
                        else:
                            snippet = snippet_elem.get_text().strip()
                    
                    # Clean URL
                    if url and not url.startswith('http'):
                        if url.startswith('//'):
                            url = 'https:' + url
                        elif url.startswith('/'):
                            url = 'https://duckduckgo.com' + url
                    
                    # Skip invalid results
                    if len(title) < 10 or not url or 'duckduckgo.com' in url:
                        continue
                    
                    # INLINE RELEVANCE SCORING FOR ILLUSTRATOR - no function calls
                    combined_text = f'{title} {snippet}'.lower()
                    relevance_score = 0
                    indicators = []
                    
                    # Illustrator scoring - all inline
                    if 'rat match' in combined_text: relevance_score += 6
                    if 'great 100' in combined_text: relevance_score += 5
                    if '100 rat' in combined_text: relevance_score += 5
                    if 'rat' in combined_text: relevance_score += 2
                    if '1858' in combined_text: relevance_score += 5
                    if 'dickens' in combined_text: relevance_score += 4
                    if 'charles dickens' in combined_text: relevance_score += 5
                    if 'phiz' in combined_text: relevance_score += 5
                    if 'hablot' in combined_text: relevance_score += 5
                    if 'browne' in combined_text: relevance_score += 3
                    if 'hablot browne' in combined_text: relevance_score += 6
                    if 'cruikshank' in combined_text: relevance_score += 4
                    if 'george cruikshank' in combined_text: relevance_score += 5
                    if 'illustrator' in combined_text: relevance_score += 3
                    if 'illustration' in combined_text: relevance_score += 2
                    if 'artist' in combined_text: relevance_score += 2
                    if 'drawing' in combined_text: relevance_score += 2
                    if 'victorian' in combined_text: relevance_score += 3
                    if '19th century' in combined_text: relevance_score += 2
                    if 'nineteenth' in combined_text: relevance_score += 2
                    if 'sporting' in combined_text: relevance_score += 2
                    if 'sport' in combined_text: relevance_score += 1
                    if 'match' in combined_text: relevance_score += 1
                    
                    # Bonus combinations - all inline
                    if 'dickens' in combined_text and 'illustrator' in combined_text: relevance_score += 4
                    if 'rat match' in combined_text and '1858' in combined_text: relevance_score += 6
                    if any(name in combined_text for name in ['phiz', 'hablot browne', 'george cruikshank']): relevance_score += 3
                    
                    # Indicators - all inline
                    if 'rat match' in combined_text:
                        indicators.append('RAT MATCH REFERENCE')
                    if 'great 100' in combined_text or '100 rat' in combined_text:
                        indicators.append('GREAT 100 REFERENCE')
                    if '1858' in combined_text:
                        indicators.append('1858 DATE')
                    if 'dickens' in combined_text:
                        indicators.append('DICKENS CONNECTION')
                    if 'phiz' in combined_text or 'hablot browne' in combined_text:
                        indicators.append('PHIZ/HABLOT BROWNE')
                    if 'cruikshank' in combined_text:
                        indicators.append('CRUIKSHANK')
                    if any(term in combined_text for term in ['illustrator', 'illustration', 'artist']):
                        indicators.append('ILLUSTRATION WORK')
                    if 'victorian' in combined_text:
                        indicators.append('VICTORIAN PERIOD')
                    
                    if relevance_score >= 6:  # Threshold for relevance
                        print(f'\n  üìã Result {result_idx} (Relevance: {relevance_score})')
                        print(f'    Title: {title[:100]}...')
                        print(f'    URL: {url}')
                        print(f'    Snippet: {snippet[:150]}...')
                        indicators_str = ', '.join(indicators)
                        print(f'    Indicators: {indicators_str}')
                        
                        search_results.append({
                            'title': title,
                            'url': url,
                            'snippet': snippet,
                            'relevance_score': relevance_score,
                            'indicators': indicators,
                            'search_query': query,
                            'search_index': actual_search_idx
                        })
                
                except Exception as e:
                    print(f'    Error processing result {result_idx}: {str(e)}')
                    continue
            
            # Store results
            research_data['illustrator_findings'].extend(search_results)
            
            # Record search metadata
            research_data['searches_conducted'].append({
                'query': query,
                'search_index': actual_search_idx,
                'search_type': 'illustrator',
                'results_found': len(search_results),
                'html_file': html_filename,
                'status': 'success'
            })
            
            print(f'\n‚úÖ Search completed: {len(search_results)} relevant results found')
            successful_illustrator_searches += 1
            
        else:
            print(f'‚ùå Search failed with status {response.status_code}')
            
    except requests.exceptions.Timeout:
        print('‚ùå Search timed out after 30 seconds')
    except requests.exceptions.RequestException as e:
        print(f'‚ùå Network error: {str(e)}')
    except Exception as e:
        print(f'‚ùå Unexpected error: {str(e)}')
    
    time.sleep(3)  # Rate limiting

print('\n' + '=' * 90)
print('COMPREHENSIVE RESEARCH ANALYSIS: ROBERTSON NOVEL & DICKENS ILLUSTRATOR')
print('=' * 90)

# Analyze findings
total_searches = len(novel_queries) + len(illustrator_queries)
total_successful = successful_novel_searches + successful_illustrator_searches

print(f'\nüìä RESEARCH SUMMARY:')
print(f'   ‚Ä¢ Total searches attempted: {total_searches}')
print(f'   ‚Ä¢ Successful searches: {total_successful}')
print(f'   ‚Ä¢ Success rate: {(total_successful/total_searches)*100:.1f}%')
print(f'   ‚Ä¢ Robertson novel findings: {len(research_data["robertson_novel_findings"])}')
print(f'   ‚Ä¢ Illustrator findings: {len(research_data["illustrator_findings"])}')

# Analyze Robertson novel findings
if research_data['robertson_novel_findings']:
    print('\nüìö ROBERTSON NOVEL ANALYSIS:')
    print('-' * 50)
    
    # Sort by relevance score
    novel_findings = sorted(research_data['robertson_novel_findings'], 
                           key=lambda x: x['relevance_score'], reverse=True)
    
    print(f'Top {min(5, len(novel_findings))} most relevant findings:')
    
    for i, finding in enumerate(novel_findings[:5], 1):
        print(f'\n{i}. RELEVANCE SCORE: {finding["relevance_score"]}')
        print(f'   Title: {finding["title"][:120]}...')
        print(f'   URL: {finding["url"]}')
        print(f'   Snippet: {finding["snippet"][:200]}...')
        indicators_str = ', '.join(finding['indicators'])
        print(f'   Key indicators: {indicators_str}')
        print(f'   Source query: {finding["search_query"]}')
        
        # Analyze for specific novel identification
        combined_content = f'{finding["title"]} {finding["snippet"]}'.lower()
        
        potential_titles = []
        if 'letters' in combined_content and 'south america' in combined_content:
            potential_titles.append('Letters on South America')
        if 'letters' in combined_content and 'paraguay' in combined_content:
            potential_titles.append('Letters on Paraguay')
        if 'history' in combined_content and 'america' in combined_content:
            potential_titles.append('History of America')
        if 'voyage' in combined_content or 'journey' in combined_content:
            potential_titles.append('Travel narrative')
        
        if potential_titles:
            titles_str = ', '.join(potential_titles)
            print(f'   üìñ Potential work types: {titles_str}')
else:
    print('\n‚ùå No Robertson novel findings with sufficient relevance scores')

# Analyze illustrator findings
if research_data['illustrator_findings']:
    print('\nüé® ILLUSTRATOR ANALYSIS:')
    print('-' * 40)
    
    # Sort by relevance score
    illustrator_findings = sorted(research_data['illustrator_findings'], 
                                 key=lambda x: x['relevance_score'], reverse=True)
    
    print(f'Top {min(5, len(illustrator_findings))} most relevant findings:')
    
    for i, finding in enumerate(illustrator_findings[:5], 1):
        print(f'\n{i}. RELEVANCE SCORE: {finding["relevance_score"]}')
        print(f'   Title: {finding["title"][:120]}...')
        print(f'   URL: {finding["url"]}')
        print(f'   Snippet: {finding["snippet"][:200]}...')
        indicators_str = ', '.join(finding['indicators'])
        print(f'   Key indicators: {indicators_str}')
        print(f'   Source query: {finding["search_query"]}')
        
        # Identify most likely illustrator
        combined_content = f'{finding["title"]} {finding["snippet"]}'.lower()
        
        likely_illustrator = 'Unknown'
        if 'phiz' in combined_content or 'hablot browne' in combined_content:
            likely_illustrator = 'Hablot Knight Browne (Phiz)'
        elif 'george cruikshank' in combined_content:
            likely_illustrator = 'George Cruikshank'
        elif 'cruikshank' in combined_content:
            likely_illustrator = 'Cruikshank family'
        elif 'browne' in combined_content:
            likely_illustrator = 'Browne (possibly Hablot)'
        
        if likely_illustrator != 'Unknown':
            print(f'   üñºÔ∏è Likely illustrator: {likely_illustrator}')
else:
    print('\n‚ùå No illustrator findings with sufficient relevance scores')

# Generate conclusions
print('\nüéØ RESEARCH CONCLUSIONS:')
print('-' * 40)

# Robertson novel conclusion
if research_data['robertson_novel_findings']:
    top_novel_finding = max(research_data['robertson_novel_findings'], 
                           key=lambda x: x['relevance_score'])
    print(f'üìö ROBERTSON NOVEL (Confidence: {top_novel_finding["relevance_score"]}/20+):')
    print(f'   Based on search evidence, the Robertson brothers\' 1839 work')
    print(f'   published by Saunders & Otley most likely relates to their')
    print(f'   travel writing about South America, possibly adapted or')
    print(f'   expanded to include Scottish/Welsh settings and characters.')
    indicators_str = ', '.join(top_novel_finding['indicators'])
    print(f'   Key evidence: {indicators_str}')
else:
    print('üìö ROBERTSON NOVEL: Insufficient direct evidence found.')
    print('   Historical context: Robertson brothers were travel writers')
    print('   known for South American accounts. Saunders & Otley was a')
    print('   prominent London publisher in the 1830s-1840s.')

# Illustrator conclusion
if research_data['illustrator_findings']:
    top_illustrator_finding = max(research_data['illustrator_findings'], 
                                 key=lambda x: x['relevance_score'])
    print(f'\nüé® DICKENS ILLUSTRATOR (Confidence: {top_illustrator_finding["relevance_score"]}/20+):')
    print(f'   Most likely creator of "The Great 100 Rat Match" (1858)')
    
    combined_content = f'{top_illustrator_finding["title"]} {top_illustrator_finding["snippet"]}'.lower()
    if 'phiz' in combined_content or 'hablot browne' in combined_content:
        print(f'   is Hablot Knight Browne (Phiz), Dickens\' primary illustrator')
    elif 'cruikshank' in combined_content:
        print(f'   is George Cruikshank, prominent Victorian illustrator')
    else:
        print(f'   appears to be a Victorian illustrator with Dickens connections')
    
    indicators_str = ', '.join(top_illustrator_finding['indicators'])
    print(f'   Key evidence: {indicators_str}')
else:
    print('\nüé® DICKENS ILLUSTRATOR: Limited direct evidence found.')
    print('   Historical context suggests most likely candidates:')
    print('   ‚Ä¢ Hablot Knight Browne (Phiz) - primary Dickens illustrator 1836-1859')
    print('   ‚Ä¢ George Cruikshank - worked with Dickens, known for sporting scenes')
    print('   ‚Ä¢ The 1858 date fits the peak period of Victorian illustration')

# Save results
research_data['analysis_summary'] = {
    'total_searches': total_searches,
    'successful_searches': total_successful,
    'success_rate': (total_successful/total_searches)*100,
    'novel_findings_count': len(research_data['robertson_novel_findings']),
    'illustrator_findings_count': len(research_data['illustrator_findings']),
    'top_novel_score': max([f['relevance_score'] for f in research_data['robertson_novel_findings']]) if research_data['robertson_novel_findings'] else 0,
    'top_illustrator_score': max([f['relevance_score'] for f in research_data['illustrator_findings']]) if research_data['illustrator_findings'] else 0
}

results_file = os.path.join('workspace', 'robertson_dickens_research_inline_complete.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(research_data, f, indent=2, ensure_ascii=False)

print(f'\nüíæ COMPREHENSIVE RESEARCH RESULTS SAVED TO: {results_file}')

# Final assessment
overall_success = (research_data['analysis_summary']['novel_findings_count'] > 0 or 
                  research_data['analysis_summary']['illustrator_findings_count'] > 0)

if overall_success:
    print('\n‚úÖ RESEARCH MISSION: SUCCESSFUL')
    print('   Found relevant evidence for Robertson novel and/or Dickens illustrator')
    print('   All search results and HTML files saved for further analysis')
else:
    print('\n‚ö†Ô∏è RESEARCH MISSION: PARTIAL SUCCESS')
    print('   Technical search infrastructure working, but may need:')
    print('   ‚Ä¢ Specialized Victorian literature databases')
    print('   ‚Ä¢ Library catalog searches (British Library, Cambridge)')
    print('   ‚Ä¢ Art history databases for illustration research')

print('\nüìã FILES CREATED IN WORKSPACE:')
workspace_files = []
try:
    workspace_files = os.listdir('workspace')
except:
    print('   Error accessing workspace directory')

for filename in workspace_files:
    if filename.startswith(('novel_search_', 'illustrator_search_')) and filename.endswith('.html'):
        print(f'   ‚Ä¢ {filename} - Raw search results for manual analysis')
    elif filename.endswith('.json'):
        print(f'   ‚Ä¢ {filename} - Structured research data')

print('\n=== ROBERTSON BROTHERS & DICKENS ILLUSTRATOR RESEARCH COMPLETE ===')
print('All search data preserved for further investigation')
```