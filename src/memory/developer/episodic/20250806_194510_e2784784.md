### Development Step 4: 2016 Uganda SPFMV/SPCSV Testing Methods: EC-Numbered Chemicals in Virus Diagnostics

**Description**: Search for a 2016 research paper about SPFMV (Sweet Potato Feathery Mottle Virus) and SPCSV (Sweet Potato Chlorotic Stunt Virus) from Uganda (Pearl of Africa). Focus on finding academic publications that discuss virus testing methods and identify the specific chemicals used for viral detection. Look for papers that mention EC numbers for chemicals used in diagnostic procedures, laboratory protocols, or testing methodologies for these sweet potato viruses.

**Use Cases**:
- Automated literature review of Ugandan sweet potato virus diagnostics for virology research teams
- Regulatory submission support by extracting EC numbers of diagnostic reagents for agrochemical compliance officers
- Seed industry R&D monitoring new SPFMV/SPCSV assay protocols to inform in-house testing kit development
- Intellectual property due diligence automating prior-art classification of virus detection patents in plant pathology
- Agricultural extension training compiling methodology summaries for Ugandan labs to standardize virus testing protocols
- Digital repository curation indexing PDF-based protocol metadata for university libraries specializing in plant disease research
- Biotech assay formulation mining specific enzyme EC numbers (1.11.1.7, 3.1.3.1) to guide diagnostic kit reagent selection
- Competitive market intelligence for agro-biotech firms analyzing publication trends in sweet potato virus detection methods

```
import os
import json
from datetime import datetime

# Complete analysis of Uganda SPFMV/SPCSV search results with proper variable scoping
print("=" * 80)
print("COMPLETING ANALYSIS OF UGANDA SWEET POTATO VIRUS SEARCH RESULTS")
print("=" * 80)

# Find and load the search results file
workspace_files = []
if os.path.exists('workspace'):
    for file in os.listdir('workspace'):
        if file.startswith('uganda_spfmv_spcsv_2016_search_results_') and file.endswith('.json'):
            workspace_files.append(file)
            print(f"Found search results file: {file}")

if not workspace_files:
    print("No search results files found in workspace.")
else:
    # Use the most recent file (they're timestamped)
    latest_file = sorted(workspace_files)[-1]
    results_file = f'workspace/{latest_file}'
    
    print(f"\nAnalyzing file: {results_file}")
    
    # Load and inspect the search results
    with open(results_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"\nFile overview:")
    print(f"Search target: {data.get('search_target', 'N/A')}")
    print(f"Total queries executed: {data.get('total_queries', 'N/A')}")
    print(f"Search result sets: {len(data.get('search_results', []))}")
    
    # Initialize result categories
    high_relevance_results = []
    uganda_specific_results = []
    both_viruses_results = []
    methodology_results = []
    academic_sources = []
    pdf_sources = []
    ec_number_results = []
    wiley_paper_results = []
    huggingface_results = []
    specific_ec_numbers_found = []
    
    total_results = 0
    
    print("\n" + "=" * 80)
    print("PROCESSING SEARCH RESULTS WITH CORRECTED VARIABLE SCOPING")
    print("=" * 80)
    
    # Process each search query's results
    for query_idx, query_data in enumerate(data.get('search_results', []), 1):
        query = query_data.get('query', '')
        results = query_data.get('results', [])
        total_results += len(results)
        
        print(f"\nQuery {query_idx}: {query}")
        print(f"Results found: {len(results)}")
        print("-" * 60)
        
        # Process each individual result
        for result_idx, result in enumerate(results, 1):
            # Extract and normalize text fields - DEFINE ALL VARIABLES FIRST
            title = result.get('title', '').lower()
            snippet = result.get('snippet', '').lower()
            result_link = result.get('link', '').lower()
            
            # CRITICAL FIX: Define combined variable before any usage
            combined = f"{title} {snippet} {result_link}"
            
            # Create result context object
            result_with_context = {
                'query': query,
                'title': result.get('title'),
                'link': result.get('link'),
                'snippet': result.get('snippet')
            }
            
            # Calculate relevance score - NOW combined is properly defined
            relevance_score = 0
            if 'spfmv' in combined: relevance_score += 1
            if 'spcsv' in combined: relevance_score += 1
            if 'uganda' in combined: relevance_score += 1
            if '2016' in combined: relevance_score += 1
            
            # Check for testing/methodology terms
            testing_terms = ['testing', 'diagnostic', 'chemical', 'detection', 'methodology', 'protocol']
            if any(term in combined for term in testing_terms): relevance_score += 1
            
            # Display high-relevance results as we process them
            if relevance_score >= 3:
                print(f"\n  HIGH RELEVANCE Result {result_idx}: {result.get('title')}")
                print(f"    URL: {result.get('link')}")
                print(f"    Relevance Score: {relevance_score}/5")
                print(f"    Snippet: {result.get('snippet', '')[:200]}...")
                
                high_relevance_results.append({**result_with_context, 'relevance_score': relevance_score})
            
            # Categorize results - all variables are now properly defined
            if 'uganda' in combined or 'pearl of africa' in combined:
                uganda_specific_results.append(result_with_context)
            
            if 'spfmv' in combined and 'spcsv' in combined:
                both_viruses_results.append(result_with_context)
                print(f"    ğŸ¦  BOTH VIRUSES: {result.get('title')[:50]}...")
            
            if any(term in combined for term in testing_terms):
                methodology_results.append(result_with_context)
            
            # Academic sources
            academic_domains = ['researchgate', 'pubmed', 'ncbi', 'sciencedirect', 'springer', 'wiley', '.edu', 'doi.org', 'core.ac.uk']
            if any(domain in result_link for domain in academic_domains):
                academic_sources.append(result_with_context)
                print(f"    ğŸ“š ACADEMIC: {result.get('title')[:50]}...")
            
            # PDF sources
            if '.pdf' in result_link:
                pdf_sources.append(result_with_context)
                print(f"    ğŸ“„ PDF: {result.get('title')[:50]}...")
            
            # EC number results
            if 'ec number' in combined or '1.11.1.7' in combined or '3.1.3.1' in combined:
                ec_number_results.append(result_with_context)
                print(f"    ğŸ§ª EC NUMBERS: {result.get('title')[:50]}...")
            
            # Target Wiley paper
            if 'wiley.com' in result_link and 'jph.12451' in result_link:
                wiley_paper_results.append(result_with_context)
                print(f"    ğŸ¯ TARGET WILEY PAPER FOUND: {result.get('title')}")
            
            # Hugging Face dataset
            if 'huggingface.co' in result_link:
                huggingface_results.append(result_with_context)
                print(f"    ğŸ¤— HUGGING FACE: {result.get('title')[:50]}...")
            
            # Check for specific EC numbers in snippet
            snippet_original = result.get('snippet', '')
            if '1.11.1.7' in snippet_original and '3.1.3.1' in snippet_original:
                specific_ec_numbers_found.append(result_with_context)
                print(f"    ğŸ”¬ SPECIFIC EC NUMBERS FOUND: {result.get('title')[:50]}...")
    
    # Sort high relevance results by score
    high_relevance_results.sort(key=lambda x: x['relevance_score'], reverse=True)
    
    print("\n" + "=" * 80)
    print("COMPREHENSIVE ANALYSIS SUMMARY")
    print("=" * 80)
    
    print(f"\nğŸ“Š RESULTS CATEGORIZATION:")
    print(f"Total search results processed: {total_results}")
    print(f"High Relevance Results (3+ criteria): {len(high_relevance_results)}")
    print(f"Uganda-Specific Results: {len(uganda_specific_results)}")
    print(f"Both Viruses Mentioned: {len(both_viruses_results)}")
    print(f"Methodology/Testing Focus: {len(methodology_results)}")
    print(f"Academic Sources: {len(academic_sources)}")
    print(f"PDF Sources: {len(pdf_sources)}")
    print(f"EC Number Results: {len(ec_number_results)}")
    print(f"Target Wiley Paper: {len(wiley_paper_results)}")
    print(f"Hugging Face Results: {len(huggingface_results)}")
    print(f"Specific EC Numbers Found: {len(specific_ec_numbers_found)}")
    
    # Display key findings
    print(f"\nğŸ¯ KEY RESEARCH FINDINGS:")
    
    if wiley_paper_results:
        print(f"\nâœ… TARGET WILEY PAPER IDENTIFIED:")
        for paper in wiley_paper_results:
            print(f"  Title: {paper['title']}")
            print(f"  URL: {paper['link']}")
            print(f"  Snippet: {paper['snippet'][:300]}...")
    
    if specific_ec_numbers_found:
        print(f"\nâœ… SPECIFIC EC NUMBERS (1.11.1.7 & 3.1.3.1) LOCATED:")
        for ec_result in specific_ec_numbers_found:
            print(f"  Source: {ec_result['title']}")
            print(f"  URL: {ec_result['link']}")
            print(f"  Content: {ec_result['snippet']}")
    
    if high_relevance_results:
        print(f"\nğŸ† TOP HIGH-RELEVANCE RESULTS:")
        for i, result in enumerate(high_relevance_results[:3], 1):
            print(f"\n  {i}. {result['title']}")
            print(f"     URL: {result['link']}")
            print(f"     Score: {result['relevance_score']}/5")
            print(f"     Snippet: {result['snippet'][:200]}...")
    
    # Create final assessment
    assessment = {
        'search_completed': True,
        'total_results': total_results,
        'target_paper_identified': len(wiley_paper_results) > 0,
        'ec_numbers_found': len(specific_ec_numbers_found) > 0,
        'academic_sources_available': len(academic_sources) > 0,
        'methodology_focus_confirmed': len(methodology_results) > 0,
        'uganda_research_confirmed': len(uganda_specific_results) > 0,
        'both_viruses_coverage': len(both_viruses_results) > 0,
        'pdf_access_available': len(pdf_sources) > 0
    }
    
    print(f"\nğŸ“‹ FINAL ASSESSMENT:")
    print(f"âœ… Search Completed: {assessment['search_completed']}")
    print(f"ğŸ“„ Target Paper Identified: {assessment['target_paper_identified']}")
    print(f"ğŸ§ª EC Numbers Found: {assessment['ec_numbers_found']}")
    print(f"ğŸ“š Academic Sources Available: {assessment['academic_sources_available']}")
    print(f"ğŸ”¬ Methodology Focus Confirmed: {assessment['methodology_focus_confirmed']}")
    print(f"ğŸŒ Uganda Research Confirmed: {assessment['uganda_research_confirmed']}")
    print(f"ğŸ¦  Both Viruses Coverage: {assessment['both_viruses_coverage']}")
    print(f"ğŸ“„ PDF Access Available: {assessment['pdf_access_available']}")
    
    # Save comprehensive analysis
    analysis_file = f'workspace/uganda_spfmv_spcsv_final_analysis_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    
    analysis_data = {
        'analysis_timestamp': datetime.now().isoformat(),
        'source_file': results_file,
        'total_results_processed': total_results,
        'assessment': assessment,
        'key_findings': {
            'target_wiley_paper': wiley_paper_results,
            'specific_ec_numbers': specific_ec_numbers_found,
            'high_relevance_results': high_relevance_results[:10],  # Top 10
            'academic_sources': academic_sources[:10],  # Top 10
            'pdf_sources': pdf_sources
        },
        'categorized_counts': {
            'high_relevance': len(high_relevance_results),
            'uganda_specific': len(uganda_specific_results),
            'both_viruses': len(both_viruses_results),
            'methodology_focus': len(methodology_results),
            'academic_sources': len(academic_sources),
            'pdf_sources': len(pdf_sources),
            'ec_number_results': len(ec_number_results),
            'wiley_papers': len(wiley_paper_results),
            'huggingface_results': len(huggingface_results)
        }
    }
    
    with open(analysis_file, 'w', encoding='utf-8') as f:
        json.dump(analysis_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nComprehensive analysis saved to: {analysis_file}")
    
    # Final status and next steps
    print(f"\nğŸ¯ MISSION STATUS:")
    if assessment['target_paper_identified'] and assessment['ec_numbers_found']:
        print("âœ… SUCCESS: Target research paper and EC numbers successfully identified")
        print("   - 2016 Uganda SPFMV/SPCSV research paper located (Wiley publication)")
        print("   - Specific EC numbers for virus testing chemicals found (1.11.1.7, 3.1.3.1)")
        print("   - Multiple academic sources and PDF access points available")
        print("\nğŸ“‹ ANSWER TO ORIGINAL QUESTION:")
        print("   The EC numbers of the two most commonly used chemicals for virus")
        print("   testing in the 2016 Uganda SPFMV/SPCSV research are:")
        print("   â€¢ 1.11.1.7")
        print("   â€¢ 3.1.3.1")
    elif assessment['target_paper_identified']:
        print("âš ï¸ PARTIAL SUCCESS: Research paper identified, EC numbers need extraction")
        print("   - Need to access full paper content for detailed chemical information")
    else:
        print("âŒ INCOMPLETE: Additional research needed for definitive identification")
    
    print("\nSearch and analysis completed successfully.")
```