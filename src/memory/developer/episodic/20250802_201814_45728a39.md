### Development Step 1: 2011 Bulgarian Census Tertiary Education Completion by Gender

**Description**: Search for the 2011 Bulgarian census data on tertiary education completion by gender. Look for official census results from Bulgaria's National Statistical Institute or other authoritative sources that provide the specific breakdown of men and women who completed tertiary education in 2011.

**Use Cases**:
- Public policy development for Bulgaria’s Ministry of Education: automate extraction of 2011 tertiary education completion rates by gender to design targeted scholarship and retention programs.
- Gender equality NGO impact assessment: gather official census figures on male vs. female university graduates in 2011 to evaluate effectiveness of women’s empowerment initiatives across Bulgarian regions.
- Academic demographic research: compile and analyze 2011 higher-education attainment data by gender for longitudinal studies on educational progress in Eastern Europe.
- Data journalism and visualization: source and parse 2011 census tables on tertiary graduates by gender to produce an interactive infographic on Bulgaria’s gender gap in higher education.
- EdTech market segmentation analysis: retrieve regional breakdowns of male and female university graduates to tailor online course offerings and marketing strategies in Bulgaria.
- Corporate workforce planning: extract historic tertiary education data by gender for HR teams in multinational firms to forecast talent availability and diversity targets in Bulgaria.
- International development benchmarking: automate collection of Bulgaria’s 2011 tertiary education gender statistics to compare with peer countries for global education reports.
- Municipal infrastructure budgeting: use gender-disaggregated 2011 graduate counts to model demand for student housing and campus facilities in key Bulgarian cities.

```
import os
import requests
from bs4 import BeautifulSoup
import json
import time
import re

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

print("=== BULGARIAN 2011 CENSUS: TERTIARY EDUCATION BY GENDER SEARCH ===")
print("Objective: Find official census data on men and women who completed tertiary education in 2011\n")

# Search strategy: Target official Bulgarian statistical sources
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

# Primary targets: Bulgarian National Statistical Institute and official census sources
search_urls = [
    "https://www.nsi.bg/en",  # National Statistical Institute - English
    "https://www.nsi.bg",     # National Statistical Institute - Bulgarian
    "https://www.nsi.bg/en/content/6710/population-education",  # Direct education statistics
    "https://www.nsi.bg/en/content/6704/population-census-2011",  # 2011 Census page
    "https://en.wikipedia.org/wiki/2011_census_in_Bulgaria"  # Wikipedia for reference
]

successful_sources = []
failed_sources = []

print("Step 1: Accessing Bulgarian National Statistical Institute and census sources...\n")

for url in search_urls:
    print(f"Trying: {url}")
    try:
        response = requests.get(url, headers=headers, timeout=20)
        print(f"Response status: {response.status_code}")
        
        if response.status_code == 200:
            print(f"✓ Successfully accessed {url}")
            
            # Save the content for analysis
            filename = url.replace('https://', '').replace('http://', '').replace('/', '_').replace('.', '_').replace('-', '_') + '.html'
            filepath = f'workspace/{filename}'
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            # Quick content analysis
            soup = BeautifulSoup(response.content, 'html.parser')
            title = soup.find('title')
            title_text = title.get_text().strip() if title else 'No title found'
            
            # Look for education and census related content
            content_text = soup.get_text().lower()
            education_indicators = ['tertiary', 'education', 'university', 'higher education', 'degree', '2011', 'census', 'gender', 'men', 'women', 'male', 'female']
            has_education_info = any(indicator in content_text for indicator in education_indicators)
            
            # Look specifically for 2011 census references
            has_2011_census = '2011' in content_text and 'census' in content_text
            
            successful_sources.append({
                'url': url,
                'title': title_text,
                'filename': filepath,
                'has_education_info': has_education_info,
                'has_2011_census': has_2011_census,
                'content_length': len(response.text)
            })
            
            print(f"  Title: {title_text}")
            print(f"  Content length: {len(response.text)} characters")
            print(f"  Contains education info: {has_education_info}")
            print(f"  Contains 2011 census info: {has_2011_census}")
            
        else:
            failed_sources.append({'url': url, 'status': response.status_code})
            print(f"✗ Failed to access {url} - Status: {response.status_code}")
            
    except Exception as e:
        failed_sources.append({'url': url, 'error': str(e)})
        print(f"✗ Error accessing {url}: {str(e)}")
    
    print()
    time.sleep(2)  # Be respectful to servers

print(f"=== INITIAL ACCESS RESULTS ===\n")
print(f"Successfully accessed: {len(successful_sources)} sources")
print(f"Failed to access: {len(failed_sources)} sources\n")

# Analyze successful sources for census and education data
if successful_sources:
    print("--- Analyzing Successful Sources ---\n")
    
    priority_sources = []
    
    for i, source in enumerate(successful_sources, 1):
        print(f"{i}. {source['url']}")
        print(f"   Title: {source['title']}")
        print(f"   File saved: {source['filename']}")
        print(f"   Has education info: {source['has_education_info']}")
        print(f"   Has 2011 census info: {source['has_2011_census']}")
        
        # Prioritize sources with both education and 2011 census content
        if source['has_education_info'] and source['has_2011_census']:
            print(f"   *** HIGH PRIORITY - Contains both education and 2011 census data ***")
            priority_sources.append(source)
        elif source['has_education_info'] or source['has_2011_census']:
            print(f"   ** MEDIUM PRIORITY - Contains relevant content **")
            priority_sources.append(source)
        
        print()
    
    # Detailed analysis of priority sources
    if priority_sources:
        print(f"=== DETAILED ANALYSIS OF {len(priority_sources)} PRIORITY SOURCES ===\n")
        
        for source in priority_sources:
            print(f"Analyzing: {source['url']}")
            
            with open(source['filename'], 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # Look for tables that might contain education statistics
            tables = soup.find_all('table')
            print(f"  Found {len(tables)} tables")
            
            # Look for links to detailed census or education reports
            links = soup.find_all('a', href=True)
            education_links = []
            census_links = []
            
            for link in links:
                href = link['href']
                link_text = link.get_text().lower()
                
                if any(word in link_text for word in ['education', 'tertiary', 'university', 'higher']):
                    education_links.append({
                        'text': link.get_text().strip(),
                        'href': href
                    })
                
                if any(word in link_text for word in ['census', '2011', 'population']):
                    census_links.append({
                        'text': link.get_text().strip(),
                        'href': href
                    })
            
            print(f"  Education-related links: {len(education_links)}")
            print(f"  Census-related links: {len(census_links)}")
            
            # Look for specific statistical data patterns
            text_content = soup.get_text()
            
            # Search for numerical data that might be tertiary education statistics
            number_patterns = re.findall(r'\d+[,.]?\d*\s*%?', text_content)
            
            # Look for gender-related terms near education terms
            gender_education_context = []
            sentences = text_content.split('.')
            
            for sentence in sentences:
                sentence_lower = sentence.lower()
                has_education = any(word in sentence_lower for word in ['tertiary', 'education', 'university', 'higher', 'degree'])
                has_gender = any(word in sentence_lower for word in ['men', 'women', 'male', 'female', 'gender'])
                has_2011 = '2011' in sentence_lower
                
                if has_education and (has_gender or has_2011):
                    gender_education_context.append(sentence.strip())
            
            print(f"  Relevant sentences found: {len(gender_education_context)}")
            
            # Save detailed analysis
            source_analysis = {
                'url': source['url'],
                'title': source['title'],
                'tables_found': len(tables),
                'education_links': education_links[:10],  # Top 10 links
                'census_links': census_links[:10],  # Top 10 links
                'relevant_sentences': gender_education_context[:5],  # Top 5 sentences
                'content_sample': text_content[:2000]  # First 2000 characters
            }
            
            analysis_filename = f'workspace/bulgarian_census_analysis_{len(priority_sources) - priority_sources.index(source)}.json'
            with open(analysis_filename, 'w', encoding='utf-8') as f:
                json.dump(source_analysis, f, indent=2, ensure_ascii=False)
            
            print(f"  Analysis saved to: {analysis_filename}")
            
            # Display some key findings
            if education_links:
                print(f"  Key education links:")
                for link in education_links[:3]:
                    print(f"    - {link['text']}: {link['href']}")
            
            if gender_education_context:
                print(f"  Sample relevant content:")
                for context in gender_education_context[:2]:
                    print(f"    - {context[:100]}...")
            
            print()
else:
    print("No sources successfully accessed. Need to try alternative search methods.")

# Save overall search summary
search_summary = {
    'search_target': 'Bulgarian 2011 census tertiary education by gender',
    'search_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'successful_sources': len(successful_sources),
    'failed_sources': len(failed_sources),
    'priority_sources': len([s for s in successful_sources if s.get('has_education_info', False) or s.get('has_2011_census', False)]),
    'sources_data': successful_sources,
    'failed_attempts': failed_sources
}

with open('workspace/bulgarian_census_search_summary.json', 'w') as f:
    json.dump(search_summary, f, indent=2)

print(f"=== SEARCH PHASE 1 COMPLETE ===\n")
print(f"Search summary saved to: workspace/bulgarian_census_search_summary.json")
print(f"Next steps: Parse priority sources for specific tertiary education statistics by gender")
print(f"Target data: Number/percentage of men and women with completed tertiary education in 2011")
```