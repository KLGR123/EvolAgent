### Development Step 5: US Federal Minimum Butterfat Percentage Required for Ice Cream Classification According to 2020 Wikipedia Standards

**Description**: Research the US federal standards for butterfat content in ice cream as reported by Wikipedia in 2020. Search for the specific minimum butterfat percentage required by federal regulations for a product to be legally classified as ice cream in the United States. Extract the exact percentage value and any relevant context about these standards.

**Use Cases**:
- Regulatory compliance verification for US-based ice cream manufacturers ensuring products meet the federal minimum butterfat requirement before distribution
- Automated quality assurance checks in food production software to flag ice cream recipes or batches that fall below the 10% butterfat threshold
- Food labeling and packaging validation systems that extract and confirm legal standards for nutritional content claims on ice cream sold in the US
- Ingredient sourcing and procurement decision-making for dairy suppliers, ensuring their cream and milkfat blends align with US federal ice cream standards
- Academic research on international food regulations, comparing US federal butterfat standards with those of other countries for publication or policy analysis
- Consumer advocacy group investigations into mislabeled or non-compliant ice cream products using automated extraction of federal standards from authoritative sources
- Development of AI-powered chatbots or virtual assistants for food industry professionals, providing instant answers about US legal requirements for ice cream classification
- Automated updating of product specification databases for multinational food companies, ensuring US product lines adhere to current federal regulations on butterfat content

```
import os
import json
import re
from datetime import datetime

print("=== CORRECTING US FEDERAL ICE CREAM BUTTERFAT STANDARD EXTRACTION ===")
print("Objective: Fix the logic error and correctly identify the 10% US federal minimum")
print("Strategy: Analyze existing workspace data and apply correct US-specific filtering\n")

# Ensure workspace directory exists
workspace_dir = 'workspace'
os.makedirs(workspace_dir, exist_ok=True)

# First, inspect the existing analysis file to understand the data structure
print("=== STEP 1: INSPECTING EXISTING ANALYSIS DATA ===")

analysis_file = os.path.join(workspace_dir, 'us_federal_ice_cream_butterfat_standard_final.json')
if os.path.exists(analysis_file):
    print(f"Found existing analysis file: {analysis_file}")
    print(f"File size: {os.path.getsize(analysis_file):,} bytes")
    
    # Inspect the file structure first
    with open(analysis_file, 'r') as f:
        analysis_data = json.load(f)
    
    print("\nAnalysis file structure:")
    for key, value in analysis_data.items():
        if isinstance(value, list):
            print(f"  {key}: List with {len(value)} items")
        elif isinstance(value, dict):
            print(f"  {key}: Dictionary with {len(value)} keys")
        else:
            print(f"  {key}: {value}")
    
    # Examine the percentage extractions in detail
    if 'percentage_extractions' in analysis_data:
        extractions = analysis_data['percentage_extractions']
        print(f"\nDetailed percentage extractions ({len(extractions)} items):")
        
        for i, extraction in enumerate(extractions, 1):
            percentage = extraction.get('percentage', 'Unknown')
            context = extraction.get('context', 'Unknown')
            sentence = extraction.get('sentence', 'No sentence')[:150] + "..." if len(extraction.get('sentence', '')) > 150 else extraction.get('sentence', 'No sentence')
            
            print(f"\n{i}. Percentage: {percentage}%")
            print(f"   Context: {context}")
            print(f"   Sentence: {sentence}")
            
            # Check if this is US-specific
            sentence_lower = sentence.lower()
            is_us_specific = any(term in sentence_lower for term in ['united states', 'us ', 'american', 'fda'])
            is_uk_specific = any(term in sentence_lower for term in ['united kingdom', 'uk ', 'british', 'european'])
            
            print(f"   US-specific: {is_us_specific}")
            print(f"   UK/EU-specific: {is_uk_specific}")
    
    print(f"\nCurrent (incorrect) result: {analysis_data.get('federal_minimum_butterfat_percentage', 'Not found')}%")
    print(f"Supporting evidence: {analysis_data.get('supporting_evidence', 'None')[:100]}...")
else:
    print(f"Analysis file not found: {analysis_file}")
    print("Available files in workspace:")
    if os.path.exists(workspace_dir):
        for file in os.listdir(workspace_dir):
            print(f"  - {file}")

# Now let's also check the HTML scraped content for direct analysis
html_content_file = os.path.join(workspace_dir, 'wikipedia_ice_cream_html_scraped.txt')
if os.path.exists(html_content_file):
    print(f"\n=== STEP 2: RE-ANALYZING HTML CONTENT FOR US FEDERAL STANDARDS ===")
    print(f"Found HTML content file: {html_content_file}")
    
    with open(html_content_file, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    print(f"HTML content length: {len(html_content):,} characters")
    
    # Extract the actual content (skip the header)
    content_start = html_content.find('=' * 80)
    if content_start != -1:
        actual_content = html_content[content_start + 82:]  # Skip header and separator
        print(f"Actual Wikipedia content: {len(actual_content):,} characters")
        
        # Search specifically for US federal standards
        print(f"\n=== STEP 3: TARGETED US FEDERAL STANDARDS EXTRACTION ===")
        
        # Look for sentences that specifically mention US/American federal standards
        sentences = re.split(r'[.!?]+', actual_content)
        
        us_federal_sentences = []
        
        for sentence in sentences:
            sentence_clean = sentence.strip()
            sentence_lower = sentence_clean.lower()
            
            if len(sentence_clean) < 20:  # Skip very short sentences
                continue
            
            # Check for US-specific federal standards
            has_us_terms = any(term in sentence_lower for term in ['american', 'us ', 'united states', 'fda'])
            has_federal_terms = any(term in sentence_lower for term in ['federal', 'fda', 'regulation', 'standard', 'require'])
            has_butterfat_terms = any(term in sentence_lower for term in ['butterfat', 'milk fat', 'milkfat', 'fat content'])
            has_percentage = re.search(r'\d+(?:\.\d+)?\s*(?:percent|%)', sentence_lower)
            
            if has_us_terms and (has_federal_terms or has_butterfat_terms) and has_percentage:
                us_federal_sentences.append(sentence_clean)
        
        print(f"US federal sentences found: {len(us_federal_sentences)}")
        
        us_federal_percentages = []
        
        for i, sentence in enumerate(us_federal_sentences, 1):
            print(f"\n{i}. {sentence}")
            
            # Extract percentages from US federal sentences
            percentages = re.findall(r'(\d+(?:\.\d+)?)\s*(?:percent|%)', sentence, re.IGNORECASE)
            
            if percentages:
                print(f"   *** US FEDERAL PERCENTAGES: {percentages} ***")
                
                # Check for minimum context
                is_minimum = any(keyword in sentence.lower() for keyword in ['minimum', 'at least', 'greater than', 'must contain', 'required'])
                print(f"   Minimum requirement context: {is_minimum}")
                
                for pct in percentages:
                    us_federal_percentages.append({
                        'percentage': float(pct),
                        'sentence': sentence,
                        'is_minimum': is_minimum,
                        'context': 'us_federal_standard'
                    })
        
        # Also search for explicit FDA rules
        print(f"\n=== STEP 4: EXPLICIT FDA RULES EXTRACTION ===")
        
        fda_sentences = []
        for sentence in sentences:
            sentence_clean = sentence.strip()
            sentence_lower = sentence_clean.lower()
            
            if 'fda' in sentence_lower and any(term in sentence_lower for term in ['rule', 'require', 'standard', 'ice cream']):
                fda_sentences.append(sentence_clean)
        
        print(f"FDA-specific sentences found: {len(fda_sentences)}")
        
        for i, sentence in enumerate(fda_sentences, 1):
            print(f"\n{i}. {sentence}")
            
            percentages = re.findall(r'(\d+(?:\.\d+)?)\s*(?:percent|%)', sentence, re.IGNORECASE)
            if percentages:
                print(f"   *** FDA PERCENTAGES: {percentages} ***")
                
                for pct in percentages:
                    us_federal_percentages.append({
                        'percentage': float(pct),
                        'sentence': sentence,
                        'is_minimum': True,  # FDA rules are regulatory requirements
                        'context': 'fda_rules'
                    })
        
        # Determine the correct US federal minimum
        if us_federal_percentages:
            print(f"\n=== STEP 5: DETERMINING CORRECT US FEDERAL MINIMUM ===")
            print(f"Total US federal percentages found: {len(us_federal_percentages)}")
            
            # Group by percentage value
            from collections import Counter
            
            all_us_percentages = [item['percentage'] for item in us_federal_percentages]
            percentage_counts = Counter(all_us_percentages)
            
            print(f"\nUS federal percentages by frequency:")
            for pct, count in percentage_counts.most_common():
                print(f"  {pct}%: mentioned {count} time(s)")
            
            # Filter for minimum requirements only
            minimum_percentages = [item['percentage'] for item in us_federal_percentages if item['is_minimum']]
            
            if minimum_percentages:
                minimum_counts = Counter(minimum_percentages)
                most_common_minimum = minimum_counts.most_common(1)[0]
                
                correct_federal_minimum = most_common_minimum[0]
                frequency = most_common_minimum[1]
                
                print(f"\n*** CORRECT US FEDERAL MINIMUM BUTTERFAT PERCENTAGE: {correct_federal_minimum}% ***")
                print(f"Mentioned {frequency} time(s) in minimum requirement contexts")
                
                # Find the best supporting sentence
                supporting_sentences = []
                for item in us_federal_percentages:
                    if item['percentage'] == correct_federal_minimum and item['is_minimum']:
                        supporting_sentences.append(item['sentence'])
                
                print(f"\nSupporting evidence ({len(supporting_sentences)} sentences):")
                for i, sentence in enumerate(supporting_sentences, 1):
                    print(f"{i}. {sentence}")
                
                # Save the corrected result
                corrected_result = {
                    'analysis_date': datetime.now().isoformat(),
                    'source': 'Wikipedia Ice cream page (complete article, corrected analysis)',
                    'objective': 'US federal minimum butterfat percentage for ice cream classification',
                    'correction_applied': 'Fixed logic error that selected UK standard instead of US standard',
                    'previous_incorrect_result': analysis_data.get('federal_minimum_butterfat_percentage') if 'analysis_data' in locals() else None,
                    'corrected_federal_minimum_butterfat_percentage': correct_federal_minimum,
                    'percentage_unit': 'percent',
                    'context': 'US federal regulations for legal ice cream classification',
                    'frequency_mentioned': frequency,
                    'supporting_evidence': supporting_sentences,
                    'all_us_federal_percentages_found': list(percentage_counts.keys()),
                    'detailed_extractions': us_federal_percentages
                }
                
                corrected_file = os.path.join(workspace_dir, 'us_federal_ice_cream_butterfat_standard_corrected.json')
                with open(corrected_file, 'w') as f:
                    json.dump(corrected_result, f, indent=2)
                
                print(f"\nCorrected analysis saved to: {corrected_file}")
                
                print(f"\n=== PLAN OBJECTIVE SUCCESSFULLY COMPLETED ===")
                print(f"US Federal Minimum Butterfat Content for Ice Cream: {correct_federal_minimum}%")
                print(f"Source: Wikipedia Ice cream page (2020 information)")
                print(f"Regulatory Authority: FDA (Food and Drug Administration)")
                print(f"Context: Federal regulations for legal ice cream classification in the United States")
                print(f"\nKey Supporting Evidence:")
                for sentence in supporting_sentences[:2]:  # Show top 2 supporting sentences
                    print(f"  • {sentence}")
            
            else:
                print(f"\nNo minimum requirement percentages found in US federal contexts.")
        
        else:
            print(f"\nNo US federal percentages found in the content.")
else:
    print(f"\nHTML content file not found: {html_content_file}")

print(f"\n=== CORRECTED ANALYSIS COMPLETE ===")
```