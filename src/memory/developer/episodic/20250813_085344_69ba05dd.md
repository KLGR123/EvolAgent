### Development Step 3: Locate ‘Little Monsters’ comic illustrator and details of their collaborations with writers.

**Description**: Search for information about the comic book 'Little Monsters' to identify its illustrator/artist. Focus on finding the artist who illustrated this comic and any information about their collaborations with writers. Look for official publication details, creator credits, and any collaborative relationships mentioned in connection with this work.

**Use Cases**:
- Comic publisher metadata enrichment and artist credit verification for updating internal digital archives with accurate illustrator information
- Public library graphic novel cataloging automation to extract and standardize illustrator and writer credits for MARC records
- Creative agency collaboration mapping to identify past partnerships between comic writers and artists for project matchmaking
- Online comic review platform automation to populate creator profiles and art-by credits for SEO-optimized content pages
- Licensing department due diligence workflow to confirm illustrator rights and collaboration history before contract negotiations
- Market research analysis of indie horror comics to chart artist-writer collaboration networks and emerging talent trends
- Fan community wiki generation to automatically verify and update ‘Little Monsters’ illustrator credits in crowd-sourced databases
- Digital rights management automation to cross-reference illustrator names across publishers for accurate royalty tracking and payout reconciliation

```
import os
import requests
from bs4 import BeautifulSoup
import json
import time
from urllib.parse import quote

# Create workspace directory if it doesn't exist
os.makedirs('workspace', exist_ok=True)

print("=== SEARCHING FOR 'LITTLE MONSTERS' COMIC ARTIST/ILLUSTRATOR ===")
print("Objective: Identify the artist who illustrated the 'Little Monsters' comic")
print("Focus: Creator credits, publication details, collaborative relationships")
print("=" * 70)

# Define headers for web requests (fixing the previous error)
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Connection': 'keep-alive'
}

def safe_request(url, timeout=15):
    """Make HTTP request with comprehensive error handling"""
    try:
        print(f"Requesting: {url}")
        response = requests.get(url, headers=headers, timeout=timeout)
        response.raise_for_status()
        return response
    except Exception as e:
        print(f"Request failed: {e}")
        return None

# Initialize search results storage
search_results = {
    'comic_matches_found': [],
    'artist_information': [],
    'publication_details': [],
    'search_attempts': [],
    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
}

print("\nSTEP 1: Conducting targeted Google searches for 'Little Monsters' comic")
print("-" * 60)

# Specific search queries to find the comic and its artist
search_queries = [
    '\"Little Monsters\" comic book artist illustrator creator',
    'Little Monsters comic series artist name writer',
    'Little Monsters graphic novel publication artist credits',
    'Little Monsters comic book \"created by\" \"art by\" \"written by\"',
    'Little Monsters horror comic artist illustrator indie'
]

for i, query in enumerate(search_queries, 1):
    print(f"\nSearch {i}: {query}")
    
    # Construct Google search URL
    google_url = f"https://www.google.com/search?q={quote(query)}"
    
    response = safe_request(google_url)
    
    if response:
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
        
        # Get clean text content
        text_content = soup.get_text()
        
        # Look for search result containers
        search_snippets = []
        
        # Try multiple selectors for Google search results
        result_selectors = ['.g', '.tF2Cxc', '.MjjYud', '.yuRUbf']
        results = []
        
        for selector in result_selectors:
            found_results = soup.select(selector)
            if found_results:
                results = found_results[:5]  # First 5 results
                break
        
        print(f"  Found {len(results)} search result containers")
        
        # Extract information from search results
        for result in results:
            # Try to find title and description
            title_elem = result.find(['h3', 'a'])
            desc_elem = result.find(['span', 'div'], string=lambda text: text and len(text) > 20)
            
            title = title_elem.get_text() if title_elem else ''
            description = desc_elem.get_text() if desc_elem else ''
            
            # Combine title and description for analysis
            combined_text = f"{title} {description}".lower()
            
            # Look for creator-related keywords
            creator_keywords = ['artist', 'illustrator', 'creator', 'writer', 'by ', 'created by', 'art by', 'illustrated by']
            
            if any(keyword in combined_text for keyword in creator_keywords) and 'little monsters' in combined_text:
                search_snippets.append({
                    'title': title[:150],
                    'description': description[:300],
                    'relevance_score': sum(1 for kw in creator_keywords if kw in combined_text)
                })
                
                print(f"    RELEVANT: {title[:80]}...")
                print(f"    Desc: {description[:120]}...")
        
        # Also search the full page text for artist mentions
        artist_mentions = []
        lines = text_content.split('\n')
        
        for line in lines:
            line_lower = line.strip().lower()
            if ('little monsters' in line_lower and 
                any(keyword in line_lower for keyword in ['artist', 'illustrator', 'creator', 'by '])):
                
                # Clean up the line
                clean_line = ' '.join(line.strip().split())
                if len(clean_line) > 20 and len(clean_line) < 200:
                    artist_mentions.append(clean_line)
        
        if artist_mentions:
            print(f"  Found {len(artist_mentions)} potential artist mentions:")
            for mention in artist_mentions[:3]:  # Show first 3
                print(f"    - {mention[:100]}...")
        
        # Record search attempt
        search_results['search_attempts'].append({
            'query': query,
            'source': 'Google Search',
            'results_found': len(search_snippets),
            'snippets': search_snippets,
            'artist_mentions': artist_mentions[:5]  # Limit to 5 mentions
        })
        
        # Save raw HTML for manual inspection
        filename = f"workspace/google_search_{i}.html"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(response.text)
        print(f"  Raw HTML saved to: {filename}")
        
    else:
        print(f"  ✗ Failed to retrieve search results")
        search_results['search_attempts'].append({
            'query': query,
            'source': 'Google Search',
            'status': 'Failed'
        })
    
    # Add delay between requests to be respectful
    time.sleep(3)

print("\nSTEP 2: Searching for specific comic publishers and 'Little Monsters'")
print("-" * 60)

# Search for specific publisher connections
publisher_queries = [
    'Little Monsters Image Comics artist creator credits',
    'Little Monsters Dark Horse Comics illustrator',
    'Little Monsters IDW Publishing artist writer',
    'Little Monsters Boom Studios creator team',
    'Little Monsters Oni Press artist illustrator'
]

for query in publisher_queries:
    print(f"\nPublisher search: {query}")
    
    google_url = f"https://www.google.com/search?q={quote(query)}"
    response = safe_request(google_url)
    
    if response:
        soup = BeautifulSoup(response.content, 'html.parser')
        text_content = soup.get_text().lower()
        
        # Check for specific publisher mentions with Little Monsters
        publisher_found = False
        
        if 'image comics' in text_content and 'little monsters' in text_content:
            publisher_found = 'Image Comics'
        elif 'dark horse' in text_content and 'little monsters' in text_content:
            publisher_found = 'Dark Horse Comics'
        elif 'idw' in text_content and 'little monsters' in text_content:
            publisher_found = 'IDW Publishing'
        elif 'boom studios' in text_content and 'little monsters' in text_content:
            publisher_found = 'Boom Studios'
        elif 'oni press' in text_content and 'little monsters' in text_content:
            publisher_found = 'Oni Press'
        
        if publisher_found:
            print(f"  ✓ Found connection: {publisher_found}")
            
            # Look for artist information in this context
            lines = text_content.split('\n')
            relevant_lines = []
            
            for line in lines:
                if ('little monsters' in line and 
                    publisher_found.lower().replace(' ', '') in line.replace(' ', '') and
                    any(kw in line for kw in ['artist', 'creator', 'illustrator'])):
                    relevant_lines.append(line.strip()[:150])
            
            search_results['publication_details'].append({
                'publisher': publisher_found,
                'query': query,
                'relevant_info': relevant_lines[:3]
            })
            
            if relevant_lines:
                print(f"    Relevant info found: {len(relevant_lines)} lines")
                for line in relevant_lines[:2]:
                    print(f"      {line[:80]}...")
        else:
            print(f"  No specific publisher connection found")
    
    time.sleep(2)

print("\nSTEP 3: Analyzing collected information for artist identification")
print("-" * 60)

# Analyze all collected search results
total_searches = len(search_results['search_attempts'])
successful_searches = len([s for s in search_results['search_attempts'] if s.get('status') != 'Failed'])

print(f"Total searches conducted: {total_searches}")
print(f"Successful searches: {successful_searches}")

# Compile potential artist names from all searches
all_artist_mentions = []
for search in search_results['search_attempts']:
    if 'artist_mentions' in search:
        all_artist_mentions.extend(search['artist_mentions'])

print(f"\nTotal artist mentions found: {len(all_artist_mentions)}")

if all_artist_mentions:
    print("\nSample artist mentions:")
    for mention in all_artist_mentions[:5]:
        print(f"  - {mention[:100]}...")

# Look for recurring names or patterns
print("\nAnalyzing mentions for potential artist names...")

# Common patterns that might indicate artist names
name_patterns = []
for mention in all_artist_mentions:
    # Look for "by [Name]" patterns
    import re
    
    # Pattern: "by [First Last]"
    by_pattern = re.findall(r'by\s+([A-Z][a-z]+\s+[A-Z][a-z]+)', mention)
    name_patterns.extend(by_pattern)
    
    # Pattern: "artist [First Last]"
    artist_pattern = re.findall(r'artist\s+([A-Z][a-z]+\s+[A-Z][a-z]+)', mention)
    name_patterns.extend(artist_pattern)
    
    # Pattern: "illustrated by [First Last]"
    illustrated_pattern = re.findall(r'illustrated\s+by\s+([A-Z][a-z]+\s+[A-Z][a-z]+)', mention)
    name_patterns.extend(illustrated_pattern)

if name_patterns:
    print(f"\nPotential artist names extracted: {len(name_patterns)}")
    # Count frequency of names
    from collections import Counter
    name_frequency = Counter(name_patterns)
    
    print("Most frequently mentioned names:")
    for name, count in name_frequency.most_common(5):
        print(f"  {name}: mentioned {count} time(s)")
        
        search_results['artist_information'].append({
            'name': name,
            'frequency': count,
            'confidence': 'Medium' if count > 1 else 'Low'
        })
else:
    print("No clear artist names extracted from patterns")

# Save comprehensive search results
results_file = 'workspace/little_monsters_comprehensive_search.json'
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(search_results, f, indent=2, ensure_ascii=False)

print(f"\n✓ Comprehensive search results saved to: {results_file}")

print("\n" + "=" * 70)
print("LITTLE MONSTERS COMIC ARTIST SEARCH SUMMARY")
print("=" * 70)

if search_results['artist_information']:
    print("\n*** POTENTIAL ARTISTS IDENTIFIED ***")
    for artist in search_results['artist_information']:
        print(f"Artist: {artist['name']}")
        print(f"Confidence: {artist['confidence']} (mentioned {artist['frequency']} times)")
        print()
else:
    print("\n*** NO DEFINITIVE ARTIST IDENTIFIED ***")
    print("Reasons this might occur:")
    print("1. Multiple comics may share the 'Little Monsters' title")
    print("2. The comic may be self-published or indie with limited online presence")
    print("3. Search results may not contain detailed creator credits")
    print("4. The comic may be a webcomic or digital-only publication")

print("\nSearch completed. Raw search data available in workspace files for manual review.")
print("Files created:")
for file in os.listdir('workspace'):
    if file.endswith(('.html', '.json')):
        print(f"  - {file}")

print("\nNext steps: Manual review of HTML files may reveal additional artist information.")
```