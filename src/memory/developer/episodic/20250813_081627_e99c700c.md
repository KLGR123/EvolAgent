### Development Step 3: Investigate Abel Hugo’s Napoleonic military service, Madrid hospital link, map publications, and ruler’s reign

**Description**: Research Abel Hugo, Victor Hugo's brother, focusing on his military service during the Napoleonic Wars and his time in Madrid. Search for information about his authorship of works containing maps of Napoleon's camps in Spain, his connection to the Hospital de Saint Louis in Madrid (converted to military hospital in 1809), and identify during which ruler's reign these events occurred. Look for biographical details about Abel Hugo's military career, his publications, and the specific timeframe when he was in Madrid with Victor Hugo.

**Use Cases**:
- Academic historian automating extraction of Abel Hugo’s military service details and Madrid activities to support a peer-reviewed Napoleonic Wars journal article
- Museum digital curator integrating scraped map and publication data on Napoleon’s Spanish camps into an interactive Peninsular War exhibit
- Genealogist constructing a Hugo family lineage uses Wikipedia and Google Books parsing to gather biographical records of Victor Hugo’s brother across French and English sources
- Education content developer compiling a timeline of the Hospital de Saint Louis’s conversion to a military hospital in 1809 under Joseph Bonaparte for a French language history curriculum
- Military history blogger automating Google Books searches to source rare Abel Hugo cartographic works for a series on 19th-century Napoleonic cartography
- Digital humanities researcher populating a database of 19th-century French military authors by merging metadata from scraped Wikipedia pages and Google Books volumes
- Publishing acquisitions analyst identifying publication dates and authorship details of Abel Hugo’s works to evaluate reprint rights and enrich historical title metadata
- AI-powered virtual tour guide for Madrid’s wartime landmarks using parsed content about Abel Hugo and the Hospital de Saint Louis to generate contextual audio narratives

```
import requests
import json
import os
from datetime import datetime
from bs4 import BeautifulSoup
import time

print("Researching Abel Hugo with corrected Wikipedia parsing...")

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

# Initialize results storage
all_results = []
search_errors = []

print("\n=== FIXED WIKIPEDIA SEARCH FOR ABEL HUGO ===")

# Wikipedia URLs to search
wikipedia_urls = [
    "https://en.wikipedia.org/wiki/Abel_Hugo",
    "https://fr.wikipedia.org/wiki/Abel_Hugo",  # French Wikipedia often has more details
    "https://en.wikipedia.org/wiki/Victor_Hugo",
    "https://en.wikipedia.org/wiki/Napoleonic_Wars",
    "https://en.wikipedia.org/wiki/Peninsular_War",
    "https://en.wikipedia.org/wiki/Madrid"
]

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

for url in wikipedia_urls:
    try:
        print(f"\nFetching: {url}")
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Extract title
        title_elem = soup.find('h1', class_='firstHeading')
        title = title_elem.get_text(strip=True) if title_elem else 'Unknown Title'
        print(f"Page title: {title}")
        
        # Extract main content - PROPERLY FIXED VERSION
        content_div = soup.find('div', {'id': 'mw-content-text'})
        if content_div:
            # Remove scripts and styles first
            for script_elem in content_div.find_all('script'):
                script_elem.decompose()
            for style_elem in content_div.find_all('style'):
                style_elem.decompose()
            
            # Remove navigation and info boxes - FIXED VARIABLE SCOPE
            divs_to_check = content_div.find_all('div')
            for div_elem in divs_to_check:
                div_classes = div_elem.get('class')
                if div_classes:  # Only process if classes exist
                    class_string = ' '.join(div_classes)
                    if any(unwanted_class in class_string for unwanted_class in ['navbox', 'infobox', 'sidebar', 'hatnote']):
                        div_elem.decompose()
            
            # Remove tables that are typically navigation or infoboxes
            for table_elem in content_div.find_all('table'):
                table_classes = table_elem.get('class')
                if table_classes:
                    table_class_string = ' '.join(table_classes)
                    if any(unwanted_class in table_class_string for unwanted_class in ['infobox', 'navbox', 'sidebar']):
                        table_elem.decompose()
            
            content = content_div.get_text(separator=' ', strip=True)
            print(f"Content length: {len(content)} characters")
            
            # Target keywords for Abel Hugo research
            target_keywords = [
                'abel hugo', 'victor hugo', 'napoleonic wars', 'madrid', 'spain', 
                'military service', 'military hospital', 'hospital',
                'napoleon', 'camps', 'maps', 'publications', 'author', 'brother',
                '1809', 'peninsular war', 'french army', 'officer', 'career',
                'joseph bonaparte', 'ferdinand vii', 'saint louis', 'saint-louis'
            ]
            
            # Find matching keywords
            content_lower = content.lower()
            found_keywords = []
            for keyword in target_keywords:
                if keyword in content_lower:
                    found_keywords.append(keyword)
            
            print(f"Keywords found: {', '.join(found_keywords)}")
            
            if found_keywords:
                result = {
                    'title': title,
                    'url': url,
                    'content': content[:5000],  # First 5000 characters
                    'keywords_found': found_keywords,
                    'source': 'Wikipedia',
                    'relevance_score': len(found_keywords)
                }
                all_results.append(result)
                print(f"Added relevant result with {len(found_keywords)} keyword matches")
                
                # Special handling for Abel Hugo pages
                if 'abel hugo' in content_lower:
                    print("\n*** ABEL HUGO BIOGRAPHICAL CONTENT FOUND ***")
                    # Extract sentences containing Abel Hugo
                    sentences = content.split('.')
                    abel_sentences = []
                    for sentence in sentences:
                        if 'abel hugo' in sentence.lower() or ('abel' in sentence.lower() and 'hugo' in sentence.lower()):
                            abel_sentences.append(sentence.strip())
                    
                    print(f"Found {len(abel_sentences)} sentences about Abel Hugo:")
                    for i, sentence in enumerate(abel_sentences[:5], 1):
                        print(f"  {i}. {sentence[:250]}...")
                    
                    # Look for specific military and Madrid information
                    military_info = []
                    madrid_info = []
                    for sentence in abel_sentences:
                        sentence_lower = sentence.lower()
                        if any(term in sentence_lower for term in ['military', 'army', 'officer', 'service', 'soldier', 'war']):
                            military_info.append(sentence)
                        if 'madrid' in sentence_lower:
                            madrid_info.append(sentence)
                    
                    if military_info:
                        print(f"\n  Military information found in {len(military_info)} sentences:")
                        for info in military_info[:3]:
                            print(f"    - {info[:200]}...")
                    
                    if madrid_info:
                        print(f"\n  Madrid information found in {len(madrid_info)} sentences:")
                        for info in madrid_info[:3]:
                            print(f"    - {info[:200]}...")
            
        time.sleep(2)  # Be respectful to Wikipedia
        
    except Exception as e:
        error_msg = f"Error fetching {url}: {str(e)}"
        print(error_msg)
        search_errors.append(error_msg)

print(f"\n=== GOOGLE BOOKS API SEARCH FOR ABEL HUGO WORKS ===")

# Search Google Books API for Abel Hugo's publications
book_queries = [
    "Abel Hugo Napoleon camps Spain maps",
    "Abel Hugo military hospital Madrid", 
    "Abel Hugo Madrid 1809 Hospital Saint Louis",
    "Abel Hugo Napoleonic Wars publications",
    "Abel Hugo Victor Hugo brother military",
    "Abel Hugo Peninsular War Spain author",
    "Abel Hugo French army officer Madrid",
    "Abel Hugo Napoleon Bonaparte Spain"
]

for query in book_queries:
    try:
        print(f"\nSearching Google Books for: {query}")
        api_url = "https://www.googleapis.com/books/v1/volumes"
        params = {
            'q': query,
            'maxResults': 10,
            'printType': 'books',
            'langRestrict': 'en'
        }
        
        response = requests.get(api_url, params=params, timeout=15)
        response.raise_for_status()
        
        data = response.json()
        
        if 'items' in data:
            print(f"Found {len(data['items'])} books")
            
            for item in data['items']:
                volume_info = item.get('volumeInfo', {})
                title = volume_info.get('title', 'Unknown Title')
                authors = volume_info.get('authors', ['Unknown Author'])
                description = volume_info.get('description', '')
                published_date = volume_info.get('publishedDate', 'Unknown Date')
                
                # Create text for keyword analysis
                book_text = (title + ' ' + ' '.join(authors) + ' ' + description).lower()
                
                # Check for relevant keywords
                target_keywords = [
                    'abel hugo', 'napoleon', 'madrid', 'spain', 'military', 'maps',
                    'camps', 'hospital', 'saint louis', '1809', 'peninsular war',
                    'victor hugo', 'brother', 'napoleonic', 'french army', 'officer',
                    'joseph bonaparte', 'publications', 'author'
                ]
                
                # Find matching keywords
                book_keywords = []
                for keyword in target_keywords:
                    if keyword in book_text:
                        book_keywords.append(keyword)
                
                # Only include if relevant (at least 2 keywords)
                if len(book_keywords) >= 2:
                    result = {
                        'title': title,
                        'authors': authors,
                        'description': description,
                        'published_date': published_date,
                        'keywords_found': book_keywords,
                        'source': 'Google Books',
                        'search_query': query,
                        'relevance_score': len(book_keywords)
                    }
                    all_results.append(result)
                    print(f"Added book: {title}")
                    print(f"Authors: {', '.join(authors)}")
                    print(f"Keywords: {', '.join(book_keywords)}")
        else:
            print(f"No books found for: {query}")
        
        time.sleep(1)  # Be respectful to API
        
    except Exception as e:
        error_msg = f"Error searching Google Books for '{query}': {str(e)}"
        print(error_msg)
        search_errors.append(error_msg)

print(f"\n=== ANALYZING RESULTS FOR ABEL HUGO RESEARCH ===")

# Sort results by relevance score
all_results.sort(key=lambda x: x['relevance_score'], reverse=True)

print(f"Total results collected: {len(all_results)}")
print(f"Total errors: {len(search_errors)}")

# Detailed analysis for Abel Hugo specific information
abel_hugo_analysis = {
    'military_service_details': [],
    'madrid_connections': [],
    'napoleon_maps_camps': [],
    'hospital_saint_louis': [],
    'publications_authorship': [],
    'timeframe_1809': [],
    'ruler_context': [],
    'victor_hugo_relationship': [],
    'biographical_details': []
}

for result in all_results:
    # Get text content for analysis
    if 'content' in result:
        text_content = result['content'].lower()
        full_text = result['content']  # Keep original case for extraction
    elif 'description' in result:
        text_content = result['description'].lower()
        full_text = result['description']
    else:
        text_content = result.get('title', '').lower()
        full_text = result.get('title', '')
    
    # Look for specific Abel Hugo details
    if 'abel hugo' in text_content:
        print(f"\nAnalyzing '{result['title']}' for Abel Hugo information...")
        
        # Military service analysis
        if any(term in text_content for term in ['military', 'army', 'officer', 'service', 'soldier', 'war', 'campaign']):
            abel_hugo_analysis['military_service_details'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': full_text[:800],
                'keywords': result['keywords_found']
            })
            print("  ✓ Military service information found")
        
        # Madrid connections
        if 'madrid' in text_content:
            abel_hugo_analysis['madrid_connections'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': full_text[:800],
                'keywords': result['keywords_found']
            })
            print("  ✓ Madrid connection found")
        
        # Napoleon maps/camps
        if 'napoleon' in text_content and ('maps' in text_content or 'camps' in text_content):
            abel_hugo_analysis['napoleon_maps_camps'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': full_text[:800],
                'keywords': result['keywords_found']
            })
            print("  ✓ Napoleon maps/camps reference found")
        
        # Hospital Saint Louis
        if 'hospital' in text_content and ('saint louis' in text_content or 'saint-louis' in text_content):
            abel_hugo_analysis['hospital_saint_louis'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': full_text[:800],
                'keywords': result['keywords_found']
            })
            print("  ✓ Hospital Saint Louis reference found")
        
        # Publications and authorship
        if any(term in text_content for term in ['author', 'wrote', 'published', 'publication', 'work', 'book']):
            abel_hugo_analysis['publications_authorship'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': full_text[:800],
                'keywords': result['keywords_found']
            })
            print("  ✓ Publication/authorship information found")
        
        # 1809 timeframe
        if '1809' in text_content:
            abel_hugo_analysis['timeframe_1809'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': full_text[:800],
                'keywords': result['keywords_found']
            })
            print("  ✓ 1809 timeframe reference found")
        
        # Ruler context
        if any(ruler in text_content for ruler in ['joseph bonaparte', 'napoleon', 'ferdinand vii', 'charles iv']):
            abel_hugo_analysis['ruler_context'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': full_text[:800],
                'keywords': result['keywords_found']
            })
            print("  ✓ Ruler context found")
        
        # Victor Hugo relationship
        if 'victor hugo' in text_content and 'brother' in text_content:
            abel_hugo_analysis['victor_hugo_relationship'].append({
                'source': result['title'],
                'url': result.get('url', ''),
                'text_sample': full_text[:800],
                'keywords': result['keywords_found']
            })
            print("  ✓ Victor Hugo brother relationship found")
        
        # General biographical details
        abel_hugo_analysis['biographical_details'].append({
            'source': result['title'],
            'url': result.get('url', ''),
            'text_sample': full_text[:1000],
            'keywords': result['keywords_found'],
            'relevance_score': result['relevance_score']
        })

# Save comprehensive Abel Hugo research
final_data = {
    'research_date': datetime.now().isoformat(),
    'research_focus': 'Abel Hugo - Victor Hugo\'s brother: military service during Napoleonic Wars, Madrid connections, Napoleon camp maps, Hospital de Saint Louis, publications, ruler context',
    'search_summary': {
        'total_results': len(all_results),
        'wikipedia_pages_searched': len(wikipedia_urls),
        'google_books_queries': len(book_queries),
        'search_errors': len(search_errors)
    },
    'all_results': all_results,
    'abel_hugo_detailed_analysis': abel_hugo_analysis,
    'search_errors': search_errors
}

output_file = 'workspace/abel_hugo_final_research.json'
with open(output_file, 'w') as f:
    json.dump(final_data, f, indent=2)

print(f"\n{'='*80}")
print("ABEL HUGO RESEARCH SUMMARY")
print(f"{'='*80}")
print(f"Results saved to: {output_file}")
print(f"Total results collected: {len(all_results)}")
print(f"Wikipedia pages processed: {len([r for r in all_results if r['source'] == 'Wikipedia'])}")
print(f"Google Books results: {len([r for r in all_results if r['source'] == 'Google Books'])}")

# Display key findings about Abel Hugo
print(f"\n=== ABEL HUGO KEY FINDINGS ===")
for category, findings in abel_hugo_analysis.items():
    if findings:
        print(f"\n{category.replace('_', ' ').title()}: {len(findings)} sources")
        # Show the most relevant finding
        best_finding = max(findings, key=lambda x: x.get('relevance_score', len(x.get('keywords', []))))
        print(f"  Best source: {best_finding['source']}")
        print(f"  Keywords: {', '.join(best_finding.get('keywords', []))}")
        print(f"  Sample: {best_finding['text_sample'][:300]}...")

print(f"\n=== SEARCH ERRORS ===")
if search_errors:
    for error in search_errors:
        print(f"  - {error}")
else:
    print("No search errors - all sources processed successfully!")

print(f"\nAbel Hugo research completed successfully!")
```