### Development Step 7: Identify oldest closed numpy.polynomial 'Regression' issue and its creation, closure, and label-add dates

**Description**: Search GitHub for numpy.polynomial issues to identify all closed issues that have the 'Regression' label. Focus on finding the oldest closed issue with this label and determine when the 'Regression' label was added to that specific issue. Use GitHub's issue search functionality with filters for repository 'numpy/numpy', path 'polynomial', status 'closed', and label 'Regression'. Extract the issue creation date, closure date, and label addition timestamp for the oldest matching issue.

**Use Cases**:
- Open source maintainers integrating automated GitHub API scripts to detect when the ‘Regression’ label is added to numpy.polynomial issues, ensuring timely backporting into long-term support (LTS) releases
- A data science research team auditing the stability of polynomial fitting methods by retrieving creation, closure, and regression label timestamps from numpy issues, supporting reproducibility in scientific publications
- DevOps engineers scheduling nightly CI jobs to flag newly closed numpy.polynomial regression issues and post alerts in Slack, accelerating triage for critical numerical library defects
- QA managers generating custom dashboards of closed regression issues in numpy.polynomial, measuring average time from issue creation to label application to improve testing SLAs
- Software architects analyzing historical labeling trends in numpy.polynomial to prioritize targeted refactoring and reduce future regression risk in core numerical modules
- Compliance auditors extracting detailed issue timelines for numpy.polynomial regressions to demonstrate adherence to internal defect management policies during software quality audits
- Community coordinators organizing focused bug-fix sprints by identifying the oldest labeled regression issues in numpy.polynomial, streamlining contributor efforts during open-source weekends
- Product owners tracking regression‐related issue resolution metrics in numpy.polynomial to inform roadmap decisions for feature deprecation and API stabilization

```
import requests
import json
from datetime import datetime
import os
import time

print("=== FINAL FIX: NUMPY POLYNOMIAL REGRESSION ISSUES SEARCH ===")
print("Objective: Completely restructure code to avoid variable scoping issues")
print("Focus: Find oldest closed issue with regression and polynomial content\n")

# Find workspace directory
workspace_dirs = [d for d in os.listdir('.') if d.startswith('workspace')]
workspace_dir = workspace_dirs[0] if workspace_dirs else 'workspace'
os.makedirs(workspace_dir, exist_ok=True)

# GitHub API configuration
base_url = "https://api.github.com"
repo = "numpy/numpy"

headers = {
    'Accept': 'application/vnd.github.v3+json',
    'User-Agent': 'Python-GitHub-Search'
}

print(f"Using workspace directory: {workspace_dir}")
print(f"Repository: {repo}\n")

# Search for closed issues with 'regression' keyword and polynomial content
search_query = f"repo:{repo} is:issue is:closed regression polynomial"

print(f"=== TARGETED SEARCH: REGRESSION + POLYNOMIAL ISSUES ===")
print(f"Query: {search_query}")
print(f"Objective: Find oldest closed issue with regression and polynomial content\n")

search_url = f"{base_url}/search/issues"
params = {
    'q': search_query,
    'sort': 'created',  # Sort by creation date
    'order': 'asc',     # Ascending order (oldest first)
    'per_page': 100     # Get more results per page
}

print("Making GitHub API request...")
response = requests.get(search_url, headers=headers, params=params)

print(f"Response status: {response.status_code}")
if response.status_code != 200:
    print(f"Error response: {response.text}")
    exit()

search_results = response.json()
total_count = search_results['total_count']
items = search_results['items']

print(f"Total issues found: {total_count}")
print(f"Issues retrieved in this page: {len(items)}\n")

if not items:
    print("No issues found with the search criteria.")
    exit()

print("=== ANALYZING REGRESSION + POLYNOMIAL ISSUES ===")
print("Processing each issue for polynomial and regression relevance...\n")

# Define polynomial keywords outside the loop
polynomial_keywords = ['polynomial', 'poly', 'chebyshev', 'legendre', 'hermite', 'laguerre']

# Function to check polynomial relevance (avoids scoping issues)
def is_polynomial_relevant(title, body):
    """Check if issue title or body contains polynomial-related keywords"""
    title_text = (title or '').lower()
    body_text = (body or '').lower()
    
    for keyword in polynomial_keywords:
        if keyword in title_text or keyword in body_text:
            return True
    return False

def has_regression_keyword(title, body):
    """Check if issue title or body contains regression keyword"""
    title_text = (title or '').lower()
    body_text = (body or '').lower()
    
    return 'regression' in title_text or 'regression' in body_text

# Process each issue using functions (eliminates variable scoping issues)
polynomial_regression_issues = []

for i, issue in enumerate(items, 1):
    # Get issue data safely
    title = issue.get('title', '') or ''
    body = issue.get('body', '') or ''
    
    # Use functions to check relevance (no scoping issues)
    is_poly_related = is_polynomial_relevant(title, body)
    has_regression = has_regression_keyword(title, body)
    
    print(f"{i}. Issue #{issue['number']}: {title[:80]}...")
    print(f"   Created: {issue['created_at']}")
    print(f"   Closed: {issue.get('closed_at', 'N/A')}")
    print(f"   State: {issue['state']}")
    print(f"   Labels: {[label['name'] for label in issue.get('labels', [])]}")
    print(f"   Polynomial-related: {is_poly_related}")
    print(f"   Has regression keyword: {has_regression}")
    print(f"   URL: {issue['html_url']}")
    
    # Store all issues (since they already match our search criteria)
    issue_data = {
        'number': issue['number'],
        'title': title,
        'created_at': issue['created_at'],
        'closed_at': issue.get('closed_at'),
        'state': issue['state'],
        'labels': [label['name'] for label in issue.get('labels', [])],
        'html_url': issue['html_url'],
        'api_url': issue['url'],
        'is_polynomial_related': is_poly_related,
        'has_regression': has_regression,
        'body_preview': body[:500] if body else '',
        'relevance_score': (2 if is_poly_related else 0) + (1 if has_regression else 0)
    }
    polynomial_regression_issues.append(issue_data)
    print()

print(f"=== ANALYSIS SUMMARY ===")
print(f"Total issues analyzed: {len(items)}")
print(f"All issues stored (matched search criteria): {len(polynomial_regression_issues)}\n")

# Sort by creation date to find the oldest
polynomial_regression_issues.sort(key=lambda x: x['created_at'])

print("=== OLDEST ISSUES (sorted by creation date) ===")
for i, issue in enumerate(polynomial_regression_issues[:10], 1):  # Show top 10 oldest
    print(f"{i}. Issue #{issue['number']}: {issue['title'][:60]}...")
    print(f"   Created: {issue['created_at']}")
    print(f"   Closed: {issue['closed_at']}")
    print(f"   Labels: {issue['labels']}")
    print(f"   Polynomial: {issue['is_polynomial_related']}, Regression: {issue['has_regression']}")
    print(f"   Relevance Score: {issue['relevance_score']}")
    print(f"   URL: {issue['html_url']}")
    print()

# Identify the oldest issue
oldest_issue = polynomial_regression_issues[0]
print(f"=== OLDEST ISSUE IDENTIFIED ===")
print(f"Issue #{oldest_issue['number']}: {oldest_issue['title']}")
print(f"Created: {oldest_issue['created_at']}")
print(f"Closed: {oldest_issue['closed_at']}")
print(f"Current labels: {oldest_issue['labels']}")
print(f"Polynomial-related: {oldest_issue['is_polynomial_related']}")
print(f"Has regression: {oldest_issue['has_regression']}")
print(f"API URL: {oldest_issue['api_url']}")

# Analyze labels across all issues
print(f"\n=== LABEL ANALYSIS ===")
all_labels = set()
regression_labeled_issues = []

for issue in polynomial_regression_issues:
    all_labels.update(issue['labels'])
    # Check for regression-related labels
    regression_labels = [label for label in issue['labels'] 
                        if 'regression' in label.lower() or 'regress' in label.lower()]
    if regression_labels:
        regression_labeled_issues.append({
            'issue': issue,
            'regression_labels': regression_labels
        })

print(f"All unique labels found: {sorted(list(all_labels))}")
print(f"Issues with regression-related labels: {len(regression_labeled_issues)}")

if regression_labeled_issues:
    print("\nIssues with regression-related labels:")
    for item in regression_labeled_issues:
        issue = item['issue']
        print(f"  Issue #{issue['number']}: {issue['title'][:50]}...")
        print(f"    Regression labels: {item['regression_labels']}")
        print(f"    Created: {issue['created_at']}")
        print()

# Save comprehensive results
results_data = {
    'search_timestamp': datetime.now().isoformat(),
    'search_query': search_query,
    'repository': repo,
    'total_issues_found': total_count,
    'issues_analyzed': len(items),
    'all_issues': polynomial_regression_issues,
    'oldest_issue': oldest_issue,
    'unique_labels_found': sorted(list(all_labels)),
    'regression_labeled_issues_count': len(regression_labeled_issues),
    'regression_labeled_issues': regression_labeled_issues,
    'next_action': 'Get detailed timeline for oldest issue to find when Regression label was added'
}

with open(f'{workspace_dir}/numpy_polynomial_regression_final_analysis.json', 'w') as f:
    json.dump(results_data, f, indent=2)

print(f"\nComprehensive analysis saved to: {workspace_dir}/numpy_polynomial_regression_final_analysis.json")
print("\nNext step: Get detailed timeline/events for the oldest issue to determine when 'Regression' label was added")
print(f"Target issue for timeline analysis: #{oldest_issue['number']}")
```