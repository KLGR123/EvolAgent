### Development Step 11: Abel Hugo’s Napoleonic Service in Madrid: Camp Maps, Hospital Role under Napoleon I

**Description**: Research Abel Hugo, Victor Hugo's brother, focusing on his military service during the Napoleonic Wars and his time in Madrid. Search for information about his authorship of works containing maps of Napoleon's camps in Spain, his connection to the Hospital de Saint Louis in Madrid (converted to military hospital in 1809), and identify during which ruler's reign these events occurred. Look for biographical details about Abel Hugo's military career, his publications, and the specific timeframe when he was in Madrid with Victor Hugo.

**Use Cases**:
- Automated extraction and analysis of Napoleonic campaign data for a military history museum’s interactive GIS exhibit
- Biographical aggregation and timeline generation for a digital humanities project profiling 19th-century literary families
- Automated monitoring of Wikipedia and Google Books entries to curate up-to-date reference materials for an academic publisher’s Peninsular War series
- Extraction of historical hospital conversion details to support a heritage preservation society documenting Madrid’s military medical facilities
- Real-time keyword-driven content enrichment for an educational platform producing multimedia lessons on Abel and Victor Hugo’s travels in Spain
- Automated assembly of author bibliographies and map illustrations for a scholarly journal special issue on Napoleon’s Spain campaigns
- Data-driven timeline and ruler-context visualization for a political history blog tracking Joseph Bonaparte’s reign in early 19th-century Madrid
- Integration of multi-source biographical and military service details into a genealogical research tool focused on European officer families of the Napoleonic era

```
import requests
import json
import os
from datetime import datetime
from bs4 import BeautifulSoup
import time

print("Abel Hugo research - comprehensive Wikipedia extraction and analysis...")

# Create workspace directory if it doesn't exist
if not os.path.exists('workspace'):
    os.makedirs('workspace')

# Initialize results storage
all_results = []
search_errors = []

print("\n=== DIRECT WIKIPEDIA EXTRACTION FOR ABEL HUGO BIOGRAPHICAL DATA ===")

# Wikipedia URLs to search for Abel Hugo biographical information
wikipedia_urls = [
    "https://en.wikipedia.org/wiki/Abel_Hugo",
    "https://fr.wikipedia.org/wiki/Abel_Hugo",
    "https://en.wikipedia.org/wiki/Victor_Hugo",
    "https://en.wikipedia.org/wiki/Jos%C3%A9_Gaspar_Rodr%C3%ADguez_de_Francia",
    "https://en.wikipedia.org/wiki/Peninsular_War",
    "https://en.wikipedia.org/wiki/Joseph_Bonaparte"
]

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

for url in wikipedia_urls:
    try:
        print(f"\nFetching: {url}")
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Extract title
        title_elem = soup.find('h1', class_='firstHeading')
        title = title_elem.get_text(strip=True) if title_elem else 'Unknown Title'
        print(f"Page title: {title}")
        
        # Extract main content using simple approach
        content_div = soup.find('div', {'id': 'mw-content-text'})
        if content_div:
            # Remove scripts and styles only
            for script in content_div.find_all('script'):
                script.decompose()
            for style in content_div.find_all('style'):
                style.decompose()
            
            # Get all text content
            content_text = content_div.get_text(separator=' ', strip=True)
            print(f"Content length: {len(content_text)} characters")
            
            # Target keywords for Abel Hugo research
            target_keywords = [
                'abel hugo', 'victor hugo', 'napoleonic wars', 'madrid', 'spain', 
                'military service', 'military hospital', 'hospital',
                'napoleon', 'camps', 'maps', 'publications', 'author', 'brother',
                '1809', 'peninsular war', 'french army', 'officer', 'career',
                'joseph bonaparte', 'ferdinand vii', 'saint louis', 'saint-louis',
                'histoire de la campagne', 'france militaire', 'essayist', 'historian'
            ]
            
            # Find matching keywords
            content_lower = content_text.lower()
            found_keywords = []
            for keyword in target_keywords:
                if keyword in content_lower:
                    found_keywords.append(keyword)
            
            print(f"Keywords found: {', '.join(found_keywords)}")
            
            if found_keywords:
                result = {
                    'title': title,
                    'url': url,
                    'content': content_text,
                    'keywords_found': found_keywords,
                    'source': 'Wikipedia',
                    'relevance_score': len(found_keywords)
                }
                all_results.append(result)
                print(f"✓ Added result with {len(found_keywords)} keyword matches")
                
                # Special extraction for Abel Hugo biographical content
                if 'abel hugo' in content_lower:
                    print("\n*** ABEL HUGO BIOGRAPHICAL CONTENT FOUND ***")
                    
                    # Extract key biographical information
                    sentences = content_text.split('.')
                    abel_sentences = []
                    
                    for sentence in sentences:
                        sentence_clean = sentence.strip()
                        if len(sentence_clean) > 20:
                            sentence_lower = sentence_clean.lower()
                            if 'abel hugo' in sentence_lower or ('abel' in sentence_lower and 'hugo' in sentence_lower):
                                abel_sentences.append(sentence_clean)
                    
                    print(f"Found {len(abel_sentences)} sentences about Abel Hugo:")
                    for i, sentence in enumerate(abel_sentences[:8], 1):
                        print(f"  {i}. {sentence[:400]}...")
                    
                    # Look for specific biographical details
                    birth_info = [s for s in abel_sentences if any(year in s for year in ['1798', 'born', 'birth'])]
                    death_info = [s for s in abel_sentences if any(year in s for year in ['1855', 'died', 'death'])]
                    military_info = [s for s in abel_sentences if any(term in s.lower() for term in ['military', 'army', 'officer', 'service', 'war'])]
                    publication_info = [s for s in abel_sentences if any(term in s.lower() for term in ['author', 'wrote', 'published', 'work', 'book', 'histoire', 'france militaire'])]
                    
                    if birth_info:
                        print(f"\n  Birth information:")
                        for info in birth_info[:2]:
                            print(f"    - {info[:300]}...")
                    
                    if death_info:
                        print(f"\n  Death information:")
                        for info in death_info[:2]:
                            print(f"    - {info[:300]}...")
                    
                    if military_info:
                        print(f"\n  Military information:")
                        for info in military_info[:3]:
                            print(f"    - {info[:300]}...")
                    
                    if publication_info:
                        print(f"\n  Publication information:")
                        for info in publication_info[:3]:
                            print(f"    - {info[:300]}...")
            
        time.sleep(2)  # Be respectful to Wikipedia
        
    except Exception as e:
        error_msg = f"Error fetching {url}: {str(e)}"
        print(error_msg)
        search_errors.append(error_msg)

# Load existing Google Books results from previous research
print(f"\n=== LOADING EXISTING GOOGLE BOOKS RESULTS ===")
existing_google_books = []

existing_files = ['abel_hugo_research_final_complete.json', 'abel_hugo_final_research.json', 'abel_hugo_complete_research.json']
for filename in existing_files:
    filepath = f'workspace/{filename}'
    if os.path.exists(filepath):
        try:
            print(f"Loading from: {filename}")
            with open(filepath, 'r') as f:
                data = json.load(f)
            
            if 'all_research_results' in data:
                results = data['all_research_results']
                books = [r for r in results if r.get('source') == 'Google Books']
                existing_google_books.extend(books)
                print(f"  Loaded {len(books)} Google Books results")
            elif 'all_results' in data:
                results = data['all_results']
                books = [r for r in results if r.get('source') == 'Google Books']
                existing_google_books.extend(books)
                print(f"  Loaded {len(books)} Google Books results")
                
        except Exception as e:
            print(f"  Error loading {filename}: {str(e)}")

# Remove duplicate Google Books results
seen_titles = set()
unique_books = []
for book in existing_google_books:
    title = book.get('title', '')
    if title and title not in seen_titles:
        seen_titles.add(title)
        unique_books.append(book)

print(f"Unique Google Books results preserved: {len(unique_books)}")

# Combine all results
all_results.extend(unique_books)
all_results.sort(key=lambda x: x['relevance_score'], reverse=True)

print(f"\n=== COMPREHENSIVE ANALYSIS OF COMBINED RESULTS ===")
print(f"Total results: {len(all_results)}")
print(f"Wikipedia results: {len([r for r in all_results if r['source'] == 'Wikipedia'])}")
print(f"Google Books results: {len([r for r in all_results if r['source'] == 'Google Books'])}")

# Analyze all results for Abel Hugo information with proper variable scoping
abel_hugo_findings = {
    'military_service_details': [],
    'madrid_connections': [],
    'napoleon_maps_camps': [],
    'hospital_saint_louis': [],
    'publications_authorship': [],
    'timeframe_1809': [],
    'ruler_context': [],
    'family_relations': [],
    'biographical_details': [],
    'key_works': []
}

# Process each result individually to avoid variable scoping issues
for i, result in enumerate(all_results, 1):
    current_title = result.get('title', '')
    current_source = result.get('source', '')
    current_keywords = result.get('keywords_found', [])
    current_score = result.get('relevance_score', 0)
    current_url = result.get('url', '')
    
    # Get text content with proper initialization
    current_text = ''
    current_original = ''
    
    if 'content' in result and result['content']:
        current_text = str(result['content']).lower()
        current_original = str(result['content'])
    elif 'description' in result and result['description']:
        current_text = str(result['description']).lower()
        current_original = str(result['description'])
    elif current_title:
        current_text = current_title.lower()
        current_original = current_title
    
    # Check for Abel Hugo relevance
    is_abel_relevant = (
        ('abel hugo' in current_text) or 
        ('abel' in current_text and 'hugo' in current_text and 'victor' in current_text) or
        (current_score >= 3)
    )
    
    if is_abel_relevant:
        print(f"\nAnalyzing: {current_title} (Score: {current_score})")
        
        # Military service analysis
        military_terms = ['military', 'army', 'officer', 'service', 'soldier', 'war', 'campaign']
        if any(term in current_text for term in military_terms):
            abel_hugo_findings['military_service_details'].append({
                'source': current_title,
                'url': current_url,
                'text_sample': current_original[:1000],
                'keywords': current_keywords,
                'score': current_score
            })
            print(f"  ✓ Military service information found")
        
        # Madrid connections
        if 'madrid' in current_text:
            abel_hugo_findings['madrid_connections'].append({
                'source': current_title,
                'url': current_url,
                'text_sample': current_original[:1000],
                'keywords': current_keywords,
                'score': current_score
            })
            print(f"  ✓ Madrid connection found")
        
        # Napoleon maps/camps
        if 'napoleon' in current_text and ('maps' in current_text or 'camps' in current_text):
            abel_hugo_findings['napoleon_maps_camps'].append({
                'source': current_title,
                'url': current_url,
                'text_sample': current_original[:1000],
                'keywords': current_keywords,
                'score': current_score
            })
            print(f"  ✓ Napoleon maps/camps reference found")
        
        # Hospital Saint Louis
        if 'hospital' in current_text and ('saint louis' in current_text or 'saint-louis' in current_text):
            abel_hugo_findings['hospital_saint_louis'].append({
                'source': current_title,
                'url': current_url,
                'text_sample': current_original[:1000],
                'keywords': current_keywords,
                'score': current_score
            })
            print(f"  ✓ Hospital Saint Louis reference found")
        
        # Publications and authorship
        publication_terms = ['author', 'wrote', 'published', 'publication', 'work', 'book', 'histoire', 'france militaire']
        if any(term in current_text for term in publication_terms):
            abel_hugo_findings['publications_authorship'].append({
                'source': current_title,
                'url': current_url,
                'text_sample': current_original[:1000],
                'keywords': current_keywords,
                'score': current_score
            })
            print(f"  ✓ Publication/authorship information found")
        
        # 1809 timeframe
        if '1809' in current_text:
            abel_hugo_findings['timeframe_1809'].append({
                'source': current_title,
                'url': current_url,
                'text_sample': current_original[:1000],
                'keywords': current_keywords,
                'score': current_score
            })
            print(f"  ✓ 1809 timeframe reference found")
        
        # Ruler context
        ruler_terms = ['joseph bonaparte', 'napoleon', 'ferdinand vii', 'charles iv']
        if any(ruler in current_text for ruler in ruler_terms):
            abel_hugo_findings['ruler_context'].append({
                'source': current_title,
                'url': current_url,
                'text_sample': current_original[:1000],
                'keywords': current_keywords,
                'score': current_score
            })
            print(f"  ✓ Ruler context found")
        
        # Family relations
        if 'victor hugo' in current_text and 'brother' in current_text:
            abel_hugo_findings['family_relations'].append({
                'source': current_title,
                'url': current_url,
                'text_sample': current_original[:1000],
                'keywords': current_keywords,
                'score': current_score
            })
            print(f"  ✓ Family relations found")
        
        # Biographical details (birth, death, profession)
        if any(term in current_text for term in ['1798', '1855', 'born', 'died', 'essayist', 'historian']):
            abel_hugo_findings['biographical_details'].append({
                'source': current_title,
                'url': current_url,
                'text_sample': current_original[:1000],
                'keywords': current_keywords,
                'score': current_score
            })
            print(f"  ✓ Biographical details found")
        
        # Key works
        if any(work in current_text for work in ['histoire de la campagne', 'france militaire', 'traité du mélodrame']):
            abel_hugo_findings['key_works'].append({
                'source': current_title,
                'url': current_url,
                'text_sample': current_original[:1000],
                'keywords': current_keywords,
                'score': current_score
            })
            print(f"  ✓ Key works information found")

# Save comprehensive research
final_research_data = {
    'research_date': datetime.now().isoformat(),
    'research_objective': 'Abel Hugo comprehensive research: military service during Napoleonic Wars, Madrid connections, Napoleon camp maps, Hospital de Saint Louis, publications, ruler context during 1809',
    'search_summary': {
        'total_results': len(all_results),
        'wikipedia_results': len([r for r in all_results if r['source'] == 'Wikipedia']),
        'google_books_results': len([r for r in all_results if r['source'] == 'Google Books']),
        'search_errors': len(search_errors),
        'highest_relevance_score': max([r['relevance_score'] for r in all_results]) if all_results else 0
    },
    'all_research_results': all_results,
    'abel_hugo_detailed_findings': abel_hugo_findings,
    'search_errors': search_errors
}

final_output_file = 'workspace/abel_hugo_comprehensive_final_research.json'
with open(final_output_file, 'w') as f:
    json.dump(final_research_data, f, indent=2)

print(f"\n{'='*80}")
print("ABEL HUGO RESEARCH - COMPREHENSIVE FINAL ANALYSIS")
print(f"{'='*80}")
print(f"Complete research saved to: {final_output_file}")
print(f"Total sources analyzed: {len(all_results)}")
print(f"Wikipedia pages successfully processed: {len([r for r in all_results if r['source'] == 'Wikipedia'])}")
print(f"Google Books sources included: {len([r for r in all_results if r['source'] == 'Google Books'])}")

# Display key research findings
print(f"\n=== ABEL HUGO KEY RESEARCH FINDINGS ===")
for category, findings in abel_hugo_findings.items():
    if findings:
        print(f"\n{category.replace('_', ' ').title()}: {len(findings)} sources found")
        best_source = max(findings, key=lambda x: x['score'])
        print(f"  Best source: {best_source['source']} (Score: {best_source['score']})")
        print(f"  Keywords: {', '.join(best_source['keywords'])}")
        print(f"  Sample text: {best_source['text_sample'][:300]}...")

# Display top sources
print(f"\n=== TOP SOURCES FOR ABEL HUGO RESEARCH ===")
for i, result in enumerate(all_results[:8], 1):
    print(f"\n{i}. {result['title']} (Relevance Score: {result['relevance_score']})")
    print(f"   Source: {result['source']}")
    if 'authors' in result:
        print(f"   Authors: {', '.join(result['authors'])}")
    print(f"   Keywords: {', '.join(result['keywords_found'])}")
    
    if 'content' in result and len(result['content']) > 100:
        print(f"   Content preview: {result['content'][:300]}...")
    elif 'description' in result:
        print(f"   Description: {result['description'][:300]}...")

print(f"\n🎯 RESEARCH SUMMARY FOR PLAN OBJECTIVES:")
print(f"✓ Abel Hugo biographical information: Found in {len(abel_hugo_findings['biographical_details'])} sources")
print(f"✓ Military service details: Found in {len(abel_hugo_findings['military_service_details'])} sources")
print(f"✓ Madrid connections: Found in {len(abel_hugo_findings['madrid_connections'])} sources")
print(f"✓ Napoleon maps/camps: Found in {len(abel_hugo_findings['napoleon_maps_camps'])} sources")
print(f"✓ Hospital Saint Louis: Found in {len(abel_hugo_findings['hospital_saint_louis'])} sources")
print(f"✓ Publications/authorship: Found in {len(abel_hugo_findings['publications_authorship'])} sources")
print(f"✓ Key works: Found in {len(abel_hugo_findings['key_works'])} sources")
print(f"✓ 1809 timeframe: Found in {len(abel_hugo_findings['timeframe_1809'])} sources")
print(f"✓ Ruler context: Found in {len(abel_hugo_findings['ruler_context'])} sources")
print(f"✓ Family relations: Found in {len(abel_hugo_findings['family_relations'])} sources")

print(f"\nAbel Hugo research completed successfully! Full results available in {final_output_file}")
```