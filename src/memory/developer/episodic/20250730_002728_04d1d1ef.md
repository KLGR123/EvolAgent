### Development Step 2: Identify City in APOD Horizon City-Light Images from August 1‚Äì7, 2015

**Description**: Search for NASA Astronomy Pictures of the Day from the first week of August 2015 (August 1-7, 2015). Look for entries that show city lights on the horizon and identify which city is featured. Use search approaches including: (1) Direct access to NASA APOD archives for August 2015, (2) Search 'NASA APOD August 2015 city lights horizon', (3) Browse the official NASA APOD website archive section for that specific date range. Extract the complete APOD entries including titles, descriptions, and image details to identify which city's lights are shown.

**Use Cases**:
- Astro-environmental researchers automating the extraction of city light mentions from historical NASA APOD pages to quantify urban light pollution trends over time
- Municipal planning offices scanning archived astrophotography content to verify their city‚Äôs skyline presence in nighttime horizon imagery for urban growth studies
- Science communicators programmatically curating location-specific astronomy images featuring recognizable city lights to boost engagement in regional outreach events
- Academic historians analyzing archived NASA APOD entries to trace the evolution of city-scape photography and public interest in urban night-sky scenes
- News media fact-checkers using regex-powered HTML parsing to confirm the exact city depicted in widely circulated astrophotography images before publication
- Tourism boards automatically sourcing high-resolution NASA images of local city lights on the horizon for inclusion in digital marketing and promotional materials
- Environmental NGOs aggregating city-specific light distribution data from APOD archives to support light pollution policy proposals and public awareness campaigns
- Digital asset managers integrating automated metadata enrichment workflows that identify and tag city names in archived astronomy images for enterprise content libraries

```
import os
import json
from bs4 import BeautifulSoup
import re

print("=== NASA APOD ANALYSIS: EXTRACTING CITY IDENTIFICATION FROM SAVED CONTENT ===\n")
print("Objective: Parse the downloaded APOD entries to identify which city's lights are shown on horizon\n")

# First, let's inspect the workspace directory structure
print("=== INSPECTING WORKSPACE DIRECTORY ===\n")

workspace_dirs = [d for d in os.listdir('.') if d.startswith('workspace')]
if not workspace_dirs:
    print("‚ùå No workspace directory found")
    exit()

workspace_dir = workspace_dirs[0]
print(f"Using workspace directory: {workspace_dir}")
print(f"Directory path: {workspace_dir}/\n")

# List all files to understand what we have
workspace_files = os.listdir(workspace_dir)
print(f"Total files in workspace: {len(workspace_files)}")

# Categorize files by type
json_files = [f for f in workspace_files if f.endswith('.json')]
html_files = [f for f in workspace_files if f.endswith('.html')]
direct_apod_files = [f for f in workspace_files if f.startswith('nasa_apod_august_') and f.endswith('2015.html')]

print(f"\nFile breakdown:")
print(f"- JSON summary files: {len(json_files)}")
print(f"- HTML content files: {len(html_files)}")
print(f"- Direct APOD daily files: {len(direct_apod_files)}")

print(f"\nDirect APOD daily files (target period Aug 1-7, 2015):")
for file in sorted(direct_apod_files):
    file_size = os.path.getsize(os.path.join(workspace_dir, file))
    print(f"  - {file} ({file_size:,} bytes)")

# First, let's examine the JSON summary to understand our findings
print(f"\n=== ANALYZING SEARCH RESULTS SUMMARY ===\n")

summary_file = None
for file in json_files:
    if 'search_results' in file:
        summary_file = file
        break

if summary_file:
    summary_path = os.path.join(workspace_dir, summary_file)
    print(f"Found summary file: {summary_file}")
    print(f"File size: {os.path.getsize(summary_path):,} bytes")
    
    # Inspect the JSON structure first
    with open(summary_path, 'r') as f:
        summary_data = json.load(f)
    
    print(f"\nJSON structure inspection:")
    for key in summary_data.keys():
        value = summary_data[key]
        if isinstance(value, list):
            print(f"  {key}: List with {len(value)} items")
        elif isinstance(value, dict):
            print(f"  {key}: Dictionary with {len(value)} keys")
        elif isinstance(value, str):
            print(f"  {key}: String (length: {len(value)})")
        else:
            print(f"  {key}: {type(value).__name__} - {value}")
    
    # Focus on the promising APOD pages
    if 'apod_pages_with_city_keywords' in summary_data:
        apod_pages = summary_data['apod_pages_with_city_keywords']
        print(f"\nüéØ PROMISING APOD PAGES FOUND: {len(apod_pages)}")
        
        for i, page in enumerate(apod_pages, 1):
            print(f"\n{i}. {page['date']}:")
            print(f"   Title: {page['title']}")
            print(f"   Keywords found: {page['city_keywords_found']}")
            print(f"   File: {page['filename']}")
            print(f"   URL: {page['url']}")
            if 'content_preview' in page:
                preview = page['content_preview'][:200] + '...' if len(page['content_preview']) > 200 else page['content_preview']
                print(f"   Content preview: {preview}")
else:
    print("‚ö†Ô∏è No search results summary file found")

# Now let's analyze the most promising direct APOD file: August 3, 2015
print(f"\n=== DETAILED ANALYSIS: AUGUST 3, 2015 APOD ===\n")

aug3_file = None
for file in direct_apod_files:
    if 'august_03_2015' in file:
        aug3_file = file
        break

if aug3_file:
    aug3_path = os.path.join(workspace_dir, aug3_file)
    print(f"Analyzing: {aug3_file}")
    print(f"File size: {os.path.getsize(aug3_path):,} bytes")
    
    # Read and parse the HTML content
    with open(aug3_path, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # Extract the title
    title_element = soup.find('title')
    title = title_element.get_text().strip() if title_element else 'No title found'
    print(f"\nTitle: {title}")
    
    # Extract the main content
    # APOD pages typically have the main content in <p> tags or after the image
    text_content = soup.get_text()
    
    print(f"\n=== SEARCHING FOR CITY IDENTIFICATION ===\n")
    
    # Look for specific city mentions in the text
    city_patterns = [
        r'city lights of ([A-Z][a-zA-Z\s,]+)',  # "city lights of CityName"
        r'lights of ([A-Z][a-zA-Z\s,]+)',       # "lights of CityName"
        r'([A-Z][a-zA-Z\s]+),\s*([A-Z][a-zA-Z\s]+),?\s*(USA|Michigan|Canada)',  # "City, State, Country"
        r'horizon[^.]*?([A-Z][a-zA-Z\s]+,\s*[A-Z][a-zA-Z\s]*)',  # "horizon ... City, State"
    ]
    
    found_cities = []
    
    for pattern in city_patterns:
        matches = re.finditer(pattern, text_content, re.IGNORECASE)
        for match in matches:
            city_info = {
                'pattern': pattern,
                'match': match.group(),
                'city_name': match.group(1) if match.groups() else match.group(),
                'context_start': max(0, match.start() - 100),
                'context_end': min(len(text_content), match.end() + 100)
            }
            context = text_content[city_info['context_start']:city_info['context_end']]
            city_info['context'] = context.strip()
            found_cities.append(city_info)
    
    print(f"Found {len(found_cities)} potential city matches:")
    for i, city in enumerate(found_cities, 1):
        print(f"\n{i}. Potential city: {city['city_name']}")
        print(f"   Full match: {city['match']}")
        print(f"   Context: {city['context']}")
    
    # Look specifically for the phrase "city lights" and nearby text
    print(f"\n=== SEARCHING FOR 'CITY LIGHTS' PHRASES ===\n")
    
    city_lights_pattern = r'city lights[^.]*?([A-Z][a-zA-Z\s,]*(?:Michigan|USA|Canada)?[^.]*?)'
    city_lights_matches = re.finditer(city_lights_pattern, text_content, re.IGNORECASE)
    
    for i, match in enumerate(city_lights_matches, 1):
        print(f"Match {i}:")
        print(f"  Full text: {match.group()}")
        context_start = max(0, match.start() - 150)
        context_end = min(len(text_content), match.end() + 150)
        context = text_content[context_start:context_end]
        print(f"  Extended context: {context}")
    
    # Extract key sentences containing relevant keywords
    print(f"\n=== EXTRACTING KEY SENTENCES ===\n")
    
    sentences = re.split(r'[.!?]+', text_content)
    relevant_sentences = []
    
    keywords = ['city', 'lights', 'horizon', 'michigan', 'marquette', 'superior', 'yellow lights']
    
    for sentence in sentences:
        sentence = sentence.strip()
        if len(sentence) > 20 and any(keyword in sentence.lower() for keyword in keywords):
            relevant_sentences.append(sentence)
    
    print(f"Found {len(relevant_sentences)} relevant sentences:")
    for i, sentence in enumerate(relevant_sentences, 1):
        print(f"\n{i}. {sentence}")
    
    # Let's also extract the raw text around the word "horizon"
    print(f"\n=== HORIZON CONTEXT ANALYSIS ===\n")
    
    horizon_matches = re.finditer(r'horizon', text_content, re.IGNORECASE)
    for i, match in enumerate(horizon_matches, 1):
        start = max(0, match.start() - 200)
        end = min(len(text_content), match.end() + 200)
        horizon_context = text_content[start:end]
        print(f"Horizon reference {i}:")
        print(f"  {horizon_context}")
        print()

else:
    print("‚ùå August 3, 2015 APOD file not found")

# Also check the other promising files
print(f"\n=== ANALYZING OTHER CANDIDATE FILES ===\n")

other_candidates = [f for f in direct_apod_files if f != aug3_file]

for candidate_file in other_candidates:
    candidate_path = os.path.join(workspace_dir, candidate_file)
    print(f"\nAnalyzing: {candidate_file}")
    
    with open(candidate_path, 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    soup = BeautifulSoup(html_content, 'html.parser')
    title_element = soup.find('title')
    title = title_element.get_text().strip() if title_element else 'No title'
    
    text_content = soup.get_text()
    
    print(f"  Title: {title}")
    
    # Quick check for city references
    city_keywords = ['city', 'urban', 'lights', 'metropolitan', 'downtown']
    found_keywords = [kw for kw in city_keywords if kw in text_content.lower()]
    
    if found_keywords:
        print(f"  Keywords found: {found_keywords}")
        
        # Extract sentences with these keywords
        sentences = re.split(r'[.!?]+', text_content)
        relevant_sentences = [s.strip() for s in sentences if any(kw in s.lower() for kw in found_keywords) and len(s.strip()) > 20]
        
        if relevant_sentences:
            print(f"  Relevant content:")
            for sentence in relevant_sentences[:2]:  # Show first 2 relevant sentences
                print(f"    - {sentence}")
    else:
        print(f"  No city-related keywords found")

# Create a detailed analysis summary
analysis_summary = {
    'analysis_date': '2024-12-19',
    'target_period': 'August 1-7, 2015',
    'objective': 'Identify city lights shown on horizon in NASA APOD entries',
    'workspace_directory': workspace_dir,
    'total_files_analyzed': len(workspace_files),
    'direct_apod_files_count': len(direct_apod_files),
    'key_findings': {
        'primary_candidate': {
            'date': 'August 3, 2015',
            'title': title if 'title' in locals() else 'A Proton Arc Over Lake Superior',
            'file': aug3_file if aug3_file else None,
            'city_matches_found': len(found_cities) if 'found_cities' in locals() else 0,
            'relevant_sentences_count': len(relevant_sentences) if 'relevant_sentences' in locals() else 0
        },
        'other_candidates': {
            'august_6_2015': 'Stereo Pluto',
            'august_7_2015': 'Full Moon, Full Earth'
        }
    },
    'search_methodology': [
        'Multi-pattern regex search for city names',
        'Context analysis around "city lights" phrases',
        'Sentence extraction with relevant keywords',
        'Horizon context analysis'
    ]
}

# Save the analysis summary
analysis_file = os.path.join(workspace_dir, 'nasa_apod_city_analysis.json')
with open(analysis_file, 'w') as f:
    json.dump(analysis_summary, f, indent=2)

print(f"\n=== ANALYSIS COMPLETE ===\n")
print(f"Analysis summary saved to: {analysis_file}")
print(f"\nKey findings:")
if 'found_cities' in locals() and found_cities:
    print(f"‚úì Found {len(found_cities)} potential city references in August 3, 2015 APOD")
    for city in found_cities:
        print(f"  - {city['city_name']}")
else:
    print(f"‚ö†Ô∏è Need to examine the HTML content more carefully")

print(f"\nBased on search results, the August 3, 2015 APOD appears to be the primary candidate")
print(f"showing city lights on the horizon. Further content parsing will reveal the specific city.")

# Save a summary of our findings to a text file for easy review
summary_text = f"""NASA APOD CITY LIGHTS SEARCH - ANALYSIS SUMMARY
==============================================

Search Period: August 1-7, 2015
Objective: Identify city lights shown on horizon

KEY FINDINGS:

Primary Candidate: August 3, 2015
- Title: A Proton Arc Over Lake Superior
- File: {aug3_file if aug3_file else 'Not found'}
- Status: Contains "city lights" and "horizon" keywords
- From search results: "In the featured image, the yellow lights on the horizon are the city lights of Marquette, Michigan, USA."

Other Candidates:
- August 6, 2015: Stereo Pluto (horizon keywords)
- August 7, 2015: Full Moon, Full Earth (illuminated keywords)

CONCLUSION:
The search has successfully identified that the August 3, 2015 NASA APOD 
"A Proton Arc Over Lake Superior" shows city lights on the horizon, 
specifically the city lights of Marquette, Michigan, USA.

Files analyzed: {len(workspace_files)}
Workspace: {workspace_dir}
"""

summary_text_file = os.path.join(workspace_dir, 'nasa_apod_search_summary.txt')
with open(summary_text_file, 'w') as f:
    f.write(summary_text)

print(f"\nDetailed summary saved to: {summary_text_file}")
print(f"\nüéØ FINAL ANSWER: Based on the comprehensive search and analysis,")
print(f"the city shown in the NASA APOD from the first week of August 2015")
print(f"is MARQUETTE, MICHIGAN, USA (August 3, 2015 - 'A Proton Arc Over Lake Superior')")
```