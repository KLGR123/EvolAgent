### Development Step 3: Search Emily Midkiff’s June 2014 Dragon Depiction Article in Fafnir Journal

**Description**: Search for information about Emily Midkiff's June 2014 article, focusing on identifying the journal named after one of Hreidmar's sons from Norse mythology. Research Hreidmar's sons (Fafnir, Regin, and Otr) to determine which one has a journal named after them, then locate Midkiff's specific article from June 2014 that discusses dragon depictions and contains quotes from two different authors expressing distaste.

**Use Cases**:
- Academic historian automating workspace inspection of downloaded HTML and JSON files to locate Emily Midkiff’s June 2014 article in the Fafnir journal for a dragon iconography dissertation
- University librarian auditing digital collections to identify and retrieve missing June 2014 issues of the mythologically named “Fafnir Journal,” updating the library management system
- Digital humanities research team extracting distaste-filled author quotations on dragon depictions from Emily Midkiff’s June 2014 paper using Python and BeautifulSoup for a folklore database
- Game development studio scraping and analyzing academic journal content on Norse mythology to inform realistic dragon design, automating extraction of relevant passages from the Fafnir journal
- Academic publisher quality control specialist validating JSON metadata against HTML search results to ensure June 2014 articles are correctly indexed in digital archives of mythologically themed journals
- Graduate student in medieval studies performing text mining on archived web pages to cross-reference Hreidmar’s sons’ journals and compile a literature review on dragon portrayals
- Museum exhibition curator automating the identification of scholarly articles in the Fafnir journal that critique dragon art to curate a thematic display on Norse mythological creatures
- Legal IP compliance team scanning downloaded HTML and JSON records to identify journals named after mythological figures and verify no trademark conflicts with a new “Fafnir” product line

```
import os
import json

print('=== INSPECTING WORKSPACE FOR PREVIOUS SEARCH RESULTS ===')
print('Objective: Review saved search data and fix technical issues to find Emily Midkiff article')
print('Target: Journal named after Hreidmar\'s son (Fafnir, Regin, or Otr) containing June 2014 article\n')

# Check workspace contents
workspace = 'workspace'
if not os.path.exists(workspace):
    print('No workspace directory found, creating...')
    os.makedirs(workspace)
else:
    print('=== WORKSPACE CONTENTS ===')
    files = os.listdir(workspace)
    print(f'Total files: {len(files)}')
    
    # Categorize files
    html_files = [f for f in files if f.endswith('.html')]
    json_files = [f for f in files if f.endswith('.json')]
    other_files = [f for f in files if not f.endswith('.html') and not f.endswith('.json')]
    
    print(f'HTML files: {len(html_files)}')
    for html_file in html_files:
        file_path = os.path.join(workspace, html_file)
        file_size = os.path.getsize(file_path)
        print(f'  - {html_file} ({file_size:,} bytes)')
    
    print(f'JSON files: {len(json_files)}')
    for json_file in json_files:
        file_path = os.path.join(workspace, json_file)
        file_size = os.path.getsize(file_path)
        print(f'  - {json_file} ({file_size:,} bytes)')
    
    if other_files:
        print(f'Other files: {len(other_files)}')
        for other_file in other_files:
            print(f'  - {other_file}')

# Inspect JSON files first to understand structure
if json_files:
    print('\n=== INSPECTING JSON FILES ===')
    for json_file in json_files:
        print(f'\n--- {json_file} ---')
        file_path = os.path.join(workspace, json_file)
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print('File structure:')
            if isinstance(data, dict):
                for key, value in data.items():
                    print(f'  {key}: {type(value).__name__}')
                    if isinstance(value, dict):
                        print(f'    Keys: {list(value.keys())[:5]}...' if len(value.keys()) > 5 else f'    Keys: {list(value.keys())}')
                    elif isinstance(value, list):
                        print(f'    Length: {len(value)}')
                        if value and isinstance(value[0], dict):
                            print(f'    Sample keys: {list(value[0].keys())}')
                    elif isinstance(value, str):
                        print(f'    Value: {value[:100]}...' if len(value) > 100 else f'    Value: {value}')
            else:
                print(f'  Root type: {type(data).__name__}')
        except Exception as e:
            print(f'  Error reading {json_file}: {str(e)}')

# Now inspect HTML files to see what search results we have
if html_files:
    print('\n=== ANALYZING HTML SEARCH RESULTS ===')
    
    # Import BeautifulSoup properly this time
    try:
        from bs4 import BeautifulSoup
        print('✓ BeautifulSoup imported successfully')
    except ImportError:
        print('✗ BeautifulSoup not available, will do text analysis instead')
        BeautifulSoup = None
    
    for html_file in html_files:
        print(f'\n--- {html_file} ---')
        file_path = os.path.join(workspace, html_file)
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            print(f'File size: {len(content):,} characters')
            
            # Determine what this search was for based on filename
            search_type = 'unknown'
            if 'fafnir' in html_file.lower():
                search_type = 'Fafnir journal search'
            elif 'midkiff' in html_file.lower():
                search_type = 'Emily Midkiff search'
            elif 'combined' in html_file.lower():
                search_type = 'Combined search'
            
            print(f'Search type: {search_type}')
            
            # Text analysis for key terms
            content_lower = content.lower()
            key_terms = {
                'fafnir': content_lower.count('fafnir'),
                'regin': content_lower.count('regin'),
                'otr': content_lower.count('otr'),
                'midkiff': content_lower.count('midkiff'),
                'emily': content_lower.count('emily'),
                'journal': content_lower.count('journal'),
                'dragon': content_lower.count('dragon'),
                '2014': content_lower.count('2014'),
                'june': content_lower.count('june')
            }
            
            print('Key term occurrences:')
            for term, count in key_terms.items():
                if count > 0:
                    print(f'  {term}: {count}')
            
            # Look for promising patterns
            promising_patterns = [
                'fafnir journal',
                'regin journal', 
                'emily midkiff',
                'midkiff 2014',
                'dragon depictions',
                'distaste',
                'norse mythology'
            ]
            
            found_patterns = []
            for pattern in promising_patterns:
                if pattern in content_lower:
                    found_patterns.append(pattern)
            
            if found_patterns:
                print(f'Promising patterns found: {found_patterns}')
            
            # If BeautifulSoup is available, do proper HTML parsing
            if BeautifulSoup:
                soup = BeautifulSoup(content, 'html.parser')
                
                # Look for result links
                links = soup.find_all('a', href=True)
                relevant_links = []
                
                for link in links:
                    href = link.get('href', '')
                    text = link.get_text().strip()
                    
                    if text and len(text) > 10:
                        # Score relevance
                        relevance_score = 0
                        text_lower = text.lower()
                        href_lower = href.lower()
                        
                        # Check for key terms
                        for term in ['fafnir', 'regin', 'midkiff', 'dragon', 'journal', '2014']:
                            if term in text_lower:
                                relevance_score += 2
                            if term in href_lower:
                                relevance_score += 1
                        
                        # Bonus for academic domains
                        academic_indicators = ['.edu', 'academia', 'jstor', 'muse', 'oxford', 'cambridge', 'taylor', 'sage']
                        if any(indicator in href_lower for indicator in academic_indicators):
                            relevance_score += 3
                        
                        if relevance_score >= 2:
                            relevant_links.append({
                                'text': text[:150],
                                'href': href,
                                'score': relevance_score
                            })
                
                # Sort by relevance
                relevant_links.sort(key=lambda x: x['score'], reverse=True)
                
                if relevant_links:
                    print(f'Found {len(relevant_links)} relevant links:')
                    for i, link in enumerate(relevant_links[:5], 1):
                        print(f'  {i}. Score {link["score"]}: {link["text"]}...')
                        print(f'     URL: {link["href"][:100]}...')
                else:
                    print('No highly relevant links found in this search result')
            
            # Extract text snippets around key terms for context
            if 'fafnir' in content_lower and 'journal' in content_lower:
                print('\n*** POTENTIAL FAFNIR JOURNAL REFERENCE ***')
                fafnir_index = content_lower.find('fafnir')
                if fafnir_index != -1:
                    start = max(0, fafnir_index - 200)
                    end = min(len(content), fafnir_index + 300)
                    context = content[start:end]
                    print(f'Context: ...{context}...')
            
            if 'midkiff' in content_lower:
                print('\n*** EMILY MIDKIFF REFERENCE ***')
                midkiff_index = content_lower.find('midkiff')
                if midkiff_index != -1:
                    start = max(0, midkiff_index - 200)
                    end = min(len(content), midkiff_index + 300)
                    context = content[start:end]
                    print(f'Context: ...{context}...')
                    
        except Exception as e:
            print(f'Error analyzing {html_file}: {str(e)}')

print('\n=== HREIDMAR\'S SONS RESEARCH SUMMARY ===')
print('Norse mythology: Hreidmar had three sons:')
print('1. Fafnir - Transformed into a dragon, most famous in Norse mythology')
print('2. Regin - Dwarf smith, foster father of Sigurd')
print('3. Otr - Could transform into an otter, killed by Loki')
print('\nObjective: Find which son has an academic journal named after them')
print('Target: Emily Midkiff\'s June 2014 article in that journal about dragon depictions')
print('\n=== WORKSPACE INSPECTION COMPLETE ===')
```