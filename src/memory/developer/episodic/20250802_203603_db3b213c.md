### Development Step 34: 2011 Bulgarian Census Tertiary Education Completion by Gender (NSI Data)

**Description**: Search for the official 2011 Bulgarian census data from the Bulgarian National Statistical Institute (NSI) or other authoritative government sources that specifically contain the tertiary education completion numbers by gender. Focus on finding the exact counts or percentages of men and women who completed tertiary education according to the 2011 census results.

**Use Cases**:
- Ministry of Education policy planning for regional scholarship allocation based on 2011 tertiary completion rates by gender
- NGO analysis of STEM gender gaps using census data to design grant programs that support women in Bulgarian technology sectors
- Corporate HR benchmarking of university-educated talent pools by comparing workforce needs against regional tertiary graduation counts by gender
- Academic research modeling the impact of female vs. male higher‐education attainment on Bulgaria’s post‐communist labor market trends
- Data journalism project creating interactive maps of urban and rural tertiary graduation rates by gender for a national news outlet
- Educational consultancy automating extraction of census education tables to advise private universities on program demand among male and female students
- International development agency evaluating the long‐term effects of gender‐focused educational initiatives using 2011 census data as a baseline
- Government statistical office automating yearly reports by integrating 2011 tertiary education by gender indicators into their national yearbook

```
import os
import json
from bs4 import BeautifulSoup
import re
import requests
import time

workspace_dir = 'workspace'

print("=== ANALYZING DOWNLOADED NSI CONTENT FOR CENSUS DATA NAVIGATION ===\n")
print("Objective: Find links to actual 2011 census tables with tertiary education by gender\n")

# First, let's examine the structure of the downloaded NSI files
nsi_files = [
    'www_nsi_bg_en_content_6704_population-census-2011.html',
    'www_nsi_bg_en_content_6710_population-education.html', 
    'www_nsi_bg_en.html'
]

print("=== PHASE 1: EXAMINING NSI FILE STRUCTURES ===\n")

for filename in nsi_files:
    filepath = os.path.join(workspace_dir, filename)
    if os.path.exists(filepath):
        print(f"--- Analyzing: {filename} ---")
        
        with open(filepath, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        print(f"File size: {len(html_content):,} characters")
        
        # Parse with BeautifulSoup
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Get page title
        title = soup.find('title')
        if title:
            print(f"Page title: {title.get_text().strip()}")
        
        # Look for navigation menu or content sections
        nav_elements = soup.find_all(['nav', 'menu', 'ul', 'div'], class_=re.compile(r'(menu|nav|content|main)', re.I))
        print(f"Navigation elements found: {len(nav_elements)}")
        
        # Look for links that might lead to census data
        all_links = soup.find_all('a', href=True)
        print(f"Total links found: {len(all_links)}")
        
        # Filter for census/education related links
        relevant_links = []
        for link in all_links:
            href = link.get('href', '')
            text = link.get_text().strip().lower()
            
            # Look for census, education, or statistical data related links
            if any(term in href.lower() or term in text for term in [
                'census', '2011', 'education', 'population', 'statistics', 
                'demographic', 'data', 'table', 'result', 'publication'
            ]):
                relevant_links.append({
                    'text': link.get_text().strip(),
                    'href': href,
                    'full_url': href if href.startswith('http') else f"https://www.nsi.bg{href}" if href.startswith('/') else f"https://www.nsi.bg/en/{href}"
                })
        
        print(f"Relevant links found: {len(relevant_links)}")
        
        if relevant_links:
            print("\nTop relevant links:")
            for i, link in enumerate(relevant_links[:10], 1):
                print(f"  {i}. Text: '{link['text']}'")
                print(f"     URL: {link['full_url']}")
        
        # Look for specific content about census or education
        text_content = soup.get_text()
        
        # Search for specific phrases that might indicate census data availability
        census_phrases = [
            'population census 2011',
            'census results',
            'educational attainment',
            'tertiary education',
            'higher education',
            'education level',
            'by gender',
            'male female',
            'statistical data',
            'census tables'
        ]
        
        found_phrases = []
        for phrase in census_phrases:
            if phrase in text_content.lower():
                # Get context around the phrase
                pattern = re.compile(f'.{{0,100}}{re.escape(phrase)}.{{0,100}}', re.IGNORECASE | re.DOTALL)
                matches = pattern.findall(text_content)
                if matches:
                    found_phrases.append((phrase, matches[0].strip()))
        
        if found_phrases:
            print(f"\nRelevant content phrases found:")
            for phrase, context in found_phrases[:5]:
                print(f"  - '{phrase}': {context[:150]}...")
        
        print("\n" + "="*60 + "\n")
    else:
        print(f"File not found: {filename}\n")

print("=== PHASE 2: ATTEMPTING TO ACCESS CENSUS DATA LINKS ===\n")

# Based on the analysis, try to access more specific census data URLs
# These are common patterns for NSI census data
specific_census_urls = [
    'https://www.nsi.bg/en/content/population-census-2011-final-results',
    'https://www.nsi.bg/en/content/population-census-2011-tables',
    'https://www.nsi.bg/en/content/education-census-2011',
    'https://www.nsi.bg/en/content/demographic-and-social-characteristics',
    'https://www.nsi.bg/sites/default/files/files/publications/Census2011final.pdf',
    'https://www.nsi.bg/sites/default/files/files/data/timeseries/Education_2.1.xls',
    'https://www.nsi.bg/sites/default/files/files/data/timeseries/Education_2.2.xls'
]

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

successful_census_sources = []

for i, url in enumerate(specific_census_urls, 1):
    print(f"{i}. Trying: {url}")
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        print(f"   Status: {response.status_code}")
        
        if response.status_code == 200:
            print(f"   ✓ Success! Content length: {len(response.content):,} bytes")
            
            # Save the content
            filename = f"nsi_census_specific_{i}." + ('pdf' if '.pdf' in url else 'xls' if '.xls' in url else 'html')
            filepath = os.path.join(workspace_dir, filename)
            
            if '.pdf' in url or '.xls' in url:
                # Save binary files
                with open(filepath, 'wb') as f:
                    f.write(response.content)
                print(f"   Binary file saved: {filename}")
            else:
                # Save HTML files
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(response.text)
                print(f"   HTML file saved: {filename}")
                
                # Quick analysis for HTML content
                soup = BeautifulSoup(response.content, 'html.parser')
                tables = soup.find_all('table')
                if tables:
                    print(f"   Tables found: {len(tables)}")
                
                # Check for education/gender content
                content_text = soup.get_text().lower()
                education_indicators = {
                    'tertiary': content_text.count('tertiary'),
                    'education': content_text.count('education'),
                    'gender': content_text.count('gender'),
                    'male': content_text.count('male'),
                    'female': content_text.count('female')
                }
                
                relevant_indicators = {k: v for k, v in education_indicators.items() if v > 0}
                if relevant_indicators:
                    print(f"   Education indicators: {relevant_indicators}")
            
            successful_census_sources.append({
                'url': url,
                'filename': filename,
                'content_type': 'pdf' if '.pdf' in url else 'excel' if '.xls' in url else 'html',
                'size': len(response.content)
            })
            
        else:
            print(f"   ✗ Failed - Status: {response.status_code}")
            
    except Exception as e:
        print(f"   ✗ Error: {str(e)}")
    
    time.sleep(1)

print(f"\n=== PHASE 2 RESULTS ===\n")
print(f"Successfully accessed: {len(successful_census_sources)} census-specific sources")

if successful_census_sources:
    print("\nSuccessful downloads:")
    for source in successful_census_sources:
        print(f"  - {source['filename']} ({source['content_type']}, {source['size']:,} bytes)")
        print(f"    URL: {source['url']}")
else:
    print("No specific census data sources were successfully accessed.")

print(f"\n=== PHASE 3: ALTERNATIVE SEARCH STRATEGY ===\n")

# If direct access fails, try searching for Bulgarian government statistical publications
print("Searching for alternative official sources...")

alternative_sources = [
    'https://www.nsi.bg/en/content/publications',
    'https://www.nsi.bg/en/content/statistical-yearbook',
    'https://www.nsi.bg/en/content/demography-social-statistics-and-income',
    'https://infostat.nsi.bg/infostat/pages/reports/query.jsf?x_2=3'
]

for url in alternative_sources:
    print(f"\nTrying alternative source: {url}")
    try:
        response = requests.get(url, headers=headers, timeout=15)
        if response.status_code == 200:
            print(f"✓ Accessible - {len(response.content):,} bytes")
            
            # Save for analysis
            filename = url.split('/')[-1] + '_alternative.html'
            if not filename.startswith('http'):
                filepath = os.path.join(workspace_dir, filename)
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(response.text)
                print(f"  Saved as: {filename}")
        else:
            print(f"✗ Status: {response.status_code}")
    except Exception as e:
        print(f"✗ Error: {str(e)}")
    
    time.sleep(1)

# Save comprehensive analysis results
analysis_results = {
    'objective': '2011 Bulgarian Census - Tertiary Education by Gender',
    'analysis_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'nsi_files_analyzed': len(nsi_files),
    'specific_census_urls_tried': len(specific_census_urls),
    'successful_census_sources': len(successful_census_sources),
    'census_sources_details': successful_census_sources,
    'recommendation': 'Analyze downloaded census files for tertiary education data tables',
    'next_steps': [
        'Parse any successfully downloaded PDF/Excel census files',
        'Look for education attainment tables in HTML sources',
        'Search for gender-disaggregated education statistics',
        'Check alternative statistical publications'
    ]
}

results_file = os.path.join(workspace_dir, 'nsi_census_comprehensive_analysis.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(analysis_results, f, indent=2, ensure_ascii=False)

print(f"\n=== ANALYSIS COMPLETE ===\n")
print(f"Comprehensive analysis saved to: {results_file}")
print(f"\nFiles in workspace: {len(os.listdir(workspace_dir))}")
print(f"\nNext step: Parse any successfully downloaded census files for tertiary education data by gender")
```