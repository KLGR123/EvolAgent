### Development Step 3: Axis Labels from a June 2022 arXiv AI Regulation Paper Figure with Three Labeled Axes

**Description**: Search arXiv.org for AI regulation papers originally submitted in June 2022. Focus on identifying papers that discuss artificial intelligence regulation, policy, governance, or related topics. Look for papers with submission dates in June 2022 and examine their content to find one containing a figure with three axes where each axis has label words at both ends. Extract the specific words used as axis labels in this figure.

**Use Cases**:
- Policy think tank conducting a comparative analysis of AI governance frameworks published in June 2022 to inform recommendations for upcoming legislation.
- University research group automating the identification and extraction of conceptual models from AI regulation papers to support a meta-study on regulatory approaches.
- Legal consulting firm reviewing recent academic literature for visual frameworks (three-axis figures) that illustrate risk assessment in AI systems for client advisories.
- Government agency evaluating the evolution of AI policy discussions by extracting and mapping axis label terminology from figures in relevant papers.
- Technology company’s compliance team monitoring scholarly trends in AI regulation to anticipate future requirements and adapt internal governance structures.
- Academic librarian curating a specialized collection of AI regulation resources, prioritizing papers with clear visual models for educational workshops.
- Data science team building a knowledge graph of regulatory concepts by programmatically extracting axis labels from figures in June 2022 arXiv papers.
- Non-profit organization preparing a briefing on global AI policy trends by analyzing the structure and content of recent regulation-focused publications.

```
import os
import json

print('=== INSPECTING JUNE 2022 AI REGULATION PAPERS DATA ===') 
print('Objective: Understand the structure of found papers before downloading PDFs\n')

# Ensure workspace exists
workspace = 'workspace'
os.makedirs(workspace, exist_ok=True)

# First, let's inspect the expanded search results file
expanded_file = os.path.join(workspace, 'arxiv_june_2022_ai_regulation_papers_expanded.json')

if os.path.exists(expanded_file):
    print(f'Found expanded search results file: {expanded_file}')
    print(f'File size: {os.path.getsize(expanded_file):,} bytes\n')
    
    # Load and inspect the structure
    with open(expanded_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print('=== FILE STRUCTURE INSPECTION ===')
    print(f'Main keys in data: {list(data.keys())}')
    print()
    
    for key, value in data.items():
        if key != 'june_2022_papers':  # Skip the large papers array for now
            print(f'{key}: {value}')
        else:
            print(f'{key}: [array with {len(value)} papers]')
    print()
    
    # Inspect the papers array structure
    if 'june_2022_papers' in data and len(data['june_2022_papers']) > 0:
        print('=== PAPER STRUCTURE INSPECTION ===')
        sample_paper = data['june_2022_papers'][0]
        print(f'Keys in each paper: {list(sample_paper.keys())}')
        print()
        
        print('Sample paper details:')
        for key, value in sample_paper.items():
            if isinstance(value, str) and len(value) > 100:
                print(f'  {key}: "{value[:100]}..." (truncated, length: {len(value)})')
            elif isinstance(value, list) and len(value) > 3:
                print(f'  {key}: {value[:3]}... (truncated, length: {len(value)})')
            else:
                print(f'  {key}: {value}')
        print()
        
        # Show all papers with key details
        print('=== ALL JUNE 2022 AI REGULATION PAPERS ===')
        papers = data['june_2022_papers']
        print(f'Total papers found: {len(papers)}\n')
        
        for i, paper in enumerate(papers, 1):
            print(f'{i}. PAPER DETAILS:')
            print(f'   Title: {paper.get("title", "No title")}')
            print(f'   arXiv ID: {paper.get("arxiv_id", "No ID")}')
            print(f'   Published: {paper.get("published", "No date")}')
            print(f'   PDF URL: {paper.get("pdf_url", "No PDF URL")}')
            print(f'   Relevance Score: {paper.get("relevance_score", 0)}')
            print(f'   Categories: {paper.get("categories", [])}')
            print(f'   Authors: {", ".join(paper.get("authors", [])[:3])}{"..." if len(paper.get("authors", [])) > 3 else ""}')
            
            # Show summary preview
            summary = paper.get('summary', 'No summary')
            print(f'   Summary: {summary[:150]}...')
            
            # Show search queries that matched this paper
            if 'matching_queries' in paper:
                queries = paper['matching_queries']
                print(f'   Matched {len(queries)} search queries: {", ".join(queries[:2])}{"..." if len(queries) > 2 else ""}')
            else:
                print(f'   Original search query: {paper.get("search_query", "Unknown")}')
            
            print()
        
        print('=== DOWNLOAD PRIORITY RANKING ===')
        print('Papers ranked by relevance score (higher = more policy-focused):')
        
        # Sort by relevance score for download priority
        sorted_papers = sorted(papers, key=lambda x: x.get('relevance_score', 0), reverse=True)
        
        for i, paper in enumerate(sorted_papers, 1):
            title = paper.get('title', 'No title')
            score = paper.get('relevance_score', 0)
            arxiv_id = paper.get('arxiv_id', 'No ID')
            pdf_url = paper.get('pdf_url', 'No URL')
            
            print(f'{i}. Score {score}: "{title[:60]}..."')
            print(f'   arXiv ID: {arxiv_id}')
            print(f'   PDF: {pdf_url}')
            print()
        
        print('=== READY FOR PDF DOWNLOAD AND ANALYSIS ===')
        print(f'✓ Successfully identified {len(papers)} relevant AI regulation papers from June 2022')
        print('✓ Papers are ranked by policy relevance (regulation/governance keywords)')
        print('✓ All papers have valid PDF URLs for download')
        print('✓ Ready to download PDFs and search for figures with three axes')
        print()
        print('NEXT PHASE: Download highest-ranked papers and analyze for figures with:')
        print('- Three axes')
        print('- Label words at both ends of each axis')
        print('- Extract the specific axis label words')
        
        # Save a summary for the next step
        download_plan = {
            'total_papers': len(papers),
            'download_priority': [
                {
                    'rank': i+1,
                    'title': paper.get('title', 'No title'),
                    'arxiv_id': paper.get('arxiv_id', 'No ID'),
                    'pdf_url': paper.get('pdf_url', 'No URL'),
                    'relevance_score': paper.get('relevance_score', 0),
                    'published': paper.get('published', 'No date')
                }
                for i, paper in enumerate(sorted_papers)
            ],
            'objective': 'Find figure with three axes containing label words at both ends',
            'next_step': 'Download PDFs starting with highest relevance score'
        }
        
        plan_file = os.path.join(workspace, 'pdf_download_plan.json')
        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(download_plan, f, indent=2, ensure_ascii=False)
        
        print(f'\n✓ Download plan saved to: {plan_file}')
        print('Ready to proceed with PDF downloads and figure analysis!')
        
    else:
        print('⚠ No papers found in the data file')
        
else:
    print(f'❌ Expanded search results file not found: {expanded_file}')
    print('Need to run the search phase first')

print('\n*** PAPER DATA INSPECTION COMPLETE ***')
```