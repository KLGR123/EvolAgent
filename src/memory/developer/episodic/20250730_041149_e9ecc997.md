### Development Step 2: Compile ASEAN Member Countries’ Capitals and Geographic Coordinates from Wikipedia

**Description**: Search for comprehensive information about ASEAN member countries and their capital cities on Wikipedia. Focus on identifying all 10 ASEAN member nations, their respective capital cities, and gather geographical coordinate data (latitude and longitude) for each capital. Use systematic search approaches: (1) Look up the main ASEAN Wikipedia page to get the complete list of member countries, (2) Access individual country pages to confirm capital cities and their coordinates, (3) Cross-reference with dedicated Wikipedia pages about ASEAN capitals if available. Extract precise geographical data needed for distance calculations between all possible capital city pairs.

**Use Cases**:
- Real-time logistics route optimization and distance computation for regional freight operators shipping goods between ASEAN capitals
- Automated multi-city tour itinerary planning and travel time estimation for travel agencies offering ASEAN circuit packages
- Trade logistics network analysis for import/export businesses assessing market proximity and shipping viability among ASEAN capitals
- Emergency response coordination and rapid resource deployment planning for disaster management agencies within the ASEAN region
- Academic geospatial research and spatial network modeling for analyzing connectivity among ASEAN capital cities
- Intra-regional airline scheduling and air-route optimization for carriers minimizing fuel costs on ASEAN capital-to-capital flights
- Geo-targeted marketing campaign planning and budget allocation for consumer brands focusing on cities in ASEAN capitals
- Government infrastructure development planning and policy analysis visualizing transportation corridors among ASEAN capitals

```
import os
import json
from bs4 import BeautifulSoup
import re
import time

print("=== ASEAN MEMBER COUNTRIES RESEARCH - STEP 2 ===\n")
print("Objective: Extract official capital cities with coordinates from correct tables")
print("Focus: Target Member States table instead of metropolitan areas table\n")

# First, let's inspect the saved HTML file to understand the table structure
html_file = 'workspace/asean_main_page.html'

if not os.path.exists(html_file):
    print(f"❌ HTML file not found: {html_file}")
    # Check what files exist in workspace
    if os.path.exists('workspace'):
        files = os.listdir('workspace')
        print(f"Available files in workspace: {files}")
        # Look for any HTML file
        html_files = [f for f in files if f.endswith('.html')]
        if html_files:
            html_file = f'workspace/{html_files[0]}'
            print(f"Using: {html_file}")
        else:
            print("No HTML files found in workspace")
            exit()
    else:
        print("No workspace directory found")
        exit()

print(f"Loading ASEAN Wikipedia page from: {html_file}")

# Load and parse the saved HTML content
with open(html_file, 'r', encoding='utf-8') as f:
    html_content = f.read()

soup = BeautifulSoup(html_content, 'html.parser')

print(f"HTML content loaded: {len(html_content):,} characters")

# Let's examine the early tables (0-5) which are more likely to contain member states info
print("\n=== ANALYZING EARLY TABLES FOR MEMBER STATES ===\n")

tables = soup.find_all('table')
print(f"Total tables found: {len(tables)}")

# Focus on the first 10 tables as they're most likely to contain basic member info
for table_idx in range(min(10, len(tables))):
    table = tables[table_idx]
    
    print(f"\n--- TABLE {table_idx} ANALYSIS ---")
    
    # Get table caption or nearby headings
    caption = table.find('caption')
    caption_text = caption.get_text().strip() if caption else "No caption"
    
    # Check for nearby headings
    prev_elements = []
    current = table
    for _ in range(3):  # Check 3 elements before the table
        current = current.find_previous_sibling()
        if current and current.name in ['h1', 'h2', 'h3', 'h4', 'p']:
            prev_elements.append(current.get_text().strip())
    
    print(f"Caption: {caption_text}")
    print(f"Previous headings: {prev_elements[:2]}")
    
    # Extract first few rows to understand structure
    rows = table.find_all('tr')
    print(f"Rows: {len(rows)}")
    
    if len(rows) >= 2:
        # Check header row
        header_row = rows[0]
        header_cells = header_row.find_all(['th', 'td'])
        headers = [cell.get_text().strip() for cell in header_cells]
        print(f"Headers: {headers}")
        
        # Check first data row
        if len(rows) > 1:
            data_row = rows[1]
            data_cells = data_row.find_all(['th', 'td'])
            data = [cell.get_text().strip() for cell in data_cells]
            print(f"First data row: {data}")
        
        # Look for member states characteristics
        table_text = table.get_text().lower()
        
        # Check if this looks like a member states table
        member_indicators = {
            'has_country_column': any('country' in h.lower() or 'state' in h.lower() or 'nation' in h.lower() for h in headers),
            'has_capital_column': any('capital' in h.lower() for h in headers),
            'has_date_column': any('date' in h.lower() or 'year' in h.lower() or 'join' in h.lower() for h in headers),
            'has_population_area': any('population' in h.lower() or 'area' in h.lower() for h in headers),
            'asean_countries_count': len([country for country in ['brunei', 'cambodia', 'indonesia', 'laos', 'malaysia', 'myanmar', 'philippines', 'singapore', 'thailand', 'vietnam'] if country in table_text])
        }
        
        print(f"Member table indicators: {member_indicators}")
        
        # This looks like a member states table if it has country info and joining dates
        is_member_table = (member_indicators['has_country_column'] and 
                          member_indicators['has_date_column'] and 
                          member_indicators['asean_countries_count'] >= 8)
        
        if is_member_table:
            print(f"*** LIKELY MEMBER STATES TABLE ***")
            
            # Extract all member country data
            print(f"\nExtracting member countries data:")
            
            member_countries = []
            
            for row_idx, row in enumerate(rows[1:], 1):  # Skip header row
                cells = row.find_all(['th', 'td'])
                cell_data = [cell.get_text().strip() for cell in cells]
                
                if len(cell_data) < 2:
                    continue
                    
                # Look for country names in the row
                row_text = ' '.join(cell_data).lower()
                
                asean_members = {
                    'brunei': ['brunei', 'brunei darussalam'],
                    'cambodia': ['cambodia', 'kingdom of cambodia'],
                    'indonesia': ['indonesia', 'republic of indonesia'],
                    'laos': ['laos', 'lao', 'lao pdr', "lao people's democratic republic"],
                    'malaysia': ['malaysia'],
                    'myanmar': ['myanmar', 'burma'],
                    'philippines': ['philippines', 'republic of the philippines'],
                    'singapore': ['singapore', 'republic of singapore'],
                    'thailand': ['thailand', 'kingdom of thailand'],
                    'vietnam': ['vietnam', 'viet nam', 'socialist republic of vietnam']
                }
                
                for country_key, variants in asean_members.items():
                    if any(variant in row_text for variant in variants):
                        member_countries.append({
                            'country': country_key.title(),
                            'row_data': cell_data,
                            'row_index': row_idx
                        })
                        print(f"  {country_key.title()}: {cell_data}")
                        break
            
            print(f"\nFound {len(member_countries)} member countries in this table")
            
            # If we found a good member states table, save the data
            if len(member_countries) >= 8:  # Should have at least 8 ASEAN countries
                member_states_data = {
                    'table_index': table_idx,
                    'table_caption': caption_text,
                    'table_headers': headers,
                    'member_countries': member_countries,
                    'extraction_timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
                }
                
                # Save member states data
                with open('workspace/asean_member_states_extracted.json', 'w') as f:
                    json.dump(member_states_data, f, indent=2)
                
                print(f"\n✓ Member states data saved to: workspace/asean_member_states_extracted.json")
                
                # Now we need to identify the capital cities from this data
                print(f"\n=== IDENTIFYING CAPITALS FROM MEMBER STATES DATA ===\n")
                
                # Analyze the table structure to find capital information
                capital_column_index = None
                for i, header in enumerate(headers):
                    if 'capital' in header.lower():
                        capital_column_index = i
                        break
                
                if capital_column_index is not None:
                    print(f"Capital column found at index: {capital_column_index}")
                    
                    # Extract capitals
                    countries_with_capitals = []
                    for country_data in member_countries:
                        row_data = country_data['row_data']
                        if len(row_data) > capital_column_index:
                            capital = row_data[capital_column_index]
                            countries_with_capitals.append({
                                'country': country_data['country'],
                                'capital': capital,
                                'full_row': row_data
                            })
                            print(f"{country_data['country']}: {capital}")
                    
                    # Save countries with capitals
                    capitals_data = {
                        'countries_with_capitals': countries_with_capitals,
                        'source_table': table_idx,
                        'extraction_method': 'Member states table parsing',
                        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
                    }
                    
                    with open('workspace/asean_countries_capitals.json', 'w') as f:
                        json.dump(capitals_data, f, indent=2)
                    
                    print(f"\n✓ Countries and capitals saved to: workspace/asean_countries_capitals.json")
                    print(f"Found capitals for {len(countries_with_capitals)} countries")
                    
                else:
                    print("No capital column found in this table")
                    print("Will need to extract capitals from individual country pages")
                    
                    # Create a list of countries without capitals for next step
                    countries_need_capitals = [{
                        'country': country_data['country'],
                        'capital': 'TO_BE_EXTRACTED',
                        'needs_coordinates': True
                    } for country_data in member_countries]
                    
                    basic_data = {
                        'countries_found': countries_need_capitals,
                        'source_table': table_idx,
                        'next_step': 'Extract capitals and coordinates from individual country pages',
                        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
                    }
                    
                    with open('workspace/asean_countries_need_capitals.json', 'w') as f:
                        json.dump(basic_data, f, indent=2)
                    
                    print(f"\n✓ Countries list saved to: workspace/asean_countries_need_capitals.json")
                
                break  # We found our member states table, no need to check others

# Summary of what we found
print(f"\n=== STEP 2 SUMMARY ===\n")

# Check what files we created
workspace_files = os.listdir('workspace')
json_files = [f for f in workspace_files if f.endswith('.json')]

print(f"Files created in this step:")
for json_file in sorted(json_files):
    if json_file not in ['asean_initial_analysis.json']:  # Exclude the previous step's file
        file_path = f'workspace/{json_file}'
        file_size = os.path.getsize(file_path)
        print(f"  - {json_file} ({file_size} bytes)")

print(f"\nNext step: Extract precise capital coordinates from individual country Wikipedia pages")
```