### Development Step 19: Locate 2011 Bulgarian Census Data on Tertiary Education Completion by Gender

**Description**: Search for the 2011 Bulgarian census data on tertiary education completion by gender. Look for official census results from Bulgaria's National Statistical Institute or other authoritative sources that provide the specific breakdown of men and women who completed tertiary education in 2011.

**Use Cases**:
- Government education policy planning and funding allocation based on gender-specific tertiary completion rates from the 2011 Bulgarian census
- Academic longitudinal study of gender parity in higher education using automated extraction of Bulgarian census data for trend analysis
- NGO gender equity reporting, compiling male vs. female tertiary graduation statistics for annual progress and advocacy reports
- Corporate HR talent mapping in Bulgaria, leveraging regional tertiary education completion by gender to optimize graduate recruitment strategies
- EdTech product development and marketing, tailoring online course offerings to regions with higher female or male university completion rates
- Urban development research correlating city-level tertiary education attainment by gender with economic growth indicators
- Data journalism and interactive visualization of education inequality in Bulgaria, pulling 2011 census figures for compelling news stories
- Business intelligence pipeline integration, feeding extracted tertiary education statistics into governmental and private-sector dashboards for demographic insights

```
import os
import json
from bs4 import BeautifulSoup
import re

print("=== BULGARIAN 2011 CENSUS TERTIARY EDUCATION BY GENDER - FINAL EXTRACTION ===")
print("Strategy: Thorough analysis of existing workspace data\n")

# First, let's understand what we have in the workspace
workspace_path = 'workspace'
if not os.path.exists(workspace_path):
    print("No workspace directory found")
    exit()

all_files = os.listdir(workspace_path)
print(f"Total files in workspace: {len(all_files)}")

# Categorize files by type
html_files = [f for f in all_files if f.endswith('.html')]
json_files = [f for f in all_files if f.endswith('.json')]
pdf_files = [f for f in all_files if f.endswith('.pdf')]
xls_files = [f for f in all_files if f.endswith('.xls')]

print(f"HTML files: {len(html_files)}")
print(f"JSON files: {len(json_files)}")
print(f"PDF files: {len(pdf_files)}")
print(f"Excel files: {len(xls_files)}")

# Let's examine the JSON analysis files first to understand what was already found
print("\n=== EXAMINING EXISTING ANALYSIS FILES ===")
for json_file in json_files:
    if 'analysis' in json_file.lower() or 'results' in json_file.lower():
        print(f"\nInspecting: {json_file}")
        filepath = os.path.join(workspace_path, json_file)
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"  Keys: {list(data.keys())[:10]}")
            
            # Look for detailed findings
            if 'detailed_findings' in data:
                findings = data['detailed_findings']
                print(f"  Detailed findings: {len(findings)} files analyzed")
                
                for finding in findings:
                    print(f"    - {finding.get('filename', 'Unknown')}: {finding.get('relevance_score', 0)} relevance")
                    if finding.get('good_sentences'):
                        print(f"      Sentences: {len(finding['good_sentences'])}")
                    if finding.get('statistical_matches'):
                        print(f"      Statistical matches: {len(finding['statistical_matches'])}")
                    if finding.get('education_tables'):
                        print(f"      Education tables: {len(finding['education_tables'])}")
            
            # Look for specific census data
            if 'tertiary_education_findings' in data:
                findings = data['tertiary_education_findings']
                print(f"  Tertiary education findings: {len(findings)}")
                for finding in findings[:3]:
                    print(f"    Match: {finding.get('match', 'No match')}")
                    print(f"    Context: {finding.get('context', 'No context')[:100]}...")
        
        except Exception as e:
            print(f"  Error reading {json_file}: {str(e)}")

# Now let's focus on the most promising HTML files - Bulgarian NSI and Demographics pages
print("\n=== ANALYZING MOST PROMISING HTML SOURCES ===")

# Identify Bulgarian NSI and census-related files
priority_files = []
for html_file in html_files:
    name_lower = html_file.lower()
    if any(term in name_lower for term in ['nsi', 'census', 'demographics', 'education']):
        filepath = os.path.join(workspace_path, html_file)
        file_size = os.path.getsize(filepath)
        if file_size > 10000:  # Skip very small files
            priority_files.append((html_file, file_size))

# Sort by file size (larger files likely have more content)
priority_files.sort(key=lambda x: x[1], reverse=True)

print(f"Priority files identified: {len(priority_files)}")
for filename, size in priority_files[:5]:
    print(f"  - {filename}: {size:,} bytes")

# Analyze the top priority files for specific tertiary education data
tertiary_education_data = []

for filename, size in priority_files[:3]:  # Analyze top 3
    print(f"\n=== ANALYZING: {filename} ===")
    filepath = os.path.join(workspace_path, filename)
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        page_title = soup.find('title')
        title_text = page_title.get_text().strip() if page_title else 'No title'
        
        print(f"Title: {title_text}")
        print(f"Content length: {len(html_content):,} characters")
        
        # Extract all text for analysis
        all_text = soup.get_text()
        
        # Search for specific patterns related to tertiary education and gender in 2011
        patterns_to_search = [
            # Pattern 1: Direct tertiary education statistics
            r'tertiary education[^.]{0,200}(?:men|women|male|female)[^.]{0,100}(\d+[.,]?\d*\s*%?)',
            # Pattern 2: Gender followed by tertiary education
            r'(?:men|women|male|female)[^.]{0,200}tertiary education[^.]{0,100}(\d+[.,]?\d*\s*%?)',
            # Pattern 3: Higher education statistics
            r'higher education[^.]{0,200}(?:men|women|male|female)[^.]{0,100}(\d+[.,]?\d*\s*%?)',
            # Pattern 4: 2011 census education data
            r'2011[^.]{0,300}(?:tertiary|higher)[^.]{0,200}(?:men|women|male|female)[^.]{0,100}(\d+[.,]?\d*\s*%?)',
            # Pattern 5: University completion by gender
            r'university[^.]{0,200}(?:completed|graduated|attained)[^.]{0,200}(?:men|women|male|female)[^.]{0,100}(\d+[.,]?\d*\s*%?)',
            # Pattern 6: Educational attainment statistics
            r'educational attainment[^.]{0,200}(?:men|women|male|female)[^.]{0,100}(\d+[.,]?\d*\s*%?)'
        ]
        
        matches_found = []
        for i, pattern in enumerate(patterns_to_search, 1):
            matches = list(re.finditer(pattern, all_text, re.IGNORECASE | re.DOTALL))
            print(f"  Pattern {i} matches: {len(matches)}")
            
            for match in matches:
                # Get broader context around the match
                context_start = max(0, match.start() - 400)
                context_end = min(len(all_text), match.end() + 400)
                context = all_text[context_start:context_end]
                
                # Check if context mentions Bulgaria and 2011
                context_lower = context.lower()
                has_bulgaria = 'bulgaria' in context_lower or 'bulgarian' in context_lower
                has_2011 = '2011' in context_lower
                
                if has_bulgaria or has_2011:
                    matches_found.append({
                        'pattern_number': i,
                        'match_text': match.group(),
                        'context': context,
                        'has_bulgaria': has_bulgaria,
                        'has_2011': has_2011,
                        'file': filename
                    })
        
        print(f"  Relevant matches found: {len(matches_found)}")
        
        # Display the most relevant matches
        if matches_found:
            print("  \n  TOP MATCHES:")
            for i, match in enumerate(matches_found[:3], 1):
                print(f"    {i}. Pattern {match['pattern_number']}: {match['match_text']}")
                print(f"       Bulgaria: {match['has_bulgaria']}, 2011: {match['has_2011']}")
                print(f"       Context: {match['context'][:200]}...")
                print()
        
        tertiary_education_data.extend(matches_found)
        
        # Also look for tables with structured data
        tables = soup.find_all('table')
        relevant_tables = []
        
        for table_idx, table in enumerate(tables):
            table_text = table.get_text()
            table_lower = table_text.lower()
            
            # Check if table contains education and gender data
            has_education_terms = any(term in table_lower for term in 
                                    ['education', 'tertiary', 'university', 'degree', 'higher'])
            has_gender_terms = any(term in table_lower for term in 
                                 ['men', 'women', 'male', 'female', 'gender'])
            has_2011_data = '2011' in table_lower
            has_numbers = bool(re.search(r'\d+', table_text))
            
            if has_education_terms and has_gender_terms and has_numbers:
                # Extract table structure
                headers = [th.get_text().strip() for th in table.find_all('th')]
                rows = table.find_all('tr')
                
                # Get sample data rows
                sample_rows = []
                for row in rows[1:4]:  # Skip header, take next 3
                    cells = [cell.get_text().strip() for cell in row.find_all(['td', 'th'])]
                    if cells and any(cell.strip() for cell in cells):
                        sample_rows.append(cells)
                
                relevant_tables.append({
                    'table_index': table_idx,
                    'headers': headers,
                    'sample_rows': sample_rows,
                    'total_rows': len(rows),
                    'has_2011': has_2011_data
                })
        
        if relevant_tables:
            print(f"  \n  RELEVANT TABLES FOUND: {len(relevant_tables)}")
            for i, table in enumerate(relevant_tables[:2], 1):
                print(f"    Table {i}:")
                print(f"      Headers: {table['headers'][:5]}")
                print(f"      Rows: {table['total_rows']}, Has 2011: {table['has_2011']}")
                if table['sample_rows']:
                    print(f"      Sample row: {table['sample_rows'][0][:3]}")
    
    except Exception as e:
        print(f"  Error analyzing {filename}: {str(e)}")

# Compile final results
print(f"\n=== FINAL COMPILATION ===")
print(f"Total tertiary education matches found: {len(tertiary_education_data)}")

# Save comprehensive results
final_results = {
    'objective': 'Bulgarian 2011 census tertiary education completion by gender',
    'analysis_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'files_analyzed': len(priority_files[:3]),
    'total_matches_found': len(tertiary_education_data),
    'detailed_matches': tertiary_education_data,
    'summary': {
        'files_with_matches': len(set(match['file'] for match in tertiary_education_data)),
        'matches_with_bulgaria': len([m for m in tertiary_education_data if m['has_bulgaria']]),
        'matches_with_2011': len([m for m in tertiary_education_data if m['has_2011']])
    }
}

results_file = os.path.join(workspace_path, 'bulgarian_census_tertiary_education_final_extraction.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(final_results, f, indent=2, ensure_ascii=False)

print(f"Results saved to: {results_file}")

# Display key findings
if tertiary_education_data:
    print("\n=== KEY FINDINGS ===")
    
    # Group by relevance (Bulgaria + 2011)
    high_relevance = [m for m in tertiary_education_data if m['has_bulgaria'] and m['has_2011']]
    medium_relevance = [m for m in tertiary_education_data if m['has_bulgaria'] or m['has_2011']]
    
    print(f"High relevance matches (Bulgaria + 2011): {len(high_relevance)}")
    print(f"Medium relevance matches (Bulgaria or 2011): {len(medium_relevance)}")
    
    # Show the best matches
    best_matches = high_relevance if high_relevance else medium_relevance
    
    for i, match in enumerate(best_matches[:5], 1):
        print(f"\n{i}. File: {match['file']}")
        print(f"   Pattern: {match['pattern_number']}")
        print(f"   Match: {match['match_text']}")
        print(f"   Context: {match['context'][:300]}...")
        print(f"   Bulgaria: {match['has_bulgaria']}, 2011: {match['has_2011']}")

else:
    print("\n=== NO SPECIFIC MATCHES FOUND ===")
    print("No specific tertiary education by gender statistics found in the analyzed files.")
    print("The data may be in a different format or require access to the actual statistical tables.")

print("\n=== EXTRACTION COMPLETE ===")
print("Comprehensive analysis of Bulgarian 2011 census tertiary education data completed.")
```