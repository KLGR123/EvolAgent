# Developer Plan 01

## Plan
Search for the official script of Doctor Who Series 9, Episode 11 ('Heaven Sent') to identify the exact location name as it appears in the first scene heading where the Doctor is trapped in the ever-shifting maze. Look for official BBC sources, script databases, or archived production materials that contain the authentic script with original scene headings and location descriptions.

## Description
This is the optimal first step because: (1) We need to locate the official script for Doctor Who Series 9, Episode 11 to find the exact location name as written in the scene headings, (2) No previous research has been conducted yet, (3) Expected outcome is to obtain the authentic script text showing how the maze location is officially designated in the first scene heading, (4) This directly addresses the TASK requirement for the setting name exactly as it appears in the official script's scene heading

## Episodic Examples
### Development Step 3: Find and Transcribe Teal‚Äôc‚Äôs Response to ‚ÄúIsn‚Äôt That Hot?‚Äù in YouTube Video

**Description**: Access and analyze the YouTube video at https://www.youtube.com/watch?v=1htKBjuUWec to locate the specific dialogue where someone asks 'Isn't that hot?' and identify Teal'c's exact response. Extract the audio/video content, transcribe the relevant dialogue section, and document Teal'c's reply to this question.

**Use Cases**:
- Fan-driven Stargate quote archive: automatically download key scenes from YouTube, extract Teal‚Äôc‚Äôs ‚ÄúIsn‚Äôt that hot?‚Äù response, transcribe the dialogue and timestamp for inclusion in a community-maintained quote database
- Linguistic analysis of fictional dialects: pull audio clips of Teal‚Äôc‚Äôs speech from YouTube, transcribe targeted question-and-answer exchanges, and analyze phonetic patterns for a research paper on constructed languages
- Streaming subtitle generation and localization: isolate the ‚ÄúIsn‚Äôt that hot?‚Äù segment, produce a precise transcript of Teal‚Äôc‚Äôs reply, and feed it into a translation workflow to create accurate subtitles in multiple languages
- AI chatbot persona training for Sci-Fi characters: collect authentic Teal‚Äôc responses by downloading and transcribing specific lines, then integrate them into a chatbot to emulate his speech style in interactive fan applications
- Compliance audit for clip licensing: extract and document exact dialogue segments from YouTube videos, log Teal‚Äôc‚Äôs reply verbatim, and attach metadata for legal review when securing broadcast rights
- Podcast episode highlight reel: automate the download, audio extraction, and transcription of fan-favorite Teal‚Äôc lines like his response to ‚ÄúIsn‚Äôt that hot?‚Äù, then assemble them into a curated nostalgia segment
- Quality assurance for automatic captioning services: use the known ‚ÄúIsn‚Äôt that hot?‚Äù exchange to verify the accuracy of speech-to-text algorithms by comparing the system‚Äôs output to the manually extracted transcript
- Educational media analysis in film studies: retrieve and transcribe Teal‚Äôc‚Äôs concise responses from selected YouTube scenes, enabling film students to examine character development through repeated dialogue patterns

```
import os
import yt_dlp
import json
from urllib.parse import urlparse, parse_qs

# The issue is clear: the video was downloaded to a different workspace directory
# Let's re-download the video to the current workspace and then extract audio

url = "https://www.youtube.com/watch?v=1htKBjuUWec"
video_id = "1htKBjuUWec"

print("=== RE-DOWNLOADING TEAL'C VIDEO TO CURRENT WORKSPACE ===")
print(f"Target URL: {url}")
print(f"Video ID: {video_id}")
print("Objective: Download video, extract audio, and find Teal'c's response to 'Isn't that hot?'\n")

# Ensure current workspace directory exists
os.makedirs("workspace", exist_ok=True)
print(f"Workspace directory confirmed: {os.path.abspath('workspace')}")

# Set up download options to get the video in current workspace
output_template = os.path.join("workspace", f"{video_id}_%(title)s.%(ext)s")
print(f"Output template: {output_template}\n")

ydl_opts = {
    'format': 'best[height<=720]',  # Download reasonable quality video
    'outtmpl': output_template,
    'quiet': False,  # Show download progress
    'no_warnings': False,
}

try:
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        # Extract info first
        print("=== EXTRACTING VIDEO INFORMATION ===")
        info = ydl.extract_info(url, download=False)
        
        print(f"Video Title: {info.get('title', 'N/A')}")
        print(f"Duration: {info.get('duration', 'N/A')} seconds")
        print(f"Uploader: {info.get('uploader', 'N/A')}")
        
        # Confirm this is the Teal'c coffee video
        title = info.get('title', '').lower()
        if 'teal' in title and 'coffee' in title:
            print("*** CONFIRMED: This is the Teal'c coffee video ***\n")
        else:
            print(f"*** WARNING: Title doesn't clearly indicate Teal'c coffee content ***\n")
        
        # Now download the video
        print("=== DOWNLOADING VIDEO ===")
        ydl.download([url])
        print("\nVideo download completed!\n")
        
        # Check what files were actually created
        print("=== CHECKING DOWNLOADED FILES ===")
        workspace_files = []
        for file in os.listdir("workspace"):
            full_path = os.path.join("workspace", file)
            if os.path.isfile(full_path):
                file_size = os.path.getsize(full_path)
                workspace_files.append((file, full_path, file_size))
        
        print(f"Files in workspace after download:")
        video_file = None
        for filename, full_path, size in workspace_files:
            size_mb = size / (1024 * 1024)
            print(f"  - {filename} ({size_mb:.2f} MB)")
            
            # Identify the video file
            if any(filename.lower().endswith(ext) for ext in ['.mp4', '.mkv', '.webm', '.avi']):
                video_file = full_path
                print(f"    *** IDENTIFIED AS VIDEO FILE ***")
        
        if video_file:
            print(f"\n=== VIDEO FILE LOCATED ===")
            print(f"Video file path: {video_file}")
            print(f"File size: {os.path.getsize(video_file) / (1024 * 1024):.2f} MB")
            
            # Save video info for reference
            video_info = {
                'url': url,
                'video_id': video_id,
                'title': info.get('title', 'N/A'),
                'duration_seconds': info.get('duration', 0),
                'uploader': info.get('uploader', 'N/A'),
                'video_file_path': video_file,
                'file_size_mb': os.path.getsize(video_file) / (1024 * 1024),
                'objective': "Find Teal'c's response to 'Isn't that hot?'"
            }
            
            with open('workspace/tealc_video_info.json', 'w', encoding='utf-8') as f:
                json.dump(video_info, f, indent=2)
            
            print(f"Video info saved to: workspace/tealc_video_info.json")
            
            print(f"\n=== READY FOR AUDIO EXTRACTION ===")
            print("Video successfully downloaded and located.")
            print("Next step: Extract audio from video for dialogue transcription.")
            
        else:
            print(f"\n*** ERROR: No video file found after download ***")
            print("Available files:")
            for filename, full_path, size in workspace_files:
                print(f"  - {filename} ({size} bytes)")
            
except Exception as e:
    print(f"\n*** ERROR DURING VIDEO DOWNLOAD ***")
    print(f"Error: {str(e)}")
    import traceback
    print(f"Full error details: {traceback.format_exc()}")

print("\n*** VIDEO DOWNLOAD PHASE COMPLETE ***")
```

### Development Step 8: Locate and Transcribe Teal‚Äôc‚Äôs Response to ‚ÄúIsn‚Äôt That Hot?‚Äù in SG-1 YouTube Clip

**Description**: Access and analyze the YouTube video at https://www.youtube.com/watch?v=1htKBjuUWec to locate the specific dialogue where someone asks 'Isn't that hot?' and identify Teal'c's exact response. Extract the audio/video content, transcribe the relevant dialogue section, and document Teal'c's reply to this question.

**Use Cases**:
- Automated quality assurance for call centers by transcribing customer support calls, locating when a customer says ‚Äúcancel my subscription,‚Äù and extracting the agent‚Äôs exact response for compliance review
- Digital archiving of corporate training videos, searching for the phrase ‚Äúsafety hazard‚Äù in noisy plant footage and documenting the instructor‚Äôs follow-up instructions for audit trails
- Film post-production localization workflows that identify and time-stamp a character‚Äôs catchphrase (e.g., ‚Äúbring me the code‚Äù) in raw footage and export the translated dialogue script for subtitling
- E-learning content indexing by detecting when an instructor asks ‚Äúany questions?‚Äù in recorded lectures and automatically generating navigation bookmarks around the ensuing student Q&A segment
- Legal deposition analysis where court reporters transcribe lengthy audio, search for the question ‚Äúdo you recall?‚Äù and extract the deponent‚Äôs precise answer for exhibit preparation
- Manufacturing process monitoring that captures machine alarms (e.g., ‚Äúoverheat warning‚Äù) from workshop audio, transcribes the alert, and logs the technician‚Äôs acknowledgment response for incident tracking
- Wildlife research audio analysis in the field, identifying when a rare bird call (‚Äútu-weet‚Äù) occurs in background recordings and extracting the surrounding researcher commentary for ecological studies
- Podcast production automation that scans recorded episodes for explicit sponsor cue phrases (e.g., ‚Äútoday‚Äôs episode is brought to you by‚Äù) and isolates the host‚Äôs tailored ad read for editing and insertion

```
import os
import json
from pydub import AudioSegment
import speech_recognition as sr
from pydub.effects import normalize, compress_dynamic_range

print("=== ALTERNATIVE APPROACHES FOR TEAL'C AUDIO TRANSCRIPTION ===")
print("Previous attempt failed with Google Speech Recognition")
print("Trying enhanced audio preprocessing and alternative methods...\n")

# First, let's check what files we have in workspace
print("=== CHECKING WORKSPACE FILES ===")
workspace_files = []
for file in os.listdir("workspace"):
    full_path = os.path.join("workspace", file)
    if os.path.isfile(full_path):
        file_size = os.path.getsize(full_path)
        workspace_files.append((file, full_path, file_size))
        size_mb = file_size / (1024 * 1024)
        print(f"  - {file} ({size_mb:.2f} MB)")

# Look for the video file and any existing audio files
video_file = None
audio_file = None

for file_name, full_path, size in workspace_files:
    if file_name.endswith('.mp4'):
        video_file = full_path
        print(f"*** Found video file: {file_name} ***")
    elif file_name.endswith('.wav') and 'tealc' in file_name.lower():
        audio_file = full_path
        print(f"*** Found existing audio file: {file_name} ***")

if not video_file:
    print("\n*** ERROR: No video file found ***")
else:
    print(f"\n=== ENHANCED AUDIO PROCESSING APPROACH ===")
    
    try:
        # Load the video file
        print("Loading video file with pydub...")
        video = AudioSegment.from_file(video_file)
        duration_seconds = len(video) / 1000
        print(f"Video duration: {duration_seconds:.1f} seconds")
        
        # Apply multiple audio enhancement techniques
        print("\n=== APPLYING AUDIO ENHANCEMENTS ===")
        
        # 1. Normalize audio levels
        print("1. Normalizing audio levels...")
        enhanced_audio = normalize(video)
        
        # 2. Apply dynamic range compression to make quiet sounds louder
        print("2. Applying dynamic range compression...")
        enhanced_audio = compress_dynamic_range(enhanced_audio)
        
        # 3. Increase volume if needed
        print("3. Boosting volume...")
        enhanced_audio = enhanced_audio + 6  # Increase by 6dB
        
        # 4. Convert to mono and optimal sample rate for speech recognition
        print("4. Converting to mono and optimal sample rate...")
        enhanced_audio = enhanced_audio.set_channels(1).set_frame_rate(16000)
        
        # Save enhanced audio
        enhanced_audio_file = "workspace/tealc_enhanced_audio.wav"
        enhanced_audio.export(enhanced_audio_file, format="wav")
        enhanced_size = os.path.getsize(enhanced_audio_file)
        print(f"Enhanced audio saved: {enhanced_audio_file} ({enhanced_size} bytes)")
        
        print("\n=== ATTEMPTING TRANSCRIPTION WITH ENHANCED AUDIO ===")
        
        # Initialize speech recognizer with adjusted settings
        recognizer = sr.Recognizer()
        
        # Adjust recognizer sensitivity
        recognizer.energy_threshold = 300  # Lower threshold for quiet audio
        recognizer.dynamic_energy_threshold = True
        recognizer.pause_threshold = 0.8  # Shorter pause threshold
        
        print("Speech recognizer initialized with enhanced settings")
        
        # Try transcription with enhanced audio
        with sr.AudioFile(enhanced_audio_file) as source:
            print("Loading enhanced audio file...")
            
            # Adjust for ambient noise with longer duration
            recognizer.adjust_for_ambient_noise(source, duration=1.0)
            print("Adjusted for ambient noise (extended duration)")
            
            # Record the audio data
            audio_data = recognizer.record(source)
            print("Audio data recorded for transcription")
            
            # Try multiple transcription attempts with different settings
            transcription_attempts = [
                {'language': 'en-US', 'show_all': False},
                {'language': 'en-US', 'show_all': True},
                {'language': 'en', 'show_all': False}
            ]
            
            transcription_success = False
            final_transcription = ""
            
            for attempt_num, settings in enumerate(transcription_attempts, 1):
                try:
                    print(f"\nTranscription attempt {attempt_num} with settings: {settings}")
                    
                    if settings['show_all']:
                        # Get all possible transcriptions with confidence scores
                        result = recognizer.recognize_google(audio_data, 
                                                            language=settings['language'], 
                                                            show_all=True)
                        if result:
                            print(f"Multiple transcription results found: {len(result.get('alternative', []))}")
                            if 'alternative' in result and result['alternative']:
                                best_result = result['alternative'][0]
                                final_transcription = best_result.get('transcript', '')
                                confidence = best_result.get('confidence', 0)
                                print(f"Best transcription (confidence: {confidence:.2f}): '{final_transcription}'")
                                transcription_success = True
                                break
                    else:
                        # Get single best transcription
                        final_transcription = recognizer.recognize_google(audio_data, 
                                                                        language=settings['language'])
                        print(f"Transcription successful: '{final_transcription}'")
                        transcription_success = True
                        break
                        
                except sr.UnknownValueError:
                    print(f"Attempt {attempt_num} failed: Could not understand audio")
                    continue
                except sr.RequestError as e:
                    print(f"Attempt {attempt_num} failed: Service error - {e}")
                    continue
            
            if transcription_success and final_transcription.strip():
                print(f"\n*** TRANSCRIPTION SUCCESSFUL ***")
                print(f"Final transcription: '{final_transcription}'")
                
                # Save the successful transcription
                transcription_file = "workspace/tealc_successful_transcription.txt"
                with open(transcription_file, 'w', encoding='utf-8') as f:
                    f.write("TEAL'C COFFEE SCENE - SUCCESSFUL TRANSCRIPTION\n")
                    f.write("=" * 50 + "\n\n")
                    f.write(f"Source: {os.path.basename(video_file)}\n")
                    f.write(f"Duration: {duration_seconds:.1f} seconds\n")
                    f.write(f"Enhancement applied: Yes\n")
                    f.write(f"Transcription: {final_transcription}\n\n")
                
                print(f"Transcription saved to: {transcription_file}")
                
                # Now analyze for the specific dialogue
                print(f"\n=== ANALYZING FOR 'ISN'T THAT HOT?' DIALOGUE ===")
                
                transcription_lower = final_transcription.lower()
                
                # Search for hot-related patterns
                hot_patterns = [
                    "isn't that hot",
                    "isnt that hot", 
                    "is that hot",
                    "isn't it hot",
                    "that hot",
                    "too hot",
                    "very hot",
                    "hot"
                ]
                
                found_patterns = []
                for pattern in hot_patterns:
                    if pattern in transcription_lower:
                        found_patterns.append(pattern)
                        print(f"*** FOUND PATTERN: '{pattern}' ***")
                
                # Look for Teal'c's characteristic responses
                tealc_patterns = [
                    "indeed",
                    "it is",
                    "extremely",
                    "most",
                    "negative",
                    "affirmative"
                ]
                
                tealc_found = []
                for pattern in tealc_patterns:
                    if pattern in transcription_lower:
                        tealc_found.append(pattern)
                        print(f"Found Teal'c response pattern: '{pattern}'")
                
                # Create final analysis
                final_analysis = {
                    'video_file': os.path.basename(video_file),
                    'duration_seconds': duration_seconds,
                    'transcription_method': 'Enhanced audio processing + Google Speech Recognition',
                    'full_transcription': final_transcription,
                    'hot_patterns_found': found_patterns,
                    'tealc_patterns_found': tealc_found,
                    'analysis_complete': True
                }
                
                # Save detailed analysis
                with open('workspace/tealc_final_analysis.json', 'w', encoding='utf-8') as f:
                    json.dump(final_analysis, f, indent=2)
                
                # Create the final answer file
                with open('workspace/tealc_response_answer.txt', 'w', encoding='utf-8') as f:
                    f.write("TEAL'C'S RESPONSE TO 'ISN'T THAT HOT?'\n")
                    f.write("=" * 50 + "\n\n")
                    f.write(f"Scene: Teal'c trying coffee for the first time\n")
                    f.write(f"Video: {os.path.basename(video_file)}\n")
                    f.write(f"Duration: {duration_seconds:.1f} seconds\n\n")
                    f.write(f"COMPLETE TRANSCRIPTION:\n")
                    f.write(f"'{final_transcription}'\n\n")
                    
                    if found_patterns:
                        f.write(f"Hot-related dialogue found: {', '.join(found_patterns)}\n")
                    if tealc_found:
                        f.write(f"Teal'c response patterns: {', '.join(tealc_found)}\n")
                    
                    f.write(f"\nTEAL'C'S EXACT RESPONSE:\n")
                    f.write(f"Based on the transcription, Teal'c's dialogue in this scene is:\n")
                    f.write(f"'{final_transcription}'\n")
                
                print(f"\n*** ANALYSIS COMPLETE ***")
                print(f"Teal'c's response has been identified and saved to workspace files.")
                print(f"Final transcription: '{final_transcription}'")
                
            else:
                print(f"\n*** ALL TRANSCRIPTION ATTEMPTS FAILED ***")
                print("The audio content may be:")
                print("- Music or sound effects without clear speech")
                print("- Very low quality or heavily distorted")
                print("- In a language not recognized by the service")
                print("- Containing only background noise")
                
                # Save failure analysis
                with open('workspace/transcription_analysis_failed.txt', 'w') as f:
                    f.write("TRANSCRIPTION ANALYSIS - ALL METHODS FAILED\n")
                    f.write("=" * 50 + "\n\n")
                    f.write(f"Video: {os.path.basename(video_file)}\n")
                    f.write(f"Duration: {duration_seconds:.1f} seconds\n")
                    f.write("Methods attempted:\n")
                    f.write("1. Standard Google Speech Recognition\n")
                    f.write("2. Enhanced audio preprocessing\n")
                    f.write("3. Multiple language settings\n")
                    f.write("4. Confidence-based transcription\n\n")
                    f.write("Conclusion: Audio may not contain clear speech dialogue\n")
                
                print(f"Failure analysis saved to: workspace/transcription_analysis_failed.txt")
        
    except Exception as e:
        print(f"\n*** ERROR DURING ENHANCED PROCESSING ***")
        print(f"Error: {str(e)}")
        import traceback
        print(f"Full error details: {traceback.format_exc()}")

print("\n*** ENHANCED TEAL'C DIALOGUE ANALYSIS COMPLETE ***")
```

### Development Step 6: Locate ‚ÄúIsn‚Äôt that hot?‚Äù exchange and transcribe Teal‚Äôc‚Äôs exact response from the YouTube video

**Description**: Access and analyze the YouTube video at https://www.youtube.com/watch?v=1htKBjuUWec to locate the specific dialogue where someone asks 'Isn't that hot?' and identify Teal'c's exact response. Extract the audio/video content, transcribe the relevant dialogue section, and document Teal'c's reply to this question.

**Use Cases**:
- Customer support call transcription and specific complaint keyword spotting for quality assurance in contact centers
- Lecture video transcription and student question‚Äêanswer extraction for e-learning platforms
- Surveillance audio analysis and suspicious phrase detection for security operations in law enforcement
- Focus group session transcription and sentiment keyword identification for product development teams
- Archival broadcast video indexing and catchphrase search for media libraries and content distributors
- Medical consultation recording transcription and symptom keyword extraction for electronic health record enhancement
- Podcast episode transcription and topic segment annotation for content creators and publishers
- Legal deposition video transcription and critical phrase highlighting for law firms and court reporting services

```
import os
import json
from pydub import AudioSegment
import speech_recognition as sr

# First, let's confirm the video file is in workspace and fix the variable naming issue
print("=== CONFIRMING VIDEO FILE AND EXTRACTING AUDIO ===\n")

# Check workspace contents
workspace_files = []
for file in os.listdir("workspace"):
    full_path = os.path.join("workspace", file)
    if os.path.isfile(full_path):
        file_size = os.path.getsize(full_path)
        workspace_files.append((file, full_path, file_size))

print(f"Files in workspace:")
video_file = None
for file_name, full_path, size in workspace_files:
    size_mb = size / (1024 * 1024)
    print(f"  - {file_name} ({size_mb:.2f} MB)")
    
    # Identify the video file (fix the variable naming issue - use file_name consistently)
    video_extensions = ['.mp4', '.mkv', '.webm', '.avi']
    if any(file_name.lower().endswith(ext) for ext in video_extensions):
        video_file = full_path
        print(f"    *** IDENTIFIED AS VIDEO FILE ***")

if not video_file:
    print("\n*** ERROR: No video file found ***")
else:
    print(f"\n=== VIDEO FILE CONFIRMED ===")
    print(f"Video file: {video_file}")
    print(f"File size: {os.path.getsize(video_file) / (1024 * 1024):.2f} MB")
    
    # Extract audio from the video
    print(f"\n=== EXTRACTING AUDIO FROM VIDEO ===")
    
    try:
        # Load video and extract audio
        print("Loading video file with pydub...")
        video = AudioSegment.from_file(video_file)
        print(f"Video loaded successfully: {len(video)} ms duration")
        
        # Convert to seconds for readability
        duration_seconds = len(video) / 1000
        print(f"Duration: {duration_seconds:.1f} seconds")
        
        # Export audio as WAV for speech recognition
        audio_file = "workspace/tealc_coffee_audio.wav"
        print(f"Exporting audio to: {audio_file}")
        
        # Export with optimal settings for speech recognition
        video.export(audio_file, format="wav", parameters=["-ar", "16000", "-ac", "1"])
        
        audio_size = os.path.getsize(audio_file)
        print(f"Audio file created: {audio_size} bytes")
        
        print(f"\n=== TRANSCRIBING AUDIO TO TEXT ===")
        
        # Initialize speech recognizer
        recognizer = sr.Recognizer()
        print("Speech recognizer initialized")
        
        # Load the audio file for transcription
        with sr.AudioFile(audio_file) as source:
            print("Loading audio file for transcription...")
            
            # Adjust for ambient noise
            recognizer.adjust_for_ambient_noise(source, duration=0.5)
            print("Adjusted for ambient noise")
            
            # Record the audio data
            audio_data = recognizer.record(source)
            print("Audio data recorded for transcription")
            
            try:
                print("\nAttempting transcription with Google Speech Recognition...")
                
                # Transcribe the audio
                transcription = recognizer.recognize_google(audio_data, language='en-US')
                
                print(f"\n*** TRANSCRIPTION SUCCESSFUL ***")
                print(f"Transcribed text length: {len(transcription)} characters")
                print(f"\n=== TEAL'C COFFEE SCENE TRANSCRIPTION ===")
                print(f"'{transcription}'")
                
                # Save the transcription
                transcription_file = "workspace/tealc_coffee_transcription.txt"
                with open(transcription_file, 'w', encoding='utf-8') as f:
                    f.write("TEAL'C COFFEE SCENE TRANSCRIPTION\n")
                    f.write("=" * 40 + "\n\n")
                    f.write(f"Source: {os.path.basename(video_file)}\n")
                    f.write(f"Duration: {duration_seconds:.1f} seconds\n")
                    f.write(f"Transcribed: {transcription}\n\n")
                
                print(f"\nTranscription saved to: {transcription_file}")
                
                # Now search for the specific dialogue
                print(f"\n=== SEARCHING FOR 'ISN'T THAT HOT?' DIALOGUE ===")
                
                transcription_lower = transcription.lower()
                
                # Look for variations of "isn't that hot?"
                hot_patterns = [
                    "isn't that hot",
                    "isnt that hot", 
                    "is that hot",
                    "isn't it hot",
                    "isnt it hot",
                    "that hot",
                    "too hot",
                    "very hot",
                    "hot"
                ]
                
                found_hot_question = False
                hot_question_context = ""
                for pattern in hot_patterns:
                    if pattern in transcription_lower:
                        print(f"*** FOUND HOT QUESTION PATTERN: '{pattern}' ***")
                        found_hot_question = True
                        
                        # Find the position of this pattern
                        start_pos = transcription_lower.find(pattern)
                        end_pos = start_pos + len(pattern)
                        
                        # Get context around the question
                        context_start = max(0, start_pos - 50)
                        context_end = min(len(transcription), end_pos + 100)
                        hot_question_context = transcription[context_start:context_end]
                        
                        print(f"Context: '{hot_question_context}'")
                        break
                
                if not found_hot_question:
                    print("No direct 'isn't that hot?' pattern found in transcription")
                    print("Let's analyze the full transcription for Teal'c's dialogue...")
                
                # Look for Teal'c's characteristic responses
                print(f"\n=== ANALYZING FOR TEAL'C'S RESPONSE ===")
                
                # Teal'c often gives short, direct responses
                tealc_patterns = [
                    "indeed",
                    "it is",
                    "i do not",
                    "negative",
                    "affirmative",
                    "most",
                    "extremely"
                ]
                
                tealc_responses_found = []
                for pattern in tealc_patterns:
                    if pattern in transcription_lower:
                        tealc_responses_found.append(pattern)
                        print(f"Found Teal'c pattern: '{pattern}'")
                
                # Analyze the dialogue structure to identify speakers and responses
                print(f"\n=== DIALOGUE STRUCTURE ANALYSIS ===")
                
                # Split transcription into sentences/phrases
                import re
                sentences = re.split(r'[.!?]+', transcription)
                sentences = [s.strip() for s in sentences if s.strip()]
                
                print(f"Dialogue broken into {len(sentences)} parts:")
                for i, sentence in enumerate(sentences, 1):
                    print(f"  {i}. '{sentence}'")
                
                # Create detailed analysis
                analysis = {
                    'video_file': video_file,
                    'duration_seconds': duration_seconds,
                    'full_transcription': transcription,
                    'dialogue_sentences': sentences,
                    'hot_question_found': found_hot_question,
                    'hot_question_context': hot_question_context,
                    'tealc_patterns_found': tealc_responses_found,
                    'objective': "Find Teal'c's response to 'Isn't that hot?'"
                }
                
                # Save detailed analysis
                with open('workspace/tealc_dialogue_analysis.json', 'w', encoding='utf-8') as f:
                    json.dump(analysis, f, indent=2)
                
                print(f"\n=== ANALYSIS SUMMARY ===")
                print(f"Full transcription: '{transcription}'")
                print(f"Hot question found: {found_hot_question}")
                print(f"Teal'c patterns found: {tealc_responses_found}")
                print(f"Dialogue parts: {len(sentences)}")
                
                # Determine Teal'c's response based on the analysis
                print(f"\n*** IDENTIFYING TEAL'C'S RESPONSE ***")
                
                if found_hot_question:
                    print(f"Hot question context found: '{hot_question_context}'")
                    response_analysis = "Based on the context, Teal'c's response appears to be in the dialogue."
                else:
                    print("No explicit 'isn't that hot?' found, but analyzing complete dialogue for Teal'c's response...")
                    response_analysis = "Analyzing complete dialogue to identify Teal'c's characteristic response."
                
                # Save the final answer
                with open('workspace/tealc_final_answer.txt', 'w', encoding='utf-8') as f:
                    f.write("TEAL'C'S RESPONSE TO 'ISN'T THAT HOT?'\n")
                    f.write("=" * 50 + "\n\n")
                    f.write(f"Scene: Teal'c trying coffee for the first time\n")
                    f.write(f"Video: {os.path.basename(video_file)}\n")
                    f.write(f"Duration: {duration_seconds:.1f} seconds\n\n")
                    f.write(f"Complete dialogue transcription:\n")
                    f.write(f"'{transcription}'\n\n")
                    f.write(f"Hot question found: {found_hot_question}\n")
                    if found_hot_question:
                        f.write(f"Hot question context: '{hot_question_context}'\n")
                    f.write(f"\nDialogue breakdown:\n")
                    for i, sentence in enumerate(sentences, 1):
                        f.write(f"  {i}. '{sentence}'\n")
                    f.write(f"\nTeal'c patterns identified: {tealc_responses_found}\n")
                    f.write(f"\nAnalysis: {response_analysis}\n")
                
                print(f"\nDetailed analysis saved to: workspace/tealc_dialogue_analysis.json")
                print(f"Final answer saved to: workspace/tealc_final_answer.txt")
                
                print(f"\n*** TRANSCRIPTION AND ANALYSIS COMPLETE ***")
                print(f"The complete dialogue from the Teal'c coffee scene has been transcribed and analyzed.")
                print(f"Teal'c's exact response to questions about the coffee being hot is captured in the transcription.")
                
            except sr.UnknownValueError:
                print("\n*** TRANSCRIPTION FAILED ***")
                print("Google Speech Recognition could not understand the audio")
                print("The audio may be unclear, contain background noise, or have no speech")
                
                # Still save what we can
                with open('workspace/transcription_failed.txt', 'w') as f:
                    f.write("TRANSCRIPTION FAILED\n")
                    f.write(f"Video: {video_file}\n")
                    f.write(f"Duration: {duration_seconds:.1f} seconds\n")
                    f.write("Reason: Google Speech Recognition could not understand the audio\n")
                
            except sr.RequestError as e:
                print(f"\n*** SPEECH RECOGNITION SERVICE ERROR ***")
                print(f"Could not request results from Google Speech Recognition: {e}")
        
    except Exception as e:
        print(f"\n*** ERROR DURING AUDIO PROCESSING ***")
        print(f"Error: {str(e)}")
        import traceback
        print(f"Full error details: {traceback.format_exc()}")

print("\n*** TEAL'C DIALOGUE ANALYSIS COMPLETE ***")
```

### Development Step 24: Search for 17th-Century Chronicles Documenting Irish Spectral Army and Supernatural Events

**Description**: Search for historical documents from the 17th century that record both a spectral army apparition in Ireland and unusual supernatural events. Focus on identifying chronicles, historical accounts, or antiquarian records from that period that document both phenomena. Look for works by historians, chroniclers, or antiquarians who recorded supernatural occurrences across Britain and Ireland during the 1600s, as this dual documentation will help identify the specific source that M.R. James likely used for his Suffolk spider curse inspiration.

**Use Cases**:
- Historical archives digitization team extracting and cataloging 17th-century Irish chronicle references to spectral army accounts for curating a specialized research database
- Folklore studies department automatically processing HTML transcripts of digitized manuscripts to identify supernatural event descriptions for publication in an annotated monograph on ghostly warfare traditions
- Digital humanities lab analyzing online repositories of Gaelic annals to map temporal occurrences of phantom armies for thesis-level quantitative analysis and interactive visualization
- Cultural heritage organization mining local council website archives to extract narratives of spectral apparitions for designing an immersive museum exhibit on Irish supernatural folklore
- Paranormal documentary producers scanning web-hosted historical chronicles to source authentic supernatural event descriptions for episode scripts on spectral phenomena in Ireland
- University library special collections team batch-processing downloaded chronicle HTML files to compile metadata on chronicle references and supernatural stories for enriched digital finding aids
- Genealogy researchers searching online Irish annals for mentions of family lineages affected by supernatural occurrences to build comprehensive ancestral profiles
- Tour operators using an automated script to extract chronological supernatural events from HTML archives for creating data-driven ghost trail itineraries across historic Irish sites

```
import os
import json
from bs4 import BeautifulSoup
import re

print('=== FIXED ANALYSIS: 17TH CENTURY IRISH CHRONICLES FROM SAVED HTML FILES ===')
print('Processing downloaded HTML files to extract chronicle references and supernatural content\n')

# Ensure workspace directory exists
workspace_dir = 'workspace'
if not os.path.exists(workspace_dir):
    print(f'‚ùå Workspace directory not found: {workspace_dir}')
else:
    print(f'‚úÖ Workspace directory found: {workspace_dir}')

# First, let's see what HTML files we have from the previous searches
html_files = []
for filename in os.listdir(workspace_dir):
    if filename.endswith('.html') and 'search_' in filename:
        html_files.append(filename)

print(f'\nüìÅ FOUND {len(html_files)} HTML FILES FROM PREVIOUS SEARCHES:')
print('-' * 60)
for i, filename in enumerate(html_files, 1):
    filepath = os.path.join(workspace_dir, filename)
    file_size = os.path.getsize(filepath)
    print(f'{i:2d}. {filename} ({file_size:,} bytes)')

if not html_files:
    print('‚ùå No HTML search files found to process')
else:
    print(f'\nüîç PROCESSING {len(html_files)} HTML FILES FOR CHRONICLE CONTENT:')
    print('=' * 70)
    
    # Initialize results storage
    chronicle_analysis = {
        'analysis_timestamp': '2024-12-19',
        'objective': 'Extract 17th century Irish chronicle references from downloaded HTML files',
        'files_processed': [],
        'chronicle_references': [],
        'supernatural_events': [],
        'historical_sources': [],
        'analysis_summary': {}
    }
    
    # Define search patterns for analysis
    chronicle_patterns = [
        r'annals of the four masters',
        r'ann√°la r√≠oghachta √©ireann',
        r'geoffrey keating',
        r'seathr√∫n c√©itinn', 
        r'foras feasa ar √©irinn',
        r'annals of ulster',
        r'ann√°la uladh',
        r'annals of inisfallen',
        r'chronicon scotorum',
        r'annals of tigernach',
        r'annals of clonmacnoise'
    ]
    
    supernatural_patterns = [
        r'spectral army',
        r'phantom army', 
        r'ghostly host',
        r'supernatural army',
        r'apparition',
        r'phantom',
        r'spectral',
        r'ghostly',
        r'supernatural'
    ]
    
    time_patterns = [
        r'17th century',
        r'seventeenth century',
        r'1600s',
        r'1650s',
        r'1680s',
        r'1690s',
        r'\b16[0-9]{2}\b'  # Any year in 1600s
    ]
    
    irish_patterns = [
        r'\birish\b',
        r'\bireland\b',
        r'\bceltic\b',
        r'\bgaelic\b',
        r'\bdublin\b',
        r'\bcork\b',
        r'\bulster\b'
    ]
    
    # Process each HTML file
    for i, filename in enumerate(html_files, 1):
        print(f'\nProcessing {i}/{len(html_files)}: {filename}')
        print('-' * 50)
        
        filepath = os.path.join(workspace_dir, filename)
        
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                html_content = f.read()
            
            # Parse with BeautifulSoup
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # Remove script and style elements
            for script in soup(['script', 'style']):
                script.decompose()
            
            # Get text content
            text_content = soup.get_text()
            text_lower = text_content.lower()
            
            print(f'  Text content length: {len(text_content):,} characters')
            
            # Count pattern matches
            chronicle_matches = []
            supernatural_matches = []
            time_matches = []
            irish_matches = []
            
            # Search for chronicle patterns
            for pattern in chronicle_patterns:
                matches = re.findall(pattern, text_lower, re.IGNORECASE)
                if matches:
                    chronicle_matches.extend(matches)
                    print(f'  ‚úì Chronicle pattern found: {pattern} ({len(matches)} times)')
            
            # Search for supernatural patterns
            for pattern in supernatural_patterns:
                matches = re.findall(pattern, text_lower, re.IGNORECASE)
                if matches:
                    supernatural_matches.extend(matches)
            
            # Search for time patterns
            for pattern in time_patterns:
                matches = re.findall(pattern, text_lower, re.IGNORECASE)
                if matches:
                    time_matches.extend(matches)
            
            # Search for Irish patterns
            for pattern in irish_patterns:
                matches = re.findall(pattern, text_lower, re.IGNORECASE)
                if matches:
                    irish_matches.extend(matches)
            
            # Calculate relevance score
            relevance_score = (len(chronicle_matches) * 5 + 
                             len(supernatural_matches) * 3 + 
                             len(time_matches) * 2 + 
                             len(irish_matches) * 2)
            
            print(f'  Pattern matches: Chronicle({len(chronicle_matches)}) | '
                  f'Supernatural({len(supernatural_matches)}) | '
                  f'17th Century({len(time_matches)}) | '
                  f'Irish({len(irish_matches)})')
            print(f'  Relevance score: {relevance_score}')
            
            # Store file analysis
            file_analysis = {
                'filename': filename,
                'content_length': len(text_content),
                'relevance_score': relevance_score,
                'pattern_matches': {
                    'chronicle': list(set(chronicle_matches)),
                    'supernatural': list(set(supernatural_matches)),
                    'time': list(set(time_matches)),
                    'irish': list(set(irish_matches))
                }
            }
            
            chronicle_analysis['files_processed'].append(file_analysis)
            
            # Extract specific chronicle references if high relevance
            if relevance_score >= 10:
                print('  üéØ HIGH RELEVANCE - Extracting specific references...')
                
                # Split into sentences for detailed analysis
                sentences = re.split(r'[.!?]+', text_content)
                
                for sentence in sentences:
                    sentence_clean = sentence.strip()
                    sentence_lower = sentence_clean.lower()
                    
                    # Skip very short or very long sentences
                    if not (20 <= len(sentence_clean) <= 300):
                        continue
                    
                    # Check for chronicle + supernatural + time/irish combinations
                    has_chronicle = any(re.search(pattern, sentence_lower) for pattern in chronicle_patterns)
                    has_supernatural = any(re.search(pattern, sentence_lower) for pattern in supernatural_patterns)
                    has_time = any(re.search(pattern, sentence_lower) for pattern in time_patterns)
                    has_irish = any(re.search(pattern, sentence_lower) for pattern in irish_patterns)
                    
                    # Chronicle references
                    if has_chronicle and (has_supernatural or has_time or has_irish):
                        chronicle_analysis['chronicle_references'].append({
                            'text': sentence_clean,
                            'source_file': filename,
                            'has_supernatural': has_supernatural,
                            'has_time': has_time,
                            'has_irish': has_irish
                        })
                        print(f'    ‚úì Chronicle reference: {sentence_clean[:100]}...')
                    
                    # Supernatural events
                    if has_supernatural and has_irish and (has_time or 'army' in sentence_lower or 'host' in sentence_lower):
                        chronicle_analysis['supernatural_events'].append({
                            'text': sentence_clean,
                            'source_file': filename,
                            'has_chronicle': has_chronicle,
                            'has_time': has_time
                        })
                        print(f'    üëª Supernatural event: {sentence_clean[:100]}...')
                    
                    # Historical sources
                    if has_chronicle or (has_time and has_irish and len(chronicle_matches) > 0):
                        chronicle_analysis['historical_sources'].append({
                            'text': sentence_clean,
                            'source_file': filename,
                            'relevance_indicators': {
                                'chronicle': has_chronicle,
                                'supernatural': has_supernatural,
                                'time': has_time,
                                'irish': has_irish
                            }
                        })
            
            elif relevance_score >= 5:
                print('  üìù MODERATE RELEVANCE - Basic content extraction...')
                
                # Extract key paragraphs with multiple relevant terms
                paragraphs = text_content.split('\n\n')
                for paragraph in paragraphs:
                    if len(paragraph.strip()) > 100:
                        para_lower = paragraph.lower()
                        
                        # Count relevant terms in paragraph
                        para_score = 0
                        if any(re.search(pattern, para_lower) for pattern in chronicle_patterns):
                            para_score += 3
                        if any(re.search(pattern, para_lower) for pattern in supernatural_patterns):
                            para_score += 2
                        if any(re.search(pattern, para_lower) for pattern in time_patterns):
                            para_score += 2
                        if any(re.search(pattern, para_lower) for pattern in irish_patterns):
                            para_score += 1
                        
                        if para_score >= 4:
                            chronicle_analysis['historical_sources'].append({
                                'text': paragraph.strip()[:300] + '...',
                                'source_file': filename,
                                'paragraph_score': para_score
                            })
            
            else:
                print('  ‚ùì LOW RELEVANCE - Minimal content extraction')
        
        except Exception as e:
            print(f'  ‚ùå Error processing {filename}: {str(e)}')
    
    print('\n' + '=' * 80)
    print('COMPREHENSIVE ANALYSIS OF EXTRACTED CHRONICLE CONTENT')
    print('=' * 80)
    
    # Sort files by relevance
    chronicle_analysis['files_processed'].sort(key=lambda x: x['relevance_score'], reverse=True)
    
    total_files = len(chronicle_analysis['files_processed'])
    high_relevance_files = len([f for f in chronicle_analysis['files_processed'] if f['relevance_score'] >= 10])
    moderate_relevance_files = len([f for f in chronicle_analysis['files_processed'] if 5 <= f['relevance_score'] < 10])
    
    print(f'üìä FILE PROCESSING SUMMARY:')
    print(f'   ‚Ä¢ Total files processed: {total_files}')
    print(f'   ‚Ä¢ High relevance files (10+): {high_relevance_files}')
    print(f'   ‚Ä¢ Moderate relevance files (5-9): {moderate_relevance_files}')
    print(f'   ‚Ä¢ Chronicle references extracted: {len(chronicle_analysis["chronicle_references"])}')
    print(f'   ‚Ä¢ Supernatural events found: {len(chronicle_analysis["supernatural_events"])}')
    print(f'   ‚Ä¢ Historical sources identified: {len(chronicle_analysis["historical_sources"])}')
    
    if chronicle_analysis['files_processed']:
        print('\nüèÜ TOP RELEVANT FILES:')
        print('-' * 30)
        
        for i, file_data in enumerate(chronicle_analysis['files_processed'][:5], 1):
            print(f'{i}. {file_data["filename"]}')  
            print(f'   Score: {file_data["relevance_score"]} | Length: {file_data["content_length"]:,} chars')
            
            # Show pattern matches
            patterns = file_data['pattern_matches']
            if patterns['chronicle']:
                print(f'   Chronicles: {" | ".join(patterns["chronicle"][:3])}')
            if patterns['supernatural']:
                print(f'   Supernatural: {" | ".join(patterns["supernatural"][:3])}')
            if patterns['time']:
                print(f'   Time periods: {" | ".join(patterns["time"][:3])}')
            print()
    
    if chronicle_analysis['chronicle_references']:
        print('üìö SPECIFIC CHRONICLE REFERENCES FOUND:')
        print('-' * 45)
        
        for i, ref in enumerate(chronicle_analysis['chronicle_references'][:8], 1):
            print(f'{i}. {ref["text"][:150]}...')
            print(f'   Source: {ref["source_file"]}')
            
            context = []
            if ref['has_supernatural']: context.append('SUPERNATURAL')
            if ref['has_time']: context.append('17TH CENTURY')
            if ref['has_irish']: context.append('IRISH')
            print(f'   Context: {" + ".join(context)}\n')
    
    if chronicle_analysis['supernatural_events']:
        print('üëª SUPERNATURAL EVENTS IN IRISH CONTEXT:')
        print('-' * 45)
        
        for i, event in enumerate(chronicle_analysis['supernatural_events'][:5], 1):
            print(f'{i}. {event["text"][:150]}...')
            print(f'   Source: {event["source_file"]}')
            
            context = []
            if event['has_chronicle']: context.append('CHRONICLE')
            if event['has_time']: context.append('17TH CENTURY')
            print(f'   Context: {" + ".join(context)}\n')
    
    if chronicle_analysis['historical_sources']:
        print(f'üìñ HISTORICAL SOURCES IDENTIFIED ({len(chronicle_analysis["historical_sources"])}):')
        print('-' * 55)
        
        # Show top 5 historical sources
        for i, source in enumerate(chronicle_analysis['historical_sources'][:5], 1):
            print(f'{i}. {source["text"][:200]}...')
            print(f'   Source: {source["source_file"]}')
            
            if 'relevance_indicators' in source:
                indicators = source['relevance_indicators']
                context = []
                if indicators.get('chronicle'): context.append('CHRONICLE')
                if indicators.get('supernatural'): context.append('SUPERNATURAL')
                if indicators.get('time'): context.append('17TH CENTURY')
                if indicators.get('irish'): context.append('IRISH')
                print(f'   Indicators: {" + ".join(context)}')
            
            print()
    
    # Save comprehensive analysis
    analysis_file = os.path.join(workspace_dir, '17th_century_irish_chronicles_extracted_analysis.json')
    with open(analysis_file, 'w', encoding='utf-8') as f:
        json.dump(chronicle_analysis, f, indent=2, ensure_ascii=False)
    
    print(f'üíæ COMPREHENSIVE ANALYSIS SAVED TO: {analysis_file}')
    
    # Generate summary analysis
    chronicle_analysis['analysis_summary'] = {
        'total_files_processed': total_files,
        'high_relevance_files': high_relevance_files,
        'moderate_relevance_files': moderate_relevance_files,
        'chronicle_references_found': len(chronicle_analysis['chronicle_references']),
        'supernatural_events_found': len(chronicle_analysis['supernatural_events']),
        'historical_sources_identified': len(chronicle_analysis['historical_sources']),
        'most_relevant_file': chronicle_analysis['files_processed'][0]['filename'] if chronicle_analysis['files_processed'] else None,
        'top_chronicle_patterns': []
    }
    
    # Identify most common chronicle patterns
    all_chronicle_matches = []
    for file_data in chronicle_analysis['files_processed']:
        all_chronicle_matches.extend(file_data['pattern_matches']['chronicle'])
    
    from collections import Counter
    if all_chronicle_matches:
        chronicle_counter = Counter(all_chronicle_matches)
        chronicle_analysis['analysis_summary']['top_chronicle_patterns'] = chronicle_counter.most_common(5)
    
    print('\nüéØ FINAL ASSESSMENT: 17TH CENTURY IRISH CHRONICLES IDENTIFICATION')
    print('-' * 75)
    
    success_level = 0
    
    if len(chronicle_analysis['chronicle_references']) >= 3:
        success_level = 4
        print('‚úÖ HIGH SUCCESS: Multiple specific chronicle references identified!')
        print('   Found direct references to 17th century Irish chronicles that')
        print('   documented supernatural events and spectral phenomena.')
        print('   These sources provide strong evidence for the historical')
        print('   foundation that inspired M.R. James\' Suffolk spider curse.')
    elif len(chronicle_analysis['chronicle_references']) >= 1:
        success_level = 3
        print('üìù MODERATE SUCCESS: Chronicle references identified.')
        print('   Found evidence of specific Irish chronicles documenting')
        print('   supernatural events that could have inspired M.R. James.')
    elif len(chronicle_analysis['supernatural_events']) >= 2:
        success_level = 2
        print('üîç PARTIAL SUCCESS: Supernatural events in Irish context found.')
        print('   Identified historical documentation of paranormal phenomena')
        print('   in Irish sources that may have influenced ghost story writing.')
    elif len(chronicle_analysis['historical_sources']) >= 5:
        success_level = 1
        print('üìã FOUNDATION SUCCESS: Historical context established.')
        print('   Gathered relevant information about Irish chronicles and')
        print('   supernatural traditions from the 17th century period.')
    else:
        success_level = 0
        print('‚ùì LIMITED SUCCESS: Minimal relevant content extracted.')
        print('   Technical issues or content filtering may have affected')
        print('   the extraction of chronicle references.')
    
    print('\n‚úÖ SEARCH OBJECTIVE COMPLETION STATUS:')
    if success_level >= 3:
        print('   üéØ OBJECTIVE ACHIEVED: Successfully identified 17th century Irish')
        print('   chronicles that documented both spectral army apparitions and')
        print('   unusual supernatural events. Analysis provides concrete evidence')
        print('   of historical sources that inspired M.R. James\' Suffolk spider')
        print('   curse and other ghost stories.')
    elif success_level >= 2:
        print('   üìù OBJECTIVE PARTIALLY ACHIEVED: Found evidence of supernatural')
        print('   events in Irish historical context that likely influenced')
        print('   M.R. James\' ghost story writing, though specific chronicle')
        print('   identification requires additional research.')
    else:
        print('   üîç OBJECTIVE IN PROGRESS: Established foundation for chronicle')
        print('   research but requires additional investigation to identify')
        print('   specific 17th century Irish sources documenting spectral armies.')
    
    print('\nüìã KEY FINDINGS SUMMARY:')
    print(f'   ‚Ä¢ HTML files analyzed: {total_files}')
    print(f'   ‚Ä¢ Chronicle references: {len(chronicle_analysis["chronicle_references"])}')
    print(f'   ‚Ä¢ Supernatural events: {len(chronicle_analysis["supernatural_events"])}')
    print(f'   ‚Ä¢ Historical sources: {len(chronicle_analysis["historical_sources"])}')
    print(f'   ‚Ä¢ High-relevance files: {high_relevance_files}')
    
    if chronicle_analysis['analysis_summary']['top_chronicle_patterns']:
        print('\nüìö MOST REFERENCED CHRONICLES:')
        for chronicle, count in chronicle_analysis['analysis_summary']['top_chronicle_patterns']:
            print(f'   ‚Ä¢ {chronicle.title()}: {count} references')
    
    print('\nüéØ RECOMMENDED NEXT STEPS:')
    print('1. üìñ Review specific chronicle references for detailed content')
    print('2. üîç Cross-reference found chronicles with M.R. James\' known research')
    print('3. üìö Investigate supernatural events in identified chronicles')
    print('4. üéØ Connect findings to Suffolk spider curse inspiration')
    print('5. üìã Examine high-relevance HTML files for additional context')

print('\n=== 17TH CENTURY IRISH CHRONICLES EXTRACTION COMPLETE ===')
```

### Development Step 9: Extract and Transcribe "Isn't That Hot?" Dialogue and Teal‚Äôc‚Äôs Reply from YouTube Video

**Description**: Access and analyze the YouTube video at https://www.youtube.com/watch?v=1htKBjuUWec to locate the specific dialogue where someone asks 'Isn't that hot?' and identify Teal'c's exact response. Extract the audio/video content, transcribe the relevant dialogue section, and document Teal'c's reply to this question.

**Use Cases**:
- Legal video evidence processing to transcribe courtroom footage and extract witness statements containing specific phrases for case preparation
- Customer support call QA automation by transcribing recorded service calls to identify ‚ÄúI‚Äôm not satisfied‚Äù or similar complaint triggers for supervisor review
- Market research on product demo videos to locate and compile user feedback comments like ‚Äúthis feature is great‚Äù for prioritizing development roadmaps
- Social media moderation by analyzing livestreams to detect and flag policy-violating language in real time for compliance teams
- Educational lecture indexing to transcribe university seminars, tag question-and-answer segments, and enable students to search for ‚ÄúCan you explain...‚Äù queries
- Media production highlight creation by extracting memorable soundbites from celebrity interviews (‚ÄúThat was awesome!‚Äù) for promotional reels
- Accessibility caption generation for online courses by transcribing instructor dialogue and identifying speaker changes for precise subtitle synchronization
- Linguistic research on archival broadcasts to automatically transcribe and analyze usage patterns of phrases such as ‚ÄúDo you really think...‚Äù across decades

```
import os
import json
from pydub import AudioSegment
import speech_recognition as sr

print("=== FOCUSED TRANSCRIPTION ATTEMPT WITH EXISTING ENHANCED AUDIO ===")
print("Using the enhanced audio file that was created in the previous attempt...\n")

# Check what files we have in workspace
print("=== CHECKING WORKSPACE FILES ===")
workspace_files = []
for file in os.listdir("workspace"):
    full_path = os.path.join("workspace", file)
    if os.path.isfile(full_path):
        file_size = os.path.getsize(full_path)
        workspace_files.append((file, full_path, file_size))
        size_mb = file_size / (1024 * 1024)
        print(f"  - {file} ({size_mb:.2f} MB)")

# Look for enhanced audio file or create it if needed
enhanced_audio_file = None
video_file = None

for file_name, full_path, size in workspace_files:
    if 'enhanced' in file_name.lower() and file_name.endswith('.wav'):
        enhanced_audio_file = full_path
        print(f"*** Found enhanced audio file: {file_name} ***")
    elif file_name.endswith('.mp4'):
        video_file = full_path
        print(f"*** Found video file: {file_name} ***")
    elif 'tealc' in file_name.lower() and file_name.endswith('.wav'):
        # Use existing audio file if no enhanced version found
        if not enhanced_audio_file:
            enhanced_audio_file = full_path
            print(f"*** Using existing audio file: {file_name} ***")

if not enhanced_audio_file and video_file:
    print("\n=== CREATING ENHANCED AUDIO FILE ===")
    try:
        # Load video and create enhanced audio
        video = AudioSegment.from_file(video_file)
        duration_seconds = len(video) / 1000
        print(f"Video duration: {duration_seconds:.1f} seconds")
        
        # Apply enhancements
        from pydub.effects import normalize
        enhanced_audio = normalize(video)
        enhanced_audio = enhanced_audio + 10  # Boost volume by 10dB
        enhanced_audio = enhanced_audio.set_channels(1).set_frame_rate(16000)
        
        enhanced_audio_file = "workspace/tealc_enhanced_audio.wav"
        enhanced_audio.export(enhanced_audio_file, format="wav")
        print(f"Enhanced audio created: {enhanced_audio_file}")
        
    except Exception as e:
        print(f"Error creating enhanced audio: {e}")
        enhanced_audio_file = None

if not enhanced_audio_file:
    print("\n*** ERROR: No audio file available for transcription ***")
else:
    print(f"\n=== ATTEMPTING TRANSCRIPTION ===")
    print(f"Using audio file: {os.path.basename(enhanced_audio_file)}")
    
    # Get audio file info
    audio_size = os.path.getsize(enhanced_audio_file)
    print(f"Audio file size: {audio_size} bytes")
    
    try:
        # Load audio to check duration
        audio_segment = AudioSegment.from_wav(enhanced_audio_file)
        duration_ms = len(audio_segment)
        duration_seconds = duration_ms / 1000
        print(f"Audio duration: {duration_seconds:.1f} seconds")
        
        # Initialize speech recognizer with optimized settings
        recognizer = sr.Recognizer()
        recognizer.energy_threshold = 200  # Lower threshold for quiet speech
        recognizer.dynamic_energy_threshold = True
        recognizer.pause_threshold = 0.5  # Shorter pause detection
        
        print("Speech recognizer initialized with optimized settings")
        
        # Attempt transcription
        with sr.AudioFile(enhanced_audio_file) as source:
            print("Loading audio file for transcription...")
            
            # Adjust for ambient noise
            recognizer.adjust_for_ambient_noise(source, duration=0.8)
            print("Adjusted for ambient noise")
            
            # Record the audio data
            audio_data = recognizer.record(source)
            print("Audio data recorded successfully")
            
            # Try transcription with multiple approaches
            transcription_methods = [
                {'name': 'Standard English', 'lang': 'en-US', 'show_all': False},
                {'name': 'English with alternatives', 'lang': 'en-US', 'show_all': True},
                {'name': 'Generic English', 'lang': 'en', 'show_all': False}
            ]
            
            successful_transcription = None
            
            for method in transcription_methods:
                try:
                    print(f"\nTrying method: {method['name']}")
                    
                    if method['show_all']:
                        result = recognizer.recognize_google(audio_data, 
                                                            language=method['lang'], 
                                                            show_all=True)
                        if result and 'alternative' in result and result['alternative']:
                            best_alternative = result['alternative'][0]
                            transcription = best_alternative.get('transcript', '')
                            confidence = best_alternative.get('confidence', 0)
                            print(f"Transcription with confidence {confidence:.2f}: '{transcription}'")
                            if transcription.strip():
                                successful_transcription = transcription
                                break
                    else:
                        transcription = recognizer.recognize_google(audio_data, language=method['lang'])
                        print(f"Transcription result: '{transcription}'")
                        if transcription.strip():
                            successful_transcription = transcription
                            break
                            
                except sr.UnknownValueError:
                    print(f"Method '{method['name']}' could not understand the audio")
                    continue
                except sr.RequestError as e:
                    print(f"Method '{method['name']}' service error: {e}")
                    continue
                except Exception as e:
                    print(f"Method '{method['name']}' unexpected error: {e}")
                    continue
            
            if successful_transcription:
                print(f"\n*** TRANSCRIPTION SUCCESSFUL ***")
                print(f"Final transcription: '{successful_transcription}'")
                
                # Analyze the transcription for the specific dialogue
                print(f"\n=== ANALYZING TRANSCRIPTION FOR 'ISN'T THAT HOT?' DIALOGUE ===")
                
                transcription_lower = successful_transcription.lower()
                
                # Search for hot-related patterns
                hot_patterns = [
                    "isn't that hot",
                    "isnt that hot", 
                    "is that hot",
                    "isn't it hot",
                    "that hot",
                    "too hot",
                    "very hot",
                    "hot"
                ]
                
                found_hot_patterns = []
                hot_context = ""
                
                for pattern in hot_patterns:
                    if pattern in transcription_lower:
                        found_hot_patterns.append(pattern)
                        # Get context around the pattern
                        start_pos = transcription_lower.find(pattern)
                        context_start = max(0, start_pos - 30)
                        context_end = min(len(successful_transcription), start_pos + len(pattern) + 30)
                        hot_context = successful_transcription[context_start:context_end]
                        print(f"*** FOUND HOT PATTERN: '{pattern}' ***")
                        print(f"Context: '{hot_context}'")
                        break
                
                # Look for Teal'c's characteristic responses
                print(f"\n=== IDENTIFYING TEAL'C'S RESPONSE PATTERNS ===")
                
                tealc_patterns = [
                    "indeed",
                    "it is",
                    "extremely",
                    "most",
                    "negative",
                    "affirmative",
                    "i do not",
                    "yes",
                    "no"
                ]
                
                found_tealc_patterns = []
                for pattern in tealc_patterns:
                    if pattern in transcription_lower:
                        found_tealc_patterns.append(pattern)
                        print(f"Found Teal'c response pattern: '{pattern}'")
                
                # Create comprehensive analysis
                analysis_results = {
                    'video_source': 'YouTube video: https://www.youtube.com/watch?v=1htKBjuUWec',
                    'scene_description': "Teal'c trying coffee for the first time",
                    'duration_seconds': duration_seconds,
                    'transcription_successful': True,
                    'full_transcription': successful_transcription,
                    'hot_question_patterns_found': found_hot_patterns,
                    'hot_question_context': hot_context,
                    'tealc_response_patterns_found': found_tealc_patterns,
                    'objective_completed': len(found_hot_patterns) > 0
                }
                
                # Save detailed results
                with open('workspace/tealc_dialogue_complete_analysis.json', 'w', encoding='utf-8') as f:
                    json.dump(analysis_results, f, indent=2)
                
                # Create final answer file
                with open('workspace/tealc_final_response.txt', 'w', encoding='utf-8') as f:
                    f.write("TEAL'C'S RESPONSE TO 'ISN'T THAT HOT?'\n")
                    f.write("=" * 50 + "\n\n")
                    f.write(f"Source: YouTube video https://www.youtube.com/watch?v=1htKBjuUWec\n")
                    f.write(f"Scene: Teal'c trying coffee for the first time (Stargate SG-1)\n")
                    f.write(f"Duration: {duration_seconds:.1f} seconds\n\n")
                    f.write(f"COMPLETE DIALOGUE TRANSCRIPTION:\n")
                    f.write(f"'{successful_transcription}'\n\n")
                    
                    if found_hot_patterns:
                        f.write(f"HOT QUESTION FOUND: Yes\n")
                        f.write(f"Patterns detected: {', '.join(found_hot_patterns)}\n")
                        f.write(f"Context: '{hot_context}'\n\n")
                        
                        f.write(f"TEAL'C'S EXACT RESPONSE:\n")
                        f.write(f"Based on the transcription, when someone asks about the coffee being hot,\n")
                        f.write(f"Teal'c's response is contained within this dialogue:\n")
                        f.write(f"'{successful_transcription}'\n\n")
                        
                        if found_tealc_patterns:
                            f.write(f"Teal'c's characteristic response patterns identified: {', '.join(found_tealc_patterns)}\n")
                    else:
                        f.write(f"HOT QUESTION FOUND: No direct 'isn't that hot?' pattern detected\n")
                        f.write(f"However, the complete dialogue is: '{successful_transcription}'\n")
                        f.write(f"Teal'c's response patterns found: {', '.join(found_tealc_patterns)}\n")
                
                print(f"\n*** ANALYSIS COMPLETE ***")
                print(f"Complete transcription: '{successful_transcription}'")
                print(f"Hot question patterns found: {found_hot_patterns}")
                print(f"Teal'c response patterns found: {found_tealc_patterns}")
                print(f"\nResults saved to:")
                print(f"  - workspace/tealc_dialogue_complete_analysis.json")
                print(f"  - workspace/tealc_final_response.txt")
                
                if found_hot_patterns:
                    print(f"\n*** OBJECTIVE ACHIEVED ***")
                    print(f"Successfully identified dialogue containing 'hot' question and Teal'c's response!")
                else:
                    print(f"\n*** PARTIAL SUCCESS ***")
                    print(f"Transcription successful, but no direct 'isn't that hot?' pattern found.")
                    print(f"The complete dialogue may still contain Teal'c's response in different wording.")
                
            else:
                print(f"\n*** ALL TRANSCRIPTION METHODS FAILED ***")
                print("The audio file may contain:")
                print("- Only music/sound effects without speech")
                print("- Very poor audio quality")
                print("- Speech in a different language")
                print("- Only background noise")
                
                # Create failure report
                with open('workspace/transcription_final_failure.txt', 'w') as f:
                    f.write("TRANSCRIPTION FINAL FAILURE REPORT\n")
                    f.write("=" * 40 + "\n\n")
                    f.write(f"Video: Teal'c coffee scene (29 seconds)\n")
                    f.write(f"Audio file: {os.path.basename(enhanced_audio_file)}\n")
                    f.write(f"Audio size: {audio_size} bytes\n")
                    f.write(f"Duration: {duration_seconds:.1f} seconds\n\n")
                    f.write("Methods attempted:\n")
                    for method in transcription_methods:
                        f.write(f"- {method['name']} ({method['lang']})\n")
                    f.write("\nConclusion: Audio does not contain recognizable speech dialogue\n")
                
                print(f"Failure report saved to: workspace/transcription_final_failure.txt")
        
    except Exception as e:
        print(f"\n*** ERROR DURING TRANSCRIPTION PROCESS ***")
        print(f"Error: {str(e)}")
        import traceback
        print(f"Full error details: {traceback.format_exc()}")

print("\n*** TEAL'C DIALOGUE TRANSCRIPTION ATTEMPT COMPLETE ***")
```

## Created Time
2025-08-11 05:08:03
