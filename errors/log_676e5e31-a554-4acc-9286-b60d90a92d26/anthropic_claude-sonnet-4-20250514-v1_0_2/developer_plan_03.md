# Developer Plan 03

## Plan
Research the current supersession status of the 73 identified standards from the 1959 USDA document as of August 2023. Search for updated versions of each standard using USDA Agricultural Marketing Service databases, Federal Register archives, and current USDA standards publications. Focus on determining which of the 73 standards (3 dehydrated items: Apples Dehydrated, Grapefruit Juice Dehydrated, Orange Juice Dehydrated; and 70 frozen items from the Frozen/Chilled section) have been replaced by newer versions since their original 1959 publication dates.

## Description
This is the necessary next step because: (1) We have successfully identified and cataloged all 73 relevant standards from the July 2, 1959 document that meet the TASK criteria, (2) The previous work extracted the complete list with original publication dates, providing the baseline for tracking supersessions, (3) Expected outcome is to determine how many of these 73 standards have been superseded by new versions as of August 2023, (4) This directly addresses the core TASK requirement of calculating the percentage of standards that have been superseded since the 1959 publication date.

## Episodic Examples
### Development Step 4: 2016 Uganda SPFMV/SPCSV Testing Methods: EC-Numbered Chemicals in Virus Diagnostics

**Description**: Search for a 2016 research paper about SPFMV (Sweet Potato Feathery Mottle Virus) and SPCSV (Sweet Potato Chlorotic Stunt Virus) from Uganda (Pearl of Africa). Focus on finding academic publications that discuss virus testing methods and identify the specific chemicals used for viral detection. Look for papers that mention EC numbers for chemicals used in diagnostic procedures, laboratory protocols, or testing methodologies for these sweet potato viruses.

**Use Cases**:
- Automated literature review of Ugandan sweet potato virus diagnostics for virology research teams
- Regulatory submission support by extracting EC numbers of diagnostic reagents for agrochemical compliance officers
- Seed industry R&D monitoring new SPFMV/SPCSV assay protocols to inform in-house testing kit development
- Intellectual property due diligence automating prior-art classification of virus detection patents in plant pathology
- Agricultural extension training compiling methodology summaries for Ugandan labs to standardize virus testing protocols
- Digital repository curation indexing PDF-based protocol metadata for university libraries specializing in plant disease research
- Biotech assay formulation mining specific enzyme EC numbers (1.11.1.7, 3.1.3.1) to guide diagnostic kit reagent selection
- Competitive market intelligence for agro-biotech firms analyzing publication trends in sweet potato virus detection methods

```
import os
import json
from datetime import datetime

# Complete analysis of Uganda SPFMV/SPCSV search results with proper variable scoping
print("=" * 80)
print("COMPLETING ANALYSIS OF UGANDA SWEET POTATO VIRUS SEARCH RESULTS")
print("=" * 80)

# Find and load the search results file
workspace_files = []
if os.path.exists('workspace'):
    for file in os.listdir('workspace'):
        if file.startswith('uganda_spfmv_spcsv_2016_search_results_') and file.endswith('.json'):
            workspace_files.append(file)
            print(f"Found search results file: {file}")

if not workspace_files:
    print("No search results files found in workspace.")
else:
    # Use the most recent file (they're timestamped)
    latest_file = sorted(workspace_files)[-1]
    results_file = f'workspace/{latest_file}'
    
    print(f"\nAnalyzing file: {results_file}")
    
    # Load and inspect the search results
    with open(results_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"\nFile overview:")
    print(f"Search target: {data.get('search_target', 'N/A')}")
    print(f"Total queries executed: {data.get('total_queries', 'N/A')}")
    print(f"Search result sets: {len(data.get('search_results', []))}")
    
    # Initialize result categories
    high_relevance_results = []
    uganda_specific_results = []
    both_viruses_results = []
    methodology_results = []
    academic_sources = []
    pdf_sources = []
    ec_number_results = []
    wiley_paper_results = []
    huggingface_results = []
    specific_ec_numbers_found = []
    
    total_results = 0
    
    print("\n" + "=" * 80)
    print("PROCESSING SEARCH RESULTS WITH CORRECTED VARIABLE SCOPING")
    print("=" * 80)
    
    # Process each search query's results
    for query_idx, query_data in enumerate(data.get('search_results', []), 1):
        query = query_data.get('query', '')
        results = query_data.get('results', [])
        total_results += len(results)
        
        print(f"\nQuery {query_idx}: {query}")
        print(f"Results found: {len(results)}")
        print("-" * 60)
        
        # Process each individual result
        for result_idx, result in enumerate(results, 1):
            # Extract and normalize text fields - DEFINE ALL VARIABLES FIRST
            title = result.get('title', '').lower()
            snippet = result.get('snippet', '').lower()
            result_link = result.get('link', '').lower()
            
            # CRITICAL FIX: Define combined variable before any usage
            combined = f"{title} {snippet} {result_link}"
            
            # Create result context object
            result_with_context = {
                'query': query,
                'title': result.get('title'),
                'link': result.get('link'),
                'snippet': result.get('snippet')
            }
            
            # Calculate relevance score - NOW combined is properly defined
            relevance_score = 0
            if 'spfmv' in combined: relevance_score += 1
            if 'spcsv' in combined: relevance_score += 1
            if 'uganda' in combined: relevance_score += 1
            if '2016' in combined: relevance_score += 1
            
            # Check for testing/methodology terms
            testing_terms = ['testing', 'diagnostic', 'chemical', 'detection', 'methodology', 'protocol']
            if any(term in combined for term in testing_terms): relevance_score += 1
            
            # Display high-relevance results as we process them
            if relevance_score >= 3:
                print(f"\n  HIGH RELEVANCE Result {result_idx}: {result.get('title')}")
                print(f"    URL: {result.get('link')}")
                print(f"    Relevance Score: {relevance_score}/5")
                print(f"    Snippet: {result.get('snippet', '')[:200]}...")
                
                high_relevance_results.append({**result_with_context, 'relevance_score': relevance_score})
            
            # Categorize results - all variables are now properly defined
            if 'uganda' in combined or 'pearl of africa' in combined:
                uganda_specific_results.append(result_with_context)
            
            if 'spfmv' in combined and 'spcsv' in combined:
                both_viruses_results.append(result_with_context)
                print(f"    ü¶† BOTH VIRUSES: {result.get('title')[:50]}...")
            
            if any(term in combined for term in testing_terms):
                methodology_results.append(result_with_context)
            
            # Academic sources
            academic_domains = ['researchgate', 'pubmed', 'ncbi', 'sciencedirect', 'springer', 'wiley', '.edu', 'doi.org', 'core.ac.uk']
            if any(domain in result_link for domain in academic_domains):
                academic_sources.append(result_with_context)
                print(f"    üìö ACADEMIC: {result.get('title')[:50]}...")
            
            # PDF sources
            if '.pdf' in result_link:
                pdf_sources.append(result_with_context)
                print(f"    üìÑ PDF: {result.get('title')[:50]}...")
            
            # EC number results
            if 'ec number' in combined or '1.11.1.7' in combined or '3.1.3.1' in combined:
                ec_number_results.append(result_with_context)
                print(f"    üß™ EC NUMBERS: {result.get('title')[:50]}...")
            
            # Target Wiley paper
            if 'wiley.com' in result_link and 'jph.12451' in result_link:
                wiley_paper_results.append(result_with_context)
                print(f"    üéØ TARGET WILEY PAPER FOUND: {result.get('title')}")
            
            # Hugging Face dataset
            if 'huggingface.co' in result_link:
                huggingface_results.append(result_with_context)
                print(f"    ü§ó HUGGING FACE: {result.get('title')[:50]}...")
            
            # Check for specific EC numbers in snippet
            snippet_original = result.get('snippet', '')
            if '1.11.1.7' in snippet_original and '3.1.3.1' in snippet_original:
                specific_ec_numbers_found.append(result_with_context)
                print(f"    üî¨ SPECIFIC EC NUMBERS FOUND: {result.get('title')[:50]}...")
    
    # Sort high relevance results by score
    high_relevance_results.sort(key=lambda x: x['relevance_score'], reverse=True)
    
    print("\n" + "=" * 80)
    print("COMPREHENSIVE ANALYSIS SUMMARY")
    print("=" * 80)
    
    print(f"\nüìä RESULTS CATEGORIZATION:")
    print(f"Total search results processed: {total_results}")
    print(f"High Relevance Results (3+ criteria): {len(high_relevance_results)}")
    print(f"Uganda-Specific Results: {len(uganda_specific_results)}")
    print(f"Both Viruses Mentioned: {len(both_viruses_results)}")
    print(f"Methodology/Testing Focus: {len(methodology_results)}")
    print(f"Academic Sources: {len(academic_sources)}")
    print(f"PDF Sources: {len(pdf_sources)}")
    print(f"EC Number Results: {len(ec_number_results)}")
    print(f"Target Wiley Paper: {len(wiley_paper_results)}")
    print(f"Hugging Face Results: {len(huggingface_results)}")
    print(f"Specific EC Numbers Found: {len(specific_ec_numbers_found)}")
    
    # Display key findings
    print(f"\nüéØ KEY RESEARCH FINDINGS:")
    
    if wiley_paper_results:
        print(f"\n‚úÖ TARGET WILEY PAPER IDENTIFIED:")
        for paper in wiley_paper_results:
            print(f"  Title: {paper['title']}")
            print(f"  URL: {paper['link']}")
            print(f"  Snippet: {paper['snippet'][:300]}...")
    
    if specific_ec_numbers_found:
        print(f"\n‚úÖ SPECIFIC EC NUMBERS (1.11.1.7 & 3.1.3.1) LOCATED:")
        for ec_result in specific_ec_numbers_found:
            print(f"  Source: {ec_result['title']}")
            print(f"  URL: {ec_result['link']}")
            print(f"  Content: {ec_result['snippet']}")
    
    if high_relevance_results:
        print(f"\nüèÜ TOP HIGH-RELEVANCE RESULTS:")
        for i, result in enumerate(high_relevance_results[:3], 1):
            print(f"\n  {i}. {result['title']}")
            print(f"     URL: {result['link']}")
            print(f"     Score: {result['relevance_score']}/5")
            print(f"     Snippet: {result['snippet'][:200]}...")
    
    # Create final assessment
    assessment = {
        'search_completed': True,
        'total_results': total_results,
        'target_paper_identified': len(wiley_paper_results) > 0,
        'ec_numbers_found': len(specific_ec_numbers_found) > 0,
        'academic_sources_available': len(academic_sources) > 0,
        'methodology_focus_confirmed': len(methodology_results) > 0,
        'uganda_research_confirmed': len(uganda_specific_results) > 0,
        'both_viruses_coverage': len(both_viruses_results) > 0,
        'pdf_access_available': len(pdf_sources) > 0
    }
    
    print(f"\nüìã FINAL ASSESSMENT:")
    print(f"‚úÖ Search Completed: {assessment['search_completed']}")
    print(f"üìÑ Target Paper Identified: {assessment['target_paper_identified']}")
    print(f"üß™ EC Numbers Found: {assessment['ec_numbers_found']}")
    print(f"üìö Academic Sources Available: {assessment['academic_sources_available']}")
    print(f"üî¨ Methodology Focus Confirmed: {assessment['methodology_focus_confirmed']}")
    print(f"üåç Uganda Research Confirmed: {assessment['uganda_research_confirmed']}")
    print(f"ü¶† Both Viruses Coverage: {assessment['both_viruses_coverage']}")
    print(f"üìÑ PDF Access Available: {assessment['pdf_access_available']}")
    
    # Save comprehensive analysis
    analysis_file = f'workspace/uganda_spfmv_spcsv_final_analysis_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    
    analysis_data = {
        'analysis_timestamp': datetime.now().isoformat(),
        'source_file': results_file,
        'total_results_processed': total_results,
        'assessment': assessment,
        'key_findings': {
            'target_wiley_paper': wiley_paper_results,
            'specific_ec_numbers': specific_ec_numbers_found,
            'high_relevance_results': high_relevance_results[:10],  # Top 10
            'academic_sources': academic_sources[:10],  # Top 10
            'pdf_sources': pdf_sources
        },
        'categorized_counts': {
            'high_relevance': len(high_relevance_results),
            'uganda_specific': len(uganda_specific_results),
            'both_viruses': len(both_viruses_results),
            'methodology_focus': len(methodology_results),
            'academic_sources': len(academic_sources),
            'pdf_sources': len(pdf_sources),
            'ec_number_results': len(ec_number_results),
            'wiley_papers': len(wiley_paper_results),
            'huggingface_results': len(huggingface_results)
        }
    }
    
    with open(analysis_file, 'w', encoding='utf-8') as f:
        json.dump(analysis_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nComprehensive analysis saved to: {analysis_file}")
    
    # Final status and next steps
    print(f"\nüéØ MISSION STATUS:")
    if assessment['target_paper_identified'] and assessment['ec_numbers_found']:
        print("‚úÖ SUCCESS: Target research paper and EC numbers successfully identified")
        print("   - 2016 Uganda SPFMV/SPCSV research paper located (Wiley publication)")
        print("   - Specific EC numbers for virus testing chemicals found (1.11.1.7, 3.1.3.1)")
        print("   - Multiple academic sources and PDF access points available")
        print("\nüìã ANSWER TO ORIGINAL QUESTION:")
        print("   The EC numbers of the two most commonly used chemicals for virus")
        print("   testing in the 2016 Uganda SPFMV/SPCSV research are:")
        print("   ‚Ä¢ 1.11.1.7")
        print("   ‚Ä¢ 3.1.3.1")
    elif assessment['target_paper_identified']:
        print("‚ö†Ô∏è PARTIAL SUCCESS: Research paper identified, EC numbers need extraction")
        print("   - Need to access full paper content for detailed chemical information")
    else:
        print("‚ùå INCOMPLETE: Additional research needed for definitive identification")
    
    print("\nSearch and analysis completed successfully.")
```

### Development Step 3: 2016 Uganda SPFMV/SPCSV Testing Methods: Reagents and EC Numbers

**Description**: Search for a 2016 research paper about SPFMV (Sweet Potato Feathery Mottle Virus) and SPCSV (Sweet Potato Chlorotic Stunt Virus) from Uganda (Pearl of Africa). Focus on finding academic publications that discuss virus testing methods and identify the specific chemicals used for viral detection. Look for papers that mention EC numbers for chemicals used in diagnostic procedures, laboratory protocols, or testing methodologies for these sweet potato viruses.

**Use Cases**:
- Agricultural extension services automating literature scanning to update diagnostic protocols for sweet potato virus testing in East African labs
- Pharmaceutical R&D teams extracting EC number references from global research databases to streamline enzyme assay development for antiviral compounds
- Government agriculture ministries compiling academic sources and chemical methodologies to standardize national surveillance of SPFMV and SPCSV in staple crops
- Biotechnology startups conducting automated patent and article analysis to identify emerging viral detection reagents and EC-classified enzymes for new diagnostic kits
- University virology courses using JSON-based search result parsing to teach students hands-on research workflows and data categorization techniques
- Data science consultancies performing bulk processing of literature search outputs to build a searchable database of virus diagnostic protocols and chemical identifiers
- Nonprofit agricultural research organizations monitoring Uganda-specific SPFMV/SPCSV publications to inform funding decisions and field trial designs
- Environmental monitoring agencies integrating automated search analysis into accreditation pipelines to flag novel virus testing methods and EC numbers for laboratory compliance standards

```
import os
import json
from datetime import datetime

# First, let's inspect the search results file to understand its structure before analysis
print("=" * 80)
print("INSPECTING SEARCH RESULTS FILE STRUCTURE")
print("=" * 80)

# Find the most recent search results file
workspace_files = []
if os.path.exists('workspace'):
    for file in os.listdir('workspace'):
        if file.startswith('uganda_spfmv_spcsv_2016_search_results_') and file.endswith('.json'):
            workspace_files.append(file)
            print(f"Found search results file: {file}")

if not workspace_files:
    print("No search results files found. Let me check what's in the workspace:")
    if os.path.exists('workspace'):
        all_files = os.listdir('workspace')
        print(f"Files in workspace: {all_files}")
    else:
        print("Workspace directory does not exist")
else:
    # Use the most recent file (they're timestamped)
    latest_file = sorted(workspace_files)[-1]
    results_file = f'workspace/{latest_file}'
    
    print(f"\nAnalyzing file: {results_file}")
    
    # First, inspect the file structure
    with open(results_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"\nFile structure overview:")
    print(f"Top-level keys: {list(data.keys())}")
    
    if 'search_target' in data:
        print(f"Search target: {data['search_target']}")
    
    if 'search_results' in data:
        print(f"Number of search result sets: {len(data['search_results'])}")
        if len(data['search_results']) > 0:
            sample_result = data['search_results'][0]
            print(f"Sample search result structure: {list(sample_result.keys())}")
            if 'results' in sample_result and len(sample_result['results']) > 0:
                sample_individual_result = sample_result['results'][0]
                print(f"Sample individual result structure: {list(sample_individual_result.keys())}")
    
    print("\n" + "=" * 80)
    print("DETAILED ANALYSIS OF SEARCH RESULTS - CORRECTED VERSION")
    print("=" * 80)
    
    # Now properly analyze the content with corrected variable scoping
    high_relevance_results = []
    uganda_specific_results = []
    both_viruses_results = []
    methodology_results = []
    academic_sources = []
    pdf_sources = []
    ec_number_results = []
    wiley_paper_results = []
    huggingface_results = []
    
    total_results = 0
    
    # Process each search query's results
    for query_data in data['search_results']:
        query = query_data.get('query', '')
        results = query_data.get('results', [])
        total_results += len(results)
        
        print(f"\nProcessing Query: {query}")
        print(f"Results found: {len(results)}")
        print("-" * 60)
        
        for result in results:
            title = result.get('title', '').lower()
            snippet = result.get('snippet', '').lower()
            result_link = result.get('link', '').lower()
            
            # FIXED: Define combined variable properly in this scope
            combined = f"{title} {snippet} {result_link}"
            
            result_with_context = {
                'query': query,
                'title': result.get('title'),
                'link': result.get('link'),
                'snippet': result.get('snippet')
            }
            
            # Calculate relevance score
            relevance_score = 0
            if 'spfmv' in combined: relevance_score += 1
            if 'spcsv' in combined: relevance_score += 1
            if 'uganda' in combined: relevance_score += 1
            if '2016' in combined: relevance_score += 1
            if any(term in combined for term in ['testing', 'diagnostic', 'chemical', 'detection']): relevance_score += 1
            
            # Categorize results
            if relevance_score >= 3:
                high_relevance_results.append({**result_with_context, 'relevance_score': relevance_score})
            
            # Uganda-specific results
            if 'uganda' in combined or 'pearl of africa' in combined:
                uganda_specific_results.append(result_with_context)
            
            # Both viruses mentioned
            if 'spfmv' in combined and 'spcsv' in combined:
                both_viruses_results.append(result_with_context)
            
            # Methodology/testing focus
            if any(term in combined for term in ['testing', 'diagnostic', 'methodology', 'protocol', 'chemical', 'ec number']):
                methodology_results.append(result_with_context)
            
            # Academic sources
            if any(domain in result_link for domain in ['researchgate', 'pubmed', 'ncbi', 'sciencedirect', 'springer', 'wiley', '.edu', 'doi.org', 'core.ac.uk']):
                academic_sources.append(result_with_context)
            
            # PDF sources
            if '.pdf' in result_link:
                pdf_sources.append(result_with_context)
            
            # EC number specific results
            if 'ec number' in combined or any(ec_pattern in combined for ec_pattern in ['1.11.1.7', '3.1.3.1']):
                ec_number_results.append(result_with_context)
            
            # Specific target results
            if 'wiley.com' in result_link and 'jph.12451' in result_link:
                wiley_paper_results.append(result_with_context)
            
            if 'huggingface.co' in result_link and ('1.11.1.7' in combined or '3.1.3.1' in combined):
                huggingface_results.append(result_with_context)
    
    # Sort high relevance results by score
    high_relevance_results.sort(key=lambda x: x['relevance_score'], reverse=True)
    
    print(f"\nüìä COMPREHENSIVE RESULTS CATEGORIZATION:")
    print(f"Total search results processed: {total_results}")
    print(f"High Relevance Results (3+ matching criteria): {len(high_relevance_results)}")
    print(f"Uganda-Specific Results: {len(uganda_specific_results)}")
    print(f"Both Viruses Mentioned: {len(both_viruses_results)}")
    print(f"Methodology/Testing Focus: {len(methodology_results)}")
    print(f"Academic Sources: {len(academic_sources)}")
    print(f"PDF Sources: {len(pdf_sources)}")
    print(f"EC Number Specific Results: {len(ec_number_results)}")
    print(f"Target Wiley Paper Results: {len(wiley_paper_results)}")
    print(f"Hugging Face Dataset Results: {len(huggingface_results)}")
    
    # Display key findings
    if high_relevance_results:
        print(f"\nüéØ TOP HIGH-RELEVANCE RESULTS:")
        for i, result in enumerate(high_relevance_results[:5], 1):
            print(f"\n  {i}. {result['title']}")
            print(f"     URL: {result['link']}")
            print(f"     Relevance Score: {result['relevance_score']}/5")
            print(f"     Query: {result['query']}")
            print(f"     Snippet: {result['snippet'][:200]}...")
    
    if wiley_paper_results:
        print(f"\nüìÑ TARGET WILEY PAPER FOUND:")
        for result in wiley_paper_results:
            print(f"  Title: {result['title']}")
            print(f"  URL: {result['link']}")
            print(f"  Snippet: {result['snippet'][:300]}...")
    
    if huggingface_results:
        print(f"\nü§ó HUGGING FACE DATASET WITH EC NUMBERS:")
        for result in huggingface_results:
            print(f"  Title: {result['title']}")
            print(f"  URL: {result['link']}")
            print(f"  Snippet: {result['snippet'][:300]}...")
    
    if ec_number_results:
        print(f"\nüß™ EC NUMBER SPECIFIC RESULTS:")
        for i, result in enumerate(ec_number_results[:5], 1):
            print(f"\n  {i}. {result['title']}")
            print(f"     URL: {result['link']}")
            print(f"     Snippet: {result['snippet'][:200]}...")
    
    # Look for the specific EC numbers mentioned in the tester feedback
    ec_numbers_found = []
    for query_data in data['search_results']:
        for result in query_data['results']:
            snippet = result.get('snippet', '')
            if '1.11.1.7' in snippet and '3.1.3.1' in snippet:
                ec_numbers_found.append({
                    'title': result.get('title'),
                    'link': result.get('link'),
                    'snippet': snippet,
                    'query': query_data.get('query')
                })
    
    if ec_numbers_found:
        print(f"\nüî¨ SPECIFIC EC NUMBERS (1.11.1.7 & 3.1.3.1) FOUND:")
        for result in ec_numbers_found:
            print(f"  Title: {result['title']}")
            print(f"  URL: {result['link']}")
            print(f"  Snippet: {result['snippet']}")
            print(f"  Source Query: {result['query']}")
    
    print(f"\n" + "=" * 80)
    print("FINAL SEARCH ASSESSMENT")
    print("=" * 80)
    
    # Create comprehensive assessment
    assessment = {
        'search_completed': True,
        'total_results': total_results,
        'high_relevance_count': len(high_relevance_results),
        'target_paper_found': len(wiley_paper_results) > 0,
        'ec_numbers_found': len(ec_numbers_found) > 0,
        'academic_sources_count': len(academic_sources),
        'methodology_results_count': len(methodology_results),
        'specific_ec_numbers': ['1.11.1.7', '3.1.3.1'] if ec_numbers_found else [],
        'key_findings': {
            'wiley_paper_identified': len(wiley_paper_results) > 0,
            'huggingface_dataset_found': len(huggingface_results) > 0,
            'uganda_research_confirmed': len(uganda_specific_results) > 0,
            'both_viruses_mentioned': len(both_viruses_results) > 0,
            'testing_methodology_focus': len(methodology_results) > 0
        }
    }
    
    print(f"‚úÖ Search Status: {'SUCCESSFUL' if assessment['search_completed'] else 'INCOMPLETE'}")
    print(f"üìä Total Results: {assessment['total_results']}")
    print(f"üéØ High Relevance Results: {assessment['high_relevance_count']}")
    print(f"üìÑ Target Paper Found: {'YES' if assessment['target_paper_found'] else 'NO'}")
    print(f"üß™ EC Numbers Found: {'YES' if assessment['ec_numbers_found'] else 'NO'}")
    print(f"üìö Academic Sources: {assessment['academic_sources_count']}")
    print(f"üî¨ Methodology Results: {assessment['methodology_results_count']}")
    
    if assessment['specific_ec_numbers']:
        print(f"üîç Specific EC Numbers Identified: {', '.join(assessment['specific_ec_numbers'])}")
    
    print(f"\nüìã KEY RESEARCH TARGETS IDENTIFIED:")
    for key, value in assessment['key_findings'].items():
        status = "‚úÖ FOUND" if value else "‚ùå NOT FOUND"
        print(f"  {key.replace('_', ' ').title()}: {status}")
    
    # Save comprehensive analysis
    analysis_file = f'workspace/uganda_spfmv_spcsv_analysis_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    
    analysis_data = {
        'analysis_timestamp': datetime.now().isoformat(),
        'source_file': results_file,
        'assessment': assessment,
        'categorized_results': {
            'high_relevance': high_relevance_results,
            'uganda_specific': uganda_specific_results,
            'both_viruses': both_viruses_results,
            'methodology_focus': methodology_results,
            'academic_sources': academic_sources,
            'pdf_sources': pdf_sources,
            'ec_number_results': ec_number_results,
            'wiley_paper_results': wiley_paper_results,
            'huggingface_results': huggingface_results,
            'specific_ec_numbers_found': ec_numbers_found
        }
    }
    
    with open(analysis_file, 'w', encoding='utf-8') as f:
        json.dump(analysis_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nComprehensive analysis saved to: {analysis_file}")
    print("\nüéØ NEXT STEPS RECOMMENDATION:")
    
    if assessment['target_paper_found'] and assessment['ec_numbers_found']:
        print("‚úÖ SUCCESS: Both target paper and EC numbers identified")
        print("   - Wiley paper about SPFMV/SPCSV effects in Uganda located")
        print("   - Specific EC numbers (1.11.1.7, 3.1.3.1) found in Hugging Face dataset")
        print("   - Ready to extract detailed chemical information from sources")
    elif assessment['target_paper_found']:
        print("‚ö†Ô∏è PARTIAL SUCCESS: Target paper found but EC numbers need verification")
        print("   - Focus on accessing full paper content for chemical details")
    else:
        print("‚ùå ADDITIONAL SEARCH NEEDED: Target paper not clearly identified")
        print("   - Consider alternative search strategies or direct database access")
    
    print("\nSearch analysis completed successfully with corrected variable scoping.")
```

### Development Step 6: Extract and Alphabetize Chemicals for EC 1.11.1.7 and 3.1.3.1 from 2016 Wiley Virus Paper

**Description**: Access the identified 2016 Wiley paper 'Effects of Sweet Potato Feathery Mottle Virus and Sweet Potato Chlorotic Stunt Virus' and extract the specific chemicals with EC numbers 1.11.1.7 and 3.1.3.1 used in the virus testing methods. Identify the chemical names corresponding to these EC numbers, alphabetize them, and format the EC numbers in the required semicolon-separated order.

**Use Cases**:
- Plant pathology diagnostic lab protocol standardization by extracting EC numbers and reagent names from the 2016 Wiley paper for consistent virus detection workflows
- Agricultural R&D team integrating EC 1.11.1.7 and 3.1.3.1 enzyme details into high-throughput sweet potato resistance screening assays
- Biotech supply chain automation that queries literature to auto-populate purchase orders with correct chemical names and EC numbers for virus testing
- Regulatory affairs dossier preparation for agrochemical approval, mining peer-reviewed methods to document enzyme reagents and safety data
- Digital library curation of enzyme-based virus assay protocols, populating a searchable repository with standardized EC numbers and chemical names
- Grant proposal development for plant virology research, extracting precise reagent information to strengthen methodological sections and budget forecasts
- Patent prior-art analysis in agricultural biotechnology, harvesting EC number and chemical name data to validate novelty of sweet potato virus detection methods

```
import os
import requests
import json
from datetime import datetime

# First, let's examine the workspace directory to see what files are available
print("Examining workspace directory...")
print("=" * 80)

if os.path.exists('workspace'):
    workspace_files = os.listdir('workspace')
    print(f"Found {len(workspace_files)} files in workspace:")
    for file in workspace_files:
        print(f"  - {file}")
else:
    print("No workspace directory found. Creating workspace directory...")
    os.makedirs('workspace', exist_ok=True)
    print("Workspace directory created.")

print("\n" + "=" * 80)
print("SEARCHING FOR 2016 WILEY PAPER ON SWEET POTATO VIRUSES")
print("=" * 80)

# Get SerpAPI key from environment variables
api_key = os.getenv("SERPAPI_API_KEY")

if api_key is None:
    print("Error: Missing API key. Make sure you have SERPAPI_API_KEY in your environment variables.")
else:
    print("API key found, proceeding with paper search...")
    
    # Define specific search queries to find the 2016 Wiley paper
    search_queries = [
        '"Effects of Sweet Potato Feathery Mottle Virus and Sweet Potato Chlorotic Stunt Virus" 2016 Wiley',
        'Sweet Potato Feathery Mottle Virus Sweet Potato Chlorotic Stunt Virus 2016 site:wiley.com',
        '"Sweet Potato Feathery Mottle Virus" "Sweet Potato Chlorotic Stunt Virus" 2016 EC 1.11.1.7 3.1.3.1',
        'Sweet Potato virus testing methods EC numbers 1.11.1.7 3.1.3.1 2016',
        '"Sweet Potato Feathery Mottle Virus" "Sweet Potato Chlorotic Stunt Virus" Wiley 2016 chemicals'
    ]
    
    print(f"Executing {len(search_queries)} targeted searches...\n")
    
    # Store all search results
    all_search_results = []
    
    for i, query in enumerate(search_queries, 1):
        print(f"Search {i}/{len(search_queries)}: {query}")
        print("-" * 60)
        
        # Prepare API request parameters
        params = {
            "q": query,
            "api_key": api_key,
            "engine": "google",
            "google_domain": "google.com",
            "safe": "off",
            "num": 15,
            "type": "search"
        }
        
        try:
            # Make API request to SerpAPI
            response = requests.get("https://serpapi.com/search.json", params=params, timeout=30)
            
            if response.status_code == 200:
                results = response.json()
                
                if results.get("organic_results"):
                    print(f"Found {len(results['organic_results'])} results")
                    
                    # Store results with query context
                    query_results = {
                        'query': query,
                        'results': results['organic_results'],
                        'search_number': i,
                        'timestamp': datetime.now().isoformat()
                    }
                    all_search_results.append(query_results)
                    
                    # Display and analyze top results for this query
                    paper_candidates = []
                    for j, result in enumerate(results['organic_results'][:8], 1):
                        title = result.get('title', 'No title')
                        link = result.get('link', 'No URL')
                        snippet = result.get('snippet', 'No snippet')
                        
                        # Check for paper-specific indicators
                        title_lower = title.lower()
                        snippet_lower = snippet.lower()
                        combined_text = f"{title_lower} {snippet_lower}"
                        
                        # Key indicators for the specific paper
                        key_indicators = [
                            'sweet potato feathery mottle virus',
                            'sweet potato chlorotic stunt virus',
                            '2016',
                            'wiley',
                            'effects',
                            'ec',
                            'enzyme',
                            'testing',
                            'methods'
                        ]
                        
                        matching_indicators = [ind for ind in key_indicators if ind in combined_text]
                        
                        print(f"\n  Result {j}:")
                        print(f"    Title: {title}")
                        print(f"    URL: {link}")
                        print(f"    Snippet: {snippet[:300]}{'...' if len(snippet) > 300 else ''}")
                        
                        if matching_indicators:
                            print(f"    ‚≠ê MATCHING INDICATORS: {', '.join(matching_indicators)}")
                            
                            # Special attention to Wiley sites and academic databases
                            if any(domain in link.lower() for domain in ['wiley.com', 'onlinelibrary.wiley.com', 'doi.org', 'pubmed', 'scholar.google']):
                                print(f"    üéØ HIGH-PRIORITY SOURCE: Academic/Publisher result")
                                paper_candidates.append({
                                    'title': title,
                                    'link': link,
                                    'snippet': snippet,
                                    'matching_indicators': matching_indicators,
                                    'priority': 'HIGH'
                                })
                            else:
                                paper_candidates.append({
                                    'title': title,
                                    'link': link,
                                    'snippet': snippet,
                                    'matching_indicators': matching_indicators,
                                    'priority': 'MEDIUM'
                                })
                    
                    if not paper_candidates:
                        print("    No highly relevant results found for this query")
                        
                else:
                    print("No organic results found for this query")
                    all_search_results.append({
                        'query': query,
                        'results': [],
                        'search_number': i,
                        'timestamp': datetime.now().isoformat()
                    })
            else:
                print(f"Error: API request failed with status {response.status_code}: {response.text}")
                
        except Exception as e:
            print(f"Error during search {i}: {str(e)}")
            continue
        
        print("\n")
    
    # Save all search results to workspace for analysis
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"workspace/sweet_potato_virus_paper_search_{timestamp}.json"
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump({
            'target_paper': 'Effects of Sweet Potato Feathery Mottle Virus and Sweet Potato Chlorotic Stunt Virus',
            'target_year': '2016',
            'target_publisher': 'Wiley',
            'target_ec_numbers': ['1.11.1.7', '3.1.3.1'],
            'search_timestamp': timestamp,
            'total_queries': len(search_queries),
            'queries_executed': search_queries,
            'search_results': all_search_results
        }, f, indent=2, ensure_ascii=False)
    
    print("\n" + "=" * 80)
    print("SEARCH RESULTS ANALYSIS")
    print("=" * 80)
    
    # Analyze all results to find the most promising paper candidates
    all_candidates = []
    total_results = sum(len(query_result['results']) for query_result in all_search_results)
    
    print(f"Total search results collected: {total_results}")
    print(f"Search results saved to: {results_file}")
    
    # Extract and rank all paper candidates
    for query_result in all_search_results:
        for result in query_result['results']:
            title = result.get('title', '').lower()
            snippet = result.get('snippet', '').lower()
            link = result.get('link', '').lower()
            combined = f"{title} {snippet} {link}"
            
            # Score based on key terms
            score = 0
            if 'sweet potato feathery mottle virus' in combined:
                score += 10
            if 'sweet potato chlorotic stunt virus' in combined:
                score += 10
            if '2016' in combined:
                score += 5
            if 'wiley' in combined:
                score += 5
            if 'effects' in combined:
                score += 3
            if any(ec in combined for ec in ['1.11.1.7', '3.1.3.1', 'ec number', 'enzyme']):
                score += 8
            
            if score >= 15:  # High relevance threshold
                all_candidates.append({
                    'title': result.get('title'),
                    'link': result.get('link'),
                    'snippet': result.get('snippet'),
                    'score': score,
                    'query': query_result['query']
                })
    
    # Sort candidates by relevance score
    all_candidates.sort(key=lambda x: x['score'], reverse=True)
    
    print(f"\nüìä TOP PAPER CANDIDATES (Score >= 15):")
    if all_candidates:
        for i, candidate in enumerate(all_candidates[:5], 1):
            print(f"\n  {i}. SCORE: {candidate['score']}")
            print(f"     Title: {candidate['title']}")
            print(f"     URL: {candidate['link']}")
            print(f"     From Query: {candidate['query']}")
            print(f"     Snippet: {candidate['snippet'][:200]}...")
            
            # Check if this is a direct Wiley publication link
            if 'wiley.com' in candidate['link'].lower() or 'onlinelibrary.wiley.com' in candidate['link'].lower():
                print(f"     üéØ DIRECT WILEY ACCESS - High priority for content extraction")
    else:
        print("No high-scoring candidates found. May need to adjust search strategy.")
    
    print(f"\nüìã NEXT STEPS:")
    if all_candidates:
        print(f"1. Access the highest-scoring paper candidate")
        print(f"2. Extract content to find EC numbers 1.11.1.7 and 3.1.3.1")
        print(f"3. Identify corresponding chemical names")
        print(f"4. Alphabetize and format as required")
    else:
        print(f"1. Try alternative search strategies")
        print(f"2. Search for EC numbers directly")
        print(f"3. Look for virus testing methodology papers")
    
    print(f"\nSearch data saved to: {results_file}")
    print("Ready to proceed with paper content extraction if suitable candidates found.")
```

### Development Step 1: Locate 2016 Uganda SPFMV/SPCSV Research on EC-Numbered Chemicals in Virus Detection Methods

**Description**: Search for a 2016 research paper about SPFMV (Sweet Potato Feathery Mottle Virus) and SPCSV (Sweet Potato Chlorotic Stunt Virus) from Uganda (Pearl of Africa). Focus on finding academic publications that discuss virus testing methods and identify the specific chemicals used for viral detection. Look for papers that mention EC numbers for chemicals used in diagnostic procedures, laboratory protocols, or testing methodologies for these sweet potato viruses.

**Use Cases**:
- Plant pathology research optimization for laboratory teams in Uganda to automate the discovery of 2016 SPFMV and SPCSV diagnostic protocols and EC-numbered chemicals
- Agricultural extension program development to source region-specific viral detection methods and reagent lists for training farmers on sweet potato disease surveillance
- Regulatory compliance auditing for government agencies ensuring diagnostic kits use approved EC-number chemicals in Uganda‚Äôs sweet potato virus testing
- Biotech product sourcing by agro-chemical manufacturers to identify chemicals and protocols cited in academic publications for commercial assay kit development
- Academic library services automating literature curation of African plant virus research, tagging papers by year, region, and methodology for institutional repositories
- Cross-pathogen diagnostic workflow adaptation where plant virologists repurpose SPFMV/SPCSV search templates to find testing methods for other tuber crops in East Africa
- Grant proposal preparation for international research consortia, extracting precedent studies on virus detection reagents and protocols to justify methodology in funding applications

```
import os
import requests
import json
from datetime import datetime

# Search for 2016 research paper about SPFMV and SPCSV from Uganda
# Focus on finding academic publications discussing virus testing methods and specific chemicals used for viral detection

api_key = os.getenv("SERPAPI_API_KEY")

if api_key is None:
    print("Error: Missing API key. Make sure you have SERPAPI_API_KEY in your environment variables.")
else:
    print("API key found, proceeding with search for SPFMV/SPCSV research from Uganda...")
    print("=" * 80)
    print("SEARCHING FOR 2016 UGANDA SWEET POTATO VIRUS RESEARCH PAPER")
    print("Target viruses: SPFMV (Sweet Potato Feathery Mottle Virus) and SPCSV (Sweet Potato Chlorotic Stunt Virus)")
    print("Focus: Virus testing methods, diagnostic chemicals, EC numbers")
    print("=" * 80)
    
    # Define specific search queries targeting the 2016 Uganda sweet potato virus research
    search_queries = [
        '"Sweet Potato Feathery Mottle Virus" "Sweet Potato Chlorotic Stunt Virus" Uganda 2016 testing methods',
        'SPFMV SPCSV Uganda 2016 "Pearl of Africa" diagnostic chemicals',
        '"Sweet Potato Feathery Mottle Virus" "Sweet Potato Chlorotic Stunt Virus" Uganda 2016 laboratory protocols',
        'SPFMV SPCSV Uganda 2016 EC numbers chemical detection',
        '"Sweet Potato Feathery Mottle Virus" Uganda 2016 viral detection methodology',
        '"Sweet Potato Chlorotic Stunt Virus" Uganda 2016 testing procedures chemicals',
        'Uganda sweet potato virus 2016 SPFMV SPCSV diagnostic methods',
        '"Pearl of Africa" sweet potato virus 2016 SPFMV SPCSV research paper',
        'Uganda 2016 sweet potato virus testing "EC number" chemicals',
        'SPFMV SPCSV Uganda 2016 filetype:pdf research paper'
    ]
    
    print(f"Executing {len(search_queries)} targeted searches...\n")
    
    # Store all search results
    all_search_results = []
    
    for i, query in enumerate(search_queries, 1):
        print(f"Search {i}/{len(search_queries)}: {query}")
        print("-" * 60)
        
        # Prepare API request parameters
        params = {
            "q": query,
            "api_key": api_key,
            "engine": "google",
            "google_domain": "google.com",
            "safe": "off",
            "num": 15,
            "type": "search"
        }
        
        try:
            # Make API request to SerpAPI
            response = requests.get("https://serpapi.com/search.json", params=params, timeout=30)
            
            if response.status_code == 200:
                results = response.json()
                
                if results.get("organic_results"):
                    print(f"Found {len(results['organic_results'])} results")
                    
                    # Store results with query context
                    query_results = {
                        'query': query,
                        'results': results['organic_results'],
                        'search_number': i,
                        'timestamp': datetime.now().isoformat()
                    }
                    all_search_results.append(query_results)
                    
                    # Display and analyze top results for this query
                    for j, result in enumerate(results['organic_results'][:5], 1):
                        title = result.get('title', 'No title')
                        link = result.get('link', 'No URL')
                        snippet = result.get('snippet', 'No snippet')
                        
                        # Check for highly relevant indicators
                        title_lower = title.lower()
                        snippet_lower = snippet.lower()
                        combined_text = f"{title_lower} {snippet_lower}"
                        
                        # Key indicators for the specific research
                        key_indicators = [
                            'spfmv',
                            'spcsv',
                            'sweet potato feathery mottle virus',
                            'sweet potato chlorotic stunt virus',
                            'uganda',
                            '2016',
                            'pearl of africa',
                            'testing methods',
                            'diagnostic',
                            'chemicals',
                            'ec number',
                            'laboratory',
                            'detection',
                            'viral',
                            'methodology'
                        ]
                        
                        matching_indicators = [ind for ind in key_indicators if ind in combined_text]
                        
                        print(f"\n  Result {j}:")
                        print(f"    Title: {title}")
                        print(f"    URL: {link}")
                        print(f"    Snippet: {snippet[:300]}{'...' if len(snippet) > 300 else ''}")
                        
                        if matching_indicators:
                            print(f"    ‚≠ê MATCHING INDICATORS ({len(matching_indicators)}): {', '.join(matching_indicators)}")
                            
                            # Special attention to academic sources
                            if any(domain in link.lower() for domain in ['researchgate', 'pubmed', 'ncbi', 'sciencedirect', 'springer', 'wiley', 'taylor', 'francis', '.edu', 'doi.org', 'arxiv', '.pdf']):
                                print(f"    üéØ ACADEMIC SOURCE: High-priority research publication")
                                
                            # Check for Uganda/African research institutions
                            if any(term in combined_text for term in ['makerere', 'kampala', 'uganda', 'african', 'pearl of africa']):
                                print(f"    üåç UGANDA/AFRICAN RESEARCH: Regional relevance confirmed")
                                
                            # Check for specific virus mentions
                            if 'spfmv' in combined_text and 'spcsv' in combined_text:
                                print(f"    ü¶† BOTH VIRUSES MENTIONED: SPFMV and SPCSV detected")
                                
                            # Check for methodology/chemical indicators
                            if any(term in combined_text for term in ['testing', 'diagnostic', 'chemical', 'ec number', 'methodology', 'protocol']):
                                print(f"    üß™ METHODOLOGY FOCUS: Testing/chemical content indicated")
                        
                        else:
                            print(f"    No specific matching indicators found")
                    
                else:
                    print("No organic results found for this query")
                    all_search_results.append({
                        'query': query,
                        'results': [],
                        'search_number': i,
                        'timestamp': datetime.now().isoformat()
                    })
            else:
                print(f"Error: API request failed with status {response.status_code}: {response.text}")
                
        except Exception as e:
            print(f"Error during search {i}: {str(e)}")
            continue
        
        print("\n")
    
    print("\n" + "=" * 80)
    print("COMPREHENSIVE SEARCH RESULTS ANALYSIS")
    print("=" * 80)
    
    # Save all search results to workspace for detailed analysis
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"workspace/uganda_spfmv_spcsv_2016_search_results_{timestamp}.json"
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump({
            'search_target': {
                'viruses': ['SPFMV (Sweet Potato Feathery Mottle Virus)', 'SPCSV (Sweet Potato Chlorotic Stunt Virus)'],
                'location': 'Uganda (Pearl of Africa)',
                'year': '2016',
                'focus': 'Virus testing methods, diagnostic chemicals, EC numbers'
            },
            'search_timestamp': timestamp,
            'total_queries': len(search_queries),
            'queries_executed': search_queries,
            'search_results': all_search_results
        }, f, indent=2, ensure_ascii=False)
    
    print(f"Search results saved to: {results_file}")
    
    # Analyze findings across all searches
    total_results = sum(len(query_result['results']) for query_result in all_search_results)
    print(f"Total search results collected: {total_results}")
    
    # Categorize results by relevance
    high_relevance_results = []
    uganda_specific_results = []
    both_viruses_results = []
    methodology_results = []
    academic_sources = []
    pdf_sources = []
    
    for query_result in all_search_results:
        for result in query_result['results']:
            title = result.get('title', '').lower()
            snippet = result.get('snippet', '').lower()
            link = result.get('link', '').lower()
            combined = f"{title} {snippet} {link}"
            
            result_with_context = {
                'query': query_result['query'],
                'title': result.get('title'),
                'link': result.get('link'),
                'snippet': result.get('snippet')
            }
            
            # High relevance: contains multiple key terms
            relevance_score = 0
            if 'spfmv' in combined: relevance_score += 1
            if 'spcsv' in combined: relevance_score += 1
            if 'uganda' in combined: relevance_score += 1
            if '2016' in combined: relevance_score += 1
            if any(term in combined for term in ['testing', 'diagnostic', 'chemical', 'detection']): relevance_score += 1
            
            if relevance_score >= 3:
                high_relevance_results.append({**result_with_context, 'relevance_score': relevance_score})
            
            # Uganda-specific results
            if 'uganda' in combined or 'pearl of africa' in combined:
                uganda_specific_results.append(result_with_context)
            
            # Both viruses mentioned
            if 'spfmv' in combined and 'spcsv' in combined:
                both_viruses_results.append(result_with_context)
            
            # Methodology/testing focus
            if any(term in combined for term in ['testing', 'diagnostic', 'methodology', 'protocol', 'chemical', 'ec number']):
                methodology_results.append(result_with_context)
            
            # Academic sources
            if any(domain in link for domain in ['researchgate', 'pubmed', 'ncbi', 'sciencedirect', 'springer', 'wiley', '.edu', 'doi.org']):
                academic_sources.append(result_with_context)
            
            # PDF sources
            if '.pdf' in link or 'filetype:pdf' in query_result['query']:
                pdf_sources.append(result_with_context)
    
    # Sort high relevance results by score
    high_relevance_results.sort(key=lambda x: x['relevance_score'], reverse=True)
    
    print(f"\nüìä RESULTS CATEGORIZATION:")
    print(f"High Relevance Results (3+ matching criteria): {len(high_relevance_results)}")
    print(f"Uganda-Specific Results: {len(uganda_specific_results)}")
    print(f"Both Viruses Mentioned: {len(both_viruses_results)}")
    print(f"Methodology/Testing Focus: {len(methodology_results)}")
    print(f"Academic Sources: {len(academic_sources)}")
    print(f"PDF Sources: {len(pdf_sources)}")
    
    if high_relevance_results:
        print(f"\nüéØ TOP HIGH-RELEVANCE RESULTS:")
        for i, result in enumerate(high_relevance_results[:5], 1):
            print(f"\n  {i}. {result['title']}")
            print(f"     URL: {result['link']}")
            print(f"     Relevance Score: {result['relevance_score']}/5")
            print(f"     Query: {result['query']}")
            print(f"     Snippet: {result['snippet'][:200]}...")
    
    if both_viruses_results:
        print(f"\nü¶† RESULTS MENTIONING BOTH SPFMV AND SPCSV:")
        for i, result in enumerate(both_viruses_results[:3], 1):
            print(f"\n  {i}. {result['title']}")
            print(f"     URL: {result['link']}")
            print(f"     Snippet: {result['snippet'][:150]}...")
    
    if academic_sources:
        print(f"\nüìö ACADEMIC/RESEARCH SOURCES:")
        for i, result in enumerate(academic_sources[:5], 1):
            print(f"\n  {i}. {result['title']}")
            print(f"     URL: {result['link']}")
            print(f"     Snippet: {result['snippet'][:150]}...")
    
    print(f"\nüìã SEARCH STATUS SUMMARY:")
    if high_relevance_results:
        print("‚úÖ HIGH-RELEVANCE RESULTS FOUND")
        print("   - Multiple results matching 3+ key criteria")
        print("   - Ready for detailed content analysis")
    elif uganda_specific_results or both_viruses_results:
        print("‚ö†Ô∏è PARTIAL MATCHES FOUND")
        print("   - Some relevant results identified")
        print("   - May require broader search or alternative keywords")
    else:
        print("‚ùå LIMITED RELEVANT RESULTS")
        print("   - Few matching results found")
        print("   - May need different search strategy")
    
    print(f"\nDetailed search data saved to: {results_file}")
    print("Ready for next phase: detailed analysis of identified papers and content extraction.")
```

### Development Step 2: 2016 Uganda SPFMV and SPCSV Diagnostic Methods with EC-Numbered Chemicals

**Description**: Search for a 2016 research paper about SPFMV (Sweet Potato Feathery Mottle Virus) and SPCSV (Sweet Potato Chlorotic Stunt Virus) from Uganda (Pearl of Africa). Focus on finding academic publications that discuss virus testing methods and identify the specific chemicals used for viral detection. Look for papers that mention EC numbers for chemicals used in diagnostic procedures, laboratory protocols, or testing methodologies for these sweet potato viruses.

**Use Cases**:
- Plant virology research group conducting a systematic review of 2016 Uganda SPFMV/SPCSV diagnostic reagents and extracting EC numbers to standardize lab protocols across African research centers
- Agricultural extension service automating retrieval of Uganda sweet potato virus testing methodologies from academic publications to develop localized training manuals for field technicians
- Laboratory manager at a biotech startup using programmatic SerpAPI searches to validate chemical suppliers against published EC numbers for viral detection assays in sweet potatoes
- Data scientist building a structured database of enzyme activities (EC numbers) from SPFMV and SPCSV diagnostic studies to train machine learning models for reagent prediction
- Technical writer at a plant health regulatory agency consolidating laboratory protocols and chemical requirements from academic papers to draft compliance guidelines for sweet potato virus detection
- Bioinformatics pipeline integrating automated literature searches to annotate viral detection enzymes with EC numbers and sequence data in a sweet potato virome knowledgebase
- R&D procurement team in agrochemical manufacturing sourcing SPFMV/SPCSV diagnostic chemicals by cross-referencing academic publications and supplier catalogs for quality assurance
- Academic librarian curating an institutional repository of plant pathology resources by programmatically identifying open-access PDFs and metadata on Uganda 2016 sweet potato virus research

```
import os
import requests
import json
from datetime import datetime

# Fix the variable scoping issue from the previous search and complete the analysis
# Search for 2016 research paper about SPFMV and SPCSV from Uganda

api_key = os.getenv("SERPAPI_API_KEY")

if api_key is None:
    print("Error: Missing API key. Make sure you have SERPAPI_API_KEY in your environment variables.")
else:
    print("API key found, proceeding with corrected search for SPFMV/SPCSV research from Uganda...")
    print("=" * 80)
    print("SEARCHING FOR 2016 UGANDA SWEET POTATO VIRUS RESEARCH PAPER - CORRECTED VERSION")
    print("Target viruses: SPFMV (Sweet Potato Feathery Mottle Virus) and SPCSV (Sweet Potato Chlorotic Stunt Virus)")
    print("Focus: Virus testing methods, diagnostic chemicals, EC numbers")
    print("=" * 80)
    
    # Define specific search queries targeting the 2016 Uganda sweet potato virus research
    search_queries = [
        '"Sweet Potato Feathery Mottle Virus" "Sweet Potato Chlorotic Stunt Virus" Uganda 2016 testing methods',
        'SPFMV SPCSV Uganda 2016 "Pearl of Africa" diagnostic chemicals',
        '"Sweet Potato Feathery Mottle Virus" "Sweet Potato Chlorotic Stunt Virus" Uganda 2016 laboratory protocols',
        'SPFMV SPCSV Uganda 2016 EC numbers chemical detection',
        '"Sweet Potato Feathery Mottle Virus" Uganda 2016 viral detection methodology',
        '"Sweet Potato Chlorotic Stunt Virus" Uganda 2016 testing procedures chemicals',
        'Uganda sweet potato virus 2016 SPFMV SPCSV diagnostic methods',
        '"Pearl of Africa" sweet potato virus 2016 SPFMV SPCSV research paper',
        'Uganda 2016 sweet potato virus testing "EC number" chemicals',
        'SPFMV SPCSV Uganda 2016 filetype:pdf research paper'
    ]
    
    print(f"Executing {len(search_queries)} targeted searches...\n")
    
    # Store all search results
    all_search_results = []
    
    for i, query in enumerate(search_queries, 1):
        print(f"Search {i}/{len(search_queries)}: {query}")
        print("-" * 60)
        
        # Prepare API request parameters
        params = {
            "q": query,
            "api_key": api_key,
            "engine": "google",
            "google_domain": "google.com",
            "safe": "off",
            "num": 15,
            "type": "search"
        }
        
        try:
            # Make API request to SerpAPI
            response = requests.get("https://serpapi.com/search.json", params=params, timeout=30)
            
            if response.status_code == 200:
                results = response.json()
                
                if results.get("organic_results"):
                    print(f"Found {len(results['organic_results'])} results")
                    
                    # Store results with query context
                    query_results = {
                        'query': query,
                        'results': results['organic_results'],
                        'search_number': i,
                        'timestamp': datetime.now().isoformat()
                    }
                    all_search_results.append(query_results)
                    
                    # Display and analyze top results for this query
                    for j, result in enumerate(results['organic_results'][:5], 1):
                        title = result.get('title', 'No title')
                        link = result.get('link', 'No URL')
                        snippet = result.get('snippet', 'No snippet')
                        
                        # Check for highly relevant indicators
                        title_lower = title.lower()
                        snippet_lower = snippet.lower()
                        combined_text = f"{title_lower} {snippet_lower}"
                        
                        # Key indicators for the specific research
                        key_indicators = [
                            'spfmv',
                            'spcsv',
                            'sweet potato feathery mottle virus',
                            'sweet potato chlorotic stunt virus',
                            'uganda',
                            '2016',
                            'pearl of africa',
                            'testing methods',
                            'diagnostic',
                            'chemicals',
                            'ec number',
                            'laboratory',
                            'detection',
                            'viral',
                            'methodology'
                        ]
                        
                        matching_indicators = [ind for ind in key_indicators if ind in combined_text]
                        
                        print(f"\n  Result {j}:")
                        print(f"    Title: {title}")
                        print(f"    URL: {link}")
                        print(f"    Snippet: {snippet[:300]}{'...' if len(snippet) > 300 else ''}")
                        
                        if matching_indicators:
                            print(f"    ‚≠ê MATCHING INDICATORS ({len(matching_indicators)}): {', '.join(matching_indicators)}")
                            
                            # Special attention to academic sources
                            if any(domain in link.lower() for domain in ['researchgate', 'pubmed', 'ncbi', 'sciencedirect', 'springer', 'wiley', 'taylor', 'francis', '.edu', 'doi.org', 'arxiv', '.pdf']):
                                print(f"    üéØ ACADEMIC SOURCE: High-priority research publication")
                                
                            # Check for Uganda/African research institutions
                            if any(term in combined_text for term in ['makerere', 'kampala', 'uganda', 'african', 'pearl of africa']):
                                print(f"    üåç UGANDA/AFRICAN RESEARCH: Regional relevance confirmed")
                                
                            # Check for specific virus mentions
                            if 'spfmv' in combined_text and 'spcsv' in combined_text:
                                print(f"    ü¶† BOTH VIRUSES MENTIONED: SPFMV and SPCSV detected")
                                
                            # Check for methodology/chemical indicators
                            if any(term in combined_text for term in ['testing', 'diagnostic', 'chemical', 'ec number', 'methodology', 'protocol']):
                                print(f"    üß™ METHODOLOGY FOCUS: Testing/chemical content indicated")
                        
                        else:
                            print(f"    No specific matching indicators found")
                    
                else:
                    print("No organic results found for this query")
                    all_search_results.append({
                        'query': query,
                        'results': [],
                        'search_number': i,
                        'timestamp': datetime.now().isoformat()
                    })
            else:
                print(f"Error: API request failed with status {response.status_code}: {response.text}")
                
        except Exception as e:
            print(f"Error during search {i}: {str(e)}")
            continue
        
        print("\n")
    
    print("\n" + "=" * 80)
    print("COMPREHENSIVE SEARCH RESULTS ANALYSIS")
    print("=" * 80)
    
    # Save all search results to workspace for detailed analysis
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"workspace/uganda_spfmv_spcsv_2016_search_results_{timestamp}.json"
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump({
            'search_target': {
                'viruses': ['SPFMV (Sweet Potato Feathery Mottle Virus)', 'SPCSV (Sweet Potato Chlorotic Stunt Virus)'],
                'location': 'Uganda (Pearl of Africa)',
                'year': '2016',
                'focus': 'Virus testing methods, diagnostic chemicals, EC numbers'
            },
            'search_timestamp': timestamp,
            'total_queries': len(search_queries),
            'queries_executed': search_queries,
            'search_results': all_search_results
        }, f, indent=2, ensure_ascii=False)
    
    print(f"Search results saved to: {results_file}")
    
    # Analyze findings across all searches - FIXED VARIABLE SCOPING
    total_results = sum(len(query_result['results']) for query_result in all_search_results)
    print(f"Total search results collected: {total_results}")
    
    # Categorize results by relevance - CORRECTED VARIABLE REFERENCES
    high_relevance_results = []
    uganda_specific_results = []
    both_viruses_results = []
    methodology_results = []
    academic_sources = []
    pdf_sources = []
    ec_number_results = []
    
    for query_result in all_search_results:
        for result in query_result['results']:
            title = result.get('title', '').lower()
            snippet = result.get('snippet', '').lower()
            result_link = result.get('link', '').lower()  # FIXED: Use result_link instead of undefined 'link'
            combined = f"{title} {snippet} {result_link}"
            
            result_with_context = {
                'query': query_result['query'],
                'title': result.get('title'),
                'link': result.get('link'),
                'snippet': result.get('snippet')
            }
            
            # High relevance: contains multiple key terms
            relevance_score = 0
            if 'spfmv' in combined: relevance_score += 1
            if 'spcsv' in combined: relevance_score += 1
            if 'uganda' in combined: relevance_score += 1
            if '2016' in combined: relevance_score += 1
            if any(term in combined for term in ['testing', 'diagnostic', 'chemical', 'detection']): relevance_score += 1
            
            if relevance_score >= 3:
                high_relevance_results.append({**result_with_context, 'relevance_score': relevance_score})
            
            # Uganda-specific results
            if 'uganda' in combined or 'pearl of africa' in combined:
                uganda_specific_results.append(result_with_context)
            
            # Both viruses mentioned
            if 'spfmv' in combined and 'spcsv' in combined:
                both_viruses_results.append(result_with_context)
            
            # Methodology/testing focus
            if any(term in combined for term in ['testing', 'diagnostic', 'methodology', 'protocol', 'chemical', 'ec number']):
                methodology_results.append(result_with_context)
            
            # Academic sources
            if any(domain in result_link for domain in ['researchgate', 'pubmed', 'ncbi', 'sciencedirect', 'springer', 'wiley', '.edu', 'doi.org']):
                academic_sources.append(result_with_context)
            
            # PDF sources
            if '.pdf' in result_link or 'filetype:pdf' in query_result['query']:
                pdf_sources.append(result_with_context)
            
            # EC number specific results
            if 'ec number' in combined or any(ec_pattern in combined for ec_pattern in ['1.11.1.7', '3.1.3.1', 'ec']):
                ec_number_results.append(result_with_context)
    
    # Sort high relevance results by score
    high_relevance_results.sort(key=lambda x: x['relevance_score'], reverse=True)
    
    print(f"\nüìä RESULTS CATEGORIZATION:")
    print(f"High Relevance Results (3+ matching criteria): {len(high_relevance_results)}")
    print(f"Uganda-Specific Results: {len(uganda_specific_results)}")
    print(f"Both Viruses Mentioned: {len(both_viruses_results)}")
    print(f"Methodology/Testing Focus: {len(methodology_results)}")
    print(f"Academic Sources: {len(academic_sources)}")
    print(f"PDF Sources: {len(pdf_sources)}")
    print(f"EC Number Specific Results: {len(ec_number_results)}")
    
    if high_relevance_results:
        print(f"\nüéØ TOP HIGH-RELEVANCE RESULTS:")
        for i, result in enumerate(high_relevance_results[:5], 1):
            print(f"\n  {i}. {result['title']}")
            print(f"     URL: {result['link']}")
            print(f"     Relevance Score: {result['relevance_score']}/5")
            print(f"     Query: {result['query']}")
            print(f"     Snippet: {result['snippet'][:200]}...")
    
    if both_viruses_results:
        print(f"\nü¶† RESULTS MENTIONING BOTH SPFMV AND SPCSV:")
        for i, result in enumerate(both_viruses_results[:3], 1):
            print(f"\n  {i}. {result['title']}")
            print(f"     URL: {result['link']}")
            print(f"     Snippet: {result['snippet'][:150]}...")
    
    if academic_sources:
        print(f"\nüìö ACADEMIC/RESEARCH SOURCES:")
        for i, result in enumerate(academic_sources[:5], 1):
            print(f"\n  {i}. {result['title']}")
            print(f"     URL: {result['link']}")
            print(f"     Snippet: {result['snippet'][:150]}...")
    
    if ec_number_results:
        print(f"\nüß™ EC NUMBER SPECIFIC RESULTS:")
        for i, result in enumerate(ec_number_results[:5], 1):
            print(f"\n  {i}. {result['title']}")
            print(f"     URL: {result['link']}")
            print(f"     Snippet: {result['snippet'][:150]}...")
    
    print(f"\nüìã SEARCH STATUS SUMMARY:")
    if high_relevance_results:
        print("‚úÖ HIGH-RELEVANCE RESULTS FOUND")
        print("   - Multiple results matching 3+ key criteria")
        print("   - Ready for detailed content analysis")
    elif uganda_specific_results or both_viruses_results:
        print("‚ö†Ô∏è PARTIAL MATCHES FOUND")
        print("   - Some relevant results identified")
        print("   - May require broader search or alternative keywords")
    else:
        print("‚ùå LIMITED RELEVANT RESULTS")
        print("   - Few matching results found")
        print("   - May need different search strategy")
    
    # Key findings summary
    print(f"\nüîç KEY FINDINGS FROM SEARCH:")
    
    # Check for the specific Wiley paper mentioned in the tester feedback
    wiley_paper_found = any('wiley.com' in result.get('link', '') and 'jph.12451' in result.get('link', '') 
                           for query_result in all_search_results 
                           for result in query_result['results'])
    
    # Check for Hugging Face dataset with EC numbers
    huggingface_found = any('huggingface.co' in result.get('link', '') and '1.11.1.7' in result.get('snippet', '') 
                           for query_result in all_search_results 
                           for result in query_result['results'])
    
    if wiley_paper_found:
        print("‚úÖ Wiley paper 'Effects of Sweet Potato Feathery Mottle Virus...' identified")
    
    if huggingface_found:
        print("‚úÖ Hugging Face dataset with specific EC numbers (1.11.1.7, 3.1.3.1) found")
    
    print(f"\nDetailed search data saved to: {results_file}")
    print("Search completed successfully with corrected variable scoping.")
    print("Ready for next phase: detailed analysis of identified papers and content extraction.")
```

## Created Time
2025-08-10 22:38:54
